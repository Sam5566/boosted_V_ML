{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import sys\n",
    "os.chdir('/home/samhuang/ML/')\n",
    "sys.path.insert(0, '/home/samhuang/ML')\n",
    "sys.path.insert(0, '/home/samhuang/ML/sample')\n",
    "#sys.path.insert(0, '/home/samhuang/../public/Polar_new/samples')\n",
    "from readTFR import *\n",
    "from matplotlib import pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib as mpl\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import models\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from train_utils import *\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "\n",
    "#physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "#print (physical_gpus)\n",
    "#tf.config.experimental.set_memory_growth(physical_gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################  input and variables  #######################\n",
    "# Data / training parameters.\n",
    "train_epochs = 500\n",
    "batch_size = 512\n",
    "shuffle_size_tr = 1\n",
    "patience = 20\n",
    "min_delta = 0.\n",
    "learning_rate = 1e-4\n",
    "dim_image = [[75, 75], [[-0.8, 0.8], [-0.8, 0.8]]]\n",
    "save_model_name = 'best_model_ternary_CNN_kappa0.15/'\n",
    "\n",
    "# Input datasets\n",
    "#data_folder = \"sample/samples_kappa0.15/samples_kappa0.15/\"\n",
    "data_folder = \"sample/samples_kappa0.15/VBF_H5pp_ww_jjjj_and_VBF_H5mm_ww_jjjj_and_VBF_H5z_zz_jjjj/\"\n",
    "#data_folder = \"sample/samples_kappa0.15/VBF_H5pp_ww_jjjj_and_VBF_H5mm_ww_jjjj/\"\n",
    "#data_folder = \"/home/samhuang/../public/Polar_new/samples/\"\n",
    "#data_folder = \"samples/\"\n",
    "data_tr = data_folder+\"train.tfrecord\"\n",
    "data_vl = data_folder+\"valid.tfrecord\" \n",
    "data_te = data_folder+\"test.tfrecord\" \n",
    "\n",
    "\n",
    "#######################  plotting setup  ##########\n",
    "font = {'size'  : 14} \n",
    "fontsize=18\n",
    "fontsize2=16\n",
    "legendsize=16\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "plt.rcParams[\"ytick.direction\"]=\"in\"\n",
    "plt.rcParams['ytick.right'] = True\n",
    "plt.rcParams['xtick.top'] = True\n",
    "plt.rcParams[\"xtick.major.size\"] = 6 \n",
    "plt.rcParams['xtick.major.width'] = 1.5 \n",
    "plt.rcParams[\"ytick.major.size\"] = 6 \n",
    "plt.rcParams['ytick.major.width'] = 1.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 16:33:15.293315: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-07 16:33:15.301798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2022-09-07 16:33:15.307111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-09-07 16:33:15.307205: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-09-07 16:33:16.219335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-09-07 16:33:16.219381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-09-07 16:33:16.219391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-09-07 16:33:16.226470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 46729 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:3b:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set contains images\n",
      "The data set contains images\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "dataset_tr, tr_total = get_dataset(data_tr, repeat=False, \n",
    "                                   batch_size=batch_size, \n",
    "                                   dim_image=dim_image+[True], \n",
    "                                   shuffle=shuffle_size_tr)\n",
    "dataset_vl, vl_total = get_dataset(data_vl, repeat=False, \n",
    "                                   batch_size=batch_size, \n",
    "                                   dim_image=dim_image+[True], \n",
    "                                   shuffle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.45640, saving model to best_model_ternary_CNN_kappa0.15/\n",
      "INFO:tensorflow:Assets written to: best_model_ternary_CNN_kappa0.15/assets\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.45640 to 1.12564, saving model to best_model_ternary_CNN_kappa0.15/\n",
      "INFO:tensorflow:Assets written to: best_model_ternary_CNN_kappa0.15/assets\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.12564 to 0.83357, saving model to best_model_ternary_CNN_kappa0.15/\n",
      "INFO:tensorflow:Assets written to: best_model_ternary_CNN_kappa0.15/assets\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.83357 to 0.75707, saving model to best_model_ternary_CNN_kappa0.15/\n",
      "INFO:tensorflow:Assets written to: best_model_ternary_CNN_kappa0.15/assets\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.75707 to 0.73383, saving model to best_model_ternary_CNN_kappa0.15/\n",
      "INFO:tensorflow:Assets written to: best_model_ternary_CNN_kappa0.15/assets\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.73383 to 0.72721, saving model to best_model_ternary_CNN_kappa0.15/\n",
      "INFO:tensorflow:Assets written to: best_model_ternary_CNN_kappa0.15/assets\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.72721 to 0.72676, saving model to best_model_ternary_CNN_kappa0.15/\n",
      "INFO:tensorflow:Assets written to: best_model_ternary_CNN_kappa0.15/assets\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.72676 to 0.72060, saving model to best_model_ternary_CNN_kappa0.15/\n",
      "INFO:tensorflow:Assets written to: best_model_ternary_CNN_kappa0.15/assets\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.72060 to 0.71640, saving model to best_model_ternary_CNN_kappa0.15/\n",
      "INFO:tensorflow:Assets written to: best_model_ternary_CNN_kappa0.15/assets\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.71640\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.71640\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.71640 to 0.71290, saving model to best_model_ternary_CNN_kappa0.15/\n",
      "INFO:tensorflow:Assets written to: best_model_ternary_CNN_kappa0.15/assets\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.71290\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.71290\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.71290\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.71290 to 0.71279, saving model to best_model_ternary_CNN_kappa0.15/\n",
      "INFO:tensorflow:Assets written to: best_model_ternary_CNN_kappa0.15/assets\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.71279\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.71279\n",
      "Epoch 00036: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Create the model  \n",
    "model = models.CNN_ternary(dim_image=dim_image[0] + [2])\n",
    "#print(model.summary())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=min_delta, verbose=1, patience=patience)\n",
    "check_point    = tf.keras.callbacks.ModelCheckpoint(save_model_name, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "history = model.fit(dataset_tr, validation_data=dataset_vl , epochs=train_epochs, batch_size=batch_size, callbacks=[early_stopping, check_point], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\u001b[92mModel: \"CNN_ternary\"\u001b[0m\n",
      "\u001b[92m_________________________________________________________________\u001b[0m\n",
      "\u001b[92mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[92m=================================================================\u001b[0m\n",
      "\u001b[92msequential_3 (Sequential)    (None, 512)               12127912  \u001b[0m\n",
      "\u001b[92m_________________________________________________________________\u001b[0m\n",
      "\u001b[92mdense_11 (Dense)             multiple                  1539      \u001b[0m\n",
      "\u001b[92m=================================================================\u001b[0m\n",
      "\u001b[92mTotal params: 12,129,451\u001b[0m\n",
      "\u001b[92mTrainable params: 12,129,447\u001b[0m\n",
      "\u001b[92mNon-trainable params: 4\u001b[0m\n",
      "\u001b[92m_________________________________________________________________\u001b[0m\n",
      "None\n",
      "\n",
      "@LAYER1       @@@@@@@@@@@@@@@@@@@@@@\n",
      "\u001b[94mModel: \"sequential_3\"\u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[94m=================================================================\u001b[0m\n",
      "\u001b[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mflatten_3 (Flatten)          (None, 20736)             0         \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mdense_9 (Dense)              (None, 512)               10617344  \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mdropout_10 (Dropout)         (None, 512)               0         \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mdense_10 (Dense)             (None, 512)               262656    \u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "\u001b[94mdropout_11 (Dropout)         (None, 512)               0         \u001b[0m\n",
      "\u001b[94m=================================================================\u001b[0m\n",
      "\u001b[94mTotal params: 12,127,912\u001b[0m\n",
      "\u001b[94mTrainable params: 12,127,908\u001b[0m\n",
      "\u001b[94mNon-trainable params: 4\u001b[0m\n",
      "\u001b[94m_________________________________________________________________\u001b[0m\n",
      "None\n",
      "\u001b[92m%Optimizer:\n",
      "\u001b[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\u001b[92m%Layer detail:\n",
      "\u001b[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPobL2hvbWUvc2FtaHVhbmcvTUwvbW9kZWxzLnB52gg8\\nbGFtYmRhPq4AAADzAAAAAA==\\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}\n",
      "\n",
      "@LAYER2       @@@@@@@@@@@@@@@@@@@@@@\n",
      "\u001b[92m%Layer detail:\n",
      "\u001b[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "\n",
      "****************************************************\n",
      "history keys:\n",
      " dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
      "history params:\n",
      " {'verbose': 0, 'epochs': 500, 'steps': None}\n",
      "****************************************************\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n"
     ]
    }
   ],
   "source": [
    "from print_and_draw import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print_layer_and_params(model, history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (history.history.keys())\n",
    "print (history.params)\n",
    "#model.save(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Plot results curves.\n",
    "fig = plt.figure(1, figsize=(10, 14))\n",
    "fig.clf()\n",
    "x = range(len(history.history['loss']))\n",
    "# Loss.\n",
    "y_tr = history.history['loss']\n",
    "y_vl = history.history['val_loss']\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.plot(x, y_tr, \"b\", label=\"Training\")\n",
    "ax.plot(x, y_vl, \"b--\", label=\"Validation\")\n",
    "ax.set_title(\"Loss across training\")\n",
    "ax.set_xlabel(\"Training iteration\")\n",
    "ax.set_ylabel(\"Loss (categorical cross-entropy)\")\n",
    "ax.legend()\n",
    "# Accuracy.\n",
    "y_tr = history.history['accuracy']\n",
    "y_vl = history.history['val_accuracy']\n",
    "ax = fig.add_subplot(2, 1, 2)\n",
    "ax.plot(x, y_tr, \"b\", label=\"Training\")\n",
    "ax.plot(x, y_vl, \"b--\", label=\"Test\")\n",
    "ax.set_title(\"Accuracy across training\")\n",
    "ax.set_xlabel(\"Training iteration\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(save_model_name)\n",
    "\n",
    "dataset_te, te_total  = get_dataset(data_te, repeat=False, \n",
    "                                    batch_size=1, \n",
    "                                    dim_image=dim_image+[True], \n",
    "                                    shuffle=0)\n",
    "\n",
    "results = loaded_model.evaluate(dataset_te)\n",
    "print(\"Testing Loss = {0:f}, Testing Accuracy = {1:f}\".format(results[0], results[1]))\n",
    "\n",
    "labels = [x[1][0].tolist() for x in dataset_te.as_numpy_iterator()]\n",
    "\n",
    "dataset_te, te_total  = get_dataset(data_te, repeat=False, \n",
    "                                    batch_size=1, \n",
    "                                    dim_image=dim_image+[False], \n",
    "                                    shuffle=0)\n",
    "\n",
    "predictions = loaded_model.predict(dataset_te).tolist()\n",
    "\n",
    "data = {'test_scores': predictions, 'test_labels': labels}\n",
    "\n",
    "print (predictions[:10])\n",
    "print (labels[:10])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(labels, predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_name = 'best_model_CNN_1/best'\n",
    "loaded_model = tf.keras.models.load_model(save_model_name)\n",
    "\n",
    "dim_image = [[75, 75], [[-0.8, 0.8], [-0.8, 0.8]]]\n",
    "data_te = \"sample/test.tfrecord\"\n",
    "dataset_te, te_total  = get_dataset(data_te, repeat=False, \n",
    "                                    batch_size=1, \n",
    "                                    dim_image=dim_image+[True], \n",
    "                                    shuffle=0)\n",
    "\n",
    "results = loaded_model.evaluate(dataset_te)\n",
    "print(\"Testing Loss = {0:f}, Testing Accuracy = {1:f}\".format(results[0], results[1]))\n",
    "\n",
    "labels = [x[1][0].tolist() for x in dataset_te.as_numpy_iterator()]\n",
    "\n",
    "dataset_te, te_total  = get_dataset(data_te, repeat=False, \n",
    "                                    batch_size=1, \n",
    "                                    dim_image=dim_image+[False], \n",
    "                                    shuffle=0)\n",
    "\n",
    "predictions = loaded_model.predict(dataset_te).tolist()\n",
    "\n",
    "data = {'test_scores': predictions, 'test_labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#predictions = loaded_model.predict(dataset_te)\n",
    "#print ([x for x in dataset_te][0])\n",
    "#labels = np.concatenate([y for x, y in dataset_te], axis=0)\n",
    "labels = np.array(labels)\n",
    "predictions = np.array(predictions)\n",
    "n_class = np.shape(labels)[1]\n",
    "print (n_class)\n",
    "\n",
    " \n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "for i in range(n_class):\n",
    "    fpr[i], tpr[i], _ = roc_curve(labels[:, i], predictions[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    " \n",
    "plt.figure(figsize=(8,6))\n",
    "signal=[r'$W^+$',r'$W^-$',r'$Z$']\n",
    "for i in range(n_class):\n",
    "    plt.plot(fpr[i], tpr[i], label='{0} (auc = {1:0.2f})'.format(signal[i], roc_auc[i]))\n",
    "            \n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='lower right', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['test_labels']\n",
    "scores = data['test_scores']\n",
    "\n",
    "labels_EW_LL, scores_EW_LL = [], []\n",
    "labels_EW_nonLL, scores_EW_nonLL  = [], []\n",
    "labels_QCD, scores_QCD  = [], []\n",
    "\n",
    "for idx in tqdm(range(len(labels))):\n",
    "    if labels[idx][0] > 0.5 or labels[idx][1] > 0.5:\n",
    "        labels_EW_LL.append([labels[idx][0], labels[idx][1]])\n",
    "        total_EW_LL = scores[idx][0] + scores[idx][1]\n",
    "        if int(scores[idx][2]) == 1:\n",
    "            scores_EW_LL.append([0.5, 0.5])\n",
    "        else:\n",
    "            scores_EW_LL.append([scores[idx][0]/total_EW_LL, scores[idx][1]/total_EW_LL])\n",
    "    if labels[idx][0] > 0.5 or labels[idx][2] > 0.5:\n",
    "        labels_EW_nonLL.append([labels[idx][0], labels[idx][2]])\n",
    "        total_EW_nonLL = scores[idx][0] + scores[idx][2]\n",
    "        if int(scores[idx][1]) == 1:\n",
    "            scores_EW_nonLL.append([0.5, 0.5])\n",
    "        else:\n",
    "            scores_EW_nonLL.append([scores[idx][0]/total_EW_nonLL, scores[idx][2]/total_EW_nonLL])\n",
    "    if labels[idx][1] > 0.5 or labels[idx][2] > 0.5:\n",
    "        labels_QCD.append([labels[idx][1], labels[idx][2]])\n",
    "        total_QCD = scores[idx][1] + scores[idx][2]\n",
    "        if int(scores[idx][0]) == 1:\n",
    "            scores_QCD.append([0.5, 0.5])\n",
    "        else:\n",
    "            scores_QCD.append([scores[idx][1]/total_QCD, scores[idx][2]/total_QCD])\n",
    "\n",
    "labels_EW_LL, scores_EW_LL = np.array(labels_EW_LL), np.array(scores_EW_LL)\n",
    "labels_EW_nonLL, scores_EW_nonLL = np.array(labels_EW_nonLL), np.array(scores_EW_nonLL)\n",
    "labels_QCD, scores_QCD = np.array(labels_QCD), np.array(scores_QCD)\n",
    "        \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(2):\n",
    "    fpr['EW_LL'], tpr['EW_LL'], _ = roc_curve(labels_EW_LL[:, i], scores_EW_LL[:, i])\n",
    "    roc_auc['EW_LL'] = auc(fpr['EW_LL'], tpr['EW_LL'])\n",
    "    \n",
    "    fpr['EW_nonLL'], tpr['EW_nonLL'], _ = roc_curve(labels_EW_nonLL[:, i], scores_EW_nonLL[:, i])\n",
    "    roc_auc['EW_nonLL'] = auc(fpr['EW_nonLL'], tpr['EW_nonLL'])\n",
    "    \n",
    "    fpr['QCD'], tpr['QCD'], _ = roc_curve(labels_QCD[:, i], scores_QCD[:, i])\n",
    "    roc_auc['QCD'] = auc(fpr['QCD'], tpr['QCD'])\n",
    "\n",
    "plt.figure(1, figsize=(8, 6))\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    fpr['EW_LL'],\n",
    "    tpr['EW_LL'],\n",
    "    color=\"red\",\n",
    "    lw=lw,\n",
    "    label=r\"ROC curve (area = %0.2f), EW, LL\" % roc_auc['EW_LL'],\n",
    ")\n",
    "plt.plot(\n",
    "    fpr['EW_nonLL'],\n",
    "    tpr['EW_nonLL'],\n",
    "    color=\"green\",\n",
    "    lw=lw,\n",
    "    label=r\"ROC curve (area = %0.2f), EW, non-LL\" % roc_auc['EW_nonLL'],\n",
    ")\n",
    "plt.plot(\n",
    "    fpr['QCD'],\n",
    "    tpr['QCD'],\n",
    "    color=\"blue\",\n",
    "    lw=lw,\n",
    "    label=r\"ROC curve (area = %0.2f), QCD\" % roc_auc['QCD'],\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"black\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Testing ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f73079b68cca470a01c16fb702ee20894d299af9d84ef28f8cf2cbe580dfc66e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
