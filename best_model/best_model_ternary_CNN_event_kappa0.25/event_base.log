

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-25 10:37:53.266811
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 33s 209ms/step - loss: 12.4823 - accuracy: 0.1983 - val_loss: 8.7662 - val_accuracy: 0.2155

Epoch 00001: val_loss improved from inf to 8.76621, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 2/100
83/83 [==============================] - 6s 70ms/step - loss: 6.8314 - accuracy: 0.2096 - val_loss: 5.3856 - val_accuracy: 0.2146

Epoch 00002: val_loss improved from 8.76621 to 5.38562, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.5826 - accuracy: 0.2301 - val_loss: 3.9528 - val_accuracy: 0.2549

Epoch 00003: val_loss improved from 5.38562 to 3.95277, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.4783 - accuracy: 0.2876 - val_loss: 3.1987 - val_accuracy: 0.2739

Epoch 00004: val_loss improved from 3.95277 to 3.19869, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 2.8890 - accuracy: 0.3029 - val_loss: 2.7096 - val_accuracy: 0.3052

Epoch 00005: val_loss improved from 3.19869 to 2.70956, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5044 - accuracy: 0.3113 - val_loss: 2.3707 - val_accuracy: 0.3228

Epoch 00006: val_loss improved from 2.70956 to 2.37072, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2365 - accuracy: 0.3186 - val_loss: 2.1328 - val_accuracy: 0.3323

Epoch 00007: val_loss improved from 2.37072 to 2.13283, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0463 - accuracy: 0.3278 - val_loss: 1.9663 - val_accuracy: 0.3398

Epoch 00008: val_loss improved from 2.13283 to 1.96635, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9129 - accuracy: 0.3343 - val_loss: 1.8548 - val_accuracy: 0.3450

Epoch 00009: val_loss improved from 1.96635 to 1.85484, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8185 - accuracy: 0.3406 - val_loss: 1.7709 - val_accuracy: 0.3523

Epoch 00010: val_loss improved from 1.85484 to 1.77092, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7491 - accuracy: 0.3508 - val_loss: 1.7151 - val_accuracy: 0.3538

Epoch 00011: val_loss improved from 1.77092 to 1.71510, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6997 - accuracy: 0.3518 - val_loss: 1.6718 - val_accuracy: 0.3602

Epoch 00012: val_loss improved from 1.71510 to 1.67180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6616 - accuracy: 0.3633 - val_loss: 1.6410 - val_accuracy: 0.3672

Epoch 00013: val_loss improved from 1.67180 to 1.64096, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6347 - accuracy: 0.3710 - val_loss: 1.6189 - val_accuracy: 0.3727

Epoch 00014: val_loss improved from 1.64096 to 1.61887, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6101 - accuracy: 0.3766 - val_loss: 1.6011 - val_accuracy: 0.3812

Epoch 00015: val_loss improved from 1.61887 to 1.60111, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5904 - accuracy: 0.3837 - val_loss: 1.5885 - val_accuracy: 0.3848

Epoch 00016: val_loss improved from 1.60111 to 1.58851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5798 - accuracy: 0.3892 - val_loss: 1.5823 - val_accuracy: 0.3866

Epoch 00017: val_loss improved from 1.58851 to 1.58229, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5635 - accuracy: 0.3980 - val_loss: 1.5735 - val_accuracy: 0.3915

Epoch 00018: val_loss improved from 1.58229 to 1.57352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5546 - accuracy: 0.3965 - val_loss: 1.5678 - val_accuracy: 0.3929

Epoch 00019: val_loss improved from 1.57352 to 1.56781, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5470 - accuracy: 0.4044 - val_loss: 1.5647 - val_accuracy: 0.3935

Epoch 00020: val_loss improved from 1.56781 to 1.56468, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5411 - accuracy: 0.4079 - val_loss: 1.5608 - val_accuracy: 0.3970

Epoch 00021: val_loss improved from 1.56468 to 1.56078, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5294 - accuracy: 0.4118 - val_loss: 1.5600 - val_accuracy: 0.3954

Epoch 00022: val_loss improved from 1.56078 to 1.56003, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5249 - accuracy: 0.4171 - val_loss: 1.5639 - val_accuracy: 0.3975

Epoch 00023: val_loss did not improve from 1.56003
Epoch 24/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5200 - accuracy: 0.4205 - val_loss: 1.5581 - val_accuracy: 0.3968

Epoch 00024: val_loss improved from 1.56003 to 1.55809, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/0
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5137 - accuracy: 0.4251 - val_loss: 1.5596 - val_accuracy: 0.3986

Epoch 00025: val_loss did not improve from 1.55809
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5043 - accuracy: 0.4318 - val_loss: 1.5610 - val_accuracy: 0.3978

Epoch 00026: val_loss did not improve from 1.55809
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5011 - accuracy: 0.4338 - val_loss: 1.5646 - val_accuracy: 0.3974

Epoch 00027: val_loss did not improve from 1.55809
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4973 - accuracy: 0.4358 - val_loss: 1.5650 - val_accuracy: 0.3991

Epoch 00028: val_loss did not improve from 1.55809
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4890 - accuracy: 0.4405 - val_loss: 1.5679 - val_accuracy: 0.4000

Epoch 00029: val_loss did not improve from 1.55809
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4848 - accuracy: 0.4463 - val_loss: 1.5694 - val_accuracy: 0.4012

Epoch 00030: val_loss did not improve from 1.55809
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4757 - accuracy: 0.4508 - val_loss: 1.5741 - val_accuracy: 0.3986

Epoch 00031: val_loss did not improve from 1.55809
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4679 - accuracy: 0.4592 - val_loss: 1.5811 - val_accuracy: 0.4002

Epoch 00032: val_loss did not improve from 1.55809
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4639 - accuracy: 0.4639 - val_loss: 1.5841 - val_accuracy: 0.3985

Epoch 00033: val_loss did not improve from 1.55809
Epoch 34/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4506 - accuracy: 0.4704 - val_loss: 1.5935 - val_accuracy: 0.3957

Epoch 00034: val_loss did not improve from 1.55809
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5685 - accuracy: 0.3925
Testing Loss = 1.568454, Testing Accuracy = 0.392453
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.4085 - accuracy: 0.1989 - val_loss: 8.6782 - val_accuracy: 0.2146

Epoch 00001: val_loss improved from inf to 8.67817, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 2/100
83/83 [==============================] - 6s 69ms/step - loss: 6.7634 - accuracy: 0.2081 - val_loss: 5.3391 - val_accuracy: 0.2152

Epoch 00002: val_loss improved from 8.67817 to 5.33911, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.5228 - accuracy: 0.2493 - val_loss: 3.9465 - val_accuracy: 0.2476

Epoch 00003: val_loss improved from 5.33911 to 3.94651, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.4749 - accuracy: 0.2889 - val_loss: 3.2032 - val_accuracy: 0.2657

Epoch 00004: val_loss improved from 3.94651 to 3.20321, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 2.8941 - accuracy: 0.3024 - val_loss: 2.7210 - val_accuracy: 0.2985

Epoch 00005: val_loss improved from 3.20321 to 2.72095, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.5133 - accuracy: 0.3098 - val_loss: 2.3820 - val_accuracy: 0.3157

Epoch 00006: val_loss improved from 2.72095 to 2.38195, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2446 - accuracy: 0.3208 - val_loss: 2.1409 - val_accuracy: 0.3333

Epoch 00007: val_loss improved from 2.38195 to 2.14093, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0581 - accuracy: 0.3256 - val_loss: 1.9755 - val_accuracy: 0.3380

Epoch 00008: val_loss improved from 2.14093 to 1.97554, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9217 - accuracy: 0.3322 - val_loss: 1.8597 - val_accuracy: 0.3411

Epoch 00009: val_loss improved from 1.97554 to 1.85968, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8226 - accuracy: 0.3414 - val_loss: 1.7754 - val_accuracy: 0.3540

Epoch 00010: val_loss improved from 1.85968 to 1.77544, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 11/100
83/83 [==============================] - 6s 70ms/step - loss: 1.7545 - accuracy: 0.3486 - val_loss: 1.7187 - val_accuracy: 0.3577

Epoch 00011: val_loss improved from 1.77544 to 1.71870, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7027 - accuracy: 0.3565 - val_loss: 1.6715 - val_accuracy: 0.3698

Epoch 00012: val_loss improved from 1.71870 to 1.67153, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 13/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6623 - accuracy: 0.3692 - val_loss: 1.6415 - val_accuracy: 0.3750

Epoch 00013: val_loss improved from 1.67153 to 1.64154, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6308 - accuracy: 0.3755 - val_loss: 1.6164 - val_accuracy: 0.3814

Epoch 00014: val_loss improved from 1.64154 to 1.61636, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6072 - accuracy: 0.3844 - val_loss: 1.5986 - val_accuracy: 0.3878

Epoch 00015: val_loss improved from 1.61636 to 1.59857, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5892 - accuracy: 0.3890 - val_loss: 1.5877 - val_accuracy: 0.3925

Epoch 00016: val_loss improved from 1.59857 to 1.58766, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5769 - accuracy: 0.3924 - val_loss: 1.5791 - val_accuracy: 0.3966

Epoch 00017: val_loss improved from 1.58766 to 1.57912, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5619 - accuracy: 0.3998 - val_loss: 1.5717 - val_accuracy: 0.3915

Epoch 00018: val_loss improved from 1.57912 to 1.57174, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5515 - accuracy: 0.4030 - val_loss: 1.5666 - val_accuracy: 0.3963

Epoch 00019: val_loss improved from 1.57174 to 1.56662, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5422 - accuracy: 0.4103 - val_loss: 1.5658 - val_accuracy: 0.3988

Epoch 00020: val_loss improved from 1.56662 to 1.56584, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5342 - accuracy: 0.4146 - val_loss: 1.5601 - val_accuracy: 0.4021

Epoch 00021: val_loss improved from 1.56584 to 1.56012, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5283 - accuracy: 0.4140 - val_loss: 1.5602 - val_accuracy: 0.4025

Epoch 00022: val_loss did not improve from 1.56012
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5199 - accuracy: 0.4208 - val_loss: 1.5586 - val_accuracy: 0.4034

Epoch 00023: val_loss improved from 1.56012 to 1.55861, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/1
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5135 - accuracy: 0.4256 - val_loss: 1.5596 - val_accuracy: 0.4010

Epoch 00024: val_loss did not improve from 1.55861
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5056 - accuracy: 0.4321 - val_loss: 1.5602 - val_accuracy: 0.4040

Epoch 00025: val_loss did not improve from 1.55861
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4988 - accuracy: 0.4379 - val_loss: 1.5632 - val_accuracy: 0.4010

Epoch 00026: val_loss did not improve from 1.55861
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4916 - accuracy: 0.4408 - val_loss: 1.5639 - val_accuracy: 0.4007

Epoch 00027: val_loss did not improve from 1.55861
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4897 - accuracy: 0.4430 - val_loss: 1.5703 - val_accuracy: 0.4014

Epoch 00028: val_loss did not improve from 1.55861
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4796 - accuracy: 0.4509 - val_loss: 1.5738 - val_accuracy: 0.4011

Epoch 00029: val_loss did not improve from 1.55861
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4716 - accuracy: 0.4526 - val_loss: 1.5803 - val_accuracy: 0.4020

Epoch 00030: val_loss did not improve from 1.55861
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4638 - accuracy: 0.4612 - val_loss: 1.5870 - val_accuracy: 0.4000

Epoch 00031: val_loss did not improve from 1.55861
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4578 - accuracy: 0.4642 - val_loss: 1.5897 - val_accuracy: 0.4007

Epoch 00032: val_loss did not improve from 1.55861
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4490 - accuracy: 0.4733 - val_loss: 1.5998 - val_accuracy: 0.3976

Epoch 00033: val_loss did not improve from 1.55861
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.5686 - accuracy: 0.3962
Testing Loss = 1.568643, Testing Accuracy = 0.396174
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.3790 - accuracy: 0.1993 - val_loss: 8.6365 - val_accuracy: 0.2128

Epoch 00001: val_loss improved from inf to 8.63654, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7253 - accuracy: 0.2082 - val_loss: 5.3085 - val_accuracy: 0.2158

Epoch 00002: val_loss improved from 8.63654 to 5.30854, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5181 - accuracy: 0.2361 - val_loss: 3.9245 - val_accuracy: 0.2419

Epoch 00003: val_loss improved from 5.30854 to 3.92450, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.4547 - accuracy: 0.2876 - val_loss: 3.1845 - val_accuracy: 0.2744

Epoch 00004: val_loss improved from 3.92450 to 3.18449, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8761 - accuracy: 0.3016 - val_loss: 2.7067 - val_accuracy: 0.2954

Epoch 00005: val_loss improved from 3.18449 to 2.70669, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.4995 - accuracy: 0.3114 - val_loss: 2.3733 - val_accuracy: 0.3187

Epoch 00006: val_loss improved from 2.70669 to 2.37332, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2327 - accuracy: 0.3158 - val_loss: 2.1349 - val_accuracy: 0.3308

Epoch 00007: val_loss improved from 2.37332 to 2.13490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0493 - accuracy: 0.3226 - val_loss: 1.9698 - val_accuracy: 0.3385

Epoch 00008: val_loss improved from 2.13490 to 1.96975, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9145 - accuracy: 0.3284 - val_loss: 1.8570 - val_accuracy: 0.3387

Epoch 00009: val_loss improved from 1.96975 to 1.85703, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8186 - accuracy: 0.3396 - val_loss: 1.7757 - val_accuracy: 0.3473

Epoch 00010: val_loss improved from 1.85703 to 1.77567, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7548 - accuracy: 0.3434 - val_loss: 1.7224 - val_accuracy: 0.3499

Epoch 00011: val_loss improved from 1.77567 to 1.72244, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 12/100
83/83 [==============================] - 6s 70ms/step - loss: 1.7022 - accuracy: 0.3518 - val_loss: 1.6777 - val_accuracy: 0.3614

Epoch 00012: val_loss improved from 1.72244 to 1.67768, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6663 - accuracy: 0.3608 - val_loss: 1.6473 - val_accuracy: 0.3671

Epoch 00013: val_loss improved from 1.67768 to 1.64729, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6381 - accuracy: 0.3646 - val_loss: 1.6218 - val_accuracy: 0.3745

Epoch 00014: val_loss improved from 1.64729 to 1.62184, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6145 - accuracy: 0.3732 - val_loss: 1.6042 - val_accuracy: 0.3812

Epoch 00015: val_loss improved from 1.62184 to 1.60418, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5959 - accuracy: 0.3796 - val_loss: 1.5902 - val_accuracy: 0.3863

Epoch 00016: val_loss improved from 1.60418 to 1.59023, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5808 - accuracy: 0.3870 - val_loss: 1.5802 - val_accuracy: 0.3915

Epoch 00017: val_loss improved from 1.59023 to 1.58021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5699 - accuracy: 0.3897 - val_loss: 1.5750 - val_accuracy: 0.3928

Epoch 00018: val_loss improved from 1.58021 to 1.57505, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5578 - accuracy: 0.3985 - val_loss: 1.5678 - val_accuracy: 0.3944

Epoch 00019: val_loss improved from 1.57505 to 1.56784, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5467 - accuracy: 0.4051 - val_loss: 1.5646 - val_accuracy: 0.3943

Epoch 00020: val_loss improved from 1.56784 to 1.56463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5423 - accuracy: 0.4063 - val_loss: 1.5640 - val_accuracy: 0.3920

Epoch 00021: val_loss improved from 1.56463 to 1.56398, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5371 - accuracy: 0.4082 - val_loss: 1.5599 - val_accuracy: 0.3945

Epoch 00022: val_loss improved from 1.56398 to 1.55988, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5304 - accuracy: 0.4112 - val_loss: 1.5642 - val_accuracy: 0.3936

Epoch 00023: val_loss did not improve from 1.55988
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5208 - accuracy: 0.4173 - val_loss: 1.5590 - val_accuracy: 0.3979

Epoch 00024: val_loss improved from 1.55988 to 1.55904, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5170 - accuracy: 0.4202 - val_loss: 1.5584 - val_accuracy: 0.3946

Epoch 00025: val_loss improved from 1.55904 to 1.55837, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5110 - accuracy: 0.4230 - val_loss: 1.5580 - val_accuracy: 0.3979

Epoch 00026: val_loss improved from 1.55837 to 1.55797, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/2
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5058 - accuracy: 0.4281 - val_loss: 1.5618 - val_accuracy: 0.3960

Epoch 00027: val_loss did not improve from 1.55797
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4960 - accuracy: 0.4351 - val_loss: 1.5656 - val_accuracy: 0.3955

Epoch 00028: val_loss did not improve from 1.55797
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4911 - accuracy: 0.4408 - val_loss: 1.5710 - val_accuracy: 0.3954

Epoch 00029: val_loss did not improve from 1.55797
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4848 - accuracy: 0.4433 - val_loss: 1.5688 - val_accuracy: 0.3982

Epoch 00030: val_loss did not improve from 1.55797
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4788 - accuracy: 0.4479 - val_loss: 1.5714 - val_accuracy: 0.3973

Epoch 00031: val_loss did not improve from 1.55797
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4705 - accuracy: 0.4536 - val_loss: 1.5755 - val_accuracy: 0.3979

Epoch 00032: val_loss did not improve from 1.55797
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4623 - accuracy: 0.4600 - val_loss: 1.5796 - val_accuracy: 0.4008

Epoch 00033: val_loss did not improve from 1.55797
Epoch 34/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4625 - accuracy: 0.4601 - val_loss: 1.5885 - val_accuracy: 0.3988

Epoch 00034: val_loss did not improve from 1.55797
Epoch 35/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4539 - accuracy: 0.4693 - val_loss: 1.5991 - val_accuracy: 0.3968

Epoch 00035: val_loss did not improve from 1.55797
Epoch 36/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4466 - accuracy: 0.4732 - val_loss: 1.5983 - val_accuracy: 0.3952

Epoch 00036: val_loss did not improve from 1.55797
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5654 - accuracy: 0.3970
Testing Loss = 1.565372, Testing Accuracy = 0.396993
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4570 - accuracy: 0.1982 - val_loss: 8.7242 - val_accuracy: 0.2131

Epoch 00001: val_loss improved from inf to 8.72421, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 2/100
83/83 [==============================] - 6s 69ms/step - loss: 6.8021 - accuracy: 0.2091 - val_loss: 5.3719 - val_accuracy: 0.2124

Epoch 00002: val_loss improved from 8.72421 to 5.37187, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.5631 - accuracy: 0.2385 - val_loss: 3.9767 - val_accuracy: 0.2353

Epoch 00003: val_loss improved from 5.37187 to 3.97674, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.4891 - accuracy: 0.2889 - val_loss: 3.2160 - val_accuracy: 0.2610

Epoch 00004: val_loss improved from 3.97674 to 3.21598, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9025 - accuracy: 0.2986 - val_loss: 2.7259 - val_accuracy: 0.2955

Epoch 00005: val_loss improved from 3.21598 to 2.72589, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5175 - accuracy: 0.3065 - val_loss: 2.3861 - val_accuracy: 0.3147

Epoch 00006: val_loss improved from 2.72589 to 2.38614, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 7/100
83/83 [==============================] - 6s 70ms/step - loss: 2.2495 - accuracy: 0.3172 - val_loss: 2.1467 - val_accuracy: 0.3268

Epoch 00007: val_loss improved from 2.38614 to 2.14672, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0573 - accuracy: 0.3270 - val_loss: 1.9782 - val_accuracy: 0.3345

Epoch 00008: val_loss improved from 2.14672 to 1.97822, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9251 - accuracy: 0.3307 - val_loss: 1.8640 - val_accuracy: 0.3426

Epoch 00009: val_loss improved from 1.97822 to 1.86403, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8270 - accuracy: 0.3405 - val_loss: 1.7813 - val_accuracy: 0.3479

Epoch 00010: val_loss improved from 1.86403 to 1.78128, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7573 - accuracy: 0.3468 - val_loss: 1.7201 - val_accuracy: 0.3568

Epoch 00011: val_loss improved from 1.78128 to 1.72014, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7081 - accuracy: 0.3560 - val_loss: 1.6825 - val_accuracy: 0.3570

Epoch 00012: val_loss improved from 1.72014 to 1.68248, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6672 - accuracy: 0.3625 - val_loss: 1.6474 - val_accuracy: 0.3669

Epoch 00013: val_loss improved from 1.68248 to 1.64735, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6372 - accuracy: 0.3708 - val_loss: 1.6241 - val_accuracy: 0.3775

Epoch 00014: val_loss improved from 1.64735 to 1.62412, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6138 - accuracy: 0.3814 - val_loss: 1.6049 - val_accuracy: 0.3837

Epoch 00015: val_loss improved from 1.62412 to 1.60494, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5946 - accuracy: 0.3833 - val_loss: 1.5924 - val_accuracy: 0.3854

Epoch 00016: val_loss improved from 1.60494 to 1.59243, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 17/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5800 - accuracy: 0.3897 - val_loss: 1.5854 - val_accuracy: 0.3898

Epoch 00017: val_loss improved from 1.59243 to 1.58540, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5672 - accuracy: 0.3941 - val_loss: 1.5767 - val_accuracy: 0.3907

Epoch 00018: val_loss improved from 1.58540 to 1.57675, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5563 - accuracy: 0.4004 - val_loss: 1.5737 - val_accuracy: 0.3957

Epoch 00019: val_loss improved from 1.57675 to 1.57373, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5497 - accuracy: 0.4058 - val_loss: 1.5713 - val_accuracy: 0.3920

Epoch 00020: val_loss improved from 1.57373 to 1.57131, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 21/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5419 - accuracy: 0.4087 - val_loss: 1.5709 - val_accuracy: 0.3921

Epoch 00021: val_loss improved from 1.57131 to 1.57086, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5345 - accuracy: 0.4154 - val_loss: 1.5655 - val_accuracy: 0.3924

Epoch 00022: val_loss improved from 1.57086 to 1.56551, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5273 - accuracy: 0.4180 - val_loss: 1.5656 - val_accuracy: 0.3961

Epoch 00023: val_loss did not improve from 1.56551
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5205 - accuracy: 0.4223 - val_loss: 1.5635 - val_accuracy: 0.3938

Epoch 00024: val_loss improved from 1.56551 to 1.56352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/3
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5119 - accuracy: 0.4286 - val_loss: 1.5692 - val_accuracy: 0.3974

Epoch 00025: val_loss did not improve from 1.56352
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5054 - accuracy: 0.4322 - val_loss: 1.5693 - val_accuracy: 0.3993

Epoch 00026: val_loss did not improve from 1.56352
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5020 - accuracy: 0.4339 - val_loss: 1.5692 - val_accuracy: 0.4003

Epoch 00027: val_loss did not improve from 1.56352
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4919 - accuracy: 0.4418 - val_loss: 1.5739 - val_accuracy: 0.4017

Epoch 00028: val_loss did not improve from 1.56352
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4857 - accuracy: 0.4459 - val_loss: 1.5820 - val_accuracy: 0.3994

Epoch 00029: val_loss did not improve from 1.56352
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4777 - accuracy: 0.4525 - val_loss: 1.5859 - val_accuracy: 0.4030

Epoch 00030: val_loss did not improve from 1.56352
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4700 - accuracy: 0.4589 - val_loss: 1.5885 - val_accuracy: 0.3969

Epoch 00031: val_loss did not improve from 1.56352
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4615 - accuracy: 0.4651 - val_loss: 1.5980 - val_accuracy: 0.3998

Epoch 00032: val_loss did not improve from 1.56352
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4593 - accuracy: 0.4696 - val_loss: 1.6048 - val_accuracy: 0.3972

Epoch 00033: val_loss did not improve from 1.56352
Epoch 34/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4457 - accuracy: 0.4772 - val_loss: 1.6155 - val_accuracy: 0.3959

Epoch 00034: val_loss did not improve from 1.56352
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.5732 - accuracy: 0.3904
Testing Loss = 1.573169, Testing Accuracy = 0.390444
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4801 - accuracy: 0.1973 - val_loss: 8.7508 - val_accuracy: 0.2139

Epoch 00001: val_loss improved from inf to 8.75082, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8110 - accuracy: 0.2071 - val_loss: 5.3665 - val_accuracy: 0.2141

Epoch 00002: val_loss improved from 8.75082 to 5.36649, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5921 - accuracy: 0.2144 - val_loss: 3.9749 - val_accuracy: 0.2167

Epoch 00003: val_loss improved from 5.36649 to 3.97486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5144 - accuracy: 0.2583 - val_loss: 3.1887 - val_accuracy: 0.2689

Epoch 00004: val_loss improved from 3.97486 to 3.18868, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8820 - accuracy: 0.2922 - val_loss: 2.6992 - val_accuracy: 0.2929

Epoch 00005: val_loss improved from 3.18868 to 2.69919, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 6/100
83/83 [==============================] - 6s 71ms/step - loss: 2.4948 - accuracy: 0.3064 - val_loss: 2.3614 - val_accuracy: 0.3170

Epoch 00006: val_loss improved from 2.69919 to 2.36137, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2296 - accuracy: 0.3107 - val_loss: 2.1268 - val_accuracy: 0.3297

Epoch 00007: val_loss improved from 2.36137 to 2.12676, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.0420 - accuracy: 0.3235 - val_loss: 1.9614 - val_accuracy: 0.3365

Epoch 00008: val_loss improved from 2.12676 to 1.96140, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9099 - accuracy: 0.3331 - val_loss: 1.8491 - val_accuracy: 0.3417

Epoch 00009: val_loss improved from 1.96140 to 1.84908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8187 - accuracy: 0.3350 - val_loss: 1.7708 - val_accuracy: 0.3465

Epoch 00010: val_loss improved from 1.84908 to 1.77083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7520 - accuracy: 0.3426 - val_loss: 1.7153 - val_accuracy: 0.3539

Epoch 00011: val_loss improved from 1.77083 to 1.71525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6979 - accuracy: 0.3558 - val_loss: 1.6732 - val_accuracy: 0.3598

Epoch 00012: val_loss improved from 1.71525 to 1.67315, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6636 - accuracy: 0.3591 - val_loss: 1.6424 - val_accuracy: 0.3631

Epoch 00013: val_loss improved from 1.67315 to 1.64235, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6339 - accuracy: 0.3689 - val_loss: 1.6182 - val_accuracy: 0.3720

Epoch 00014: val_loss improved from 1.64235 to 1.61818, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6095 - accuracy: 0.3755 - val_loss: 1.6062 - val_accuracy: 0.3781

Epoch 00015: val_loss improved from 1.61818 to 1.60621, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5919 - accuracy: 0.3834 - val_loss: 1.5922 - val_accuracy: 0.3785

Epoch 00016: val_loss improved from 1.60621 to 1.59223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5800 - accuracy: 0.3865 - val_loss: 1.5863 - val_accuracy: 0.3865

Epoch 00017: val_loss improved from 1.59223 to 1.58635, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5646 - accuracy: 0.3952 - val_loss: 1.5731 - val_accuracy: 0.3886

Epoch 00018: val_loss improved from 1.58635 to 1.57312, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5556 - accuracy: 0.3983 - val_loss: 1.5738 - val_accuracy: 0.3938

Epoch 00019: val_loss did not improve from 1.57312
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5464 - accuracy: 0.3996 - val_loss: 1.5736 - val_accuracy: 0.3901

Epoch 00020: val_loss did not improve from 1.57312
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5373 - accuracy: 0.4099 - val_loss: 1.5632 - val_accuracy: 0.3970

Epoch 00021: val_loss improved from 1.57312 to 1.56324, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5294 - accuracy: 0.4124 - val_loss: 1.5618 - val_accuracy: 0.3964

Epoch 00022: val_loss improved from 1.56324 to 1.56177, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/4
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5222 - accuracy: 0.4168 - val_loss: 1.5626 - val_accuracy: 0.3960

Epoch 00023: val_loss did not improve from 1.56177
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5202 - accuracy: 0.4209 - val_loss: 1.5644 - val_accuracy: 0.3942

Epoch 00024: val_loss did not improve from 1.56177
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5127 - accuracy: 0.4232 - val_loss: 1.5682 - val_accuracy: 0.3957

Epoch 00025: val_loss did not improve from 1.56177
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5021 - accuracy: 0.4322 - val_loss: 1.5632 - val_accuracy: 0.3994

Epoch 00026: val_loss did not improve from 1.56177
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4957 - accuracy: 0.4348 - val_loss: 1.5655 - val_accuracy: 0.3998

Epoch 00027: val_loss did not improve from 1.56177
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4917 - accuracy: 0.4386 - val_loss: 1.5744 - val_accuracy: 0.3966

Epoch 00028: val_loss did not improve from 1.56177
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4901 - accuracy: 0.4427 - val_loss: 1.5695 - val_accuracy: 0.3988

Epoch 00029: val_loss did not improve from 1.56177
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4771 - accuracy: 0.4464 - val_loss: 1.5733 - val_accuracy: 0.3979

Epoch 00030: val_loss did not improve from 1.56177
Epoch 31/100
83/83 [==============================] - 6s 70ms/step - loss: 1.4746 - accuracy: 0.4547 - val_loss: 1.5772 - val_accuracy: 0.4013

Epoch 00031: val_loss did not improve from 1.56177
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4640 - accuracy: 0.4581 - val_loss: 1.5848 - val_accuracy: 0.3958

Epoch 00032: val_loss did not improve from 1.56177
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5664 - accuracy: 0.3919
Testing Loss = 1.566363, Testing Accuracy = 0.391932
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 70ms/step - loss: 12.3923 - accuracy: 0.1974 - val_loss: 8.6406 - val_accuracy: 0.2119

Epoch 00001: val_loss improved from inf to 8.64061, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.7245 - accuracy: 0.2073 - val_loss: 5.3019 - val_accuracy: 0.2127

Epoch 00002: val_loss improved from 8.64061 to 5.30191, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.5450 - accuracy: 0.2126 - val_loss: 3.9404 - val_accuracy: 0.2154

Epoch 00003: val_loss improved from 5.30191 to 3.94035, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.5234 - accuracy: 0.2340 - val_loss: 3.1821 - val_accuracy: 0.2555

Epoch 00004: val_loss improved from 3.94035 to 3.18214, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8671 - accuracy: 0.2922 - val_loss: 2.6864 - val_accuracy: 0.2912

Epoch 00005: val_loss improved from 3.18214 to 2.68641, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.4770 - accuracy: 0.3047 - val_loss: 2.3482 - val_accuracy: 0.3170

Epoch 00006: val_loss improved from 2.68641 to 2.34821, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2134 - accuracy: 0.3163 - val_loss: 2.1098 - val_accuracy: 0.3337

Epoch 00007: val_loss improved from 2.34821 to 2.10980, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0299 - accuracy: 0.3277 - val_loss: 1.9462 - val_accuracy: 0.3397

Epoch 00008: val_loss improved from 2.10980 to 1.94624, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8965 - accuracy: 0.3335 - val_loss: 1.8358 - val_accuracy: 0.3485

Epoch 00009: val_loss improved from 1.94624 to 1.83581, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 10/100
83/83 [==============================] - 6s 71ms/step - loss: 1.8037 - accuracy: 0.3433 - val_loss: 1.7566 - val_accuracy: 0.3540

Epoch 00010: val_loss improved from 1.83581 to 1.75655, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7392 - accuracy: 0.3480 - val_loss: 1.7015 - val_accuracy: 0.3570

Epoch 00011: val_loss improved from 1.75655 to 1.70151, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6885 - accuracy: 0.3581 - val_loss: 1.6609 - val_accuracy: 0.3641

Epoch 00012: val_loss improved from 1.70151 to 1.66092, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6509 - accuracy: 0.3688 - val_loss: 1.6285 - val_accuracy: 0.3767

Epoch 00013: val_loss improved from 1.66092 to 1.62848, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6216 - accuracy: 0.3741 - val_loss: 1.6059 - val_accuracy: 0.3819

Epoch 00014: val_loss improved from 1.62848 to 1.60591, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5994 - accuracy: 0.3838 - val_loss: 1.5915 - val_accuracy: 0.3890

Epoch 00015: val_loss improved from 1.60591 to 1.59150, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5824 - accuracy: 0.3872 - val_loss: 1.5853 - val_accuracy: 0.3848

Epoch 00016: val_loss improved from 1.59150 to 1.58526, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5687 - accuracy: 0.3958 - val_loss: 1.5748 - val_accuracy: 0.3894

Epoch 00017: val_loss improved from 1.58526 to 1.57482, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5544 - accuracy: 0.4001 - val_loss: 1.5690 - val_accuracy: 0.3934

Epoch 00018: val_loss improved from 1.57482 to 1.56897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5476 - accuracy: 0.4056 - val_loss: 1.5636 - val_accuracy: 0.3948

Epoch 00019: val_loss improved from 1.56897 to 1.56365, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5411 - accuracy: 0.4051 - val_loss: 1.5618 - val_accuracy: 0.3937

Epoch 00020: val_loss improved from 1.56365 to 1.56178, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5325 - accuracy: 0.4117 - val_loss: 1.5598 - val_accuracy: 0.3998

Epoch 00021: val_loss improved from 1.56178 to 1.55981, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5269 - accuracy: 0.4163 - val_loss: 1.5616 - val_accuracy: 0.3950

Epoch 00022: val_loss did not improve from 1.55981
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5175 - accuracy: 0.4177 - val_loss: 1.5593 - val_accuracy: 0.3993

Epoch 00023: val_loss improved from 1.55981 to 1.55931, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/5
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5155 - accuracy: 0.4242 - val_loss: 1.5643 - val_accuracy: 0.3994

Epoch 00024: val_loss did not improve from 1.55931
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5061 - accuracy: 0.4295 - val_loss: 1.5603 - val_accuracy: 0.4002

Epoch 00025: val_loss did not improve from 1.55931
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5010 - accuracy: 0.4292 - val_loss: 1.5632 - val_accuracy: 0.3984

Epoch 00026: val_loss did not improve from 1.55931
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4973 - accuracy: 0.4332 - val_loss: 1.5714 - val_accuracy: 0.3958

Epoch 00027: val_loss did not improve from 1.55931
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4878 - accuracy: 0.4396 - val_loss: 1.5717 - val_accuracy: 0.3995

Epoch 00028: val_loss did not improve from 1.55931
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4779 - accuracy: 0.4489 - val_loss: 1.5769 - val_accuracy: 0.3976

Epoch 00029: val_loss did not improve from 1.55931
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4728 - accuracy: 0.4519 - val_loss: 1.5805 - val_accuracy: 0.3993

Epoch 00030: val_loss did not improve from 1.55931
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4678 - accuracy: 0.4540 - val_loss: 1.5828 - val_accuracy: 0.3986

Epoch 00031: val_loss did not improve from 1.55931
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4574 - accuracy: 0.4629 - val_loss: 1.5878 - val_accuracy: 0.3983

Epoch 00032: val_loss did not improve from 1.55931
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4509 - accuracy: 0.4684 - val_loss: 1.5934 - val_accuracy: 0.3962

Epoch 00033: val_loss did not improve from 1.55931
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 4ms/step - loss: 1.5662 - accuracy: 0.3951
Testing Loss = 1.566242, Testing Accuracy = 0.395132
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4172 - accuracy: 0.2004 - val_loss: 8.7006 - val_accuracy: 0.2155

Epoch 00001: val_loss improved from inf to 8.70058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 2/100
83/83 [==============================] - 6s 69ms/step - loss: 6.7843 - accuracy: 0.2108 - val_loss: 5.3548 - val_accuracy: 0.2146

Epoch 00002: val_loss improved from 8.70058 to 5.35480, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.5852 - accuracy: 0.2157 - val_loss: 3.9704 - val_accuracy: 0.2176

Epoch 00003: val_loss improved from 5.35480 to 3.97042, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.5372 - accuracy: 0.2434 - val_loss: 3.1885 - val_accuracy: 0.2724

Epoch 00004: val_loss improved from 3.97042 to 3.18846, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8802 - accuracy: 0.2933 - val_loss: 2.6958 - val_accuracy: 0.3021

Epoch 00005: val_loss improved from 3.18846 to 2.69583, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.4899 - accuracy: 0.3041 - val_loss: 2.3621 - val_accuracy: 0.3179

Epoch 00006: val_loss improved from 2.69583 to 2.36213, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2253 - accuracy: 0.3132 - val_loss: 2.1223 - val_accuracy: 0.3300

Epoch 00007: val_loss improved from 2.36213 to 2.12229, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0381 - accuracy: 0.3253 - val_loss: 1.9593 - val_accuracy: 0.3366

Epoch 00008: val_loss improved from 2.12229 to 1.95929, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 9/100
83/83 [==============================] - 6s 67ms/step - loss: 1.9079 - accuracy: 0.3311 - val_loss: 1.8470 - val_accuracy: 0.3449

Epoch 00009: val_loss improved from 1.95929 to 1.84699, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8132 - accuracy: 0.3398 - val_loss: 1.7693 - val_accuracy: 0.3487

Epoch 00010: val_loss improved from 1.84699 to 1.76934, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7446 - accuracy: 0.3473 - val_loss: 1.7095 - val_accuracy: 0.3568

Epoch 00011: val_loss improved from 1.76934 to 1.70948, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6967 - accuracy: 0.3557 - val_loss: 1.6688 - val_accuracy: 0.3642

Epoch 00012: val_loss improved from 1.70948 to 1.66882, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6588 - accuracy: 0.3630 - val_loss: 1.6382 - val_accuracy: 0.3721

Epoch 00013: val_loss improved from 1.66882 to 1.63822, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6270 - accuracy: 0.3726 - val_loss: 1.6148 - val_accuracy: 0.3807

Epoch 00014: val_loss improved from 1.63822 to 1.61481, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6069 - accuracy: 0.3820 - val_loss: 1.5986 - val_accuracy: 0.3851

Epoch 00015: val_loss improved from 1.61481 to 1.59858, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5880 - accuracy: 0.3868 - val_loss: 1.5888 - val_accuracy: 0.3911

Epoch 00016: val_loss improved from 1.59858 to 1.58878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5721 - accuracy: 0.3930 - val_loss: 1.5784 - val_accuracy: 0.3938

Epoch 00017: val_loss improved from 1.58878 to 1.57841, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5587 - accuracy: 0.3989 - val_loss: 1.5702 - val_accuracy: 0.3970

Epoch 00018: val_loss improved from 1.57841 to 1.57021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5513 - accuracy: 0.4032 - val_loss: 1.5671 - val_accuracy: 0.3973

Epoch 00019: val_loss improved from 1.57021 to 1.56710, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5445 - accuracy: 0.4040 - val_loss: 1.5647 - val_accuracy: 0.3983

Epoch 00020: val_loss improved from 1.56710 to 1.56472, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5353 - accuracy: 0.4096 - val_loss: 1.5634 - val_accuracy: 0.3971

Epoch 00021: val_loss improved from 1.56472 to 1.56344, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5297 - accuracy: 0.4150 - val_loss: 1.5614 - val_accuracy: 0.3969

Epoch 00022: val_loss improved from 1.56344 to 1.56136, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5250 - accuracy: 0.4165 - val_loss: 1.5679 - val_accuracy: 0.3936

Epoch 00023: val_loss did not improve from 1.56136
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5151 - accuracy: 0.4236 - val_loss: 1.5612 - val_accuracy: 0.3984

Epoch 00024: val_loss improved from 1.56136 to 1.56116, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5090 - accuracy: 0.4266 - val_loss: 1.5623 - val_accuracy: 0.4001

Epoch 00025: val_loss did not improve from 1.56116
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5030 - accuracy: 0.4313 - val_loss: 1.5607 - val_accuracy: 0.3991

Epoch 00026: val_loss improved from 1.56116 to 1.56073, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/6
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4960 - accuracy: 0.4326 - val_loss: 1.5652 - val_accuracy: 0.3993

Epoch 00027: val_loss did not improve from 1.56073
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4907 - accuracy: 0.4405 - val_loss: 1.5662 - val_accuracy: 0.4004

Epoch 00028: val_loss did not improve from 1.56073
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4810 - accuracy: 0.4456 - val_loss: 1.5762 - val_accuracy: 0.3980

Epoch 00029: val_loss did not improve from 1.56073
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4784 - accuracy: 0.4485 - val_loss: 1.5777 - val_accuracy: 0.3981

Epoch 00030: val_loss did not improve from 1.56073
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4744 - accuracy: 0.4530 - val_loss: 1.5836 - val_accuracy: 0.3965

Epoch 00031: val_loss did not improve from 1.56073
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4672 - accuracy: 0.4544 - val_loss: 1.5906 - val_accuracy: 0.3973

Epoch 00032: val_loss did not improve from 1.56073
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4599 - accuracy: 0.4613 - val_loss: 1.6042 - val_accuracy: 0.3902

Epoch 00033: val_loss did not improve from 1.56073
Epoch 34/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4592 - accuracy: 0.4659 - val_loss: 1.6003 - val_accuracy: 0.3922

Epoch 00034: val_loss did not improve from 1.56073
Epoch 35/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4552 - accuracy: 0.4703 - val_loss: 1.6105 - val_accuracy: 0.3929

Epoch 00035: val_loss did not improve from 1.56073
Epoch 36/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4530 - accuracy: 0.4691 - val_loss: 1.6671 - val_accuracy: 0.3718

Epoch 00036: val_loss did not improve from 1.56073
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.5704 - accuracy: 0.3980
Testing Loss = 1.570428, Testing Accuracy = 0.398035
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 70ms/step - loss: 12.4472 - accuracy: 0.1972 - val_loss: 8.7284 - val_accuracy: 0.2128

Epoch 00001: val_loss improved from inf to 8.72843, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7994 - accuracy: 0.2091 - val_loss: 5.3603 - val_accuracy: 0.2175

Epoch 00002: val_loss improved from 8.72843 to 5.36030, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5879 - accuracy: 0.2161 - val_loss: 3.9714 - val_accuracy: 0.2227

Epoch 00003: val_loss improved from 5.36030 to 3.97145, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.5087 - accuracy: 0.2622 - val_loss: 3.1896 - val_accuracy: 0.2673

Epoch 00004: val_loss improved from 3.97145 to 3.18961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8823 - accuracy: 0.3008 - val_loss: 2.7011 - val_accuracy: 0.2977

Epoch 00005: val_loss improved from 3.18961 to 2.70107, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.4968 - accuracy: 0.3087 - val_loss: 2.3656 - val_accuracy: 0.3218

Epoch 00006: val_loss improved from 2.70107 to 2.36559, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2305 - accuracy: 0.3200 - val_loss: 2.1265 - val_accuracy: 0.3372

Epoch 00007: val_loss improved from 2.36559 to 2.12647, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0427 - accuracy: 0.3288 - val_loss: 1.9615 - val_accuracy: 0.3418

Epoch 00008: val_loss improved from 2.12647 to 1.96153, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9093 - accuracy: 0.3358 - val_loss: 1.8478 - val_accuracy: 0.3429

Epoch 00009: val_loss improved from 1.96153 to 1.84785, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8138 - accuracy: 0.3446 - val_loss: 1.7656 - val_accuracy: 0.3543

Epoch 00010: val_loss improved from 1.84785 to 1.76562, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7464 - accuracy: 0.3536 - val_loss: 1.7113 - val_accuracy: 0.3591

Epoch 00011: val_loss improved from 1.76562 to 1.71134, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6958 - accuracy: 0.3612 - val_loss: 1.6667 - val_accuracy: 0.3643

Epoch 00012: val_loss improved from 1.71134 to 1.66672, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6525 - accuracy: 0.3703 - val_loss: 1.6385 - val_accuracy: 0.3722

Epoch 00013: val_loss improved from 1.66672 to 1.63851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6256 - accuracy: 0.3750 - val_loss: 1.6139 - val_accuracy: 0.3776

Epoch 00014: val_loss improved from 1.63851 to 1.61392, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6050 - accuracy: 0.3828 - val_loss: 1.6023 - val_accuracy: 0.3830

Epoch 00015: val_loss improved from 1.61392 to 1.60229, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5863 - accuracy: 0.3869 - val_loss: 1.5869 - val_accuracy: 0.3867

Epoch 00016: val_loss improved from 1.60229 to 1.58693, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5741 - accuracy: 0.3931 - val_loss: 1.5797 - val_accuracy: 0.3892

Epoch 00017: val_loss improved from 1.58693 to 1.57967, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5624 - accuracy: 0.3963 - val_loss: 1.5719 - val_accuracy: 0.3915

Epoch 00018: val_loss improved from 1.57967 to 1.57192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5520 - accuracy: 0.4023 - val_loss: 1.5690 - val_accuracy: 0.3947

Epoch 00019: val_loss improved from 1.57192 to 1.56903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5440 - accuracy: 0.4069 - val_loss: 1.5633 - val_accuracy: 0.3947

Epoch 00020: val_loss improved from 1.56903 to 1.56329, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5366 - accuracy: 0.4064 - val_loss: 1.5617 - val_accuracy: 0.3967

Epoch 00021: val_loss improved from 1.56329 to 1.56172, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5317 - accuracy: 0.4106 - val_loss: 1.5600 - val_accuracy: 0.3968

Epoch 00022: val_loss improved from 1.56172 to 1.56003, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5202 - accuracy: 0.4196 - val_loss: 1.5606 - val_accuracy: 0.3979

Epoch 00023: val_loss did not improve from 1.56003
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5162 - accuracy: 0.4217 - val_loss: 1.5583 - val_accuracy: 0.3956

Epoch 00024: val_loss improved from 1.56003 to 1.55825, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 25/100
83/83 [==============================] - 6s 71ms/step - loss: 1.5131 - accuracy: 0.4248 - val_loss: 1.5571 - val_accuracy: 0.3977

Epoch 00025: val_loss improved from 1.55825 to 1.55715, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/7
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5045 - accuracy: 0.4280 - val_loss: 1.5596 - val_accuracy: 0.3976

Epoch 00026: val_loss did not improve from 1.55715
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5025 - accuracy: 0.4307 - val_loss: 1.5611 - val_accuracy: 0.3962

Epoch 00027: val_loss did not improve from 1.55715
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4987 - accuracy: 0.4323 - val_loss: 1.5638 - val_accuracy: 0.3953

Epoch 00028: val_loss did not improve from 1.55715
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4915 - accuracy: 0.4405 - val_loss: 1.5652 - val_accuracy: 0.3979

Epoch 00029: val_loss did not improve from 1.55715
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4832 - accuracy: 0.4446 - val_loss: 1.5696 - val_accuracy: 0.3952

Epoch 00030: val_loss did not improve from 1.55715
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4738 - accuracy: 0.4505 - val_loss: 1.5739 - val_accuracy: 0.3983

Epoch 00031: val_loss did not improve from 1.55715
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4728 - accuracy: 0.4516 - val_loss: 1.5747 - val_accuracy: 0.4002

Epoch 00032: val_loss did not improve from 1.55715
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4640 - accuracy: 0.4580 - val_loss: 1.5807 - val_accuracy: 0.3997

Epoch 00033: val_loss did not improve from 1.55715
Epoch 34/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4561 - accuracy: 0.4639 - val_loss: 1.5843 - val_accuracy: 0.4005

Epoch 00034: val_loss did not improve from 1.55715
Epoch 35/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4488 - accuracy: 0.4693 - val_loss: 1.5897 - val_accuracy: 0.4003

Epoch 00035: val_loss did not improve from 1.55715
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.5686 - accuracy: 0.3922
Testing Loss = 1.568613, Testing Accuracy = 0.392155
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4505 - accuracy: 0.1994 - val_loss: 8.7376 - val_accuracy: 0.2128

Epoch 00001: val_loss improved from inf to 8.73761, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8112 - accuracy: 0.2085 - val_loss: 5.3724 - val_accuracy: 0.2142

Epoch 00002: val_loss improved from 8.73761 to 5.37236, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5972 - accuracy: 0.2125 - val_loss: 3.9771 - val_accuracy: 0.2180

Epoch 00003: val_loss improved from 5.37236 to 3.97710, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5473 - accuracy: 0.2372 - val_loss: 3.1907 - val_accuracy: 0.2669

Epoch 00004: val_loss improved from 3.97710 to 3.19073, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8815 - accuracy: 0.2905 - val_loss: 2.6912 - val_accuracy: 0.2967

Epoch 00005: val_loss improved from 3.19073 to 2.69123, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.4910 - accuracy: 0.3033 - val_loss: 2.3547 - val_accuracy: 0.3182

Epoch 00006: val_loss improved from 2.69123 to 2.35471, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2245 - accuracy: 0.3136 - val_loss: 2.1170 - val_accuracy: 0.3326

Epoch 00007: val_loss improved from 2.35471 to 2.11698, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0367 - accuracy: 0.3243 - val_loss: 1.9562 - val_accuracy: 0.3389

Epoch 00008: val_loss improved from 2.11698 to 1.95616, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9058 - accuracy: 0.3332 - val_loss: 1.8397 - val_accuracy: 0.3439

Epoch 00009: val_loss improved from 1.95616 to 1.83969, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8106 - accuracy: 0.3405 - val_loss: 1.7605 - val_accuracy: 0.3480

Epoch 00010: val_loss improved from 1.83969 to 1.76047, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7461 - accuracy: 0.3460 - val_loss: 1.7064 - val_accuracy: 0.3576

Epoch 00011: val_loss improved from 1.76047 to 1.70639, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6942 - accuracy: 0.3542 - val_loss: 1.6664 - val_accuracy: 0.3628

Epoch 00012: val_loss improved from 1.70639 to 1.66641, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6580 - accuracy: 0.3658 - val_loss: 1.6340 - val_accuracy: 0.3732

Epoch 00013: val_loss improved from 1.66641 to 1.63404, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6264 - accuracy: 0.3722 - val_loss: 1.6137 - val_accuracy: 0.3816

Epoch 00014: val_loss improved from 1.63404 to 1.61373, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6062 - accuracy: 0.3791 - val_loss: 1.5970 - val_accuracy: 0.3845

Epoch 00015: val_loss improved from 1.61373 to 1.59700, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5891 - accuracy: 0.3849 - val_loss: 1.5877 - val_accuracy: 0.3890

Epoch 00016: val_loss improved from 1.59700 to 1.58765, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5754 - accuracy: 0.3899 - val_loss: 1.5763 - val_accuracy: 0.3897

Epoch 00017: val_loss improved from 1.58765 to 1.57635, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5610 - accuracy: 0.3958 - val_loss: 1.5706 - val_accuracy: 0.3962

Epoch 00018: val_loss improved from 1.57635 to 1.57060, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5536 - accuracy: 0.4006 - val_loss: 1.5668 - val_accuracy: 0.3947

Epoch 00019: val_loss improved from 1.57060 to 1.56678, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5431 - accuracy: 0.4080 - val_loss: 1.5612 - val_accuracy: 0.3955

Epoch 00020: val_loss improved from 1.56678 to 1.56122, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5343 - accuracy: 0.4113 - val_loss: 1.5589 - val_accuracy: 0.4021

Epoch 00021: val_loss improved from 1.56122 to 1.55888, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5285 - accuracy: 0.4131 - val_loss: 1.5591 - val_accuracy: 0.3986

Epoch 00022: val_loss did not improve from 1.55888
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5225 - accuracy: 0.4198 - val_loss: 1.5591 - val_accuracy: 0.3964

Epoch 00023: val_loss did not improve from 1.55888
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5155 - accuracy: 0.4223 - val_loss: 1.5579 - val_accuracy: 0.3974

Epoch 00024: val_loss improved from 1.55888 to 1.55787, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/8
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5080 - accuracy: 0.4263 - val_loss: 1.5649 - val_accuracy: 0.4018

Epoch 00025: val_loss did not improve from 1.55787
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5015 - accuracy: 0.4335 - val_loss: 1.5699 - val_accuracy: 0.3987

Epoch 00026: val_loss did not improve from 1.55787
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5011 - accuracy: 0.4307 - val_loss: 1.5618 - val_accuracy: 0.3976

Epoch 00027: val_loss did not improve from 1.55787
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4928 - accuracy: 0.4409 - val_loss: 1.5633 - val_accuracy: 0.3975

Epoch 00028: val_loss did not improve from 1.55787
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4883 - accuracy: 0.4452 - val_loss: 1.5727 - val_accuracy: 0.3945

Epoch 00029: val_loss did not improve from 1.55787
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4819 - accuracy: 0.4447 - val_loss: 1.5742 - val_accuracy: 0.3942

Epoch 00030: val_loss did not improve from 1.55787
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4759 - accuracy: 0.4533 - val_loss: 1.5769 - val_accuracy: 0.3960

Epoch 00031: val_loss did not improve from 1.55787
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4648 - accuracy: 0.4581 - val_loss: 1.5767 - val_accuracy: 0.4003

Epoch 00032: val_loss did not improve from 1.55787
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4584 - accuracy: 0.4650 - val_loss: 1.5892 - val_accuracy: 0.3971

Epoch 00033: val_loss did not improve from 1.55787
Epoch 34/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4492 - accuracy: 0.4684 - val_loss: 1.5897 - val_accuracy: 0.4028

Epoch 00034: val_loss did not improve from 1.55787
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.5671 - accuracy: 0.3944
Testing Loss = 1.567126, Testing Accuracy = 0.394388
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 70ms/step - loss: 12.5212 - accuracy: 0.2018 - val_loss: 8.8265 - val_accuracy: 0.2146

Epoch 00001: val_loss improved from inf to 8.82647, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 2/100
83/83 [==============================] - 6s 69ms/step - loss: 6.8855 - accuracy: 0.2099 - val_loss: 5.4322 - val_accuracy: 0.2159

Epoch 00002: val_loss improved from 8.82647 to 5.43224, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.6261 - accuracy: 0.2271 - val_loss: 3.9896 - val_accuracy: 0.2523

Epoch 00003: val_loss improved from 5.43224 to 3.98957, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 4/100
83/83 [==============================] - 6s 70ms/step - loss: 3.5036 - accuracy: 0.2864 - val_loss: 3.2193 - val_accuracy: 0.2727

Epoch 00004: val_loss improved from 3.98957 to 3.21927, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9017 - accuracy: 0.3017 - val_loss: 2.7273 - val_accuracy: 0.2945

Epoch 00005: val_loss improved from 3.21927 to 2.72731, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5104 - accuracy: 0.3135 - val_loss: 2.3788 - val_accuracy: 0.3264

Epoch 00006: val_loss improved from 2.72731 to 2.37883, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2442 - accuracy: 0.3219 - val_loss: 2.1392 - val_accuracy: 0.3375

Epoch 00007: val_loss improved from 2.37883 to 2.13920, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.0537 - accuracy: 0.3260 - val_loss: 1.9729 - val_accuracy: 0.3460

Epoch 00008: val_loss improved from 2.13920 to 1.97290, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9170 - accuracy: 0.3367 - val_loss: 1.8553 - val_accuracy: 0.3462

Epoch 00009: val_loss improved from 1.97290 to 1.85534, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8223 - accuracy: 0.3429 - val_loss: 1.7736 - val_accuracy: 0.3509

Epoch 00010: val_loss improved from 1.85534 to 1.77356, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7534 - accuracy: 0.3508 - val_loss: 1.7155 - val_accuracy: 0.3589

Epoch 00011: val_loss improved from 1.77356 to 1.71549, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7018 - accuracy: 0.3590 - val_loss: 1.6766 - val_accuracy: 0.3660

Epoch 00012: val_loss improved from 1.71549 to 1.67663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6658 - accuracy: 0.3618 - val_loss: 1.6431 - val_accuracy: 0.3724

Epoch 00013: val_loss improved from 1.67663 to 1.64306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6337 - accuracy: 0.3709 - val_loss: 1.6202 - val_accuracy: 0.3768

Epoch 00014: val_loss improved from 1.64306 to 1.62021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6100 - accuracy: 0.3783 - val_loss: 1.6041 - val_accuracy: 0.3830

Epoch 00015: val_loss improved from 1.62021 to 1.60408, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5920 - accuracy: 0.3863 - val_loss: 1.5928 - val_accuracy: 0.3876

Epoch 00016: val_loss improved from 1.60408 to 1.59281, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5780 - accuracy: 0.3948 - val_loss: 1.5823 - val_accuracy: 0.3892

Epoch 00017: val_loss improved from 1.59281 to 1.58226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5650 - accuracy: 0.3953 - val_loss: 1.5789 - val_accuracy: 0.3893

Epoch 00018: val_loss improved from 1.58226 to 1.57887, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5579 - accuracy: 0.4003 - val_loss: 1.5730 - val_accuracy: 0.3914

Epoch 00019: val_loss improved from 1.57887 to 1.57304, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5450 - accuracy: 0.4081 - val_loss: 1.5701 - val_accuracy: 0.3938

Epoch 00020: val_loss improved from 1.57304 to 1.57006, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 21/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5372 - accuracy: 0.4125 - val_loss: 1.5683 - val_accuracy: 0.3965

Epoch 00021: val_loss improved from 1.57006 to 1.56835, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5335 - accuracy: 0.4152 - val_loss: 1.5680 - val_accuracy: 0.3988

Epoch 00022: val_loss improved from 1.56835 to 1.56796, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.25/Try/9
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5247 - accuracy: 0.4186 - val_loss: 1.5682 - val_accuracy: 0.3995

Epoch 00023: val_loss did not improve from 1.56796
Epoch 24/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5182 - accuracy: 0.4243 - val_loss: 1.5695 - val_accuracy: 0.3970

Epoch 00024: val_loss did not improve from 1.56796
Epoch 25/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5131 - accuracy: 0.4284 - val_loss: 1.5683 - val_accuracy: 0.4004

Epoch 00025: val_loss did not improve from 1.56796
Epoch 26/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5049 - accuracy: 0.4345 - val_loss: 1.5722 - val_accuracy: 0.3989

Epoch 00026: val_loss did not improve from 1.56796
Epoch 27/100
83/83 [==============================] - 6s 70ms/step - loss: 1.4942 - accuracy: 0.4391 - val_loss: 1.5765 - val_accuracy: 0.4014

Epoch 00027: val_loss did not improve from 1.56796
Epoch 28/100
83/83 [==============================] - 6s 70ms/step - loss: 1.4897 - accuracy: 0.4433 - val_loss: 1.5772 - val_accuracy: 0.3997

Epoch 00028: val_loss did not improve from 1.56796
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4823 - accuracy: 0.4477 - val_loss: 1.5803 - val_accuracy: 0.4002

Epoch 00029: val_loss did not improve from 1.56796
Epoch 30/100
83/83 [==============================] - 6s 70ms/step - loss: 1.4725 - accuracy: 0.4571 - val_loss: 1.5859 - val_accuracy: 0.4009

Epoch 00030: val_loss did not improve from 1.56796
Epoch 31/100
83/83 [==============================] - 6s 70ms/step - loss: 1.4634 - accuracy: 0.4609 - val_loss: 1.5976 - val_accuracy: 0.3989

Epoch 00031: val_loss did not improve from 1.56796
Epoch 32/100
83/83 [==============================] - 6s 70ms/step - loss: 1.4585 - accuracy: 0.4668 - val_loss: 1.5986 - val_accuracy: 0.4001

Epoch 00032: val_loss did not improve from 1.56796
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.5760 - accuracy: 0.3915
Testing Loss = 1.575957, Testing Accuracy = 0.391486
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 84.23 +- 0.1220 %)
$W^-/W^-$ (auc = 83.60 +- 0.0728 %)
$Z/Z$ (auc = 76.64 +- 0.2028 %)
$W^+/W^-$ (auc = 70.61 +- 0.1809 %)
$W^+/Z$$ (auc = 67.65 +- 0.1436 %)
$W^-/Z$ (auc = 69.34 +- 0.1443 %)
The summarized testing accuracy = 39.39 +- 0.2457 %, with the loss = 1.5690 +- 0.003156
