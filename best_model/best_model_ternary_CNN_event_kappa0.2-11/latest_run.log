

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-26 23:43:28.873784
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 5s 17ms/step - loss: 12.8790 - accuracy: 0.2001 - val_loss: 10.6202 - val_accuracy: 0.2145

Epoch 00001: val_loss improved from inf to 10.62016, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 2/100
83/83 [==============================] - 1s 16ms/step - loss: 8.8988 - accuracy: 0.2306 - val_loss: 7.4069 - val_accuracy: 0.2535

Epoch 00002: val_loss improved from 10.62016 to 7.40692, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2647 - accuracy: 0.2705 - val_loss: 5.3346 - val_accuracy: 0.2898

Epoch 00003: val_loss improved from 7.40692 to 5.33458, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.6044 - accuracy: 0.2813 - val_loss: 4.0080 - val_accuracy: 0.2987

Epoch 00004: val_loss improved from 5.33458 to 4.00801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5467 - accuracy: 0.2878 - val_loss: 3.1598 - val_accuracy: 0.2985

Epoch 00005: val_loss improved from 4.00801 to 3.15983, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8704 - accuracy: 0.2933 - val_loss: 2.6168 - val_accuracy: 0.3004

Epoch 00006: val_loss improved from 3.15983 to 2.61682, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 7/100
83/83 [==============================] - 1s 14ms/step - loss: 2.4389 - accuracy: 0.2997 - val_loss: 2.2732 - val_accuracy: 0.3051

Epoch 00007: val_loss improved from 2.61682 to 2.27317, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1605 - accuracy: 0.3037 - val_loss: 2.0530 - val_accuracy: 0.3088

Epoch 00008: val_loss improved from 2.27317 to 2.05303, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9799 - accuracy: 0.3065 - val_loss: 1.9072 - val_accuracy: 0.3145

Epoch 00009: val_loss improved from 2.05303 to 1.90717, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 10/100
83/83 [==============================] - 1s 16ms/step - loss: 1.8599 - accuracy: 0.3144 - val_loss: 1.8093 - val_accuracy: 0.3225

Epoch 00010: val_loss improved from 1.90717 to 1.80929, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 11/100
83/83 [==============================] - 1s 16ms/step - loss: 1.7769 - accuracy: 0.3213 - val_loss: 1.7462 - val_accuracy: 0.3270

Epoch 00011: val_loss improved from 1.80929 to 1.74621, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7233 - accuracy: 0.3248 - val_loss: 1.7049 - val_accuracy: 0.3296

Epoch 00012: val_loss improved from 1.74621 to 1.70486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6845 - accuracy: 0.3274 - val_loss: 1.6743 - val_accuracy: 0.3345

Epoch 00013: val_loss improved from 1.70486 to 1.67426, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6561 - accuracy: 0.3328 - val_loss: 1.6564 - val_accuracy: 0.3327

Epoch 00014: val_loss improved from 1.67426 to 1.65637, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6364 - accuracy: 0.3357 - val_loss: 1.6435 - val_accuracy: 0.3337

Epoch 00015: val_loss improved from 1.65637 to 1.64346, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6220 - accuracy: 0.3387 - val_loss: 1.6350 - val_accuracy: 0.3333

Epoch 00016: val_loss improved from 1.64346 to 1.63501, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6115 - accuracy: 0.3413 - val_loss: 1.6263 - val_accuracy: 0.3386

Epoch 00017: val_loss improved from 1.63501 to 1.62629, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5997 - accuracy: 0.3455 - val_loss: 1.6201 - val_accuracy: 0.3413

Epoch 00018: val_loss improved from 1.62629 to 1.62009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 19/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5910 - accuracy: 0.3490 - val_loss: 1.6148 - val_accuracy: 0.3431

Epoch 00019: val_loss improved from 1.62009 to 1.61484, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 20/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5818 - accuracy: 0.3552 - val_loss: 1.6128 - val_accuracy: 0.3448

Epoch 00020: val_loss improved from 1.61484 to 1.61281, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/0
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5744 - accuracy: 0.3570 - val_loss: 1.6139 - val_accuracy: 0.3439

Epoch 00021: val_loss did not improve from 1.61281
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5646 - accuracy: 0.3642 - val_loss: 1.6130 - val_accuracy: 0.3453

Epoch 00022: val_loss did not improve from 1.61281
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5577 - accuracy: 0.3686 - val_loss: 1.6163 - val_accuracy: 0.3437

Epoch 00023: val_loss did not improve from 1.61281
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5473 - accuracy: 0.3784 - val_loss: 1.6203 - val_accuracy: 0.3467

Epoch 00024: val_loss did not improve from 1.61281
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5381 - accuracy: 0.3853 - val_loss: 1.6257 - val_accuracy: 0.3438

Epoch 00025: val_loss did not improve from 1.61281
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5253 - accuracy: 0.3926 - val_loss: 1.6301 - val_accuracy: 0.3465

Epoch 00026: val_loss did not improve from 1.61281
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5167 - accuracy: 0.3959 - val_loss: 1.6330 - val_accuracy: 0.3492

Epoch 00027: val_loss did not improve from 1.61281
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5018 - accuracy: 0.4050 - val_loss: 1.6414 - val_accuracy: 0.3495

Epoch 00028: val_loss did not improve from 1.61281
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4902 - accuracy: 0.4103 - val_loss: 1.6572 - val_accuracy: 0.3432

Epoch 00029: val_loss did not improve from 1.61281
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4739 - accuracy: 0.4235 - val_loss: 1.6694 - val_accuracy: 0.3447

Epoch 00030: val_loss did not improve from 1.61281
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 50s 4ms/step - loss: 1.6226 - accuracy: 0.3302
Testing Loss = 1.622563, Testing Accuracy = 0.330232
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.8812 - accuracy: 0.1978 - val_loss: 10.6317 - val_accuracy: 0.2144

Epoch 00001: val_loss improved from inf to 10.63169, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9130 - accuracy: 0.2288 - val_loss: 7.4151 - val_accuracy: 0.2541

Epoch 00002: val_loss improved from 10.63169 to 7.41512, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2736 - accuracy: 0.2742 - val_loss: 5.3391 - val_accuracy: 0.2864

Epoch 00003: val_loss improved from 7.41512 to 5.33906, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.6124 - accuracy: 0.2836 - val_loss: 4.0109 - val_accuracy: 0.2966

Epoch 00004: val_loss improved from 5.33906 to 4.01086, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5507 - accuracy: 0.2931 - val_loss: 3.1596 - val_accuracy: 0.3010

Epoch 00005: val_loss improved from 4.01086 to 3.15961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8723 - accuracy: 0.2973 - val_loss: 2.6158 - val_accuracy: 0.3043

Epoch 00006: val_loss improved from 3.15961 to 2.61581, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 7/100
83/83 [==============================] - 1s 16ms/step - loss: 2.4374 - accuracy: 0.3021 - val_loss: 2.2701 - val_accuracy: 0.3084

Epoch 00007: val_loss improved from 2.61581 to 2.27011, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1567 - accuracy: 0.3073 - val_loss: 2.0463 - val_accuracy: 0.3139

Epoch 00008: val_loss improved from 2.27011 to 2.04626, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9742 - accuracy: 0.3136 - val_loss: 1.8992 - val_accuracy: 0.3217

Epoch 00009: val_loss improved from 2.04626 to 1.89925, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8539 - accuracy: 0.3155 - val_loss: 1.8031 - val_accuracy: 0.3303

Epoch 00010: val_loss improved from 1.89925 to 1.80312, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7727 - accuracy: 0.3228 - val_loss: 1.7388 - val_accuracy: 0.3333

Epoch 00011: val_loss improved from 1.80312 to 1.73878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7157 - accuracy: 0.3283 - val_loss: 1.6970 - val_accuracy: 0.3345

Epoch 00012: val_loss improved from 1.73878 to 1.69697, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6787 - accuracy: 0.3329 - val_loss: 1.6686 - val_accuracy: 0.3392

Epoch 00013: val_loss improved from 1.69697 to 1.66861, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6518 - accuracy: 0.3364 - val_loss: 1.6511 - val_accuracy: 0.3357

Epoch 00014: val_loss improved from 1.66861 to 1.65112, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6327 - accuracy: 0.3389 - val_loss: 1.6362 - val_accuracy: 0.3410

Epoch 00015: val_loss improved from 1.65112 to 1.63623, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6159 - accuracy: 0.3433 - val_loss: 1.6306 - val_accuracy: 0.3408

Epoch 00016: val_loss improved from 1.63623 to 1.63057, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6040 - accuracy: 0.3494 - val_loss: 1.6209 - val_accuracy: 0.3415

Epoch 00017: val_loss improved from 1.63057 to 1.62088, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5950 - accuracy: 0.3519 - val_loss: 1.6134 - val_accuracy: 0.3484

Epoch 00018: val_loss improved from 1.62088 to 1.61337, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5837 - accuracy: 0.3560 - val_loss: 1.6086 - val_accuracy: 0.3511

Epoch 00019: val_loss improved from 1.61337 to 1.60865, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5735 - accuracy: 0.3632 - val_loss: 1.6056 - val_accuracy: 0.3517

Epoch 00020: val_loss improved from 1.60865 to 1.60563, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5662 - accuracy: 0.3677 - val_loss: 1.6058 - val_accuracy: 0.3523

Epoch 00021: val_loss did not improve from 1.60563
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5571 - accuracy: 0.3712 - val_loss: 1.6043 - val_accuracy: 0.3516

Epoch 00022: val_loss improved from 1.60563 to 1.60426, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/1
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5478 - accuracy: 0.3765 - val_loss: 1.6090 - val_accuracy: 0.3507

Epoch 00023: val_loss did not improve from 1.60426
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5376 - accuracy: 0.3839 - val_loss: 1.6113 - val_accuracy: 0.3503

Epoch 00024: val_loss did not improve from 1.60426
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5268 - accuracy: 0.3906 - val_loss: 1.6187 - val_accuracy: 0.3477

Epoch 00025: val_loss did not improve from 1.60426
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5183 - accuracy: 0.3967 - val_loss: 1.6208 - val_accuracy: 0.3516

Epoch 00026: val_loss did not improve from 1.60426
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5015 - accuracy: 0.4063 - val_loss: 1.6319 - val_accuracy: 0.3497

Epoch 00027: val_loss did not improve from 1.60426
Epoch 28/100
83/83 [==============================] - 1s 16ms/step - loss: 1.4867 - accuracy: 0.4186 - val_loss: 1.6460 - val_accuracy: 0.3430

Epoch 00028: val_loss did not improve from 1.60426
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4717 - accuracy: 0.4306 - val_loss: 1.6667 - val_accuracy: 0.3399

Epoch 00029: val_loss did not improve from 1.60426
Epoch 30/100
83/83 [==============================] - 1s 16ms/step - loss: 1.4553 - accuracy: 0.4371 - val_loss: 1.6823 - val_accuracy: 0.3342

Epoch 00030: val_loss did not improve from 1.60426
Epoch 31/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4395 - accuracy: 0.4479 - val_loss: 1.6935 - val_accuracy: 0.3352

Epoch 00031: val_loss did not improve from 1.60426
Epoch 32/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4152 - accuracy: 0.4629 - val_loss: 1.7175 - val_accuracy: 0.3352

Epoch 00032: val_loss did not improve from 1.60426
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 51s 4ms/step - loss: 1.6199 - accuracy: 0.3359
Testing Loss = 1.619928, Testing Accuracy = 0.335889
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.8804 - accuracy: 0.1978 - val_loss: 10.6161 - val_accuracy: 0.2149

Epoch 00001: val_loss improved from inf to 10.61611, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9186 - accuracy: 0.2081 - val_loss: 7.4131 - val_accuracy: 0.2182

Epoch 00002: val_loss improved from 10.61611 to 7.41309, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2505 - accuracy: 0.2592 - val_loss: 5.2908 - val_accuracy: 0.2856

Epoch 00003: val_loss improved from 7.41309 to 5.29083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.5636 - accuracy: 0.2828 - val_loss: 3.9657 - val_accuracy: 0.2965

Epoch 00004: val_loss improved from 5.29083 to 3.96569, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5086 - accuracy: 0.2894 - val_loss: 3.1229 - val_accuracy: 0.3061

Epoch 00005: val_loss improved from 3.96569 to 3.12288, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8404 - accuracy: 0.2929 - val_loss: 2.5887 - val_accuracy: 0.3039

Epoch 00006: val_loss improved from 3.12288 to 2.58868, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4150 - accuracy: 0.2991 - val_loss: 2.2517 - val_accuracy: 0.3074

Epoch 00007: val_loss improved from 2.58868 to 2.25174, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1438 - accuracy: 0.3017 - val_loss: 2.0356 - val_accuracy: 0.3099

Epoch 00008: val_loss improved from 2.25174 to 2.03561, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9668 - accuracy: 0.3092 - val_loss: 1.8951 - val_accuracy: 0.3166

Epoch 00009: val_loss improved from 2.03561 to 1.89513, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8510 - accuracy: 0.3146 - val_loss: 1.8000 - val_accuracy: 0.3263

Epoch 00010: val_loss improved from 1.89513 to 1.80000, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7733 - accuracy: 0.3165 - val_loss: 1.7373 - val_accuracy: 0.3271

Epoch 00011: val_loss improved from 1.80000 to 1.73734, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7180 - accuracy: 0.3245 - val_loss: 1.6950 - val_accuracy: 0.3318

Epoch 00012: val_loss improved from 1.73734 to 1.69499, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6819 - accuracy: 0.3269 - val_loss: 1.6678 - val_accuracy: 0.3355

Epoch 00013: val_loss improved from 1.69499 to 1.66781, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6551 - accuracy: 0.3328 - val_loss: 1.6489 - val_accuracy: 0.3368

Epoch 00014: val_loss improved from 1.66781 to 1.64886, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6355 - accuracy: 0.3368 - val_loss: 1.6346 - val_accuracy: 0.3385

Epoch 00015: val_loss improved from 1.64886 to 1.63460, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6207 - accuracy: 0.3400 - val_loss: 1.6274 - val_accuracy: 0.3395

Epoch 00016: val_loss improved from 1.63460 to 1.62738, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6096 - accuracy: 0.3438 - val_loss: 1.6193 - val_accuracy: 0.3408

Epoch 00017: val_loss improved from 1.62738 to 1.61926, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5986 - accuracy: 0.3481 - val_loss: 1.6142 - val_accuracy: 0.3421

Epoch 00018: val_loss improved from 1.61926 to 1.61423, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5891 - accuracy: 0.3534 - val_loss: 1.6128 - val_accuracy: 0.3420

Epoch 00019: val_loss improved from 1.61423 to 1.61276, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5804 - accuracy: 0.3581 - val_loss: 1.6100 - val_accuracy: 0.3432

Epoch 00020: val_loss improved from 1.61276 to 1.61004, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5735 - accuracy: 0.3629 - val_loss: 1.6076 - val_accuracy: 0.3446

Epoch 00021: val_loss improved from 1.61004 to 1.60763, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5652 - accuracy: 0.3653 - val_loss: 1.6037 - val_accuracy: 0.3489

Epoch 00022: val_loss improved from 1.60763 to 1.60373, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5573 - accuracy: 0.3715 - val_loss: 1.6026 - val_accuracy: 0.3510

Epoch 00023: val_loss improved from 1.60373 to 1.60256, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5482 - accuracy: 0.3793 - val_loss: 1.6024 - val_accuracy: 0.3528

Epoch 00024: val_loss improved from 1.60256 to 1.60236, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/2
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5407 - accuracy: 0.3825 - val_loss: 1.6055 - val_accuracy: 0.3517

Epoch 00025: val_loss did not improve from 1.60236
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5305 - accuracy: 0.3871 - val_loss: 1.6099 - val_accuracy: 0.3502

Epoch 00026: val_loss did not improve from 1.60236
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5201 - accuracy: 0.3962 - val_loss: 1.6197 - val_accuracy: 0.3460

Epoch 00027: val_loss did not improve from 1.60236
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5106 - accuracy: 0.4022 - val_loss: 1.6308 - val_accuracy: 0.3436

Epoch 00028: val_loss did not improve from 1.60236
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5013 - accuracy: 0.4070 - val_loss: 1.6430 - val_accuracy: 0.3383

Epoch 00029: val_loss did not improve from 1.60236
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4857 - accuracy: 0.4175 - val_loss: 1.6363 - val_accuracy: 0.3451

Epoch 00030: val_loss did not improve from 1.60236
Epoch 31/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4733 - accuracy: 0.4269 - val_loss: 1.6510 - val_accuracy: 0.3468

Epoch 00031: val_loss did not improve from 1.60236
Epoch 32/100
83/83 [==============================] - 1s 16ms/step - loss: 1.4622 - accuracy: 0.4330 - val_loss: 1.6598 - val_accuracy: 0.3434

Epoch 00032: val_loss did not improve from 1.60236
Epoch 33/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4441 - accuracy: 0.4461 - val_loss: 1.6776 - val_accuracy: 0.3376

Epoch 00033: val_loss did not improve from 1.60236
Epoch 34/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4271 - accuracy: 0.4562 - val_loss: 1.6979 - val_accuracy: 0.3392

Epoch 00034: val_loss did not improve from 1.60236
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 53s 4ms/step - loss: 1.6160 - accuracy: 0.3360
Testing Loss = 1.615982, Testing Accuracy = 0.336038
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 17ms/step - loss: 12.9114 - accuracy: 0.1996 - val_loss: 10.6613 - val_accuracy: 0.2146

Epoch 00001: val_loss improved from inf to 10.66131, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9436 - accuracy: 0.2314 - val_loss: 7.4404 - val_accuracy: 0.2442

Epoch 00002: val_loss improved from 10.66131 to 7.44044, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2906 - accuracy: 0.2731 - val_loss: 5.3580 - val_accuracy: 0.2811

Epoch 00003: val_loss improved from 7.44044 to 5.35801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.6250 - accuracy: 0.2853 - val_loss: 4.0234 - val_accuracy: 0.2966

Epoch 00004: val_loss improved from 5.35801 to 4.02336, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5574 - accuracy: 0.2929 - val_loss: 3.1652 - val_accuracy: 0.3001

Epoch 00005: val_loss improved from 4.02336 to 3.16520, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8756 - accuracy: 0.2956 - val_loss: 2.6181 - val_accuracy: 0.3049

Epoch 00006: val_loss improved from 3.16520 to 2.61811, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4375 - accuracy: 0.3013 - val_loss: 2.2707 - val_accuracy: 0.3070

Epoch 00007: val_loss improved from 2.61811 to 2.27071, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1575 - accuracy: 0.3070 - val_loss: 2.0482 - val_accuracy: 0.3104

Epoch 00008: val_loss improved from 2.27071 to 2.04824, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9763 - accuracy: 0.3093 - val_loss: 1.9039 - val_accuracy: 0.3143

Epoch 00009: val_loss improved from 2.04824 to 1.90393, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8555 - accuracy: 0.3132 - val_loss: 1.8076 - val_accuracy: 0.3217

Epoch 00010: val_loss improved from 1.90393 to 1.80761, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7756 - accuracy: 0.3171 - val_loss: 1.7451 - val_accuracy: 0.3254

Epoch 00011: val_loss improved from 1.80761 to 1.74513, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7217 - accuracy: 0.3235 - val_loss: 1.7025 - val_accuracy: 0.3282

Epoch 00012: val_loss improved from 1.74513 to 1.70249, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6811 - accuracy: 0.3305 - val_loss: 1.6744 - val_accuracy: 0.3316

Epoch 00013: val_loss improved from 1.70249 to 1.67437, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6539 - accuracy: 0.3353 - val_loss: 1.6536 - val_accuracy: 0.3332

Epoch 00014: val_loss improved from 1.67437 to 1.65364, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 15/100
83/83 [==============================] - 1s 16ms/step - loss: 1.6337 - accuracy: 0.3387 - val_loss: 1.6387 - val_accuracy: 0.3378

Epoch 00015: val_loss improved from 1.65364 to 1.63872, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 16/100
83/83 [==============================] - 1s 16ms/step - loss: 1.6174 - accuracy: 0.3425 - val_loss: 1.6306 - val_accuracy: 0.3396

Epoch 00016: val_loss improved from 1.63872 to 1.63061, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6065 - accuracy: 0.3452 - val_loss: 1.6232 - val_accuracy: 0.3411

Epoch 00017: val_loss improved from 1.63061 to 1.62324, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5952 - accuracy: 0.3496 - val_loss: 1.6199 - val_accuracy: 0.3436

Epoch 00018: val_loss improved from 1.62324 to 1.61987, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5854 - accuracy: 0.3566 - val_loss: 1.6148 - val_accuracy: 0.3432

Epoch 00019: val_loss improved from 1.61987 to 1.61476, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5747 - accuracy: 0.3613 - val_loss: 1.6143 - val_accuracy: 0.3459

Epoch 00020: val_loss improved from 1.61476 to 1.61428, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/3
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5670 - accuracy: 0.3648 - val_loss: 1.6169 - val_accuracy: 0.3444

Epoch 00021: val_loss did not improve from 1.61428
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5558 - accuracy: 0.3726 - val_loss: 1.6232 - val_accuracy: 0.3426

Epoch 00022: val_loss did not improve from 1.61428
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5475 - accuracy: 0.3768 - val_loss: 1.6324 - val_accuracy: 0.3403

Epoch 00023: val_loss did not improve from 1.61428
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5370 - accuracy: 0.3853 - val_loss: 1.6329 - val_accuracy: 0.3421

Epoch 00024: val_loss did not improve from 1.61428
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5229 - accuracy: 0.3936 - val_loss: 1.6314 - val_accuracy: 0.3421

Epoch 00025: val_loss did not improve from 1.61428
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5103 - accuracy: 0.4005 - val_loss: 1.6385 - val_accuracy: 0.3433

Epoch 00026: val_loss did not improve from 1.61428
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4951 - accuracy: 0.4143 - val_loss: 1.6490 - val_accuracy: 0.3409

Epoch 00027: val_loss did not improve from 1.61428
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4821 - accuracy: 0.4201 - val_loss: 1.6633 - val_accuracy: 0.3366

Epoch 00028: val_loss did not improve from 1.61428
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4663 - accuracy: 0.4286 - val_loss: 1.6744 - val_accuracy: 0.3347

Epoch 00029: val_loss did not improve from 1.61428
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4453 - accuracy: 0.4459 - val_loss: 1.6918 - val_accuracy: 0.3322

Epoch 00030: val_loss did not improve from 1.61428
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 53s 4ms/step - loss: 1.6268 - accuracy: 0.3335
Testing Loss = 1.626824, Testing Accuracy = 0.333507
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.9233 - accuracy: 0.1962 - val_loss: 10.6670 - val_accuracy: 0.2146

Epoch 00001: val_loss improved from inf to 10.66704, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9626 - accuracy: 0.2177 - val_loss: 7.4521 - val_accuracy: 0.2227

Epoch 00002: val_loss improved from 10.66704 to 7.45213, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2856 - accuracy: 0.2616 - val_loss: 5.3334 - val_accuracy: 0.2869

Epoch 00003: val_loss improved from 7.45213 to 5.33342, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 4/100
83/83 [==============================] - 1s 14ms/step - loss: 4.6043 - accuracy: 0.2800 - val_loss: 4.0020 - val_accuracy: 0.2957

Epoch 00004: val_loss improved from 5.33342 to 4.00198, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5380 - accuracy: 0.2920 - val_loss: 3.1490 - val_accuracy: 0.2994

Epoch 00005: val_loss improved from 4.00198 to 3.14899, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8597 - accuracy: 0.2961 - val_loss: 2.6033 - val_accuracy: 0.3000

Epoch 00006: val_loss improved from 3.14899 to 2.60332, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4288 - accuracy: 0.2971 - val_loss: 2.2611 - val_accuracy: 0.3054

Epoch 00007: val_loss improved from 2.60332 to 2.26106, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1496 - accuracy: 0.3022 - val_loss: 2.0414 - val_accuracy: 0.3062

Epoch 00008: val_loss improved from 2.26106 to 2.04140, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9703 - accuracy: 0.3075 - val_loss: 1.8995 - val_accuracy: 0.3103

Epoch 00009: val_loss improved from 2.04140 to 1.89951, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8512 - accuracy: 0.3123 - val_loss: 1.8069 - val_accuracy: 0.3146

Epoch 00010: val_loss improved from 1.89951 to 1.80693, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7721 - accuracy: 0.3193 - val_loss: 1.7426 - val_accuracy: 0.3222

Epoch 00011: val_loss improved from 1.80693 to 1.74256, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7183 - accuracy: 0.3230 - val_loss: 1.7002 - val_accuracy: 0.3276

Epoch 00012: val_loss improved from 1.74256 to 1.70022, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6814 - accuracy: 0.3273 - val_loss: 1.6721 - val_accuracy: 0.3262

Epoch 00013: val_loss improved from 1.70022 to 1.67212, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6548 - accuracy: 0.3300 - val_loss: 1.6526 - val_accuracy: 0.3315

Epoch 00014: val_loss improved from 1.67212 to 1.65257, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6353 - accuracy: 0.3336 - val_loss: 1.6388 - val_accuracy: 0.3334

Epoch 00015: val_loss improved from 1.65257 to 1.63882, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6209 - accuracy: 0.3371 - val_loss: 1.6294 - val_accuracy: 0.3359

Epoch 00016: val_loss improved from 1.63882 to 1.62945, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6093 - accuracy: 0.3433 - val_loss: 1.6248 - val_accuracy: 0.3349

Epoch 00017: val_loss improved from 1.62945 to 1.62476, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5999 - accuracy: 0.3449 - val_loss: 1.6182 - val_accuracy: 0.3358

Epoch 00018: val_loss improved from 1.62476 to 1.61819, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5907 - accuracy: 0.3499 - val_loss: 1.6115 - val_accuracy: 0.3414

Epoch 00019: val_loss improved from 1.61819 to 1.61153, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5815 - accuracy: 0.3540 - val_loss: 1.6089 - val_accuracy: 0.3439

Epoch 00020: val_loss improved from 1.61153 to 1.60887, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5740 - accuracy: 0.3587 - val_loss: 1.6074 - val_accuracy: 0.3450

Epoch 00021: val_loss improved from 1.60887 to 1.60743, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/4
Epoch 22/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5642 - accuracy: 0.3638 - val_loss: 1.6103 - val_accuracy: 0.3445

Epoch 00022: val_loss did not improve from 1.60743
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5565 - accuracy: 0.3672 - val_loss: 1.6114 - val_accuracy: 0.3458

Epoch 00023: val_loss did not improve from 1.60743
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5468 - accuracy: 0.3766 - val_loss: 1.6169 - val_accuracy: 0.3438

Epoch 00024: val_loss did not improve from 1.60743
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5386 - accuracy: 0.3809 - val_loss: 1.6290 - val_accuracy: 0.3414

Epoch 00025: val_loss did not improve from 1.60743
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5288 - accuracy: 0.3880 - val_loss: 1.6253 - val_accuracy: 0.3450

Epoch 00026: val_loss did not improve from 1.60743
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5183 - accuracy: 0.3947 - val_loss: 1.6293 - val_accuracy: 0.3438

Epoch 00027: val_loss did not improve from 1.60743
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5036 - accuracy: 0.4027 - val_loss: 1.6398 - val_accuracy: 0.3406

Epoch 00028: val_loss did not improve from 1.60743
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4894 - accuracy: 0.4119 - val_loss: 1.6501 - val_accuracy: 0.3396

Epoch 00029: val_loss did not improve from 1.60743
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4754 - accuracy: 0.4210 - val_loss: 1.6664 - val_accuracy: 0.3363

Epoch 00030: val_loss did not improve from 1.60743
Epoch 31/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4604 - accuracy: 0.4343 - val_loss: 1.6761 - val_accuracy: 0.3351

Epoch 00031: val_loss did not improve from 1.60743
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 51s 4ms/step - loss: 1.6192 - accuracy: 0.3338
Testing Loss = 1.619180, Testing Accuracy = 0.333805
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 17ms/step - loss: 12.9214 - accuracy: 0.1995 - val_loss: 10.6767 - val_accuracy: 0.2146

Epoch 00001: val_loss improved from inf to 10.67670, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9677 - accuracy: 0.2216 - val_loss: 7.4622 - val_accuracy: 0.2399

Epoch 00002: val_loss improved from 10.67670 to 7.46222, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.3034 - accuracy: 0.2672 - val_loss: 5.3581 - val_accuracy: 0.2810

Epoch 00003: val_loss improved from 7.46222 to 5.35805, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.6223 - accuracy: 0.2829 - val_loss: 4.0176 - val_accuracy: 0.2901

Epoch 00004: val_loss improved from 5.35805 to 4.01758, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5543 - accuracy: 0.2878 - val_loss: 3.1617 - val_accuracy: 0.2968

Epoch 00005: val_loss improved from 4.01758 to 3.16172, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8727 - accuracy: 0.2944 - val_loss: 2.6152 - val_accuracy: 0.3000

Epoch 00006: val_loss improved from 3.16172 to 2.61522, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4368 - accuracy: 0.2980 - val_loss: 2.2708 - val_accuracy: 0.3042

Epoch 00007: val_loss improved from 2.61522 to 2.27082, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1577 - accuracy: 0.3050 - val_loss: 2.0490 - val_accuracy: 0.3075

Epoch 00008: val_loss improved from 2.27082 to 2.04898, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9766 - accuracy: 0.3074 - val_loss: 1.9047 - val_accuracy: 0.3141

Epoch 00009: val_loss improved from 2.04898 to 1.90471, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8569 - accuracy: 0.3131 - val_loss: 1.8078 - val_accuracy: 0.3196

Epoch 00010: val_loss improved from 1.90471 to 1.80776, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7758 - accuracy: 0.3193 - val_loss: 1.7439 - val_accuracy: 0.3258

Epoch 00011: val_loss improved from 1.80776 to 1.74393, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7227 - accuracy: 0.3238 - val_loss: 1.7001 - val_accuracy: 0.3295

Epoch 00012: val_loss improved from 1.74393 to 1.70015, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6836 - accuracy: 0.3301 - val_loss: 1.6727 - val_accuracy: 0.3291

Epoch 00013: val_loss improved from 1.70015 to 1.67275, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6565 - accuracy: 0.3315 - val_loss: 1.6558 - val_accuracy: 0.3310

Epoch 00014: val_loss improved from 1.67275 to 1.65581, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6374 - accuracy: 0.3350 - val_loss: 1.6405 - val_accuracy: 0.3336

Epoch 00015: val_loss improved from 1.65581 to 1.64054, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6226 - accuracy: 0.3407 - val_loss: 1.6298 - val_accuracy: 0.3361

Epoch 00016: val_loss improved from 1.64054 to 1.62978, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 17/100
83/83 [==============================] - 1s 16ms/step - loss: 1.6105 - accuracy: 0.3452 - val_loss: 1.6225 - val_accuracy: 0.3400

Epoch 00017: val_loss improved from 1.62978 to 1.62253, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6001 - accuracy: 0.3460 - val_loss: 1.6166 - val_accuracy: 0.3418

Epoch 00018: val_loss improved from 1.62253 to 1.61656, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5892 - accuracy: 0.3538 - val_loss: 1.6111 - val_accuracy: 0.3458

Epoch 00019: val_loss improved from 1.61656 to 1.61105, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5810 - accuracy: 0.3587 - val_loss: 1.6074 - val_accuracy: 0.3483

Epoch 00020: val_loss improved from 1.61105 to 1.60741, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 21/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5714 - accuracy: 0.3642 - val_loss: 1.6053 - val_accuracy: 0.3483

Epoch 00021: val_loss improved from 1.60741 to 1.60533, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/5
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5635 - accuracy: 0.3650 - val_loss: 1.6076 - val_accuracy: 0.3429

Epoch 00022: val_loss did not improve from 1.60533
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5568 - accuracy: 0.3744 - val_loss: 1.6113 - val_accuracy: 0.3435

Epoch 00023: val_loss did not improve from 1.60533
Epoch 24/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5476 - accuracy: 0.3774 - val_loss: 1.6136 - val_accuracy: 0.3438

Epoch 00024: val_loss did not improve from 1.60533
Epoch 25/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5382 - accuracy: 0.3850 - val_loss: 1.6224 - val_accuracy: 0.3408

Epoch 00025: val_loss did not improve from 1.60533
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5299 - accuracy: 0.3889 - val_loss: 1.6234 - val_accuracy: 0.3453

Epoch 00026: val_loss did not improve from 1.60533
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5157 - accuracy: 0.3997 - val_loss: 1.6327 - val_accuracy: 0.3430

Epoch 00027: val_loss did not improve from 1.60533
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5083 - accuracy: 0.4042 - val_loss: 1.6412 - val_accuracy: 0.3388

Epoch 00028: val_loss did not improve from 1.60533
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4966 - accuracy: 0.4124 - val_loss: 1.6422 - val_accuracy: 0.3407

Epoch 00029: val_loss did not improve from 1.60533
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4789 - accuracy: 0.4217 - val_loss: 1.6519 - val_accuracy: 0.3404

Epoch 00030: val_loss did not improve from 1.60533
Epoch 31/100
83/83 [==============================] - 1s 14ms/step - loss: 1.4646 - accuracy: 0.4312 - val_loss: 1.6625 - val_accuracy: 0.3416

Epoch 00031: val_loss did not improve from 1.60533
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 51s 4ms/step - loss: 1.6167 - accuracy: 0.3357
Testing Loss = 1.616680, Testing Accuracy = 0.335740
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.8759 - accuracy: 0.1999 - val_loss: 10.6060 - val_accuracy: 0.2146

Epoch 00001: val_loss improved from inf to 10.60596, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 2/100
83/83 [==============================] - 1s 14ms/step - loss: 8.8808 - accuracy: 0.2311 - val_loss: 7.3883 - val_accuracy: 0.2567

Epoch 00002: val_loss improved from 10.60596 to 7.38825, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2405 - accuracy: 0.2724 - val_loss: 5.3084 - val_accuracy: 0.2894

Epoch 00003: val_loss improved from 7.38825 to 5.30839, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.5835 - accuracy: 0.2841 - val_loss: 3.9863 - val_accuracy: 0.3022

Epoch 00004: val_loss improved from 5.30839 to 3.98631, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5284 - accuracy: 0.2896 - val_loss: 3.1408 - val_accuracy: 0.3036

Epoch 00005: val_loss improved from 3.98631 to 3.14077, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8557 - accuracy: 0.2937 - val_loss: 2.6013 - val_accuracy: 0.3058

Epoch 00006: val_loss improved from 3.14077 to 2.60128, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 7/100
83/83 [==============================] - 1s 14ms/step - loss: 2.4250 - accuracy: 0.3010 - val_loss: 2.2606 - val_accuracy: 0.3070

Epoch 00007: val_loss improved from 2.60128 to 2.26057, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1489 - accuracy: 0.3023 - val_loss: 2.0419 - val_accuracy: 0.3130

Epoch 00008: val_loss improved from 2.26057 to 2.04186, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9698 - accuracy: 0.3082 - val_loss: 1.8978 - val_accuracy: 0.3182

Epoch 00009: val_loss improved from 2.04186 to 1.89777, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8516 - accuracy: 0.3151 - val_loss: 1.8021 - val_accuracy: 0.3286

Epoch 00010: val_loss improved from 1.89777 to 1.80206, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7704 - accuracy: 0.3228 - val_loss: 1.7402 - val_accuracy: 0.3300

Epoch 00011: val_loss improved from 1.80206 to 1.74020, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7154 - accuracy: 0.3279 - val_loss: 1.6979 - val_accuracy: 0.3336

Epoch 00012: val_loss improved from 1.74020 to 1.69787, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6780 - accuracy: 0.3313 - val_loss: 1.6688 - val_accuracy: 0.3356

Epoch 00013: val_loss improved from 1.69787 to 1.66876, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6535 - accuracy: 0.3337 - val_loss: 1.6499 - val_accuracy: 0.3392

Epoch 00014: val_loss improved from 1.66876 to 1.64993, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6323 - accuracy: 0.3395 - val_loss: 1.6348 - val_accuracy: 0.3425

Epoch 00015: val_loss improved from 1.64993 to 1.63477, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6152 - accuracy: 0.3451 - val_loss: 1.6280 - val_accuracy: 0.3440

Epoch 00016: val_loss improved from 1.63477 to 1.62805, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6050 - accuracy: 0.3463 - val_loss: 1.6241 - val_accuracy: 0.3412

Epoch 00017: val_loss improved from 1.62805 to 1.62414, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5927 - accuracy: 0.3512 - val_loss: 1.6127 - val_accuracy: 0.3476

Epoch 00018: val_loss improved from 1.62414 to 1.61267, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5844 - accuracy: 0.3588 - val_loss: 1.6098 - val_accuracy: 0.3492

Epoch 00019: val_loss improved from 1.61267 to 1.60985, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5757 - accuracy: 0.3596 - val_loss: 1.6063 - val_accuracy: 0.3496

Epoch 00020: val_loss improved from 1.60985 to 1.60633, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/6
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5647 - accuracy: 0.3662 - val_loss: 1.6098 - val_accuracy: 0.3460

Epoch 00021: val_loss did not improve from 1.60633
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5573 - accuracy: 0.3707 - val_loss: 1.6117 - val_accuracy: 0.3439

Epoch 00022: val_loss did not improve from 1.60633
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5487 - accuracy: 0.3757 - val_loss: 1.6141 - val_accuracy: 0.3442

Epoch 00023: val_loss did not improve from 1.60633
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5380 - accuracy: 0.3830 - val_loss: 1.6189 - val_accuracy: 0.3419

Epoch 00024: val_loss did not improve from 1.60633
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5284 - accuracy: 0.3888 - val_loss: 1.6279 - val_accuracy: 0.3411

Epoch 00025: val_loss did not improve from 1.60633
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5176 - accuracy: 0.3972 - val_loss: 1.6319 - val_accuracy: 0.3436

Epoch 00026: val_loss did not improve from 1.60633
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5056 - accuracy: 0.4033 - val_loss: 1.6312 - val_accuracy: 0.3489

Epoch 00027: val_loss did not improve from 1.60633
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4901 - accuracy: 0.4142 - val_loss: 1.6440 - val_accuracy: 0.3459

Epoch 00028: val_loss did not improve from 1.60633
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4781 - accuracy: 0.4212 - val_loss: 1.6519 - val_accuracy: 0.3447

Epoch 00029: val_loss did not improve from 1.60633
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4645 - accuracy: 0.4313 - val_loss: 1.6639 - val_accuracy: 0.3430

Epoch 00030: val_loss did not improve from 1.60633
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 51s 4ms/step - loss: 1.6171 - accuracy: 0.3378
Testing Loss = 1.617086, Testing Accuracy = 0.337824
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 17ms/step - loss: 12.9066 - accuracy: 0.1988 - val_loss: 10.6484 - val_accuracy: 0.2145

Epoch 00001: val_loss improved from inf to 10.64839, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9478 - accuracy: 0.2123 - val_loss: 7.4413 - val_accuracy: 0.2252

Epoch 00002: val_loss improved from 10.64839 to 7.44133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2744 - accuracy: 0.2612 - val_loss: 5.3194 - val_accuracy: 0.2911

Epoch 00003: val_loss improved from 7.44133 to 5.31940, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.5885 - accuracy: 0.2806 - val_loss: 3.9866 - val_accuracy: 0.3020

Epoch 00004: val_loss improved from 5.31940 to 3.98658, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5279 - accuracy: 0.2898 - val_loss: 3.1387 - val_accuracy: 0.3038

Epoch 00005: val_loss improved from 3.98658 to 3.13866, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8529 - accuracy: 0.2969 - val_loss: 2.6004 - val_accuracy: 0.3077

Epoch 00006: val_loss improved from 3.13866 to 2.60037, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4246 - accuracy: 0.3003 - val_loss: 2.2592 - val_accuracy: 0.3099

Epoch 00007: val_loss improved from 2.60037 to 2.25920, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1493 - accuracy: 0.3083 - val_loss: 2.0399 - val_accuracy: 0.3131

Epoch 00008: val_loss improved from 2.25920 to 2.03989, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 9/100
83/83 [==============================] - 1s 16ms/step - loss: 1.9685 - accuracy: 0.3110 - val_loss: 1.8962 - val_accuracy: 0.3208

Epoch 00009: val_loss improved from 2.03989 to 1.89618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8509 - accuracy: 0.3179 - val_loss: 1.8014 - val_accuracy: 0.3268

Epoch 00010: val_loss improved from 1.89618 to 1.80144, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7715 - accuracy: 0.3226 - val_loss: 1.7401 - val_accuracy: 0.3285

Epoch 00011: val_loss improved from 1.80144 to 1.74008, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7153 - accuracy: 0.3308 - val_loss: 1.6985 - val_accuracy: 0.3308

Epoch 00012: val_loss improved from 1.74008 to 1.69853, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6791 - accuracy: 0.3300 - val_loss: 1.6679 - val_accuracy: 0.3369

Epoch 00013: val_loss improved from 1.69853 to 1.66786, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6519 - accuracy: 0.3369 - val_loss: 1.6504 - val_accuracy: 0.3362

Epoch 00014: val_loss improved from 1.66786 to 1.65042, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6303 - accuracy: 0.3419 - val_loss: 1.6357 - val_accuracy: 0.3392

Epoch 00015: val_loss improved from 1.65042 to 1.63569, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6147 - accuracy: 0.3453 - val_loss: 1.6263 - val_accuracy: 0.3413

Epoch 00016: val_loss improved from 1.63569 to 1.62628, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6026 - accuracy: 0.3510 - val_loss: 1.6192 - val_accuracy: 0.3434

Epoch 00017: val_loss improved from 1.62628 to 1.61923, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5910 - accuracy: 0.3556 - val_loss: 1.6148 - val_accuracy: 0.3441

Epoch 00018: val_loss improved from 1.61923 to 1.61478, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5809 - accuracy: 0.3597 - val_loss: 1.6105 - val_accuracy: 0.3479

Epoch 00019: val_loss improved from 1.61478 to 1.61051, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5712 - accuracy: 0.3652 - val_loss: 1.6081 - val_accuracy: 0.3497

Epoch 00020: val_loss improved from 1.61051 to 1.60814, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5619 - accuracy: 0.3726 - val_loss: 1.6069 - val_accuracy: 0.3478

Epoch 00021: val_loss improved from 1.60814 to 1.60689, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/7
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5496 - accuracy: 0.3765 - val_loss: 1.6089 - val_accuracy: 0.3481

Epoch 00022: val_loss did not improve from 1.60689
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5440 - accuracy: 0.3822 - val_loss: 1.6178 - val_accuracy: 0.3436

Epoch 00023: val_loss did not improve from 1.60689
Epoch 24/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5316 - accuracy: 0.3903 - val_loss: 1.6260 - val_accuracy: 0.3412

Epoch 00024: val_loss did not improve from 1.60689
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5210 - accuracy: 0.3983 - val_loss: 1.6262 - val_accuracy: 0.3456

Epoch 00025: val_loss did not improve from 1.60689
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5079 - accuracy: 0.4060 - val_loss: 1.6288 - val_accuracy: 0.3460

Epoch 00026: val_loss did not improve from 1.60689
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4956 - accuracy: 0.4132 - val_loss: 1.6411 - val_accuracy: 0.3438

Epoch 00027: val_loss did not improve from 1.60689
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4806 - accuracy: 0.4246 - val_loss: 1.6533 - val_accuracy: 0.3417

Epoch 00028: val_loss did not improve from 1.60689
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4641 - accuracy: 0.4343 - val_loss: 1.6660 - val_accuracy: 0.3420

Epoch 00029: val_loss did not improve from 1.60689
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4482 - accuracy: 0.4452 - val_loss: 1.6779 - val_accuracy: 0.3411

Epoch 00030: val_loss did not improve from 1.60689
Epoch 31/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4262 - accuracy: 0.4558 - val_loss: 1.7020 - val_accuracy: 0.3407

Epoch 00031: val_loss did not improve from 1.60689
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 51s 4ms/step - loss: 1.6205 - accuracy: 0.3360
Testing Loss = 1.620472, Testing Accuracy = 0.335963
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.9026 - accuracy: 0.1954 - val_loss: 10.6408 - val_accuracy: 0.2146

Epoch 00001: val_loss improved from inf to 10.64079, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9299 - accuracy: 0.2213 - val_loss: 7.4191 - val_accuracy: 0.2362

Epoch 00002: val_loss improved from 10.64079 to 7.41912, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2593 - accuracy: 0.2642 - val_loss: 5.3179 - val_accuracy: 0.2859

Epoch 00003: val_loss improved from 7.41912 to 5.31793, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.5878 - accuracy: 0.2849 - val_loss: 3.9914 - val_accuracy: 0.2976

Epoch 00004: val_loss improved from 5.31793 to 3.99141, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5316 - accuracy: 0.2913 - val_loss: 3.1423 - val_accuracy: 0.3061

Epoch 00005: val_loss improved from 3.99141 to 3.14226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8570 - accuracy: 0.2949 - val_loss: 2.6026 - val_accuracy: 0.3032

Epoch 00006: val_loss improved from 3.14226 to 2.60262, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4256 - accuracy: 0.3010 - val_loss: 2.2622 - val_accuracy: 0.3043

Epoch 00007: val_loss improved from 2.60262 to 2.26218, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1489 - accuracy: 0.3029 - val_loss: 2.0432 - val_accuracy: 0.3041

Epoch 00008: val_loss improved from 2.26218 to 2.04320, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9705 - accuracy: 0.3089 - val_loss: 1.9027 - val_accuracy: 0.3122

Epoch 00009: val_loss improved from 2.04320 to 1.90271, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8519 - accuracy: 0.3128 - val_loss: 1.8080 - val_accuracy: 0.3192

Epoch 00010: val_loss improved from 1.90271 to 1.80803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7708 - accuracy: 0.3191 - val_loss: 1.7444 - val_accuracy: 0.3251

Epoch 00011: val_loss improved from 1.80803 to 1.74441, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7188 - accuracy: 0.3250 - val_loss: 1.7002 - val_accuracy: 0.3318

Epoch 00012: val_loss improved from 1.74441 to 1.70021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6798 - accuracy: 0.3294 - val_loss: 1.6719 - val_accuracy: 0.3320

Epoch 00013: val_loss improved from 1.70021 to 1.67191, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6523 - accuracy: 0.3330 - val_loss: 1.6524 - val_accuracy: 0.3374

Epoch 00014: val_loss improved from 1.67191 to 1.65240, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6323 - accuracy: 0.3395 - val_loss: 1.6411 - val_accuracy: 0.3375

Epoch 00015: val_loss improved from 1.65240 to 1.64109, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6167 - accuracy: 0.3405 - val_loss: 1.6281 - val_accuracy: 0.3422

Epoch 00016: val_loss improved from 1.64109 to 1.62813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6041 - accuracy: 0.3455 - val_loss: 1.6203 - val_accuracy: 0.3446

Epoch 00017: val_loss improved from 1.62813 to 1.62034, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5924 - accuracy: 0.3524 - val_loss: 1.6151 - val_accuracy: 0.3447

Epoch 00018: val_loss improved from 1.62034 to 1.61512, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 19/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5815 - accuracy: 0.3591 - val_loss: 1.6144 - val_accuracy: 0.3463

Epoch 00019: val_loss improved from 1.61512 to 1.61443, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/8
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5716 - accuracy: 0.3628 - val_loss: 1.6158 - val_accuracy: 0.3447

Epoch 00020: val_loss did not improve from 1.61443
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5628 - accuracy: 0.3673 - val_loss: 1.6165 - val_accuracy: 0.3448

Epoch 00021: val_loss did not improve from 1.61443
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5532 - accuracy: 0.3727 - val_loss: 1.6184 - val_accuracy: 0.3450

Epoch 00022: val_loss did not improve from 1.61443
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5445 - accuracy: 0.3791 - val_loss: 1.6250 - val_accuracy: 0.3450

Epoch 00023: val_loss did not improve from 1.61443
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5333 - accuracy: 0.3877 - val_loss: 1.6243 - val_accuracy: 0.3446

Epoch 00024: val_loss did not improve from 1.61443
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5234 - accuracy: 0.3925 - val_loss: 1.6331 - val_accuracy: 0.3421

Epoch 00025: val_loss did not improve from 1.61443
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5085 - accuracy: 0.4030 - val_loss: 1.6340 - val_accuracy: 0.3438

Epoch 00026: val_loss did not improve from 1.61443
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4929 - accuracy: 0.4114 - val_loss: 1.6455 - val_accuracy: 0.3425

Epoch 00027: val_loss did not improve from 1.61443
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4804 - accuracy: 0.4181 - val_loss: 1.6531 - val_accuracy: 0.3415

Epoch 00028: val_loss did not improve from 1.61443
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4653 - accuracy: 0.4284 - val_loss: 1.6659 - val_accuracy: 0.3398

Epoch 00029: val_loss did not improve from 1.61443
Epoch 00029: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 50s 4ms/step - loss: 1.6262 - accuracy: 0.3303
Testing Loss = 1.626168, Testing Accuracy = 0.330307
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.9243 - accuracy: 0.1992 - val_loss: 10.6651 - val_accuracy: 0.2158

Epoch 00001: val_loss improved from inf to 10.66512, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9652 - accuracy: 0.2092 - val_loss: 7.4573 - val_accuracy: 0.2237

Epoch 00002: val_loss improved from 10.66512 to 7.45727, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2872 - accuracy: 0.2585 - val_loss: 5.3247 - val_accuracy: 0.2790

Epoch 00003: val_loss improved from 7.45727 to 5.32469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 4/100
83/83 [==============================] - 1s 14ms/step - loss: 4.5932 - accuracy: 0.2799 - val_loss: 3.9895 - val_accuracy: 0.2943

Epoch 00004: val_loss improved from 5.32469 to 3.98955, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5293 - accuracy: 0.2891 - val_loss: 3.1394 - val_accuracy: 0.2991

Epoch 00005: val_loss improved from 3.98955 to 3.13944, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8557 - accuracy: 0.2927 - val_loss: 2.6002 - val_accuracy: 0.3009

Epoch 00006: val_loss improved from 3.13944 to 2.60021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4250 - accuracy: 0.3009 - val_loss: 2.2580 - val_accuracy: 0.3036

Epoch 00007: val_loss improved from 2.60021 to 2.25801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1487 - accuracy: 0.3023 - val_loss: 2.0419 - val_accuracy: 0.3066

Epoch 00008: val_loss improved from 2.25801 to 2.04187, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9709 - accuracy: 0.3091 - val_loss: 1.8991 - val_accuracy: 0.3118

Epoch 00009: val_loss improved from 2.04187 to 1.89907, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8525 - accuracy: 0.3105 - val_loss: 1.8038 - val_accuracy: 0.3229

Epoch 00010: val_loss improved from 1.89907 to 1.80377, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7740 - accuracy: 0.3141 - val_loss: 1.7411 - val_accuracy: 0.3257

Epoch 00011: val_loss improved from 1.80377 to 1.74115, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 12/100
83/83 [==============================] - 1s 14ms/step - loss: 1.7196 - accuracy: 0.3231 - val_loss: 1.6996 - val_accuracy: 0.3293

Epoch 00012: val_loss improved from 1.74115 to 1.69955, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6812 - accuracy: 0.3301 - val_loss: 1.6711 - val_accuracy: 0.3319

Epoch 00013: val_loss improved from 1.69955 to 1.67111, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 14/100
83/83 [==============================] - 1s 16ms/step - loss: 1.6568 - accuracy: 0.3297 - val_loss: 1.6530 - val_accuracy: 0.3299

Epoch 00014: val_loss improved from 1.67111 to 1.65297, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 15/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6360 - accuracy: 0.3363 - val_loss: 1.6387 - val_accuracy: 0.3319

Epoch 00015: val_loss improved from 1.65297 to 1.63874, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6212 - accuracy: 0.3386 - val_loss: 1.6288 - val_accuracy: 0.3375

Epoch 00016: val_loss improved from 1.63874 to 1.62879, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 17/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6096 - accuracy: 0.3426 - val_loss: 1.6210 - val_accuracy: 0.3384

Epoch 00017: val_loss improved from 1.62879 to 1.62101, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5993 - accuracy: 0.3464 - val_loss: 1.6173 - val_accuracy: 0.3407

Epoch 00018: val_loss improved from 1.62101 to 1.61735, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5912 - accuracy: 0.3524 - val_loss: 1.6119 - val_accuracy: 0.3461

Epoch 00019: val_loss improved from 1.61735 to 1.61195, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5806 - accuracy: 0.3582 - val_loss: 1.6075 - val_accuracy: 0.3464

Epoch 00020: val_loss improved from 1.61195 to 1.60753, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5735 - accuracy: 0.3611 - val_loss: 1.6062 - val_accuracy: 0.3475

Epoch 00021: val_loss improved from 1.60753 to 1.60621, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-11/Try/9
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5647 - accuracy: 0.3646 - val_loss: 1.6100 - val_accuracy: 0.3400

Epoch 00022: val_loss did not improve from 1.60621
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5564 - accuracy: 0.3709 - val_loss: 1.6125 - val_accuracy: 0.3452

Epoch 00023: val_loss did not improve from 1.60621
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5494 - accuracy: 0.3737 - val_loss: 1.6189 - val_accuracy: 0.3438

Epoch 00024: val_loss did not improve from 1.60621
Epoch 25/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5397 - accuracy: 0.3832 - val_loss: 1.6177 - val_accuracy: 0.3463

Epoch 00025: val_loss did not improve from 1.60621
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5302 - accuracy: 0.3868 - val_loss: 1.6296 - val_accuracy: 0.3424

Epoch 00026: val_loss did not improve from 1.60621
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5198 - accuracy: 0.3957 - val_loss: 1.6295 - val_accuracy: 0.3409

Epoch 00027: val_loss did not improve from 1.60621
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5059 - accuracy: 0.4059 - val_loss: 1.6317 - val_accuracy: 0.3427

Epoch 00028: val_loss did not improve from 1.60621
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4941 - accuracy: 0.4113 - val_loss: 1.6404 - val_accuracy: 0.3430

Epoch 00029: val_loss did not improve from 1.60621
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4793 - accuracy: 0.4191 - val_loss: 1.6566 - val_accuracy: 0.3427

Epoch 00030: val_loss did not improve from 1.60621
Epoch 31/100
83/83 [==============================] - 1s 14ms/step - loss: 1.4646 - accuracy: 0.4310 - val_loss: 1.6719 - val_accuracy: 0.3399

Epoch 00031: val_loss did not improve from 1.60621
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 51s 4ms/step - loss: 1.6185 - accuracy: 0.3347
Testing Loss = 1.618484, Testing Accuracy = 0.334698
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 81.43 +- 0.1111 %)
$W^-/W^-$ (auc = 80.81 +- 0.0884 %)
$Z/Z$ (auc = 65.88 +- 0.5802 %)
$W^+/W^-$ (auc = 65.23 +- 0.4659 %)
$W^+/Z$$ (auc = 65.51 +- 0.1443 %)
$W^-/Z$ (auc = 67.20 +- 0.1707 %)
The summarized testing accuracy = 33.44 +- 0.2371 %, with the loss = 1.6203 +- 0.003590
