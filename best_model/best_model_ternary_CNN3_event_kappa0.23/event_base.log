

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-12-12 01:01:27.776277
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
63 - accuracy: 0.1989     83/Unknown - 99s 1s/step - loss: 12.4515 - accuracy: 0.1991
Epoch 1: val_loss improved from inf to 8.71981, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 109s 1s/step - loss: 12.4515 - accuracy: 0.1991 - val_loss: 8.7198 - val_accuracy: 0.2105
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.7865 - accuracy: 0.2078
Epoch 2: val_loss improved from 8.71981 to 5.35444, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 103s 1s/step - loss: 6.7865 - accuracy: 0.2078 - val_loss: 5.3544 - val_accuracy: 0.2120
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5563 - accuracy: 0.2306
Epoch 3: val_loss improved from 5.35444 to 3.95510, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 103s 1s/step - loss: 4.5563 - accuracy: 0.2306 - val_loss: 3.9551 - val_accuracy: 0.2396
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4729 - accuracy: 0.2870
Epoch 4: val_loss improved from 3.95510 to 3.18608, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 102s 1s/step - loss: 3.4729 - accuracy: 0.2870 - val_loss: 3.1861 - val_accuracy: 0.2755
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8882 - accuracy: 0.2995
Epoch 5: val_loss improved from 3.18608 to 2.70769, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 102s 1s/step - loss: 2.8882 - accuracy: 0.2995 - val_loss: 2.7077 - val_accuracy: 0.2980
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5060 - accuracy: 0.3075
Epoch 6: val_loss improved from 2.70769 to 2.37156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 102s 1s/step - loss: 2.5060 - accuracy: 0.3075 - val_loss: 2.3716 - val_accuracy: 0.3104
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2384 - accuracy: 0.3135
Epoch 7: val_loss improved from 2.37156 to 2.13496, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 102s 1s/step - loss: 2.2384 - accuracy: 0.3135 - val_loss: 2.1350 - val_accuracy: 0.3248
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0508 - accuracy: 0.3235
Epoch 8: val_loss improved from 2.13496 to 1.97102, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 101s 1s/step - loss: 2.0508 - accuracy: 0.3235 - val_loss: 1.9710 - val_accuracy: 0.3263
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9152 - accuracy: 0.3310
Epoch 9: val_loss improved from 1.97102 to 1.86096, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 102s 1s/step - loss: 1.9152 - accuracy: 0.3310 - val_loss: 1.8610 - val_accuracy: 0.3343
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8225 - accuracy: 0.3367
Epoch 10: val_loss improved from 1.86096 to 1.78264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 101s 1s/step - loss: 1.8225 - accuracy: 0.3367 - val_loss: 1.7826 - val_accuracy: 0.3396
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7530 - accuracy: 0.3488
Epoch 11: val_loss improved from 1.78264 to 1.72855, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 102s 1s/step - loss: 1.7530 - accuracy: 0.3488 - val_loss: 1.7285 - val_accuracy: 0.3445
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7061 - accuracy: 0.3539
Epoch 12: val_loss improved from 1.72855 to 1.69008, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 101s 1s/step - loss: 1.7061 - accuracy: 0.3539 - val_loss: 1.6901 - val_accuracy: 0.3493
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6667 - accuracy: 0.3588
Epoch 13: val_loss improved from 1.69008 to 1.65642, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 102s 1s/step - loss: 1.6667 - accuracy: 0.3588 - val_loss: 1.6564 - val_accuracy: 0.3547
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6381 - accuracy: 0.3674
Epoch 14: val_loss improved from 1.65642 to 1.63065, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 101s 1s/step - loss: 1.6381 - accuracy: 0.3674 - val_loss: 1.6306 - val_accuracy: 0.3683
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6154 - accuracy: 0.3757
Epoch 15: val_loss improved from 1.63065 to 1.61232, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 101s 1s/step - loss: 1.6154 - accuracy: 0.3757 - val_loss: 1.6123 - val_accuracy: 0.3718
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5964 - accuracy: 0.3798
Epoch 16: val_loss improved from 1.61232 to 1.59643, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 101s 1s/step - loss: 1.5964 - accuracy: 0.3798 - val_loss: 1.5964 - val_accuracy: 0.3828
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5781 - accuracy: 0.3891
Epoch 17: val_loss improved from 1.59643 to 1.58621, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 102s 1s/step - loss: 1.5781 - accuracy: 0.3891 - val_loss: 1.5862 - val_accuracy: 0.3875
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5647 - accuracy: 0.3982
Epoch 18: val_loss improved from 1.58621 to 1.57952, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 101s 1s/step - loss: 1.5647 - accuracy: 0.3982 - val_loss: 1.5795 - val_accuracy: 0.3891
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5585 - accuracy: 0.3996
Epoch 19: val_loss improved from 1.57952 to 1.57448, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 101s 1s/step - loss: 1.5585 - accuracy: 0.3996 - val_loss: 1.5745 - val_accuracy: 0.3924
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5454 - accuracy: 0.4066
Epoch 20: val_loss improved from 1.57448 to 1.57158, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 101s 1s/step - loss: 1.5454 - accuracy: 0.4066 - val_loss: 1.5716 - val_accuracy: 0.3942
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5394 - accuracy: 0.4106
Epoch 21: val_loss improved from 1.57158 to 1.57111, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 101s 1s/step - loss: 1.5394 - accuracy: 0.4106 - val_loss: 1.5711 - val_accuracy: 0.3929
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5278 - accuracy: 0.4160
Epoch 22: val_loss improved from 1.57111 to 1.56745, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 101s 1s/step - loss: 1.5278 - accuracy: 0.4160 - val_loss: 1.5674 - val_accuracy: 0.3957
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5204 - accuracy: 0.4212
Epoch 23: val_loss improved from 1.56745 to 1.56714, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
83/83 [==============================] - 95s 1s/step - loss: 1.5204 - accuracy: 0.4212 - val_loss: 1.5671 - val_accuracy: 0.3965
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5130 - accuracy: 0.4249
Epoch 24: val_loss did not improve from 1.56714
83/83 [==============================] - 95s 1s/step - loss: 1.5130 - accuracy: 0.4249 - val_loss: 1.5688 - val_accuracy: 0.3954
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5088 - accuracy: 0.4299
Epoch 25: val_loss did not improve from 1.56714
83/83 [==============================] - 94s 1s/step - loss: 1.5088 - accuracy: 0.4299 - val_loss: 1.5709 - val_accuracy: 0.3936
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.4981 - accuracy: 0.4378
Epoch 26: val_loss did not improve from 1.56714
83/83 [==============================] - 95s 1s/step - loss: 1.4981 - accuracy: 0.4378 - val_loss: 1.5698 - val_accuracy: 0.3985
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4923 - accuracy: 0.4410
Epoch 27: val_loss did not improve from 1.56714
83/83 [==============================] - 92s 1s/step - loss: 1.4923 - accuracy: 0.4410 - val_loss: 1.5732 - val_accuracy: 0.3956
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4864 - accuracy: 0.4461
Epoch 28: val_loss did not improve from 1.56714
83/83 [==============================] - 92s 1s/step - loss: 1.4864 - accuracy: 0.4461 - val_loss: 1.5804 - val_accuracy: 0.3969
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4761 - accuracy: 0.4516
Epoch 29: val_loss did not improve from 1.56714
83/83 [==============================] - 92s 1s/step - loss: 1.4761 - accuracy: 0.4516 - val_loss: 1.5846 - val_accuracy: 0.3963
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4688 - accuracy: 0.4601
Epoch 30: val_loss did not improve from 1.56714
83/83 [==============================] - 92s 1s/step - loss: 1.4688 - accuracy: 0.4601 - val_loss: 1.5882 - val_accuracy: 0.3945
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4607 - accuracy: 0.4643
Epoch 31: val_loss did not improve from 1.56714
83/83 [==============================] - 94s 1s/step - loss: 1.4607 - accuracy: 0.4643 - val_loss: 1.6007 - val_accuracy: 0.3924
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4540 - accuracy: 0.4689
Epoch 32: val_loss did not improve from 1.56714
83/83 [==============================] - 93s 1s/step - loss: 1.4540 - accuracy: 0.4689 - val_loss: 1.6119 - val_accuracy: 0.3907
Epoch 33/100
83/83 [==============================] - ETA: 0s - loss: 1.4412 - accuracy: 0.4749
Epoch 33: val_loss did not improve from 1.56714
83/83 [==============================] - 91s 1s/step - loss: 1.4412 - accuracy: 0.4749 - val_loss: 1.6113 - val_accuracy: 0.3971
Epoch 33: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential (Sequential)     (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_2 (Dense)             multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda (Lambda)             (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization (BatchN  (None, 75, 75, 2)        8         [0m
[94m ormalization)                                                   [0m
[94m                                                                 [0m
[94m conv2d (Conv2D)             (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d (MaxPooling2D  (None, 37, 37, 32)       0         [0m
[94m )                                                               [0m
[94m                                                                 [0m
[94m conv2d_1 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_1 (MaxPooling  (None, 18, 18, 128)      0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_2 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_2 (MaxPooling  (None, 9, 9, 256)        0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m dropout (Dropout)           (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten (Flatten)           (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense (Dense)               (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_1 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_1 (Dense)             (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_2 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 133s 10ms/step - loss: 1.5700 - accuracy: 0.3947
Testing Loss = 1.570006, Testing Accuracy = 0.394686
The data set contains images
  13433/Unknown - 125s 9ms/step13437/13437 [==============================] - 125s 9ms/step
[[0.016590191051363945, 0.0680067390203476, 0.5000267028808594, 0.03920949622988701, 0.12303667515516281, 0.2531302273273468], [0.4054649770259857, 0.03131679818034172, 0.03665235638618469, 0.2812812030315399, 0.1882047951221466, 0.05707991495728493], [0.1309543401002884, 0.04398973286151886, 0.29224565625190735, 0.10389284044504166, 0.27601954340934753, 0.1528979241847992], [0.06449232995510101, 0.031058546155691147, 0.3008688986301422, 0.14507092535495758, 0.2664986848831177, 0.19201058149337769], [0.004117934033274651, 0.10297060757875443, 0.44211333990097046, 0.028367793187499046, 0.06526494771242142, 0.3571653366088867], [0.05428842082619667, 0.28868404030799866, 0.04786282777786255, 0.35562536120414734, 0.07697222381830215, 0.17656706273555756], [0.35035714507102966, 0.0395742766559124, 0.11474975943565369, 0.15866822004318237, 0.24544377624988556, 0.09120690822601318], [0.23971426486968994, 0.08810191601514816, 0.05745064094662666, 0.32381966710090637, 0.18032942712306976, 0.11058400571346283], [0.018406620249152184, 0.09355518966913223, 0.40992745757102966, 0.05186568573117256, 0.12647603452205658, 0.29976898431777954], [0.16933658719062805, 0.01762741431593895, 0.3036791980266571, 0.08159325271844864, 0.32740962505340576, 0.1003539115190506]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
98 - accuracy: 0.1943     83/Unknown - 87s 1s/step - loss: 12.5655 - accuracy: 0.1944
Epoch 1: val_loss improved from inf to 8.86600, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 95s 1s/step - loss: 12.5655 - accuracy: 0.1944 - val_loss: 8.8660 - val_accuracy: 0.2112
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.9100 - accuracy: 0.2061
Epoch 2: val_loss improved from 8.86600 to 5.44638, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 93s 1s/step - loss: 6.9100 - accuracy: 0.2061 - val_loss: 5.4464 - val_accuracy: 0.2100
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.6521 - accuracy: 0.2124
Epoch 3: val_loss improved from 5.44638 to 4.01758, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 95s 1s/step - loss: 4.6521 - accuracy: 0.2124 - val_loss: 4.0176 - val_accuracy: 0.2170
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.5477 - accuracy: 0.2580
Epoch 4: val_loss improved from 4.01758 to 3.20202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 94s 1s/step - loss: 3.5477 - accuracy: 0.2580 - val_loss: 3.2020 - val_accuracy: 0.2688
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.9036 - accuracy: 0.2909
Epoch 5: val_loss improved from 3.20202 to 2.70574, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 95s 1s/step - loss: 2.9036 - accuracy: 0.2909 - val_loss: 2.7057 - val_accuracy: 0.2983
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5094 - accuracy: 0.3030
Epoch 6: val_loss improved from 2.70574 to 2.36879, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 95s 1s/step - loss: 2.5094 - accuracy: 0.3030 - val_loss: 2.3688 - val_accuracy: 0.3141
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2389 - accuracy: 0.3124
Epoch 7: val_loss improved from 2.36879 to 2.12793, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 96s 1s/step - loss: 2.2389 - accuracy: 0.3124 - val_loss: 2.1279 - val_accuracy: 0.3272
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0488 - accuracy: 0.3190
Epoch 8: val_loss improved from 2.12793 to 1.96739, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 96s 1s/step - loss: 2.0488 - accuracy: 0.3190 - val_loss: 1.9674 - val_accuracy: 0.3279
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9133 - accuracy: 0.3305
Epoch 9: val_loss improved from 1.96739 to 1.85506, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 95s 1s/step - loss: 1.9133 - accuracy: 0.3305 - val_loss: 1.8551 - val_accuracy: 0.3391
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8225 - accuracy: 0.3355
Epoch 10: val_loss improved from 1.85506 to 1.77903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 97s 1s/step - loss: 1.8225 - accuracy: 0.3355 - val_loss: 1.7790 - val_accuracy: 0.3378
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7556 - accuracy: 0.3405
Epoch 11: val_loss improved from 1.77903 to 1.72535, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 96s 1s/step - loss: 1.7556 - accuracy: 0.3405 - val_loss: 1.7254 - val_accuracy: 0.3442
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7075 - accuracy: 0.3445
Epoch 12: val_loss improved from 1.72535 to 1.68700, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 96s 1s/step - loss: 1.7075 - accuracy: 0.3445 - val_loss: 1.6870 - val_accuracy: 0.3450
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6705 - accuracy: 0.3570
Epoch 13: val_loss improved from 1.68700 to 1.66286, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 95s 1s/step - loss: 1.6705 - accuracy: 0.3570 - val_loss: 1.6629 - val_accuracy: 0.3479
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6414 - accuracy: 0.3615
Epoch 14: val_loss improved from 1.66286 to 1.63203, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 96s 1s/step - loss: 1.6414 - accuracy: 0.3615 - val_loss: 1.6320 - val_accuracy: 0.3618
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6192 - accuracy: 0.3697
Epoch 15: val_loss improved from 1.63203 to 1.61158, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 96s 1s/step - loss: 1.6192 - accuracy: 0.3697 - val_loss: 1.6116 - val_accuracy: 0.3699
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5991 - accuracy: 0.3782
Epoch 16: val_loss improved from 1.61158 to 1.59613, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 95s 1s/step - loss: 1.5991 - accuracy: 0.3782 - val_loss: 1.5961 - val_accuracy: 0.3767
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5831 - accuracy: 0.3839
Epoch 17: val_loss improved from 1.59613 to 1.58709, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 96s 1s/step - loss: 1.5831 - accuracy: 0.3839 - val_loss: 1.5871 - val_accuracy: 0.3832
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5687 - accuracy: 0.3912
Epoch 18: val_loss improved from 1.58709 to 1.57720, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 95s 1s/step - loss: 1.5687 - accuracy: 0.3912 - val_loss: 1.5772 - val_accuracy: 0.3865
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5611 - accuracy: 0.3980
Epoch 19: val_loss improved from 1.57720 to 1.57340, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 95s 1s/step - loss: 1.5611 - accuracy: 0.3980 - val_loss: 1.5734 - val_accuracy: 0.3911
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5495 - accuracy: 0.4016
Epoch 20: val_loss improved from 1.57340 to 1.57031, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 96s 1s/step - loss: 1.5495 - accuracy: 0.4016 - val_loss: 1.5703 - val_accuracy: 0.3930
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5395 - accuracy: 0.4097
Epoch 21: val_loss improved from 1.57031 to 1.56696, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 96s 1s/step - loss: 1.5395 - accuracy: 0.4097 - val_loss: 1.5670 - val_accuracy: 0.3919
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5296 - accuracy: 0.4159
Epoch 22: val_loss improved from 1.56696 to 1.56434, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/1
83/83 [==============================] - 94s 1s/step - loss: 1.5296 - accuracy: 0.4159 - val_loss: 1.5643 - val_accuracy: 0.3975
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5259 - accuracy: 0.4163
Epoch 23: val_loss did not improve from 1.56434
83/83 [==============================] - 94s 1s/step - loss: 1.5259 - accuracy: 0.4163 - val_loss: 1.5696 - val_accuracy: 0.3948
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5204 - accuracy: 0.4221
Epoch 24: val_loss did not improve from 1.56434
83/83 [==============================] - 94s 1s/step - loss: 1.5204 - accuracy: 0.4221 - val_loss: 1.5651 - val_accuracy: 0.3975
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5108 - accuracy: 0.4279
Epoch 25: val_loss did not improve from 1.56434
83/83 [==============================] - 94s 1s/step - loss: 1.5108 - accuracy: 0.4279 - val_loss: 1.5671 - val_accuracy: 0.4004
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.5062 - accuracy: 0.4309
Epoch 26: val_loss did not improve from 1.56434
83/83 [==============================] - 93s 1s/step - loss: 1.5062 - accuracy: 0.4309 - val_loss: 1.5647 - val_accuracy: 0.4002
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4984 - accuracy: 0.4375
Epoch 27: val_loss did not improve from 1.56434
83/83 [==============================] - 93s 1s/step - loss: 1.4984 - accuracy: 0.4375 - val_loss: 1.5663 - val_accuracy: 0.4029
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4884 - accuracy: 0.4409
Epoch 28: val_loss did not improve from 1.56434
83/83 [==============================] - 94s 1s/step - loss: 1.4884 - accuracy: 0.4409 - val_loss: 1.5703 - val_accuracy: 0.3990
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4824 - accuracy: 0.4482
Epoch 29: val_loss did not improve from 1.56434
83/83 [==============================] - 93s 1s/step - loss: 1.4824 - accuracy: 0.4482 - val_loss: 1.5738 - val_accuracy: 0.4043
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4760 - accuracy: 0.4527
Epoch 30: val_loss did not improve from 1.56434
83/83 [==============================] - 93s 1s/step - loss: 1.4760 - accuracy: 0.4527 - val_loss: 1.5792 - val_accuracy: 0.3982
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4714 - accuracy: 0.4573
Epoch 31: val_loss did not improve from 1.56434
83/83 [==============================] - 94s 1s/step - loss: 1.4714 - accuracy: 0.4573 - val_loss: 1.5819 - val_accuracy: 0.4034
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4611 - accuracy: 0.4631
Epoch 32: val_loss did not improve from 1.56434
83/83 [==============================] - 93s 1s/step - loss: 1.4611 - accuracy: 0.4631 - val_loss: 1.5893 - val_accuracy: 0.4006
Epoch 32: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_1 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_5 (Dense)             multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_1 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_1 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_3 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_3 (MaxPooling  (None, 37, 37, 32)       0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_4 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_4 (MaxPooling  (None, 18, 18, 128)      0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_5 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_5 (MaxPooling  (None, 9, 9, 256)        0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m dropout_3 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_1 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_3 (Dense)             (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_4 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_4 (Dense)             (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_5 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 133s 10ms/step - loss: 1.5694 - accuracy: 0.3940
Testing Loss = 1.569374, Testing Accuracy = 0.394016
The data set contains images
  13435/Unknown - 125s 9ms/step13437/13437 [==============================] - 125s 9ms/step
[[0.014266138896346092, 0.043116290122270584, 0.5846347808837891, 0.028559759259223938, 0.11480338126420975, 0.21461963653564453], [0.3077649474143982, 0.024797668680548668, 0.08093021810054779, 0.2405007779598236, 0.2695789635181427, 0.0764274150133133], [0.1636948138475418, 0.03525764122605324, 0.2889237105846405, 0.08803697675466537, 0.29749658703804016, 0.1265902817249298], [0.1049017384648323, 0.022328538820147514, 0.2700813412666321, 0.1487956941127777, 0.3100563585758209, 0.14383627474308014], [0.007088271901011467, 0.11479822546243668, 0.3995039761066437, 0.038686636835336685, 0.07517636567354202, 0.3647465407848358], [0.05835113301873207, 0.2708318829536438, 0.06459132581949234, 0.3109688460826874, 0.09347257018089294, 0.20178428292274475], [0.42535871267318726, 0.03599676117300987, 0.09716285020112991, 0.14117111265659332, 0.22806136310100555, 0.07224930077791214], [0.3352315127849579, 0.04089369997382164, 0.06735807657241821, 0.24919342994689941, 0.22336795926094055, 0.08395534753799438], [0.016653023660182953, 0.08223553001880646, 0.4447305500507355, 0.043250299990177155, 0.11643240600824356, 0.2966982126235962], [0.15346217155456543, 0.039494242519140244, 0.2601703405380249, 0.11994575709104538, 0.28494057059288025, 0.1419868916273117]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
23 - accuracy: 0.1998     83/Unknown - 87s 1s/step - loss: 12.4174 - accuracy: 0.2001
Epoch 1: val_loss improved from inf to 8.68270, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 12.4174 - accuracy: 0.2001 - val_loss: 8.6827 - val_accuracy: 0.2086
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.7556 - accuracy: 0.2071
Epoch 2: val_loss improved from 8.68270 to 5.32854, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 96s 1s/step - loss: 6.7556 - accuracy: 0.2071 - val_loss: 5.3285 - val_accuracy: 0.2116
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5480 - accuracy: 0.2235
Epoch 3: val_loss improved from 5.32854 to 3.92976, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 4.5480 - accuracy: 0.2235 - val_loss: 3.9298 - val_accuracy: 0.2521
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4689 - accuracy: 0.2826
Epoch 4: val_loss improved from 3.92976 to 3.17382, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 94s 1s/step - loss: 3.4689 - accuracy: 0.2826 - val_loss: 3.1738 - val_accuracy: 0.2796
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8771 - accuracy: 0.2963
Epoch 5: val_loss improved from 3.17382 to 2.69395, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 94s 1s/step - loss: 2.8771 - accuracy: 0.2963 - val_loss: 2.6940 - val_accuracy: 0.3048
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.4993 - accuracy: 0.3053
Epoch 6: val_loss improved from 2.69395 to 2.36224, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 2.4993 - accuracy: 0.3053 - val_loss: 2.3622 - val_accuracy: 0.3209
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2340 - accuracy: 0.3126
Epoch 7: val_loss improved from 2.36224 to 2.12490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 2.2340 - accuracy: 0.3126 - val_loss: 2.1249 - val_accuracy: 0.3271
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0462 - accuracy: 0.3233
Epoch 8: val_loss improved from 2.12490 to 1.96427, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 94s 1s/step - loss: 2.0462 - accuracy: 0.3233 - val_loss: 1.9643 - val_accuracy: 0.3312
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9118 - accuracy: 0.3303
Epoch 9: val_loss improved from 1.96427 to 1.85487, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 1.9118 - accuracy: 0.3303 - val_loss: 1.8549 - val_accuracy: 0.3350
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8181 - accuracy: 0.3404
Epoch 10: val_loss improved from 1.85487 to 1.77566, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 96s 1s/step - loss: 1.8181 - accuracy: 0.3404 - val_loss: 1.7757 - val_accuracy: 0.3438
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7509 - accuracy: 0.3461
Epoch 11: val_loss improved from 1.77566 to 1.72345, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 94s 1s/step - loss: 1.7509 - accuracy: 0.3461 - val_loss: 1.7234 - val_accuracy: 0.3456
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7005 - accuracy: 0.3530
Epoch 12: val_loss improved from 1.72345 to 1.67765, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 1.7005 - accuracy: 0.3530 - val_loss: 1.6777 - val_accuracy: 0.3591
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6603 - accuracy: 0.3652
Epoch 13: val_loss improved from 1.67765 to 1.64427, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 96s 1s/step - loss: 1.6603 - accuracy: 0.3652 - val_loss: 1.6443 - val_accuracy: 0.3663
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6360 - accuracy: 0.3679
Epoch 14: val_loss improved from 1.64427 to 1.62757, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 94s 1s/step - loss: 1.6360 - accuracy: 0.3679 - val_loss: 1.6276 - val_accuracy: 0.3685
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6096 - accuracy: 0.3794
Epoch 15: val_loss improved from 1.62757 to 1.60518, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 1.6096 - accuracy: 0.3794 - val_loss: 1.6052 - val_accuracy: 0.3764
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5899 - accuracy: 0.3866
Epoch 16: val_loss improved from 1.60518 to 1.59130, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 1.5899 - accuracy: 0.3866 - val_loss: 1.5913 - val_accuracy: 0.3844
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5775 - accuracy: 0.3912
Epoch 17: val_loss improved from 1.59130 to 1.58547, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 96s 1s/step - loss: 1.5775 - accuracy: 0.3912 - val_loss: 1.5855 - val_accuracy: 0.3861
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5666 - accuracy: 0.3953
Epoch 18: val_loss improved from 1.58547 to 1.58120, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 1.5666 - accuracy: 0.3953 - val_loss: 1.5812 - val_accuracy: 0.3872
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5516 - accuracy: 0.4016
Epoch 19: val_loss improved from 1.58120 to 1.57329, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 1.5516 - accuracy: 0.4016 - val_loss: 1.5733 - val_accuracy: 0.3902
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5417 - accuracy: 0.4087
Epoch 20: val_loss did not improve from 1.57329
83/83 [==============================] - 92s 1s/step - loss: 1.5417 - accuracy: 0.4087 - val_loss: 1.5753 - val_accuracy: 0.3874
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5339 - accuracy: 0.4129
Epoch 21: val_loss improved from 1.57329 to 1.57188, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 1.5339 - accuracy: 0.4129 - val_loss: 1.5719 - val_accuracy: 0.3912
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5267 - accuracy: 0.4183
Epoch 22: val_loss improved from 1.57188 to 1.56925, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/2
83/83 [==============================] - 95s 1s/step - loss: 1.5267 - accuracy: 0.4183 - val_loss: 1.5692 - val_accuracy: 0.3924
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5164 - accuracy: 0.4223
Epoch 23: val_loss did not improve from 1.56925
83/83 [==============================] - 94s 1s/step - loss: 1.5164 - accuracy: 0.4223 - val_loss: 1.5706 - val_accuracy: 0.3922
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5107 - accuracy: 0.4274
Epoch 24: val_loss did not improve from 1.56925
83/83 [==============================] - 94s 1s/step - loss: 1.5107 - accuracy: 0.4274 - val_loss: 1.5728 - val_accuracy: 0.3917
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5032 - accuracy: 0.4342
Epoch 25: val_loss did not improve from 1.56925
83/83 [==============================] - 92s 1s/step - loss: 1.5032 - accuracy: 0.4342 - val_loss: 1.5729 - val_accuracy: 0.3897
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.4959 - accuracy: 0.4365
Epoch 26: val_loss did not improve from 1.56925
83/83 [==============================] - 93s 1s/step - loss: 1.4959 - accuracy: 0.4365 - val_loss: 1.5752 - val_accuracy: 0.3932
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4934 - accuracy: 0.4414
Epoch 27: val_loss did not improve from 1.56925
83/83 [==============================] - 93s 1s/step - loss: 1.4934 - accuracy: 0.4414 - val_loss: 1.5840 - val_accuracy: 0.3938
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4809 - accuracy: 0.4493
Epoch 28: val_loss did not improve from 1.56925
83/83 [==============================] - 93s 1s/step - loss: 1.4809 - accuracy: 0.4493 - val_loss: 1.5878 - val_accuracy: 0.3908
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4714 - accuracy: 0.4555
Epoch 29: val_loss did not improve from 1.56925
83/83 [==============================] - 92s 1s/step - loss: 1.4714 - accuracy: 0.4555 - val_loss: 1.5908 - val_accuracy: 0.3927
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4604 - accuracy: 0.4615
Epoch 30: val_loss did not improve from 1.56925
83/83 [==============================] - 93s 1s/step - loss: 1.4604 - accuracy: 0.4615 - val_loss: 1.5975 - val_accuracy: 0.3930
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4531 - accuracy: 0.4693
Epoch 31: val_loss did not improve from 1.56925
83/83 [==============================] - 93s 1s/step - loss: 1.4531 - accuracy: 0.4693 - val_loss: 1.6102 - val_accuracy: 0.3950
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4472 - accuracy: 0.4728
Epoch 32: val_loss did not improve from 1.56925
83/83 [==============================] - 93s 1s/step - loss: 1.4472 - accuracy: 0.4728 - val_loss: 1.6210 - val_accuracy: 0.3876
Epoch 32: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_2 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_8 (Dense)             multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_2 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_2 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_6 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_6 (MaxPooling  (None, 37, 37, 32)       0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_7 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_7 (MaxPooling  (None, 18, 18, 128)      0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_8 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_8 (MaxPooling  (None, 9, 9, 256)        0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m dropout_6 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_2 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_6 (Dense)             (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_7 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_7 (Dense)             (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_8 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 132s 10ms/step - loss: 1.5733 - accuracy: 0.3992
Testing Loss = 1.573332, Testing Accuracy = 0.399152
The data set contains images
  13435/Unknown - 124s 9ms/step13437/13437 [==============================] - 124s 9ms/step
[[0.013321596197783947, 0.049724653363227844, 0.5474201440811157, 0.033517513424158096, 0.12024235725402832, 0.23577378690242767], [0.30929991602897644, 0.03449517488479614, 0.06661853194236755, 0.2611500322818756, 0.24950620532035828, 0.07893022149801254], [0.1228371411561966, 0.03069731965661049, 0.34604519605636597, 0.07312928885221481, 0.2937566041946411, 0.1335344910621643], [0.0903257355093956, 0.03348366916179657, 0.23950375616550446, 0.17472846806049347, 0.28957465291023254, 0.17238375544548035], [0.007732278201729059, 0.17888495326042175, 0.2959226667881012, 0.05418575182557106, 0.07614000141620636, 0.3871343433856964], [0.05377788841724396, 0.3121927082538605, 0.05179585516452789, 0.3185127079486847, 0.07948064804077148, 0.18424028158187866], [0.3616938591003418, 0.03842707350850105, 0.11222733557224274, 0.15115006268024445, 0.2501668334007263, 0.08633478730916977], [0.27766188979148865, 0.05478843301534653, 0.07747766375541687, 0.2461896538734436, 0.23871208727359772, 0.10517025738954544], [0.01837354525923729, 0.06916773319244385, 0.4683624804019928, 0.045355286449193954, 0.13246871531009674, 0.26627224683761597], [0.2498389482498169, 0.03813204541802406, 0.18657878041267395, 0.13089029490947723, 0.2836408317089081, 0.11091915518045425]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
61 - accuracy: 0.1987     83/Unknown - 87s 1s/step - loss: 12.3913 - accuracy: 0.1988
Epoch 1: val_loss improved from inf to 8.66276, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 12.3913 - accuracy: 0.1988 - val_loss: 8.6628 - val_accuracy: 0.2083
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.7412 - accuracy: 0.2074
Epoch 2: val_loss improved from 8.66276 to 5.31794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 94s 1s/step - loss: 6.7412 - accuracy: 0.2074 - val_loss: 5.3179 - val_accuracy: 0.2108
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5063 - accuracy: 0.2461
Epoch 3: val_loss improved from 5.31794 to 3.92560, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 4.5063 - accuracy: 0.2461 - val_loss: 3.9256 - val_accuracy: 0.2444
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4588 - accuracy: 0.2884
Epoch 4: val_loss improved from 3.92560 to 3.18552, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 96s 1s/step - loss: 3.4588 - accuracy: 0.2884 - val_loss: 3.1855 - val_accuracy: 0.2696
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8842 - accuracy: 0.3028
Epoch 5: val_loss improved from 3.18552 to 2.70519, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 96s 1s/step - loss: 2.8842 - accuracy: 0.3028 - val_loss: 2.7052 - val_accuracy: 0.2967
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5059 - accuracy: 0.3076
Epoch 6: val_loss improved from 2.70519 to 2.37161, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 2.5059 - accuracy: 0.3076 - val_loss: 2.3716 - val_accuracy: 0.3166
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2410 - accuracy: 0.3157
Epoch 7: val_loss improved from 2.37161 to 2.13763, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 2.2410 - accuracy: 0.3157 - val_loss: 2.1376 - val_accuracy: 0.3267
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0545 - accuracy: 0.3233
Epoch 8: val_loss improved from 2.13763 to 1.97504, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 2.0545 - accuracy: 0.3233 - val_loss: 1.9750 - val_accuracy: 0.3335
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9196 - accuracy: 0.3333
Epoch 9: val_loss improved from 1.97504 to 1.86288, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 1.9196 - accuracy: 0.3333 - val_loss: 1.8629 - val_accuracy: 0.3396
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8281 - accuracy: 0.3380
Epoch 10: val_loss improved from 1.86288 to 1.78452, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 1.8281 - accuracy: 0.3380 - val_loss: 1.7845 - val_accuracy: 0.3434
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7577 - accuracy: 0.3470
Epoch 11: val_loss improved from 1.78452 to 1.72884, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 96s 1s/step - loss: 1.7577 - accuracy: 0.3470 - val_loss: 1.7288 - val_accuracy: 0.3492
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7070 - accuracy: 0.3532
Epoch 12: val_loss improved from 1.72884 to 1.69166, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 96s 1s/step - loss: 1.7070 - accuracy: 0.3532 - val_loss: 1.6917 - val_accuracy: 0.3527
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6675 - accuracy: 0.3620
Epoch 13: val_loss improved from 1.69166 to 1.65152, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 1.6675 - accuracy: 0.3620 - val_loss: 1.6515 - val_accuracy: 0.3610
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6348 - accuracy: 0.3712
Epoch 14: val_loss improved from 1.65152 to 1.62549, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 1.6348 - accuracy: 0.3712 - val_loss: 1.6255 - val_accuracy: 0.3727
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6134 - accuracy: 0.3789
Epoch 15: val_loss improved from 1.62549 to 1.61538, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 94s 1s/step - loss: 1.6134 - accuracy: 0.3789 - val_loss: 1.6154 - val_accuracy: 0.3719
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5933 - accuracy: 0.3870
Epoch 16: val_loss improved from 1.61538 to 1.59869, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 94s 1s/step - loss: 1.5933 - accuracy: 0.3870 - val_loss: 1.5987 - val_accuracy: 0.3784
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5765 - accuracy: 0.3931
Epoch 17: val_loss improved from 1.59869 to 1.58786, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 97s 1s/step - loss: 1.5765 - accuracy: 0.3931 - val_loss: 1.5879 - val_accuracy: 0.3849
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5635 - accuracy: 0.3984
Epoch 18: val_loss improved from 1.58786 to 1.58052, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 1.5635 - accuracy: 0.3984 - val_loss: 1.5805 - val_accuracy: 0.3916
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5497 - accuracy: 0.4052
Epoch 19: val_loss improved from 1.58052 to 1.57880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 1.5497 - accuracy: 0.4052 - val_loss: 1.5788 - val_accuracy: 0.3923
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5381 - accuracy: 0.4122
Epoch 20: val_loss improved from 1.57880 to 1.57461, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 96s 1s/step - loss: 1.5381 - accuracy: 0.4122 - val_loss: 1.5746 - val_accuracy: 0.3931
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5313 - accuracy: 0.4192
Epoch 21: val_loss did not improve from 1.57461
83/83 [==============================] - 94s 1s/step - loss: 1.5313 - accuracy: 0.4192 - val_loss: 1.5798 - val_accuracy: 0.3878
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5234 - accuracy: 0.4230
Epoch 22: val_loss improved from 1.57461 to 1.57339, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 95s 1s/step - loss: 1.5234 - accuracy: 0.4230 - val_loss: 1.5734 - val_accuracy: 0.3908
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5152 - accuracy: 0.4294
Epoch 23: val_loss improved from 1.57339 to 1.57114, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/3
83/83 [==============================] - 96s 1s/step - loss: 1.5152 - accuracy: 0.4294 - val_loss: 1.5711 - val_accuracy: 0.3955
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5085 - accuracy: 0.4342
Epoch 24: val_loss did not improve from 1.57114
83/83 [==============================] - 94s 1s/step - loss: 1.5085 - accuracy: 0.4342 - val_loss: 1.5736 - val_accuracy: 0.3947
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5042 - accuracy: 0.4347
Epoch 25: val_loss did not improve from 1.57114
83/83 [==============================] - 94s 1s/step - loss: 1.5042 - accuracy: 0.4347 - val_loss: 1.5769 - val_accuracy: 0.3928
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.4958 - accuracy: 0.4413
Epoch 26: val_loss did not improve from 1.57114
83/83 [==============================] - 94s 1s/step - loss: 1.4958 - accuracy: 0.4413 - val_loss: 1.5782 - val_accuracy: 0.3977
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4881 - accuracy: 0.4471
Epoch 27: val_loss did not improve from 1.57114
83/83 [==============================] - 95s 1s/step - loss: 1.4881 - accuracy: 0.4471 - val_loss: 1.5827 - val_accuracy: 0.3960
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4788 - accuracy: 0.4541
Epoch 28: val_loss did not improve from 1.57114
83/83 [==============================] - 93s 1s/step - loss: 1.4788 - accuracy: 0.4541 - val_loss: 1.5919 - val_accuracy: 0.3953
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4696 - accuracy: 0.4595
Epoch 29: val_loss did not improve from 1.57114
83/83 [==============================] - 94s 1s/step - loss: 1.4696 - accuracy: 0.4595 - val_loss: 1.5932 - val_accuracy: 0.3945
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4622 - accuracy: 0.4637
Epoch 30: val_loss did not improve from 1.57114
83/83 [==============================] - 94s 1s/step - loss: 1.4622 - accuracy: 0.4637 - val_loss: 1.6030 - val_accuracy: 0.3933
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4530 - accuracy: 0.4692
Epoch 31: val_loss did not improve from 1.57114
83/83 [==============================] - 95s 1s/step - loss: 1.4530 - accuracy: 0.4692 - val_loss: 1.6132 - val_accuracy: 0.3944
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4432 - accuracy: 0.4799
Epoch 32: val_loss did not improve from 1.57114
83/83 [==============================] - 94s 1s/step - loss: 1.4432 - accuracy: 0.4799 - val_loss: 1.6267 - val_accuracy: 0.3950
Epoch 33/100
83/83 [==============================] - ETA: 0s - loss: 1.4311 - accuracy: 0.4908
Epoch 33: val_loss did not improve from 1.57114
83/83 [==============================] - 95s 1s/step - loss: 1.4311 - accuracy: 0.4908 - val_loss: 1.6408 - val_accuracy: 0.3930
Epoch 33: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_3 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_11 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_3 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_3 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_9 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_9 (MaxPooling  (None, 37, 37, 32)       0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_10 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_10 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_11 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_11 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_9 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_3 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_9 (Dense)             (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_10 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_10 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_11 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 131s 10ms/step - loss: 1.5763 - accuracy: 0.3921
Testing Loss = 1.576324, Testing Accuracy = 0.392081
The data set contains images
  13434/Unknown - 126s 9ms/step13437/13437 [==============================] - 126s 9ms/step
[[0.01211097463965416, 0.03803873807191849, 0.5953693985939026, 0.02795163169503212, 0.11509689688682556, 0.2114323228597641], [0.41584330797195435, 0.026822322979569435, 0.03793511167168617, 0.25334301590919495, 0.21265648305416107, 0.053399764001369476], [0.09673768281936646, 0.03617609664797783, 0.34817248582839966, 0.08381261676549911, 0.2768212854862213, 0.15827979147434235], [0.061841901391744614, 0.024171466007828712, 0.3326687812805176, 0.11864786595106125, 0.28739142417907715, 0.17527851462364197], [0.004651604685932398, 0.13956622779369354, 0.34208613634109497, 0.03994898870587349, 0.0635380893945694, 0.41020897030830383], [0.0479571595788002, 0.2956436276435852, 0.04349673539400101, 0.3513232171535492, 0.07878439873456955, 0.18279488384723663], [0.4654194116592407, 0.02897145226597786, 0.07379557192325592, 0.14507956802845, 0.22488325834274292, 0.06185072287917137], [0.3017430603504181, 0.04517345502972603, 0.07021894305944443, 0.24197721481323242, 0.24752779304981232, 0.09335953742265701], [0.014216167852282524, 0.09499920159578323, 0.42103174328804016, 0.04678132385015488, 0.11436668038368225, 0.308604896068573], [0.1790951043367386, 0.019581902772188187, 0.3121304214000702, 0.07141130417585373, 0.31800317764282227, 0.09977816045284271]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
88 - accuracy: 0.2001     83/Unknown - 88s 1s/step - loss: 12.4240 - accuracy: 0.2004
Epoch 1: val_loss improved from inf to 8.69015, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 97s 1s/step - loss: 12.4240 - accuracy: 0.2004 - val_loss: 8.6901 - val_accuracy: 0.2080
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.7540 - accuracy: 0.2050
Epoch 2: val_loss improved from 8.69015 to 5.32009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 95s 1s/step - loss: 6.7540 - accuracy: 0.2050 - val_loss: 5.3201 - val_accuracy: 0.2127
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5520 - accuracy: 0.2131
Epoch 3: val_loss improved from 5.32009 to 3.94459, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 97s 1s/step - loss: 4.5520 - accuracy: 0.2131 - val_loss: 3.9446 - val_accuracy: 0.2175
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4989 - accuracy: 0.2528
Epoch 4: val_loss improved from 3.94459 to 3.16941, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 95s 1s/step - loss: 3.4989 - accuracy: 0.2528 - val_loss: 3.1694 - val_accuracy: 0.2703
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8641 - accuracy: 0.2936
Epoch 5: val_loss improved from 3.16941 to 2.67754, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 94s 1s/step - loss: 2.8641 - accuracy: 0.2936 - val_loss: 2.6775 - val_accuracy: 0.3021
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.4846 - accuracy: 0.3052
Epoch 6: val_loss improved from 2.67754 to 2.34851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 95s 1s/step - loss: 2.4846 - accuracy: 0.3052 - val_loss: 2.3485 - val_accuracy: 0.3181
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2195 - accuracy: 0.3146
Epoch 7: val_loss improved from 2.34851 to 2.11668, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 96s 1s/step - loss: 2.2195 - accuracy: 0.3146 - val_loss: 2.1167 - val_accuracy: 0.3252
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0341 - accuracy: 0.3262
Epoch 8: val_loss improved from 2.11668 to 1.95658, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 96s 1s/step - loss: 2.0341 - accuracy: 0.3262 - val_loss: 1.9566 - val_accuracy: 0.3321
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9040 - accuracy: 0.3308
Epoch 9: val_loss improved from 1.95658 to 1.84655, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 96s 1s/step - loss: 1.9040 - accuracy: 0.3308 - val_loss: 1.8466 - val_accuracy: 0.3393
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8132 - accuracy: 0.3365
Epoch 10: val_loss improved from 1.84655 to 1.77008, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 96s 1s/step - loss: 1.8132 - accuracy: 0.3365 - val_loss: 1.7701 - val_accuracy: 0.3429
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7458 - accuracy: 0.3453
Epoch 11: val_loss improved from 1.77008 to 1.71631, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 95s 1s/step - loss: 1.7458 - accuracy: 0.3453 - val_loss: 1.7163 - val_accuracy: 0.3488
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.6984 - accuracy: 0.3532
Epoch 12: val_loss improved from 1.71631 to 1.68174, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 95s 1s/step - loss: 1.6984 - accuracy: 0.3532 - val_loss: 1.6817 - val_accuracy: 0.3487
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6600 - accuracy: 0.3606
Epoch 13: val_loss improved from 1.68174 to 1.64764, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 95s 1s/step - loss: 1.6600 - accuracy: 0.3606 - val_loss: 1.6476 - val_accuracy: 0.3603
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6306 - accuracy: 0.3684
Epoch 14: val_loss improved from 1.64764 to 1.61901, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 95s 1s/step - loss: 1.6306 - accuracy: 0.3684 - val_loss: 1.6190 - val_accuracy: 0.3704
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6064 - accuracy: 0.3793
Epoch 15: val_loss improved from 1.61901 to 1.60286, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 94s 1s/step - loss: 1.6064 - accuracy: 0.3793 - val_loss: 1.6029 - val_accuracy: 0.3810
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5918 - accuracy: 0.3842
Epoch 16: val_loss improved from 1.60286 to 1.59642, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 94s 1s/step - loss: 1.5918 - accuracy: 0.3842 - val_loss: 1.5964 - val_accuracy: 0.3747
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5724 - accuracy: 0.3931
Epoch 17: val_loss improved from 1.59642 to 1.57953, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 94s 1s/step - loss: 1.5724 - accuracy: 0.3931 - val_loss: 1.5795 - val_accuracy: 0.3903
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5620 - accuracy: 0.3979
Epoch 18: val_loss improved from 1.57953 to 1.57584, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 94s 1s/step - loss: 1.5620 - accuracy: 0.3979 - val_loss: 1.5758 - val_accuracy: 0.3934
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5523 - accuracy: 0.4047
Epoch 19: val_loss improved from 1.57584 to 1.56904, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 93s 1s/step - loss: 1.5523 - accuracy: 0.4047 - val_loss: 1.5690 - val_accuracy: 0.3955
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5402 - accuracy: 0.4112
Epoch 20: val_loss improved from 1.56904 to 1.56676, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 94s 1s/step - loss: 1.5402 - accuracy: 0.4112 - val_loss: 1.5668 - val_accuracy: 0.3937
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5300 - accuracy: 0.4160
Epoch 21: val_loss improved from 1.56676 to 1.56535, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 95s 1s/step - loss: 1.5300 - accuracy: 0.4160 - val_loss: 1.5654 - val_accuracy: 0.3984
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5230 - accuracy: 0.4207
Epoch 22: val_loss improved from 1.56535 to 1.56359, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/4
83/83 [==============================] - 93s 1s/step - loss: 1.5230 - accuracy: 0.4207 - val_loss: 1.5636 - val_accuracy: 0.4011
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5178 - accuracy: 0.4255
Epoch 23: val_loss did not improve from 1.56359
83/83 [==============================] - 92s 1s/step - loss: 1.5178 - accuracy: 0.4255 - val_loss: 1.5651 - val_accuracy: 0.4004
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5072 - accuracy: 0.4304
Epoch 24: val_loss did not improve from 1.56359
83/83 [==============================] - 94s 1s/step - loss: 1.5072 - accuracy: 0.4304 - val_loss: 1.5678 - val_accuracy: 0.3980
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.4998 - accuracy: 0.4343
Epoch 25: val_loss did not improve from 1.56359
83/83 [==============================] - 92s 1s/step - loss: 1.4998 - accuracy: 0.4343 - val_loss: 1.5656 - val_accuracy: 0.4019
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.4954 - accuracy: 0.4385
Epoch 26: val_loss did not improve from 1.56359
83/83 [==============================] - 93s 1s/step - loss: 1.4954 - accuracy: 0.4385 - val_loss: 1.5710 - val_accuracy: 0.3981
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4879 - accuracy: 0.4465
Epoch 27: val_loss did not improve from 1.56359
83/83 [==============================] - 92s 1s/step - loss: 1.4879 - accuracy: 0.4465 - val_loss: 1.5746 - val_accuracy: 0.3975
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4861 - accuracy: 0.4466
Epoch 28: val_loss did not improve from 1.56359
83/83 [==============================] - 92s 1s/step - loss: 1.4861 - accuracy: 0.4466 - val_loss: 1.5730 - val_accuracy: 0.4012
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4687 - accuracy: 0.4582
Epoch 29: val_loss did not improve from 1.56359
83/83 [==============================] - 93s 1s/step - loss: 1.4687 - accuracy: 0.4582 - val_loss: 1.5812 - val_accuracy: 0.4007
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4654 - accuracy: 0.4591
Epoch 30: val_loss did not improve from 1.56359
83/83 [==============================] - 92s 1s/step - loss: 1.4654 - accuracy: 0.4591 - val_loss: 1.5869 - val_accuracy: 0.3980
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4577 - accuracy: 0.4643
Epoch 31: val_loss did not improve from 1.56359
83/83 [==============================] - 92s 1s/step - loss: 1.4577 - accuracy: 0.4643 - val_loss: 1.5904 - val_accuracy: 0.4007
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4456 - accuracy: 0.4742
Epoch 32: val_loss did not improve from 1.56359
83/83 [==============================] - 92s 1s/step - loss: 1.4456 - accuracy: 0.4742 - val_loss: 1.6038 - val_accuracy: 0.3955
Epoch 32: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_4 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_14 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_4 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_4 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_12 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_12 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_13 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_13 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_14 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_14 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_12 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_4 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_12 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_13 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_13 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_14 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 130s 10ms/step - loss: 1.5708 - accuracy: 0.3974
Testing Loss = 1.570770, Testing Accuracy = 0.397440
The data set contains images
  13435/Unknown - 125s 9ms/step13437/13437 [==============================] - 125s 9ms/step
[[0.013783901929855347, 0.05128666013479233, 0.5338147878646851, 0.03320370241999626, 0.1166340708732605, 0.2512768507003784], [0.30105340480804443, 0.03666964918375015, 0.055412039160728455, 0.3072127401828766, 0.22273214161396027, 0.0769200325012207], [0.13088901340961456, 0.030490219593048096, 0.3382180333137512, 0.08005068451166153, 0.28742942214012146, 0.13292263448238373], [0.08055088669061661, 0.018942363560199738, 0.31788238883018494, 0.12144939601421356, 0.30839803814888, 0.15277691185474396], [0.004579448141157627, 0.09897414594888687, 0.4193594455718994, 0.03089827299118042, 0.06494324654340744, 0.3812454342842102], [0.06006404757499695, 0.23241929709911346, 0.04577942565083504, 0.40548986196517944, 0.08990570157766342, 0.1663416177034378], [0.43719905614852905, 0.03351137042045593, 0.0872538834810257, 0.14506451785564423, 0.2298140525817871, 0.06715725362300873], [0.27127060294151306, 0.04486953094601631, 0.07478366047143936, 0.2712758481502533, 0.2391144335269928, 0.09868593513965607], [0.022933339700102806, 0.1100219264626503, 0.3563002943992615, 0.06523221731185913, 0.13018833100795746, 0.3153238892555237], [0.2108815610408783, 0.02823827974498272, 0.2296362966299057, 0.11408916860818863, 0.3087911307811737, 0.10836353898048401]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
51 - accuracy: 0.1987     83/Unknown - 87s 1s/step - loss: 12.5004 - accuracy: 0.1989
Epoch 1: val_loss improved from inf to 8.77918, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 96s 1s/step - loss: 12.5004 - accuracy: 0.1989 - val_loss: 8.7792 - val_accuracy: 0.2110
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.8332 - accuracy: 0.2078
Epoch 2: val_loss improved from 8.77918 to 5.38402, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 95s 1s/step - loss: 6.8332 - accuracy: 0.2078 - val_loss: 5.3840 - val_accuracy: 0.2138
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5993 - accuracy: 0.2149
Epoch 3: val_loss improved from 5.38402 to 3.97802, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 94s 1s/step - loss: 4.5993 - accuracy: 0.2149 - val_loss: 3.9780 - val_accuracy: 0.2189
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4965 - accuracy: 0.2742
Epoch 4: val_loss improved from 3.97802 to 3.18778, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 94s 1s/step - loss: 3.4965 - accuracy: 0.2742 - val_loss: 3.1878 - val_accuracy: 0.2782
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8864 - accuracy: 0.2965
Epoch 5: val_loss improved from 3.18778 to 2.70293, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 95s 1s/step - loss: 2.8864 - accuracy: 0.2965 - val_loss: 2.7029 - val_accuracy: 0.2999
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5036 - accuracy: 0.3053
Epoch 6: val_loss improved from 2.70293 to 2.36714, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 94s 1s/step - loss: 2.5036 - accuracy: 0.3053 - val_loss: 2.3671 - val_accuracy: 0.3147
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2367 - accuracy: 0.3150
Epoch 7: val_loss improved from 2.36714 to 2.12971, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 93s 1s/step - loss: 2.2367 - accuracy: 0.3150 - val_loss: 2.1297 - val_accuracy: 0.3270
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0474 - accuracy: 0.3216
Epoch 8: val_loss improved from 2.12971 to 1.96747, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 95s 1s/step - loss: 2.0474 - accuracy: 0.3216 - val_loss: 1.9675 - val_accuracy: 0.3347
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9151 - accuracy: 0.3292
Epoch 9: val_loss improved from 1.96747 to 1.85734, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 94s 1s/step - loss: 1.9151 - accuracy: 0.3292 - val_loss: 1.8573 - val_accuracy: 0.3348
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8218 - accuracy: 0.3356
Epoch 10: val_loss improved from 1.85734 to 1.77780, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 95s 1s/step - loss: 1.8218 - accuracy: 0.3356 - val_loss: 1.7778 - val_accuracy: 0.3412
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7537 - accuracy: 0.3446
Epoch 11: val_loss improved from 1.77780 to 1.72536, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 94s 1s/step - loss: 1.7537 - accuracy: 0.3446 - val_loss: 1.7254 - val_accuracy: 0.3413
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7032 - accuracy: 0.3518
Epoch 12: val_loss improved from 1.72536 to 1.68756, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 95s 1s/step - loss: 1.7032 - accuracy: 0.3518 - val_loss: 1.6876 - val_accuracy: 0.3455
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6669 - accuracy: 0.3570
Epoch 13: val_loss improved from 1.68756 to 1.65026, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 94s 1s/step - loss: 1.6669 - accuracy: 0.3570 - val_loss: 1.6503 - val_accuracy: 0.3567
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6358 - accuracy: 0.3676
Epoch 14: val_loss improved from 1.65026 to 1.62819, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 95s 1s/step - loss: 1.6358 - accuracy: 0.3676 - val_loss: 1.6282 - val_accuracy: 0.3647
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6162 - accuracy: 0.3740
Epoch 15: val_loss improved from 1.62819 to 1.60622, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 95s 1s/step - loss: 1.6162 - accuracy: 0.3740 - val_loss: 1.6062 - val_accuracy: 0.3755
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5941 - accuracy: 0.3849
Epoch 16: val_loss improved from 1.60622 to 1.59088, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 94s 1s/step - loss: 1.5941 - accuracy: 0.3849 - val_loss: 1.5909 - val_accuracy: 0.3829
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5814 - accuracy: 0.3880
Epoch 17: val_loss improved from 1.59088 to 1.58226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 95s 1s/step - loss: 1.5814 - accuracy: 0.3880 - val_loss: 1.5823 - val_accuracy: 0.3844
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5701 - accuracy: 0.3926
Epoch 18: val_loss improved from 1.58226 to 1.57401, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 94s 1s/step - loss: 1.5701 - accuracy: 0.3926 - val_loss: 1.5740 - val_accuracy: 0.3870
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5573 - accuracy: 0.3989
Epoch 19: val_loss improved from 1.57401 to 1.56820, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 95s 1s/step - loss: 1.5573 - accuracy: 0.3989 - val_loss: 1.5682 - val_accuracy: 0.3895
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5472 - accuracy: 0.4018
Epoch 20: val_loss improved from 1.56820 to 1.56660, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 95s 1s/step - loss: 1.5472 - accuracy: 0.4018 - val_loss: 1.5666 - val_accuracy: 0.3920
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5377 - accuracy: 0.4094
Epoch 21: val_loss improved from 1.56660 to 1.56480, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 94s 1s/step - loss: 1.5377 - accuracy: 0.4094 - val_loss: 1.5648 - val_accuracy: 0.3960
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5317 - accuracy: 0.4176
Epoch 22: val_loss improved from 1.56480 to 1.56266, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 95s 1s/step - loss: 1.5317 - accuracy: 0.4176 - val_loss: 1.5627 - val_accuracy: 0.3957
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5243 - accuracy: 0.4196
Epoch 23: val_loss did not improve from 1.56266
83/83 [==============================] - 94s 1s/step - loss: 1.5243 - accuracy: 0.4196 - val_loss: 1.5632 - val_accuracy: 0.3964
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5168 - accuracy: 0.4221
Epoch 24: val_loss improved from 1.56266 to 1.56227, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/5
83/83 [==============================] - 94s 1s/step - loss: 1.5168 - accuracy: 0.4221 - val_loss: 1.5623 - val_accuracy: 0.3977
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5088 - accuracy: 0.4290
Epoch 25: val_loss did not improve from 1.56227
83/83 [==============================] - 92s 1s/step - loss: 1.5088 - accuracy: 0.4290 - val_loss: 1.5665 - val_accuracy: 0.3998
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.5038 - accuracy: 0.4337
Epoch 26: val_loss did not improve from 1.56227
83/83 [==============================] - 93s 1s/step - loss: 1.5038 - accuracy: 0.4337 - val_loss: 1.5688 - val_accuracy: 0.3979
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4931 - accuracy: 0.4382
Epoch 27: val_loss did not improve from 1.56227
83/83 [==============================] - 93s 1s/step - loss: 1.4931 - accuracy: 0.4382 - val_loss: 1.5745 - val_accuracy: 0.3982
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4927 - accuracy: 0.4391
Epoch 28: val_loss did not improve from 1.56227
83/83 [==============================] - 93s 1s/step - loss: 1.4927 - accuracy: 0.4391 - val_loss: 1.5717 - val_accuracy: 0.4010
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4787 - accuracy: 0.4526
Epoch 29: val_loss did not improve from 1.56227
83/83 [==============================] - 93s 1s/step - loss: 1.4787 - accuracy: 0.4526 - val_loss: 1.5788 - val_accuracy: 0.3996
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4756 - accuracy: 0.4534
Epoch 30: val_loss did not improve from 1.56227
83/83 [==============================] - 92s 1s/step - loss: 1.4756 - accuracy: 0.4534 - val_loss: 1.5850 - val_accuracy: 0.3987
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4641 - accuracy: 0.4626
Epoch 31: val_loss did not improve from 1.56227
83/83 [==============================] - 93s 1s/step - loss: 1.4641 - accuracy: 0.4626 - val_loss: 1.5924 - val_accuracy: 0.3964
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4618 - accuracy: 0.4658
Epoch 32: val_loss did not improve from 1.56227
83/83 [==============================] - 92s 1s/step - loss: 1.4618 - accuracy: 0.4658 - val_loss: 1.6027 - val_accuracy: 0.3947
Epoch 33/100
83/83 [==============================] - ETA: 0s - loss: 1.4471 - accuracy: 0.4745
Epoch 33: val_loss did not improve from 1.56227
83/83 [==============================] - 93s 1s/step - loss: 1.4471 - accuracy: 0.4745 - val_loss: 1.6109 - val_accuracy: 0.3973
Epoch 34/100
83/83 [==============================] - ETA: 0s - loss: 1.4382 - accuracy: 0.4819
Epoch 34: val_loss did not improve from 1.56227
83/83 [==============================] - 93s 1s/step - loss: 1.4382 - accuracy: 0.4819 - val_loss: 1.6196 - val_accuracy: 0.3953
Epoch 34: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_5 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_17 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_5 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_5 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_15 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_15 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_16 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_16 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_17 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_17 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_15 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_5 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_15 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_16 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_16 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_17 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 133s 10ms/step - loss: 1.5699 - accuracy: 0.4004
Testing Loss = 1.569943, Testing Accuracy = 0.400417
The data set contains images
  13435/Unknown - 125s 9ms/step13437/13437 [==============================] - 125s 9ms/step
[[0.011303149163722992, 0.03022870421409607, 0.6170936822891235, 0.023492936044931412, 0.11385843902826309, 0.20402300357818604], [0.3617238700389862, 0.04320070520043373, 0.03972141817212105, 0.2946004867553711, 0.19768404960632324, 0.0630694255232811], [0.19559410214424133, 0.04051618650555611, 0.21633216738700867, 0.12196218967437744, 0.2934409976005554, 0.1321544349193573], [0.08540824055671692, 0.01964390277862549, 0.3328859210014343, 0.10910041630268097, 0.2978053689002991, 0.1551561802625656], [0.006014858838170767, 0.11635924130678177, 0.38554802536964417, 0.03509329631924629, 0.06760358065366745, 0.38938093185424805], [0.037566836923360825, 0.28617388010025024, 0.06899954378604889, 0.2944718599319458, 0.08359603583812714, 0.229191854596138], [0.3974475860595703, 0.04241124913096428, 0.07702967524528503, 0.18522684276103973, 0.22150832414627075, 0.0763762891292572], [0.32739555835723877, 0.042581744492053986, 0.0668625459074974, 0.24364610016345978, 0.23532767593860626, 0.08418641984462738], [0.018263202160596848, 0.09507583826780319, 0.4027397632598877, 0.05174481123685837, 0.11756929755210876, 0.31460708379745483], [0.20386655628681183, 0.0320296548306942, 0.24663640558719635, 0.10462650656700134, 0.29749640822410583, 0.11534451693296432]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
50 - accuracy: 0.1981     83/Unknown - 88s 1s/step - loss: 12.4402 - accuracy: 0.1984
Epoch 1: val_loss improved from inf to 8.71291, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 97s 1s/step - loss: 12.4402 - accuracy: 0.1984 - val_loss: 8.7129 - val_accuracy: 0.2088
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.7868 - accuracy: 0.2082
Epoch 2: val_loss improved from 8.71291 to 5.35831, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 95s 1s/step - loss: 6.7868 - accuracy: 0.2082 - val_loss: 5.3583 - val_accuracy: 0.2088
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5729 - accuracy: 0.2211
Epoch 3: val_loss improved from 5.35831 to 3.94994, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 94s 1s/step - loss: 4.5729 - accuracy: 0.2211 - val_loss: 3.9499 - val_accuracy: 0.2427
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4845 - accuracy: 0.2824
Epoch 4: val_loss improved from 3.94994 to 3.19288, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 94s 1s/step - loss: 3.4845 - accuracy: 0.2824 - val_loss: 3.1929 - val_accuracy: 0.2683
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8933 - accuracy: 0.2982
Epoch 5: val_loss improved from 3.19288 to 2.71151, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 95s 1s/step - loss: 2.8933 - accuracy: 0.2982 - val_loss: 2.7115 - val_accuracy: 0.2911
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5074 - accuracy: 0.3052
Epoch 6: val_loss improved from 2.71151 to 2.37252, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 95s 1s/step - loss: 2.5074 - accuracy: 0.3052 - val_loss: 2.3725 - val_accuracy: 0.3182
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2424 - accuracy: 0.3157
Epoch 7: val_loss improved from 2.37252 to 2.13569, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 94s 1s/step - loss: 2.2424 - accuracy: 0.3157 - val_loss: 2.1357 - val_accuracy: 0.3235
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0546 - accuracy: 0.3220
Epoch 8: val_loss improved from 2.13569 to 1.97461, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 95s 1s/step - loss: 2.0546 - accuracy: 0.3220 - val_loss: 1.9746 - val_accuracy: 0.3317
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9202 - accuracy: 0.3282
Epoch 9: val_loss improved from 1.97461 to 1.86020, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 96s 1s/step - loss: 1.9202 - accuracy: 0.3282 - val_loss: 1.8602 - val_accuracy: 0.3368
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8264 - accuracy: 0.3370
Epoch 10: val_loss improved from 1.86020 to 1.78250, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 95s 1s/step - loss: 1.8264 - accuracy: 0.3370 - val_loss: 1.7825 - val_accuracy: 0.3407
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7601 - accuracy: 0.3442
Epoch 11: val_loss improved from 1.78250 to 1.72939, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 95s 1s/step - loss: 1.7601 - accuracy: 0.3442 - val_loss: 1.7294 - val_accuracy: 0.3396
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7108 - accuracy: 0.3467
Epoch 12: val_loss improved from 1.72939 to 1.69074, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 96s 1s/step - loss: 1.7108 - accuracy: 0.3467 - val_loss: 1.6907 - val_accuracy: 0.3477
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6733 - accuracy: 0.3545
Epoch 13: val_loss improved from 1.69074 to 1.66185, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 95s 1s/step - loss: 1.6733 - accuracy: 0.3545 - val_loss: 1.6619 - val_accuracy: 0.3529
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6445 - accuracy: 0.3638
Epoch 14: val_loss improved from 1.66185 to 1.63275, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 95s 1s/step - loss: 1.6445 - accuracy: 0.3638 - val_loss: 1.6328 - val_accuracy: 0.3629
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6212 - accuracy: 0.3710
Epoch 15: val_loss improved from 1.63275 to 1.61394, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 95s 1s/step - loss: 1.6212 - accuracy: 0.3710 - val_loss: 1.6139 - val_accuracy: 0.3689
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.6021 - accuracy: 0.3790
Epoch 16: val_loss improved from 1.61394 to 1.60147, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 96s 1s/step - loss: 1.6021 - accuracy: 0.3790 - val_loss: 1.6015 - val_accuracy: 0.3733
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5857 - accuracy: 0.3845
Epoch 17: val_loss improved from 1.60147 to 1.58965, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 94s 1s/step - loss: 1.5857 - accuracy: 0.3845 - val_loss: 1.5896 - val_accuracy: 0.3800
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5767 - accuracy: 0.3897
Epoch 18: val_loss improved from 1.58965 to 1.58580, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 94s 1s/step - loss: 1.5767 - accuracy: 0.3897 - val_loss: 1.5858 - val_accuracy: 0.3891
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5650 - accuracy: 0.3953
Epoch 19: val_loss improved from 1.58580 to 1.57652, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 95s 1s/step - loss: 1.5650 - accuracy: 0.3953 - val_loss: 1.5765 - val_accuracy: 0.3873
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5523 - accuracy: 0.4044
Epoch 20: val_loss did not improve from 1.57652
83/83 [==============================] - 93s 1s/step - loss: 1.5523 - accuracy: 0.4044 - val_loss: 1.5779 - val_accuracy: 0.3815
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5450 - accuracy: 0.4063
Epoch 21: val_loss improved from 1.57652 to 1.57002, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 94s 1s/step - loss: 1.5450 - accuracy: 0.4063 - val_loss: 1.5700 - val_accuracy: 0.3902
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5325 - accuracy: 0.4125
Epoch 22: val_loss improved from 1.57002 to 1.56808, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 93s 1s/step - loss: 1.5325 - accuracy: 0.4125 - val_loss: 1.5681 - val_accuracy: 0.3945
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5274 - accuracy: 0.4182
Epoch 23: val_loss improved from 1.56808 to 1.56600, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/6
83/83 [==============================] - 95s 1s/step - loss: 1.5274 - accuracy: 0.4182 - val_loss: 1.5660 - val_accuracy: 0.3954
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5192 - accuracy: 0.4239
Epoch 24: val_loss did not improve from 1.56600
83/83 [==============================] - 93s 1s/step - loss: 1.5192 - accuracy: 0.4239 - val_loss: 1.5705 - val_accuracy: 0.3916
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5133 - accuracy: 0.4275
Epoch 25: val_loss did not improve from 1.56600
83/83 [==============================] - 92s 1s/step - loss: 1.5133 - accuracy: 0.4275 - val_loss: 1.5687 - val_accuracy: 0.3958
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.5047 - accuracy: 0.4309
Epoch 26: val_loss did not improve from 1.56600
83/83 [==============================] - 93s 1s/step - loss: 1.5047 - accuracy: 0.4309 - val_loss: 1.5701 - val_accuracy: 0.3957
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.5018 - accuracy: 0.4370
Epoch 27: val_loss did not improve from 1.56600
83/83 [==============================] - 92s 1s/step - loss: 1.5018 - accuracy: 0.4370 - val_loss: 1.5709 - val_accuracy: 0.3967
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4930 - accuracy: 0.4421
Epoch 28: val_loss did not improve from 1.56600
83/83 [==============================] - 92s 1s/step - loss: 1.4930 - accuracy: 0.4421 - val_loss: 1.5735 - val_accuracy: 0.3966
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4837 - accuracy: 0.4506
Epoch 29: val_loss did not improve from 1.56600
83/83 [==============================] - 92s 1s/step - loss: 1.4837 - accuracy: 0.4506 - val_loss: 1.5796 - val_accuracy: 0.3967
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4781 - accuracy: 0.4513
Epoch 30: val_loss did not improve from 1.56600
83/83 [==============================] - 93s 1s/step - loss: 1.4781 - accuracy: 0.4513 - val_loss: 1.5825 - val_accuracy: 0.3957
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4698 - accuracy: 0.4577
Epoch 31: val_loss did not improve from 1.56600
83/83 [==============================] - 93s 1s/step - loss: 1.4698 - accuracy: 0.4577 - val_loss: 1.5895 - val_accuracy: 0.3949
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4618 - accuracy: 0.4649
Epoch 32: val_loss did not improve from 1.56600
83/83 [==============================] - 92s 1s/step - loss: 1.4618 - accuracy: 0.4649 - val_loss: 1.5950 - val_accuracy: 0.3965
Epoch 33/100
83/83 [==============================] - ETA: 0s - loss: 1.4500 - accuracy: 0.4712
Epoch 33: val_loss did not improve from 1.56600
83/83 [==============================] - 92s 1s/step - loss: 1.4500 - accuracy: 0.4712 - val_loss: 1.6054 - val_accuracy: 0.3947
Epoch 33: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_6 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_20 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_6 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_6 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_18 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_18 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_19 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_19 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_20 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_20 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_18 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_6 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_18 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_19 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_19 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_20 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 132s 10ms/step - loss: 1.5698 - accuracy: 0.3965
Testing Loss = 1.569833, Testing Accuracy = 0.396547
The data set contains images
  13431/Unknown - 125s 9ms/step13437/13437 [==============================] - 125s 9ms/step
[[0.013382437638938427, 0.03485995531082153, 0.6141636967658997, 0.02705415152013302, 0.11994684487581253, 0.190592959523201], [0.24984006583690643, 0.043747685849666595, 0.07287035882472992, 0.2910734713077545, 0.24587999284267426, 0.0965883806347847], [0.12279577553272247, 0.03697310760617256, 0.3391718864440918, 0.0792413130402565, 0.27794966101646423, 0.1438683271408081], [0.09756012260913849, 0.025811724364757538, 0.26609644293785095, 0.14691570401191711, 0.3002089858055115, 0.16340692341327667], [0.003615303197875619, 0.12421030551195145, 0.3950984477996826, 0.03000091388821602, 0.060922592878341675, 0.3861524164676666], [0.04864826798439026, 0.28224772214889526, 0.058793116360902786, 0.3216947317123413, 0.08244068920612335, 0.20617547631263733], [0.3943904936313629, 0.035351306200027466, 0.10505396872758865, 0.1392831951379776, 0.2459799200296402, 0.07994114607572556], [0.3657597303390503, 0.03441464528441429, 0.06407923251390457, 0.22464068233966827, 0.23363924026489258, 0.0774664506316185], [0.01865135319530964, 0.0854559987783432, 0.42811480164527893, 0.05131053552031517, 0.12717783451080322, 0.28928953409194946], [0.23318710923194885, 0.028245167806744576, 0.21428459882736206, 0.11826930940151215, 0.3023028075695038, 0.10371098667383194]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
25 - accuracy: 0.2005     83/Unknown - 88s 1s/step - loss: 12.3877 - accuracy: 0.2007
Epoch 1: val_loss improved from inf to 8.64507, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 96s 1s/step - loss: 12.3877 - accuracy: 0.2007 - val_loss: 8.6451 - val_accuracy: 0.2074
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.7304 - accuracy: 0.2083
Epoch 2: val_loss improved from 8.64507 to 5.31394, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 6.7304 - accuracy: 0.2083 - val_loss: 5.3139 - val_accuracy: 0.2098
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5530 - accuracy: 0.2138
Epoch 3: val_loss improved from 5.31394 to 3.94889, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 95s 1s/step - loss: 4.5530 - accuracy: 0.2138 - val_loss: 3.9489 - val_accuracy: 0.2195
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4841 - accuracy: 0.2669
Epoch 4: val_loss improved from 3.94889 to 3.16870, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 3.4841 - accuracy: 0.2669 - val_loss: 3.1687 - val_accuracy: 0.2676
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8738 - accuracy: 0.2951
Epoch 5: val_loss improved from 3.16870 to 2.68913, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 2.8738 - accuracy: 0.2951 - val_loss: 2.6891 - val_accuracy: 0.3044
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.4926 - accuracy: 0.3048
Epoch 6: val_loss improved from 2.68913 to 2.35745, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 2.4926 - accuracy: 0.3048 - val_loss: 2.3575 - val_accuracy: 0.3126
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2286 - accuracy: 0.3143
Epoch 7: val_loss improved from 2.35745 to 2.12191, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 2.2286 - accuracy: 0.3143 - val_loss: 2.1219 - val_accuracy: 0.3262
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0411 - accuracy: 0.3212
Epoch 8: val_loss improved from 2.12191 to 1.96054, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 2.0411 - accuracy: 0.3212 - val_loss: 1.9605 - val_accuracy: 0.3339
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9108 - accuracy: 0.3296
Epoch 9: val_loss improved from 1.96054 to 1.84972, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 1.9108 - accuracy: 0.3296 - val_loss: 1.8497 - val_accuracy: 0.3404
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8159 - accuracy: 0.3371
Epoch 10: val_loss improved from 1.84972 to 1.77621, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 95s 1s/step - loss: 1.8159 - accuracy: 0.3371 - val_loss: 1.7762 - val_accuracy: 0.3383
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7493 - accuracy: 0.3419
Epoch 11: val_loss improved from 1.77621 to 1.71913, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 1.7493 - accuracy: 0.3419 - val_loss: 1.7191 - val_accuracy: 0.3503
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7003 - accuracy: 0.3532
Epoch 12: val_loss improved from 1.71913 to 1.68233, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 1.7003 - accuracy: 0.3532 - val_loss: 1.6823 - val_accuracy: 0.3509
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6631 - accuracy: 0.3591
Epoch 13: val_loss improved from 1.68233 to 1.64734, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 95s 1s/step - loss: 1.6631 - accuracy: 0.3591 - val_loss: 1.6473 - val_accuracy: 0.3646
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6339 - accuracy: 0.3692
Epoch 14: val_loss improved from 1.64734 to 1.62188, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 95s 1s/step - loss: 1.6339 - accuracy: 0.3692 - val_loss: 1.6219 - val_accuracy: 0.3715
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6107 - accuracy: 0.3764
Epoch 15: val_loss improved from 1.62188 to 1.61068, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 95s 1s/step - loss: 1.6107 - accuracy: 0.3764 - val_loss: 1.6107 - val_accuracy: 0.3684
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5903 - accuracy: 0.3848
Epoch 16: val_loss improved from 1.61068 to 1.59377, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 1.5903 - accuracy: 0.3848 - val_loss: 1.5938 - val_accuracy: 0.3766
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5758 - accuracy: 0.3884
Epoch 17: val_loss improved from 1.59377 to 1.58564, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 95s 1s/step - loss: 1.5758 - accuracy: 0.3884 - val_loss: 1.5856 - val_accuracy: 0.3809
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5633 - accuracy: 0.3980
Epoch 18: val_loss improved from 1.58564 to 1.57796, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 1.5633 - accuracy: 0.3980 - val_loss: 1.5780 - val_accuracy: 0.3867
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5550 - accuracy: 0.4037
Epoch 19: val_loss did not improve from 1.57796
83/83 [==============================] - 92s 1s/step - loss: 1.5550 - accuracy: 0.4037 - val_loss: 1.5788 - val_accuracy: 0.3853
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5453 - accuracy: 0.4080
Epoch 20: val_loss improved from 1.57796 to 1.57606, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 94s 1s/step - loss: 1.5453 - accuracy: 0.4080 - val_loss: 1.5761 - val_accuracy: 0.3885
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5319 - accuracy: 0.4114
Epoch 21: val_loss improved from 1.57606 to 1.56845, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/7
83/83 [==============================] - 93s 1s/step - loss: 1.5319 - accuracy: 0.4114 - val_loss: 1.5685 - val_accuracy: 0.3935
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5246 - accuracy: 0.4195
Epoch 22: val_loss did not improve from 1.56845
83/83 [==============================] - 92s 1s/step - loss: 1.5246 - accuracy: 0.4195 - val_loss: 1.5700 - val_accuracy: 0.3937
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5197 - accuracy: 0.4209
Epoch 23: val_loss did not improve from 1.56845
83/83 [==============================] - 92s 1s/step - loss: 1.5197 - accuracy: 0.4209 - val_loss: 1.5698 - val_accuracy: 0.3953
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5066 - accuracy: 0.4319
Epoch 24: val_loss did not improve from 1.56845
83/83 [==============================] - 92s 1s/step - loss: 1.5066 - accuracy: 0.4319 - val_loss: 1.5694 - val_accuracy: 0.4007
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5011 - accuracy: 0.4330
Epoch 25: val_loss did not improve from 1.56845
83/83 [==============================] - 93s 1s/step - loss: 1.5011 - accuracy: 0.4330 - val_loss: 1.5732 - val_accuracy: 0.4000
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.4944 - accuracy: 0.4397
Epoch 26: val_loss did not improve from 1.56845
83/83 [==============================] - 97s 1s/step - loss: 1.4944 - accuracy: 0.4397 - val_loss: 1.5753 - val_accuracy: 0.3932
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4868 - accuracy: 0.4454
Epoch 27: val_loss did not improve from 1.56845
83/83 [==============================] - 97s 1s/step - loss: 1.4868 - accuracy: 0.4454 - val_loss: 1.5798 - val_accuracy: 0.3960
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4787 - accuracy: 0.4516
Epoch 28: val_loss did not improve from 1.56845
83/83 [==============================] - 94s 1s/step - loss: 1.4787 - accuracy: 0.4516 - val_loss: 1.5837 - val_accuracy: 0.3952
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4694 - accuracy: 0.4571
Epoch 29: val_loss did not improve from 1.56845
83/83 [==============================] - 96s 1s/step - loss: 1.4694 - accuracy: 0.4571 - val_loss: 1.5904 - val_accuracy: 0.3943
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4623 - accuracy: 0.4634
Epoch 30: val_loss did not improve from 1.56845
83/83 [==============================] - 97s 1s/step - loss: 1.4623 - accuracy: 0.4634 - val_loss: 1.6026 - val_accuracy: 0.3952
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4519 - accuracy: 0.4697
Epoch 31: val_loss did not improve from 1.56845
83/83 [==============================] - 97s 1s/step - loss: 1.4519 - accuracy: 0.4697 - val_loss: 1.6099 - val_accuracy: 0.3933
Epoch 31: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_7 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_23 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_7 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_7 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_21 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_21 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_22 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_22 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_23 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_23 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_21 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_7 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_21 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_22 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_22 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_23 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 131s 10ms/step - loss: 1.5732 - accuracy: 0.3925
Testing Loss = 1.573165, Testing Accuracy = 0.392453
The data set contains images
  13436/Unknown - 126s 9ms/step13437/13437 [==============================] - 126s 9ms/step
[[0.01848597638309002, 0.057384341955184937, 0.50745689868927, 0.043605804443359375, 0.13154859840869904, 0.24151833355426788], [0.2522926330566406, 0.03695078194141388, 0.07307163625955582, 0.2961949110031128, 0.24440133571624756, 0.09708874672651291], [0.13252337276935577, 0.04005414620041847, 0.30310001969337463, 0.10068824887275696, 0.27897006273269653, 0.1446642279624939], [0.10620997101068497, 0.03110903687775135, 0.1820557415485382, 0.24425014853477478, 0.27737438678741455, 0.1590006947517395], [0.006296135950833559, 0.11567842215299606, 0.39002642035484314, 0.04131481796503067, 0.07297482341527939, 0.3737093210220337], [0.06041290611028671, 0.2810154855251312, 0.055570490658283234, 0.33883586525917053, 0.08457867056131363, 0.1795865148305893], [0.4676274061203003, 0.03156530112028122, 0.06495615094900131, 0.16769526898860931, 0.2083500474691391, 0.05980576202273369], [0.24479088187217712, 0.059796515852212906, 0.08030056953430176, 0.2811938226222992, 0.22512519359588623, 0.1087929755449295], [0.024646298959851265, 0.14261695742607117, 0.2711712419986725, 0.095220647752285, 0.12681971490383148, 0.3395251929759979], [0.28145071864128113, 0.042242251336574554, 0.14750778675079346, 0.15928944945335388, 0.2670806646347046, 0.10242916643619537]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
91 - accuracy: 0.1968     83/Unknown - 88s 1s/step - loss: 12.3843 - accuracy: 0.1967
Epoch 1: val_loss improved from inf to 8.64019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 97s 1s/step - loss: 12.3843 - accuracy: 0.1967 - val_loss: 8.6402 - val_accuracy: 0.2079
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.7212 - accuracy: 0.2070
Epoch 2: val_loss improved from 8.64019 to 5.30139, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 99s 1s/step - loss: 6.7212 - accuracy: 0.2070 - val_loss: 5.3014 - val_accuracy: 0.2086
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5450 - accuracy: 0.2096
Epoch 3: val_loss improved from 5.30139 to 3.94097, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 98s 1s/step - loss: 4.5450 - accuracy: 0.2096 - val_loss: 3.9410 - val_accuracy: 0.2141
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.5246 - accuracy: 0.2341
Epoch 4: val_loss improved from 3.94097 to 3.17760, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 99s 1s/step - loss: 3.5246 - accuracy: 0.2341 - val_loss: 3.1776 - val_accuracy: 0.2543
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8697 - accuracy: 0.2893
Epoch 5: val_loss improved from 3.17760 to 2.67776, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 99s 1s/step - loss: 2.8697 - accuracy: 0.2893 - val_loss: 2.6778 - val_accuracy: 0.2941
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.4822 - accuracy: 0.3002
Epoch 6: val_loss improved from 2.67776 to 2.34584, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 97s 1s/step - loss: 2.4822 - accuracy: 0.3002 - val_loss: 2.3458 - val_accuracy: 0.3127
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2196 - accuracy: 0.3095
Epoch 7: val_loss improved from 2.34584 to 2.11376, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 98s 1s/step - loss: 2.2196 - accuracy: 0.3095 - val_loss: 2.1138 - val_accuracy: 0.3209
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0337 - accuracy: 0.3190
Epoch 8: val_loss improved from 2.11376 to 1.95336, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 98s 1s/step - loss: 2.0337 - accuracy: 0.3190 - val_loss: 1.9534 - val_accuracy: 0.3286
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9031 - accuracy: 0.3224
Epoch 9: val_loss improved from 1.95336 to 1.84584, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 98s 1s/step - loss: 1.9031 - accuracy: 0.3224 - val_loss: 1.8458 - val_accuracy: 0.3315
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8141 - accuracy: 0.3326
Epoch 10: val_loss improved from 1.84584 to 1.77359, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 99s 1s/step - loss: 1.8141 - accuracy: 0.3326 - val_loss: 1.7736 - val_accuracy: 0.3352
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7470 - accuracy: 0.3379
Epoch 11: val_loss improved from 1.77359 to 1.71559, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 99s 1s/step - loss: 1.7470 - accuracy: 0.3379 - val_loss: 1.7156 - val_accuracy: 0.3455
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7005 - accuracy: 0.3458
Epoch 12: val_loss improved from 1.71559 to 1.68195, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 95s 1s/step - loss: 1.7005 - accuracy: 0.3458 - val_loss: 1.6820 - val_accuracy: 0.3465
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6660 - accuracy: 0.3521
Epoch 13: val_loss improved from 1.68195 to 1.65562, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 94s 1s/step - loss: 1.6660 - accuracy: 0.3521 - val_loss: 1.6556 - val_accuracy: 0.3481
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6379 - accuracy: 0.3616
Epoch 14: val_loss improved from 1.65562 to 1.62901, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 95s 1s/step - loss: 1.6379 - accuracy: 0.3616 - val_loss: 1.6290 - val_accuracy: 0.3588
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6143 - accuracy: 0.3700
Epoch 15: val_loss improved from 1.62901 to 1.60880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 95s 1s/step - loss: 1.6143 - accuracy: 0.3700 - val_loss: 1.6088 - val_accuracy: 0.3683
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5953 - accuracy: 0.3794
Epoch 16: val_loss improved from 1.60880 to 1.59539, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 94s 1s/step - loss: 1.5953 - accuracy: 0.3794 - val_loss: 1.5954 - val_accuracy: 0.3719
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5803 - accuracy: 0.3853
Epoch 17: val_loss improved from 1.59539 to 1.58335, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 94s 1s/step - loss: 1.5803 - accuracy: 0.3853 - val_loss: 1.5833 - val_accuracy: 0.3786
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5678 - accuracy: 0.3928
Epoch 18: val_loss improved from 1.58335 to 1.57639, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 95s 1s/step - loss: 1.5678 - accuracy: 0.3928 - val_loss: 1.5764 - val_accuracy: 0.3839
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5581 - accuracy: 0.3969
Epoch 19: val_loss improved from 1.57639 to 1.57114, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 96s 1s/step - loss: 1.5581 - accuracy: 0.3969 - val_loss: 1.5711 - val_accuracy: 0.3873
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5478 - accuracy: 0.4018
Epoch 20: val_loss did not improve from 1.57114
83/83 [==============================] - 94s 1s/step - loss: 1.5478 - accuracy: 0.4018 - val_loss: 1.5718 - val_accuracy: 0.3867
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5387 - accuracy: 0.4087
Epoch 21: val_loss improved from 1.57114 to 1.56623, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 95s 1s/step - loss: 1.5387 - accuracy: 0.4087 - val_loss: 1.5662 - val_accuracy: 0.3925
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5309 - accuracy: 0.4134
Epoch 22: val_loss improved from 1.56623 to 1.56574, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 95s 1s/step - loss: 1.5309 - accuracy: 0.4134 - val_loss: 1.5657 - val_accuracy: 0.3932
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5226 - accuracy: 0.4195
Epoch 23: val_loss improved from 1.56574 to 1.56476, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/8
83/83 [==============================] - 96s 1s/step - loss: 1.5226 - accuracy: 0.4195 - val_loss: 1.5648 - val_accuracy: 0.3937
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5171 - accuracy: 0.4231
Epoch 24: val_loss did not improve from 1.56476
83/83 [==============================] - 93s 1s/step - loss: 1.5171 - accuracy: 0.4231 - val_loss: 1.5681 - val_accuracy: 0.3953
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5098 - accuracy: 0.4286
Epoch 25: val_loss did not improve from 1.56476
83/83 [==============================] - 93s 1s/step - loss: 1.5098 - accuracy: 0.4286 - val_loss: 1.5670 - val_accuracy: 0.3933
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.5036 - accuracy: 0.4317
Epoch 26: val_loss did not improve from 1.56476
83/83 [==============================] - 93s 1s/step - loss: 1.5036 - accuracy: 0.4317 - val_loss: 1.5689 - val_accuracy: 0.3959
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4940 - accuracy: 0.4362
Epoch 27: val_loss did not improve from 1.56476
83/83 [==============================] - 93s 1s/step - loss: 1.4940 - accuracy: 0.4362 - val_loss: 1.5735 - val_accuracy: 0.3952
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4918 - accuracy: 0.4393
Epoch 28: val_loss did not improve from 1.56476
83/83 [==============================] - 93s 1s/step - loss: 1.4918 - accuracy: 0.4393 - val_loss: 1.5743 - val_accuracy: 0.3979
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4811 - accuracy: 0.4472
Epoch 29: val_loss did not improve from 1.56476
83/83 [==============================] - 93s 1s/step - loss: 1.4811 - accuracy: 0.4472 - val_loss: 1.5791 - val_accuracy: 0.3946
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4781 - accuracy: 0.4511
Epoch 30: val_loss did not improve from 1.56476
83/83 [==============================] - 93s 1s/step - loss: 1.4781 - accuracy: 0.4511 - val_loss: 1.5831 - val_accuracy: 0.3992
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4696 - accuracy: 0.4538
Epoch 31: val_loss did not improve from 1.56476
83/83 [==============================] - 93s 1s/step - loss: 1.4696 - accuracy: 0.4538 - val_loss: 1.5912 - val_accuracy: 0.3957
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4611 - accuracy: 0.4635
Epoch 32: val_loss did not improve from 1.56476
83/83 [==============================] - 94s 1s/step - loss: 1.4611 - accuracy: 0.4635 - val_loss: 1.6043 - val_accuracy: 0.3927
Epoch 33/100
83/83 [==============================] - ETA: 0s - loss: 1.4566 - accuracy: 0.4643
Epoch 33: val_loss did not improve from 1.56476
83/83 [==============================] - 93s 1s/step - loss: 1.4566 - accuracy: 0.4643 - val_loss: 1.6258 - val_accuracy: 0.3826
Epoch 33: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_8 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_26 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_8 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_8 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_24 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_24 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_25 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_25 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_26 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_26 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_24 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_8 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_24 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_25 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_25 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_26 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 131s 10ms/step - loss: 1.5677 - accuracy: 0.3924
Testing Loss = 1.567664, Testing Accuracy = 0.392379
The data set contains images
  13435/Unknown - 125s 9ms/step13437/13437 [==============================] - 125s 9ms/step
[[0.013175033032894135, 0.03915074095129967, 0.5893921256065369, 0.026411117985844612, 0.11271277815103531, 0.21915818750858307], [0.2968734800815582, 0.04563557356595993, 0.04293585941195488, 0.32968607544898987, 0.2070215344429016, 0.07784739881753922], [0.1375090777873993, 0.038079023361206055, 0.2917126417160034, 0.10365580022335052, 0.28341424465179443, 0.1456291526556015], [0.11431394517421722, 0.03561539202928543, 0.18679633736610413, 0.23259977996349335, 0.27114659547805786, 0.15952791273593903], [0.008969065733253956, 0.17765410244464874, 0.2776181995868683, 0.058212559670209885, 0.07414288073778152, 0.40340328216552734], [0.05798690766096115, 0.2439577877521515, 0.06280729919672012, 0.34973716735839844, 0.09884702414274216, 0.18666377663612366], [0.442375123500824, 0.025532374158501625, 0.09389007091522217, 0.1252557784318924, 0.24655739963054657, 0.06638926267623901], [0.2920042872428894, 0.06074286252260208, 0.05884246900677681, 0.2810901999473572, 0.20793777704238892, 0.09938240796327591], [0.02043662779033184, 0.09777969866991043, 0.3840610086917877, 0.05881299450993538, 0.12470968067646027, 0.3142000138759613], [0.2418971210718155, 0.03682432696223259, 0.19995562732219696, 0.12167508900165558, 0.284275084733963, 0.11537277698516846]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
47 - accuracy: 0.1980     83/Unknown - 89s 1s/step - loss: 12.3800 - accuracy: 0.1983
Epoch 1: val_loss improved from inf to 8.65808, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 97s 1s/step - loss: 12.3800 - accuracy: 0.1983 - val_loss: 8.6581 - val_accuracy: 0.2098
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.7410 - accuracy: 0.2070
Epoch 2: val_loss improved from 8.65808 to 5.31993, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 95s 1s/step - loss: 6.7410 - accuracy: 0.2070 - val_loss: 5.3199 - val_accuracy: 0.2123
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5572 - accuracy: 0.2131
Epoch 3: val_loss improved from 5.31993 to 3.95132, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 94s 1s/step - loss: 4.5572 - accuracy: 0.2131 - val_loss: 3.9513 - val_accuracy: 0.2176
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4864 - accuracy: 0.2637
Epoch 4: val_loss improved from 3.95132 to 3.16746, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 96s 1s/step - loss: 3.4864 - accuracy: 0.2637 - val_loss: 3.1675 - val_accuracy: 0.2745
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8733 - accuracy: 0.2954
Epoch 5: val_loss improved from 3.16746 to 2.69247, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 96s 1s/step - loss: 2.8733 - accuracy: 0.2954 - val_loss: 2.6925 - val_accuracy: 0.2984
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.4930 - accuracy: 0.3000
Epoch 6: val_loss improved from 2.69247 to 2.35524, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 96s 1s/step - loss: 2.4930 - accuracy: 0.3000 - val_loss: 2.3552 - val_accuracy: 0.3176
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2294 - accuracy: 0.3100
Epoch 7: val_loss improved from 2.35524 to 2.12441, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 95s 1s/step - loss: 2.2294 - accuracy: 0.3100 - val_loss: 2.1244 - val_accuracy: 0.3236
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0443 - accuracy: 0.3172
Epoch 8: val_loss improved from 2.12441 to 1.96452, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 95s 1s/step - loss: 2.0443 - accuracy: 0.3172 - val_loss: 1.9645 - val_accuracy: 0.3264
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9135 - accuracy: 0.3258
Epoch 9: val_loss improved from 1.96452 to 1.85239, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 95s 1s/step - loss: 1.9135 - accuracy: 0.3258 - val_loss: 1.8524 - val_accuracy: 0.3342
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8209 - accuracy: 0.3353
Epoch 10: val_loss improved from 1.85239 to 1.77807, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 95s 1s/step - loss: 1.8209 - accuracy: 0.3353 - val_loss: 1.7781 - val_accuracy: 0.3408
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7542 - accuracy: 0.3392
Epoch 11: val_loss improved from 1.77807 to 1.72679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 95s 1s/step - loss: 1.7542 - accuracy: 0.3392 - val_loss: 1.7268 - val_accuracy: 0.3400
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7068 - accuracy: 0.3474
Epoch 12: val_loss improved from 1.72679 to 1.68801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 96s 1s/step - loss: 1.7068 - accuracy: 0.3474 - val_loss: 1.6880 - val_accuracy: 0.3458
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6713 - accuracy: 0.3523
Epoch 13: val_loss improved from 1.68801 to 1.66193, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 95s 1s/step - loss: 1.6713 - accuracy: 0.3523 - val_loss: 1.6619 - val_accuracy: 0.3502
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6435 - accuracy: 0.3579
Epoch 14: val_loss improved from 1.66193 to 1.63491, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 96s 1s/step - loss: 1.6435 - accuracy: 0.3579 - val_loss: 1.6349 - val_accuracy: 0.3593
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6157 - accuracy: 0.3696
Epoch 15: val_loss improved from 1.63491 to 1.61135, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 96s 1s/step - loss: 1.6157 - accuracy: 0.3696 - val_loss: 1.6113 - val_accuracy: 0.3686
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5975 - accuracy: 0.3802
Epoch 16: val_loss improved from 1.61135 to 1.59837, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 97s 1s/step - loss: 1.5975 - accuracy: 0.3802 - val_loss: 1.5984 - val_accuracy: 0.3716
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5821 - accuracy: 0.3867
Epoch 17: val_loss improved from 1.59837 to 1.58769, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 95s 1s/step - loss: 1.5821 - accuracy: 0.3867 - val_loss: 1.5877 - val_accuracy: 0.3830
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5678 - accuracy: 0.3961
Epoch 18: val_loss improved from 1.58769 to 1.57919, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 96s 1s/step - loss: 1.5678 - accuracy: 0.3961 - val_loss: 1.5792 - val_accuracy: 0.3861
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5564 - accuracy: 0.3996
Epoch 19: val_loss improved from 1.57919 to 1.57637, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 96s 1s/step - loss: 1.5564 - accuracy: 0.3996 - val_loss: 1.5764 - val_accuracy: 0.3847
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5456 - accuracy: 0.4079
Epoch 20: val_loss improved from 1.57637 to 1.56990, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 96s 1s/step - loss: 1.5456 - accuracy: 0.4079 - val_loss: 1.5699 - val_accuracy: 0.3884
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5366 - accuracy: 0.4115
Epoch 21: val_loss did not improve from 1.56990
83/83 [==============================] - 93s 1s/step - loss: 1.5366 - accuracy: 0.4115 - val_loss: 1.5709 - val_accuracy: 0.3873
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5279 - accuracy: 0.4143
Epoch 22: val_loss improved from 1.56990 to 1.56868, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 96s 1s/step - loss: 1.5279 - accuracy: 0.4143 - val_loss: 1.5687 - val_accuracy: 0.3959
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5209 - accuracy: 0.4231
Epoch 23: val_loss improved from 1.56868 to 1.56499, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/9
83/83 [==============================] - 96s 1s/step - loss: 1.5209 - accuracy: 0.4231 - val_loss: 1.5650 - val_accuracy: 0.3935
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5129 - accuracy: 0.4259
Epoch 24: val_loss did not improve from 1.56499
83/83 [==============================] - 95s 1s/step - loss: 1.5129 - accuracy: 0.4259 - val_loss: 1.5683 - val_accuracy: 0.3939
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5068 - accuracy: 0.4281
Epoch 25: val_loss did not improve from 1.56499
83/83 [==============================] - 92s 1s/step - loss: 1.5068 - accuracy: 0.4281 - val_loss: 1.5743 - val_accuracy: 0.3913
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.4967 - accuracy: 0.4382
Epoch 26: val_loss did not improve from 1.56499
83/83 [==============================] - 93s 1s/step - loss: 1.4967 - accuracy: 0.4382 - val_loss: 1.5731 - val_accuracy: 0.3911
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4881 - accuracy: 0.4411
Epoch 27: val_loss did not improve from 1.56499
83/83 [==============================] - 95s 1s/step - loss: 1.4881 - accuracy: 0.4411 - val_loss: 1.5730 - val_accuracy: 0.3960
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4830 - accuracy: 0.4471
Epoch 28: val_loss did not improve from 1.56499
83/83 [==============================] - 95s 1s/step - loss: 1.4830 - accuracy: 0.4471 - val_loss: 1.5783 - val_accuracy: 0.3956
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4754 - accuracy: 0.4503
Epoch 29: val_loss did not improve from 1.56499
83/83 [==============================] - 94s 1s/step - loss: 1.4754 - accuracy: 0.4503 - val_loss: 1.5836 - val_accuracy: 0.3970
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.4589
Epoch 30: val_loss did not improve from 1.56499
83/83 [==============================] - 94s 1s/step - loss: 1.4639 - accuracy: 0.4589 - val_loss: 1.5870 - val_accuracy: 0.3957
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4550 - accuracy: 0.4654
Epoch 31: val_loss did not improve from 1.56499
83/83 [==============================] - 95s 1s/step - loss: 1.4550 - accuracy: 0.4654 - val_loss: 1.6024 - val_accuracy: 0.3972
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4503 - accuracy: 0.4704
Epoch 32: val_loss did not improve from 1.56499
83/83 [==============================] - 95s 1s/step - loss: 1.4503 - accuracy: 0.4704 - val_loss: 1.6112 - val_accuracy: 0.3936
Epoch 33/100
83/83 [==============================] - ETA: 0s - loss: 1.4328 - accuracy: 0.4793
Epoch 33: val_loss did not improve from 1.56499
83/83 [==============================] - 94s 1s/step - loss: 1.4328 - accuracy: 0.4793 - val_loss: 1.6138 - val_accuracy: 0.3970
Epoch 33: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_9 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_29 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_9 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_9 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_27 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_27 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_28 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_28 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_29 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_29 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_27 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_9 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_27 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_28 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_28 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_29 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 134s 10ms/step - loss: 1.5696 - accuracy: 0.3940
Testing Loss = 1.569571, Testing Accuracy = 0.394016
The data set contains images
  13434/Unknown - 124s 9ms/step13437/13437 [==============================] - 125s 9ms/step
[[0.010564257390797138, 0.03787835314869881, 0.6081719994544983, 0.02220168337225914, 0.10813181102275848, 0.21305187046527863], [0.27524062991142273, 0.032501012086868286, 0.07283376902341843, 0.27068430185317993, 0.262403279542923, 0.08633697777986526], [0.14629638195037842, 0.04049352556467056, 0.2777760624885559, 0.09965386241674423, 0.2883492410182953, 0.1474309116601944], [0.09539737552404404, 0.029730381444096565, 0.22837421298027039, 0.1856852024793625, 0.29687175154685974, 0.16394111514091492], [0.004567870404571295, 0.11239123344421387, 0.3891019821166992, 0.03345983475446701, 0.0656512901186943, 0.39482778310775757], [0.041197557002305984, 0.3444794714450836, 0.04970725625753403, 0.2941795587539673, 0.0712551400065422, 0.19918105006217957], [0.40275895595550537, 0.026145899668335915, 0.10918733477592468, 0.12876559793949127, 0.25929367542266846, 0.07384850084781647], [0.30167266726493835, 0.04372945800423622, 0.07346563786268234, 0.24362441897392273, 0.24103476107120514, 0.0964730829000473], [0.018893631175160408, 0.0968681126832962, 0.4025706648826599, 0.05064559727907181, 0.12476768344640732, 0.3062543570995331], [0.2567318379878998, 0.03449707850813866, 0.1857205033302307, 0.12977151572704315, 0.28393176198005676, 0.1093473955988884]]
N of classes 6
$W^+/W^+$ (auc = 84.12 +- 0.0640 %)
$W^-/W^-$ (auc = 83.75 +- 0.0783 %)
$Z/Z$ (auc = 76.34 +- 0.1950 %)
$W^+/W^-$ (auc = 70.77 +- 0.1019 %)
$W^+/Z$$ (auc = 67.45 +- 0.1531 %)
$W^-/Z$ (auc = 69.33 +- 0.1084 %)
The summarized testing accuracy = 39.53 +- 0.2790 %, with the loss = 1.5710 +- 0.002404


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-12-23 23:03:53.112312
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
82/82 [==============================] - 138s 848ms/step - loss: 8.0235 - accuracy: 0.2008 - val_loss: 5.6335 - val_accuracy: 0.2148

Epoch 00001: val_loss improved from inf to 5.63347, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 2/100
82/82 [==============================] - 69s 840ms/step - loss: 5.0584 - accuracy: 0.2088 - val_loss: 4.5371 - val_accuracy: 0.2171

Epoch 00002: val_loss improved from 5.63347 to 4.53706, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 3/100
82/82 [==============================] - 70s 849ms/step - loss: 4.1269 - accuracy: 0.2133 - val_loss: 3.7501 - val_accuracy: 0.2236

Epoch 00003: val_loss improved from 4.53706 to 3.75012, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 4/100
82/82 [==============================] - 71s 855ms/step - loss: 3.3651 - accuracy: 0.2760 - val_loss: 3.1140 - val_accuracy: 0.2970

Epoch 00004: val_loss improved from 3.75012 to 3.11401, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 5/100
82/82 [==============================] - 75s 912ms/step - loss: 2.8404 - accuracy: 0.3020 - val_loss: 2.6764 - val_accuracy: 0.3079

Epoch 00005: val_loss improved from 3.11401 to 2.67644, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 6/100
82/82 [==============================] - 74s 905ms/step - loss: 2.4794 - accuracy: 0.3184 - val_loss: 2.3637 - val_accuracy: 0.3227

Epoch 00006: val_loss improved from 2.67644 to 2.36368, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 7/100
82/82 [==============================] - 71s 867ms/step - loss: 2.2166 - accuracy: 0.3342 - val_loss: 2.1135 - val_accuracy: 0.3475

Epoch 00007: val_loss improved from 2.36368 to 2.11352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 8/100
82/82 [==============================] - 70s 852ms/step - loss: 2.0280 - accuracy: 0.3476 - val_loss: 1.9509 - val_accuracy: 0.3542

Epoch 00008: val_loss improved from 2.11352 to 1.95089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 9/100
82/82 [==============================] - 75s 915ms/step - loss: 1.8880 - accuracy: 0.3584 - val_loss: 1.8237 - val_accuracy: 0.3669

Epoch 00009: val_loss improved from 1.95089 to 1.82372, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 10/100
82/82 [==============================] - 75s 910ms/step - loss: 1.7902 - accuracy: 0.3659 - val_loss: 1.7458 - val_accuracy: 0.3710

Epoch 00010: val_loss improved from 1.82372 to 1.74582, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 11/100
82/82 [==============================] - 70s 855ms/step - loss: 1.7170 - accuracy: 0.3763 - val_loss: 1.6986 - val_accuracy: 0.3735

Epoch 00011: val_loss improved from 1.74582 to 1.69856, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 12/100
82/82 [==============================] - 70s 849ms/step - loss: 1.6688 - accuracy: 0.3822 - val_loss: 1.6448 - val_accuracy: 0.3825

Epoch 00012: val_loss improved from 1.69856 to 1.64479, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 13/100
82/82 [==============================] - 75s 916ms/step - loss: 1.6276 - accuracy: 0.3903 - val_loss: 1.6117 - val_accuracy: 0.3931

Epoch 00013: val_loss improved from 1.64479 to 1.61170, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 14/100
82/82 [==============================] - 74s 904ms/step - loss: 1.5989 - accuracy: 0.3962 - val_loss: 1.5974 - val_accuracy: 0.3926

Epoch 00014: val_loss improved from 1.61170 to 1.59737, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 15/100
82/82 [==============================] - 74s 901ms/step - loss: 1.5789 - accuracy: 0.3999 - val_loss: 1.5785 - val_accuracy: 0.3970

Epoch 00015: val_loss improved from 1.59737 to 1.57850, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 16/100
82/82 [==============================] - 74s 903ms/step - loss: 1.5603 - accuracy: 0.4066 - val_loss: 1.5635 - val_accuracy: 0.4021

Epoch 00016: val_loss improved from 1.57850 to 1.56348, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 17/100
82/82 [==============================] - 69s 840ms/step - loss: 1.5459 - accuracy: 0.4135 - val_loss: 1.5612 - val_accuracy: 0.4013

Epoch 00017: val_loss improved from 1.56348 to 1.56124, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 18/100
82/82 [==============================] - 74s 896ms/step - loss: 1.5369 - accuracy: 0.4138 - val_loss: 1.5625 - val_accuracy: 0.4015

Epoch 00018: val_loss did not improve from 1.56124
Epoch 19/100
82/82 [==============================] - 74s 897ms/step - loss: 1.5270 - accuracy: 0.4188 - val_loss: 1.5534 - val_accuracy: 0.4072

Epoch 00019: val_loss improved from 1.56124 to 1.55341, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 20/100
82/82 [==============================] - 68s 823ms/step - loss: 1.5185 - accuracy: 0.4276 - val_loss: 1.5482 - val_accuracy: 0.4128

Epoch 00020: val_loss improved from 1.55341 to 1.54816, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 21/100
82/82 [==============================] - 67s 818ms/step - loss: 1.5052 - accuracy: 0.4334 - val_loss: 1.5689 - val_accuracy: 0.4050

Epoch 00021: val_loss did not improve from 1.54816
Epoch 22/100
82/82 [==============================] - 68s 822ms/step - loss: 1.5067 - accuracy: 0.4365 - val_loss: 1.5492 - val_accuracy: 0.4121

Epoch 00022: val_loss did not improve from 1.54816
Epoch 23/100
82/82 [==============================] - 67s 818ms/step - loss: 1.4889 - accuracy: 0.4447 - val_loss: 1.5583 - val_accuracy: 0.4110

Epoch 00023: val_loss did not improve from 1.54816
Epoch 24/100
82/82 [==============================] - 67s 813ms/step - loss: 1.4859 - accuracy: 0.4501 - val_loss: 1.5677 - val_accuracy: 0.4106

Epoch 00024: val_loss did not improve from 1.54816
Epoch 25/100
82/82 [==============================] - 68s 821ms/step - loss: 1.4825 - accuracy: 0.4510 - val_loss: 1.5743 - val_accuracy: 0.4078

Epoch 00025: val_loss did not improve from 1.54816
Epoch 26/100
82/82 [==============================] - 68s 821ms/step - loss: 1.4685 - accuracy: 0.4660 - val_loss: 1.5779 - val_accuracy: 0.4136

Epoch 00026: val_loss did not improve from 1.54816
Epoch 27/100
82/82 [==============================] - 67s 815ms/step - loss: 1.4562 - accuracy: 0.4747 - val_loss: 1.5980 - val_accuracy: 0.4113

Epoch 00027: val_loss did not improve from 1.54816
Epoch 28/100
82/82 [==============================] - 68s 822ms/step - loss: 1.4472 - accuracy: 0.4840 - val_loss: 1.6063 - val_accuracy: 0.4125

Epoch 00028: val_loss did not improve from 1.54816
Epoch 29/100
82/82 [==============================] - 67s 814ms/step - loss: 1.4297 - accuracy: 0.4964 - val_loss: 1.6406 - val_accuracy: 0.4071

Epoch 00029: val_loss did not improve from 1.54816
Epoch 30/100
82/82 [==============================] - 67s 813ms/step - loss: 1.4236 - accuracy: 0.5049 - val_loss: 1.6562 - val_accuracy: 0.4054

Epoch 00030: val_loss did not improve from 1.54816
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN3"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               365105320 [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 365,108,398[0m
[92mTrainable params: 365,108,394[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 75, 75, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 37, 37, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 37, 37, 512)       4719104   [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 700928)            0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               358875648 [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 365,105,320[0m
[94mTrainable params: 365,105,316[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT52AAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 512, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 178s 13ms/step - loss: 1.5494 - accuracy: 0.4145
Testing Loss = 1.549389, Testing Accuracy = 0.414453
The data set contains images
[[0.11667034775018692, 0.09131838381290436, 0.24316592514514923, 0.12179511040449142, 0.2230617105960846, 0.2039884626865387], [0.11752638220787048, 0.18810433149337769, 0.04852178320288658, 0.38532155752182007, 0.12373802065849304, 0.13678796589374542], [0.029652275145053864, 0.19436083734035492, 0.2586226463317871, 0.07590601593255997, 0.11051703989505768, 0.33094120025634766], [0.39251190423965454, 0.02918783389031887, 0.09983963519334793, 0.15339523553848267, 0.24834975600242615, 0.0767156109213829], [0.36493104696273804, 0.013503956608474255, 0.20319609344005585, 0.0556442029774189, 0.29102638363838196, 0.07169828563928604], [0.03147083893418312, 0.27060237526893616, 0.17326241731643677, 0.12515300512313843, 0.10601066052913666, 0.29350078105926514], [0.406690776348114, 0.022713597863912582, 0.10261248797178268, 0.12020377814769745, 0.27507638931274414, 0.07270298898220062], [0.016984643414616585, 0.6090738773345947, 0.04966820403933525, 0.09577198326587677, 0.042686425149440765, 0.18581481277942657], [0.4729524552822113, 0.06234307959675789, 0.0535275973379612, 0.179722398519516, 0.16109970211982727, 0.07035476714372635], [0.31737273931503296, 0.06337646394968033, 0.05761636793613434, 0.29102134704589844, 0.18952423334121704, 0.0810888260602951]]
N of classes 6
$W^+/W^+$ (auc = 85.43 +- 0.0000 %)
$W^-/W^-$ (auc = 84.06 +- 0.0000 %)
$Z/Z$ (auc = 79.39 +- 0.0000 %)
$W^+/W^-$ (auc = 72.49 +- 0.0000 %)
$W^+/Z$ (auc = 68.05 +- 0.0000 %)
$W^-/Z$ (auc = 69.40 +- 0.0000 %)
N of classes 6
$W^+/W^+$ (acc = 43.73 +- 0.0000 %
$W^-/W^-$ (acc = 46.59 +- 0.0000 %
$Z/Z$ (acc = 49.77 +- 0.0000 %
$W^+/W^-$ (acc = 35.86 +- 0.0000 %
$W^+/Z$ (acc = 32.18 +- 0.0000 %
$W^-/Z$ (acc = 32.68 +- 0.0000 %
The summarized testing accuracy = 41.45 +- 0.0000 %, with the loss = 1.5494 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-12-26 00:21:13.863153
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
82/82 [==============================] - 340s 3s/step - loss: 7.5566 - accuracy: 0.1986 - val_loss: 5.6577 - val_accuracy: 0.2140

Epoch 00001: val_loss improved from inf to 5.65774, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 2/100
82/82 [==============================] - 228s 3s/step - loss: 5.1102 - accuracy: 0.2091 - val_loss: 4.6048 - val_accuracy: 0.2152

Epoch 00002: val_loss improved from 5.65774 to 4.60476, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 3/100
82/82 [==============================] - 228s 3s/step - loss: 4.1794 - accuracy: 0.2399 - val_loss: 3.8450 - val_accuracy: 0.2592

Epoch 00003: val_loss improved from 4.60476 to 3.84499, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 4/100
82/82 [==============================] - 228s 3s/step - loss: 3.4420 - accuracy: 0.2896 - val_loss: 3.2168 - val_accuracy: 0.2790

Epoch 00004: val_loss improved from 3.84499 to 3.21676, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 5/100
82/82 [==============================] - 228s 3s/step - loss: 2.9370 - accuracy: 0.3019 - val_loss: 2.7754 - val_accuracy: 0.3012

Epoch 00005: val_loss improved from 3.21676 to 2.77544, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 6/100
82/82 [==============================] - 228s 3s/step - loss: 2.5794 - accuracy: 0.3097 - val_loss: 2.4551 - val_accuracy: 0.3135

Epoch 00006: val_loss improved from 2.77544 to 2.45509, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 7/100
82/82 [==============================] - 228s 3s/step - loss: 2.3220 - accuracy: 0.3126 - val_loss: 2.2224 - val_accuracy: 0.3138

Epoch 00007: val_loss improved from 2.45509 to 2.22245, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 8/100
82/82 [==============================] - 228s 3s/step - loss: 2.1337 - accuracy: 0.3168 - val_loss: 2.0602 - val_accuracy: 0.3133

Epoch 00008: val_loss improved from 2.22245 to 2.06018, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 9/100
82/82 [==============================] - 232s 3s/step - loss: 1.9948 - accuracy: 0.3201 - val_loss: 1.9456 - val_accuracy: 0.3211

Epoch 00009: val_loss improved from 2.06018 to 1.94565, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 10/100
82/82 [==============================] - 233s 3s/step - loss: 1.8949 - accuracy: 0.3231 - val_loss: 1.8565 - val_accuracy: 0.3235

Epoch 00010: val_loss improved from 1.94565 to 1.85648, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 11/100
82/82 [==============================] - 232s 3s/step - loss: 1.8208 - accuracy: 0.3290 - val_loss: 1.7868 - val_accuracy: 0.3325

Epoch 00011: val_loss improved from 1.85648 to 1.78679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 12/100
82/82 [==============================] - 233s 3s/step - loss: 1.7673 - accuracy: 0.3318 - val_loss: 1.7405 - val_accuracy: 0.3396

Epoch 00012: val_loss improved from 1.78679 to 1.74049, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 13/100
82/82 [==============================] - 229s 3s/step - loss: 1.7282 - accuracy: 0.3365 - val_loss: 1.7234 - val_accuracy: 0.3369

Epoch 00013: val_loss improved from 1.74049 to 1.72341, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 14/100
82/82 [==============================] - 228s 3s/step - loss: 1.6940 - accuracy: 0.3473 - val_loss: 1.6773 - val_accuracy: 0.3530

Epoch 00014: val_loss improved from 1.72341 to 1.67731, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 15/100
82/82 [==============================] - 228s 3s/step - loss: 1.6653 - accuracy: 0.3576 - val_loss: 1.6478 - val_accuracy: 0.3673

Epoch 00015: val_loss improved from 1.67731 to 1.64776, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 16/100
82/82 [==============================] - 228s 3s/step - loss: 1.6452 - accuracy: 0.3683 - val_loss: 1.6413 - val_accuracy: 0.3699

Epoch 00016: val_loss improved from 1.64776 to 1.64133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 17/100
82/82 [==============================] - 228s 3s/step - loss: 1.6231 - accuracy: 0.3800 - val_loss: 1.6223 - val_accuracy: 0.3778

Epoch 00017: val_loss improved from 1.64133 to 1.62233, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 18/100
82/82 [==============================] - 228s 3s/step - loss: 1.6027 - accuracy: 0.3917 - val_loss: 1.6265 - val_accuracy: 0.3754

Epoch 00018: val_loss did not improve from 1.62233
Epoch 19/100
82/82 [==============================] - 229s 3s/step - loss: 1.5965 - accuracy: 0.3943 - val_loss: 1.6250 - val_accuracy: 0.3780

Epoch 00019: val_loss did not improve from 1.62233
Epoch 20/100
82/82 [==============================] - 228s 3s/step - loss: 1.5831 - accuracy: 0.4029 - val_loss: 1.6257 - val_accuracy: 0.3796

Epoch 00020: val_loss did not improve from 1.62233
Epoch 21/100
82/82 [==============================] - 228s 3s/step - loss: 1.5749 - accuracy: 0.4115 - val_loss: 1.6219 - val_accuracy: 0.3890

Epoch 00021: val_loss improved from 1.62233 to 1.62190, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN3_event_kappa0.23/Try/0
Epoch 22/100
82/82 [==============================] - 228s 3s/step - loss: 1.5680 - accuracy: 0.4177 - val_loss: 1.6237 - val_accuracy: 0.3917

Epoch 00022: val_loss did not improve from 1.62190
Epoch 23/100
82/82 [==============================] - 228s 3s/step - loss: 1.5603 - accuracy: 0.4269 - val_loss: 1.6282 - val_accuracy: 0.3944

Epoch 00023: val_loss did not improve from 1.62190
Epoch 24/100
82/82 [==============================] - 228s 3s/step - loss: 1.5478 - accuracy: 0.4413 - val_loss: 1.6387 - val_accuracy: 0.3933

Epoch 00024: val_loss did not improve from 1.62190
Epoch 25/100
82/82 [==============================] - 228s 3s/step - loss: 1.5443 - accuracy: 0.4494 - val_loss: 1.6728 - val_accuracy: 0.3882

Epoch 00025: val_loss did not improve from 1.62190
Epoch 26/100
82/82 [==============================] - 228s 3s/step - loss: 1.5324 - accuracy: 0.4612 - val_loss: 1.6972 - val_accuracy: 0.3877

Epoch 00026: val_loss did not improve from 1.62190
Epoch 27/100
82/82 [==============================] - 228s 3s/step - loss: 1.5167 - accuracy: 0.4802 - val_loss: 1.7301 - val_accuracy: 0.3907

Epoch 00027: val_loss did not improve from 1.62190
Epoch 28/100
82/82 [==============================] - 228s 3s/step - loss: 1.5216 - accuracy: 0.4886 - val_loss: 1.7977 - val_accuracy: 0.3586

Epoch 00028: val_loss did not improve from 1.62190
Epoch 29/100
82/82 [==============================] - 228s 3s/step - loss: 1.5058 - accuracy: 0.5066 - val_loss: 1.8394 - val_accuracy: 0.3616

Epoch 00029: val_loss did not improve from 1.62190
Epoch 30/100
82/82 [==============================] - 228s 3s/step - loss: 1.4976 - accuracy: 0.5219 - val_loss: 1.8563 - val_accuracy: 0.3739

Epoch 00030: val_loss did not improve from 1.62190
Epoch 31/100
82/82 [==============================] - 228s 3s/step - loss: 1.4647 - accuracy: 0.5501 - val_loss: 1.9427 - val_accuracy: 0.3588

Epoch 00031: val_loss did not improve from 1.62190
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN3"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               1480790184[0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 1,480,793,262[0m
[92mTrainable params: 1,480,793,258[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 75, 75, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 75, 75, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 512)       4719104   [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 2880000)           0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               1474560512[0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 1,480,790,184[0m
[94mTrainable params: 1,480,790,180[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT52AAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 512, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 492s 37ms/step - loss: 1.6212 - accuracy: 0.3898
Testing Loss = 1.621219, Testing Accuracy = 0.389784
The data set contains images
[[0.08379563689231873, 0.0831499919295311, 0.30481448769569397, 0.11670302599668503, 0.20957763493061066, 0.20195920765399933], [0.19789978861808777, 0.11156010627746582, 0.0647982805967331, 0.3429807424545288, 0.16715139150619507, 0.1156095489859581], [0.04424798861145973, 0.060799531638622284, 0.41074350476264954, 0.05883477255702019, 0.17161811888217926, 0.25375601649284363], [0.3568160831928253, 0.019076945260167122, 0.13620594143867493, 0.13983337581157684, 0.26145464181900024, 0.08661296963691711], [0.37128159403800964, 0.01653994247317314, 0.18730206787586212, 0.062466178089380264, 0.2945699393749237, 0.06784027069807053], [0.033501993864774704, 0.1517009288072586, 0.3134005665779114, 0.10623799264431, 0.1606358140707016, 0.23452267050743103], [0.5498228669166565, 0.011522571556270123, 0.07597535848617554, 0.0998225137591362, 0.2250005602836609, 0.037856221199035645], [0.010613824240863323, 0.616299569606781, 0.04738270863890648, 0.0825778916478157, 0.03087068535387516, 0.21225537359714508], [0.44264715909957886, 0.05021271854639053, 0.07937758415937424, 0.15638794004917145, 0.19840823113918304, 0.07296638190746307], [0.34258267283439636, 0.053578201681375504, 0.06326912343502045, 0.2683410942554474, 0.19599276781082153, 0.07623621821403503]]
N of classes 6
$W^+/W^+$ (auc = 84.81 +- 0.0000 %)
$W^-/W^-$ (auc = 83.31 +- 0.0000 %)
$Z/Z$ (auc = 77.17 +- 0.0000 %)
$W^+/W^-$ (auc = 71.01 +- 0.0000 %)
$W^+/Z$ (auc = 66.68 +- 0.0000 %)
$W^-/Z$ (auc = 68.61 +- 0.0000 %)
N of classes 6
$W^+/W^+$ (acc = 38.95 +- 0.0000 %
$W^-/W^-$ (acc = 50.11 +- 0.0000 %
$Z/Z$ (acc = 45.09 +- 0.0000 %
$W^+/W^-$ (acc = 34.07 +- 0.0000 %
$W^+/Z$ (acc = 28.26 +- 0.0000 %
$W^-/Z$ (acc = 31.85 +- 0.0000 %
The summarized testing accuracy = 38.98 +- 0.0000 %, with the loss = 1.6212 +- 0.000000
