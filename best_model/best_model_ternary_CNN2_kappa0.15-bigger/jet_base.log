

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-05 19:52:25.339382
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 67s 67ms/step - loss: 3.2067 - accuracy: 0.5824 - val_loss: 1.0016 - val_accuracy: 0.6465

Epoch 00001: val_loss improved from inf to 1.00159, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 2/100
937/937 [==============================] - 63s 68ms/step - loss: 0.9128 - accuracy: 0.6403 - val_loss: 0.8603 - val_accuracy: 0.6509

Epoch 00002: val_loss improved from 1.00159 to 0.86032, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 3/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8638 - accuracy: 0.6457 - val_loss: 0.8557 - val_accuracy: 0.6485

Epoch 00003: val_loss improved from 0.86032 to 0.85569, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 4/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8525 - accuracy: 0.6502 - val_loss: 0.8466 - val_accuracy: 0.6520

Epoch 00004: val_loss improved from 0.85569 to 0.84664, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 5/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8449 - accuracy: 0.6527 - val_loss: 0.8342 - val_accuracy: 0.6583

Epoch 00005: val_loss improved from 0.84664 to 0.83418, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 6/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8390 - accuracy: 0.6556 - val_loss: 0.8390 - val_accuracy: 0.6549

Epoch 00006: val_loss did not improve from 0.83418
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8342 - accuracy: 0.6573 - val_loss: 0.8340 - val_accuracy: 0.6543

Epoch 00007: val_loss improved from 0.83418 to 0.83405, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8297 - accuracy: 0.6600 - val_loss: 0.8292 - val_accuracy: 0.6584

Epoch 00008: val_loss improved from 0.83405 to 0.82921, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 9/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8250 - accuracy: 0.6627 - val_loss: 0.8316 - val_accuracy: 0.6566

Epoch 00009: val_loss did not improve from 0.82921
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8214 - accuracy: 0.6644 - val_loss: 0.8294 - val_accuracy: 0.6582

Epoch 00010: val_loss did not improve from 0.82921
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8182 - accuracy: 0.6661 - val_loss: 0.8248 - val_accuracy: 0.6600

Epoch 00011: val_loss improved from 0.82921 to 0.82476, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 12/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8158 - accuracy: 0.6672 - val_loss: 0.8220 - val_accuracy: 0.6608

Epoch 00012: val_loss improved from 0.82476 to 0.82204, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 13/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8127 - accuracy: 0.6681 - val_loss: 0.8254 - val_accuracy: 0.6589

Epoch 00013: val_loss did not improve from 0.82204
Epoch 14/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8103 - accuracy: 0.6694 - val_loss: 0.8206 - val_accuracy: 0.6620

Epoch 00014: val_loss improved from 0.82204 to 0.82063, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 15/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8084 - accuracy: 0.6710 - val_loss: 0.8203 - val_accuracy: 0.6614

Epoch 00015: val_loss improved from 0.82063 to 0.82035, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 16/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8066 - accuracy: 0.6716 - val_loss: 0.8195 - val_accuracy: 0.6618

Epoch 00016: val_loss improved from 0.82035 to 0.81948, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 17/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8051 - accuracy: 0.6725 - val_loss: 0.8183 - val_accuracy: 0.6629

Epoch 00017: val_loss improved from 0.81948 to 0.81832, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 18/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8035 - accuracy: 0.6738 - val_loss: 0.8196 - val_accuracy: 0.6615

Epoch 00018: val_loss did not improve from 0.81832
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8017 - accuracy: 0.6747 - val_loss: 0.8101 - val_accuracy: 0.6672

Epoch 00019: val_loss improved from 0.81832 to 0.81009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 20/100
937/937 [==============================] - 169s 180ms/step - loss: 0.8000 - accuracy: 0.6755 - val_loss: 0.8171 - val_accuracy: 0.6633

Epoch 00020: val_loss did not improve from 0.81009
Epoch 21/100
937/937 [==============================] - 198s 211ms/step - loss: 0.7998 - accuracy: 0.6750 - val_loss: 0.8140 - val_accuracy: 0.6648

Epoch 00021: val_loss did not improve from 0.81009
Epoch 22/100
937/937 [==============================] - 200s 213ms/step - loss: 0.7975 - accuracy: 0.6766 - val_loss: 0.8094 - val_accuracy: 0.6687

Epoch 00022: val_loss improved from 0.81009 to 0.80939, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 23/100
937/937 [==============================] - 196s 209ms/step - loss: 0.7970 - accuracy: 0.6773 - val_loss: 0.8116 - val_accuracy: 0.6664

Epoch 00023: val_loss did not improve from 0.80939
Epoch 24/100
937/937 [==============================] - 194s 207ms/step - loss: 0.7958 - accuracy: 0.6778 - val_loss: 0.8041 - val_accuracy: 0.6703

Epoch 00024: val_loss improved from 0.80939 to 0.80407, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 25/100
937/937 [==============================] - 204s 218ms/step - loss: 0.7945 - accuracy: 0.6785 - val_loss: 0.8133 - val_accuracy: 0.6646

Epoch 00025: val_loss did not improve from 0.80407
Epoch 26/100
937/937 [==============================] - 194s 207ms/step - loss: 0.7937 - accuracy: 0.6790 - val_loss: 0.8048 - val_accuracy: 0.6701

Epoch 00026: val_loss did not improve from 0.80407
Epoch 27/100
937/937 [==============================] - 172s 183ms/step - loss: 0.7925 - accuracy: 0.6792 - val_loss: 0.8005 - val_accuracy: 0.6730

Epoch 00027: val_loss improved from 0.80407 to 0.80052, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 28/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7916 - accuracy: 0.6805 - val_loss: 0.8035 - val_accuracy: 0.6700

Epoch 00028: val_loss did not improve from 0.80052
Epoch 29/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7904 - accuracy: 0.6811 - val_loss: 0.8031 - val_accuracy: 0.6709

Epoch 00029: val_loss did not improve from 0.80052
Epoch 30/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7898 - accuracy: 0.6815 - val_loss: 0.8016 - val_accuracy: 0.6723

Epoch 00030: val_loss did not improve from 0.80052
Epoch 31/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7887 - accuracy: 0.6824 - val_loss: 0.7978 - val_accuracy: 0.6744

Epoch 00031: val_loss improved from 0.80052 to 0.79784, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 32/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7876 - accuracy: 0.6826 - val_loss: 0.8015 - val_accuracy: 0.6720

Epoch 00032: val_loss did not improve from 0.79784
Epoch 33/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7870 - accuracy: 0.6829 - val_loss: 0.8003 - val_accuracy: 0.6729

Epoch 00033: val_loss did not improve from 0.79784
Epoch 34/100
937/937 [==============================] - 61s 65ms/step - loss: 0.7858 - accuracy: 0.6841 - val_loss: 0.7987 - val_accuracy: 0.6738

Epoch 00034: val_loss did not improve from 0.79784
Epoch 35/100
937/937 [==============================] - 61s 66ms/step - loss: 0.7852 - accuracy: 0.6835 - val_loss: 0.7985 - val_accuracy: 0.6744

Epoch 00035: val_loss did not improve from 0.79784
Epoch 36/100
937/937 [==============================] - 61s 65ms/step - loss: 0.7841 - accuracy: 0.6853 - val_loss: 0.7992 - val_accuracy: 0.6736

Epoch 00036: val_loss did not improve from 0.79784
Epoch 37/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7837 - accuracy: 0.6854 - val_loss: 0.8019 - val_accuracy: 0.6712

Epoch 00037: val_loss did not improve from 0.79784
Epoch 38/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7825 - accuracy: 0.6856 - val_loss: 0.8049 - val_accuracy: 0.6695

Epoch 00038: val_loss did not improve from 0.79784
Epoch 39/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7814 - accuracy: 0.6865 - val_loss: 0.7964 - val_accuracy: 0.6758

Epoch 00039: val_loss improved from 0.79784 to 0.79640, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 40/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7810 - accuracy: 0.6873 - val_loss: 0.7991 - val_accuracy: 0.6733

Epoch 00040: val_loss did not improve from 0.79640
Epoch 41/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7793 - accuracy: 0.6878 - val_loss: 0.8000 - val_accuracy: 0.6730

Epoch 00041: val_loss did not improve from 0.79640
Epoch 42/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7791 - accuracy: 0.6881 - val_loss: 0.7934 - val_accuracy: 0.6779

Epoch 00042: val_loss improved from 0.79640 to 0.79340, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN2_kappa0.15-bigger/Try/0
Epoch 43/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7778 - accuracy: 0.6891 - val_loss: 0.7941 - val_accuracy: 0.6774

Epoch 00043: val_loss did not improve from 0.79340
Epoch 44/100
937/937 [==============================] - 61s 65ms/step - loss: 0.7774 - accuracy: 0.6897 - val_loss: 0.7970 - val_accuracy: 0.6754

Epoch 00044: val_loss did not improve from 0.79340
Epoch 45/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7763 - accuracy: 0.6906 - val_loss: 0.8044 - val_accuracy: 0.6714

Epoch 00045: val_loss did not improve from 0.79340
Epoch 46/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7758 - accuracy: 0.6908 - val_loss: 0.7958 - val_accuracy: 0.6757

Epoch 00046: val_loss did not improve from 0.79340
Epoch 47/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7748 - accuracy: 0.6917 - val_loss: 0.8053 - val_accuracy: 0.6704

Epoch 00047: val_loss did not improve from 0.79340
Epoch 48/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7736 - accuracy: 0.6925 - val_loss: 0.7978 - val_accuracy: 0.6747

Epoch 00048: val_loss did not improve from 0.79340
Epoch 49/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7724 - accuracy: 0.6926 - val_loss: 0.7975 - val_accuracy: 0.6751

Epoch 00049: val_loss did not improve from 0.79340
Epoch 50/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7721 - accuracy: 0.6936 - val_loss: 0.7986 - val_accuracy: 0.6747

Epoch 00050: val_loss did not improve from 0.79340
Epoch 51/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7709 - accuracy: 0.6940 - val_loss: 0.7943 - val_accuracy: 0.6780

Epoch 00051: val_loss did not improve from 0.79340
Epoch 52/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7700 - accuracy: 0.6947 - val_loss: 0.7957 - val_accuracy: 0.6772

Epoch 00052: val_loss did not improve from 0.79340
Epoch 00052: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN2"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92mlambda (Lambda)              multiple                  0 (unused)[0m
[92m_________________________________________________________________[0m
[92mbatch_normalization (BatchNo multiple                  0 (unused)[0m
[92m_________________________________________________________________[0m
[92mconv2d (Conv2D)              multiple                  0 (unused)[0m
[92m_________________________________________________________________[0m
[92mmax_pooling2d (MaxPooling2D) multiple                  0 (unused)[0m
[92m_________________________________________________________________[0m
[92mconv2d_1 (Conv2D)            multiple                  0 (unused)[0m
[92m_________________________________________________________________[0m
[92mconv2d_2 (Conv2D)            multiple                  0 (unused)[0m
[92m_________________________________________________________________[0m
[92mdropout (Dropout)            multiple                  0 (unused)[0m
[92m_________________________________________________________________[0m
[92mflatten (Flatten)            multiple                  0 (unused)[0m
[92m_________________________________________________________________[0m
[92mdense (Dense)                multiple                  0 (unused)[0m
[92m_________________________________________________________________[0m
[92mdropout_1 (Dropout)          multiple                  0 (unused)[0m
[92m_________________________________________________________________[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_3 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT5kAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}

@LAYER3       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

@LAYER4       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}

@LAYER5       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

@LAYER6       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

@LAYER7       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}

@LAYER8       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}

@LAYER9       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

@LAYER10       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}

@LAYER11       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_2 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT5wAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER12       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 598s 4ms/step - loss: 0.7896 - accuracy: 0.6804
Testing Loss = 0.789582, Testing Accuracy = 0.680367
The data set contains images
N of classes 3
$W^+$ (auc = 85.54 +- 0.0000 %)
$W^-$ (auc = 85.47 +- 0.0000 %)
$Z$ (auc = 83.80 +- 0.0000 %)
The summarized testing accuracy = 68.04 +- 0.0000 %, with the loss = 0.7896 +- 0.000000
