

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2023-01-31 14:12:42.725061
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 46493.
Epoch 1/100
90/90 [==============================] - 10s 72ms/step - loss: 11.4143 - accuracy: 0.3702 - val_loss: 7.5797 - val_accuracy: 0.3869

Epoch 00001: val_loss improved from inf to 7.57971, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 2/100
90/90 [==============================] - 6s 68ms/step - loss: 5.5827 - accuracy: 0.5558 - val_loss: 4.3754 - val_accuracy: 0.4780

Epoch 00002: val_loss improved from 7.57971 to 4.37544, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 3/100
90/90 [==============================] - 6s 67ms/step - loss: 3.4803 - accuracy: 0.6162 - val_loss: 3.0452 - val_accuracy: 0.5447

Epoch 00003: val_loss improved from 4.37544 to 3.04518, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 4/100
90/90 [==============================] - 6s 66ms/step - loss: 2.5335 - accuracy: 0.6270 - val_loss: 2.2928 - val_accuracy: 0.6113

Epoch 00004: val_loss improved from 3.04518 to 2.29281, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 5/100
90/90 [==============================] - 6s 67ms/step - loss: 1.9685 - accuracy: 0.6390 - val_loss: 1.7989 - val_accuracy: 0.6444

Epoch 00005: val_loss improved from 2.29281 to 1.79894, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 6/100
90/90 [==============================] - 6s 67ms/step - loss: 1.5943 - accuracy: 0.6531 - val_loss: 1.4758 - val_accuracy: 0.6444

Epoch 00006: val_loss improved from 1.79894 to 1.47576, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 7/100
90/90 [==============================] - 6s 67ms/step - loss: 1.3373 - accuracy: 0.6641 - val_loss: 1.2403 - val_accuracy: 0.6674

Epoch 00007: val_loss improved from 1.47576 to 1.24034, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 8/100
90/90 [==============================] - 8s 93ms/step - loss: 1.1530 - accuracy: 0.6785 - val_loss: 1.0960 - val_accuracy: 0.6710

Epoch 00008: val_loss improved from 1.24034 to 1.09601, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 9/100
90/90 [==============================] - 6s 66ms/step - loss: 1.0254 - accuracy: 0.6900 - val_loss: 0.9767 - val_accuracy: 0.6949

Epoch 00009: val_loss improved from 1.09601 to 0.97673, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 10/100
90/90 [==============================] - 6s 67ms/step - loss: 0.9304 - accuracy: 0.7031 - val_loss: 0.9192 - val_accuracy: 0.6920

Epoch 00010: val_loss improved from 0.97673 to 0.91916, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 11/100
90/90 [==============================] - 6s 66ms/step - loss: 0.8699 - accuracy: 0.7118 - val_loss: 0.8687 - val_accuracy: 0.6990

Epoch 00011: val_loss improved from 0.91916 to 0.86872, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 12/100
90/90 [==============================] - 6s 67ms/step - loss: 0.8212 - accuracy: 0.7211 - val_loss: 0.8237 - val_accuracy: 0.7108

Epoch 00012: val_loss improved from 0.86872 to 0.82370, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 13/100
90/90 [==============================] - 6s 67ms/step - loss: 0.7877 - accuracy: 0.7285 - val_loss: 0.8042 - val_accuracy: 0.7120

Epoch 00013: val_loss improved from 0.82370 to 0.80424, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 14/100
90/90 [==============================] - 6s 67ms/step - loss: 0.7676 - accuracy: 0.7319 - val_loss: 0.7903 - val_accuracy: 0.7172

Epoch 00014: val_loss improved from 0.80424 to 0.79035, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 15/100
90/90 [==============================] - 6s 67ms/step - loss: 0.7419 - accuracy: 0.7401 - val_loss: 0.7827 - val_accuracy: 0.7161

Epoch 00015: val_loss improved from 0.79035 to 0.78267, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 16/100
90/90 [==============================] - 6s 67ms/step - loss: 0.7256 - accuracy: 0.7486 - val_loss: 0.7857 - val_accuracy: 0.7122

Epoch 00016: val_loss did not improve from 0.78267
Epoch 17/100
90/90 [==============================] - 6s 67ms/step - loss: 0.7162 - accuracy: 0.7512 - val_loss: 0.7721 - val_accuracy: 0.7205

Epoch 00017: val_loss improved from 0.78267 to 0.77212, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 18/100
90/90 [==============================] - 6s 67ms/step - loss: 0.6990 - accuracy: 0.7576 - val_loss: 0.7892 - val_accuracy: 0.7109

Epoch 00018: val_loss did not improve from 0.77212
Epoch 19/100
90/90 [==============================] - 6s 67ms/step - loss: 0.6901 - accuracy: 0.7640 - val_loss: 0.7913 - val_accuracy: 0.7104

Epoch 00019: val_loss did not improve from 0.77212
Epoch 20/100
90/90 [==============================] - 6s 67ms/step - loss: 0.6837 - accuracy: 0.7676 - val_loss: 0.7794 - val_accuracy: 0.7174

Epoch 00020: val_loss did not improve from 0.77212
Epoch 21/100
90/90 [==============================] - 6s 67ms/step - loss: 0.6684 - accuracy: 0.7771 - val_loss: 0.7788 - val_accuracy: 0.7212

Epoch 00021: val_loss did not improve from 0.77212
Epoch 22/100
90/90 [==============================] - 6s 67ms/step - loss: 0.6603 - accuracy: 0.7832 - val_loss: 0.7855 - val_accuracy: 0.7178

Epoch 00022: val_loss did not improve from 0.77212
Epoch 23/100
90/90 [==============================] - 6s 67ms/step - loss: 0.6462 - accuracy: 0.7908 - val_loss: 0.7887 - val_accuracy: 0.7211

Epoch 00023: val_loss did not improve from 0.77212
Epoch 24/100
90/90 [==============================] - 6s 67ms/step - loss: 0.6369 - accuracy: 0.7989 - val_loss: 0.7879 - val_accuracy: 0.7221

Epoch 00024: val_loss did not improve from 0.77212
Epoch 25/100
90/90 [==============================] - 6s 67ms/step - loss: 0.6249 - accuracy: 0.8058 - val_loss: 0.8155 - val_accuracy: 0.7130

Epoch 00025: val_loss did not improve from 0.77212
Epoch 26/100
90/90 [==============================] - 6s 67ms/step - loss: 0.6153 - accuracy: 0.8125 - val_loss: 0.8158 - val_accuracy: 0.7159

Epoch 00026: val_loss did not improve from 0.77212
Epoch 27/100
90/90 [==============================] - 6s 67ms/step - loss: 0.6088 - accuracy: 0.8172 - val_loss: 0.8054 - val_accuracy: 0.7232

Epoch 00027: val_loss did not improve from 0.77212
Epoch 00027: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
14530/14530 [==============================] - 70s 5ms/step - loss: 0.7772 - accuracy: 0.7167
Testing Loss = 0.777208, Testing Accuracy = 0.716724
The data set contains images
[[0.4392295181751251, 0.2650168240070343, 0.29575368762016296], [0.012596233747899532, 0.2209770679473877, 0.7664267420768738], [0.023154549300670624, 0.8233835697174072, 0.15346188843250275], [0.8641066551208496, 0.043704595416784286, 0.09218881279230118], [0.41802823543548584, 0.043887123465538025, 0.5380846261978149], [0.6570385694503784, 0.10949936509132385, 0.23346208035945892], [0.09620954841375351, 0.8354908227920532, 0.06829957664012909], [0.7396214008331299, 0.04228152707219124, 0.2180970311164856], [0.06998828053474426, 0.579564094543457, 0.3504476249217987], [0.43381616473197937, 0.36058589816093445, 0.20559796690940857]]
N of classes 3
$W^+/W^+$ (auc = 90.17 +- 0.0000 %)
$W^-/W^-$ (auc = 89.76 +- 0.0000 %)
$Z/Z$ (auc = 84.09 +- 0.0000 %)
N of classes 3
$W^+/W^+$ (acc = 71.31 +- 0.0000 %
$W^-/W^-$ (acc = 70.13 +- 0.0000 %
$Z/Z$ (acc = 74.24 +- 0.0000 %
The summarized testing accuracy = 71.67 +- 0.0000 %, with the loss = 0.7772 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2023-01-31 14:20:18.289075
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 46493.
Epoch 1/100
90/90 [==============================] - 10s 71ms/step - loss: 11.4198 - accuracy: 0.3669 - val_loss: 7.5764 - val_accuracy: 0.3893

Epoch 00001: val_loss improved from inf to 7.57640, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 2/100
90/90 [==============================] - 6s 67ms/step - loss: 5.6226 - accuracy: 0.5141 - val_loss: 4.3683 - val_accuracy: 0.4647

Epoch 00002: val_loss improved from 7.57640 to 4.36829, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 3/100
90/90 [==============================] - 6s 67ms/step - loss: 3.4811 - accuracy: 0.6106 - val_loss: 3.0462 - val_accuracy: 0.5516

Epoch 00003: val_loss improved from 4.36829 to 3.04624, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 4/100
90/90 [==============================] - 6s 67ms/step - loss: 2.5342 - accuracy: 0.6260 - val_loss: 2.2929 - val_accuracy: 0.6136

Epoch 00004: val_loss improved from 3.04624 to 2.29292, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 5/100
90/90 [==============================] - 6s 68ms/step - loss: 1.9717 - accuracy: 0.6359 - val_loss: 1.8058 - val_accuracy: 0.6402

Epoch 00005: val_loss improved from 2.29292 to 1.80583, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 6/100
90/90 [==============================] - 6s 68ms/step - loss: 1.5958 - accuracy: 0.6525 - val_loss: 1.4676 - val_accuracy: 0.6483

Epoch 00006: val_loss improved from 1.80583 to 1.46756, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 7/100
90/90 [==============================] - 6s 68ms/step - loss: 1.3415 - accuracy: 0.6620 - val_loss: 1.2370 - val_accuracy: 0.6750

Epoch 00007: val_loss improved from 1.46756 to 1.23698, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 8/100
90/90 [==============================] - 6s 67ms/step - loss: 1.1569 - accuracy: 0.6754 - val_loss: 1.0889 - val_accuracy: 0.6799

Epoch 00008: val_loss improved from 1.23698 to 1.08890, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 9/100
90/90 [==============================] - 6s 67ms/step - loss: 1.0302 - accuracy: 0.6871 - val_loss: 0.9837 - val_accuracy: 0.6935

Epoch 00009: val_loss improved from 1.08890 to 0.98366, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 10/100
90/90 [==============================] - 6s 68ms/step - loss: 0.9390 - accuracy: 0.6977 - val_loss: 0.9120 - val_accuracy: 0.6999

Epoch 00010: val_loss improved from 0.98366 to 0.91197, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 11/100
90/90 [==============================] - 7s 80ms/step - loss: 0.8717 - accuracy: 0.7101 - val_loss: 0.8625 - val_accuracy: 0.7036

Epoch 00011: val_loss improved from 0.91197 to 0.86249, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 12/100
90/90 [==============================] - 6s 67ms/step - loss: 0.8231 - accuracy: 0.7209 - val_loss: 0.8451 - val_accuracy: 0.7037

Epoch 00012: val_loss improved from 0.86249 to 0.84513, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 13/100
90/90 [==============================] - 6s 68ms/step - loss: 0.7893 - accuracy: 0.7276 - val_loss: 0.8094 - val_accuracy: 0.7170

Epoch 00013: val_loss improved from 0.84513 to 0.80939, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 14/100
90/90 [==============================] - 6s 68ms/step - loss: 0.7635 - accuracy: 0.7350 - val_loss: 0.7899 - val_accuracy: 0.7183

Epoch 00014: val_loss improved from 0.80939 to 0.78990, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 15/100
90/90 [==============================] - 6s 68ms/step - loss: 0.7407 - accuracy: 0.7434 - val_loss: 0.7989 - val_accuracy: 0.7124

Epoch 00015: val_loss did not improve from 0.78990
Epoch 16/100
90/90 [==============================] - 6s 68ms/step - loss: 0.7288 - accuracy: 0.7472 - val_loss: 0.7723 - val_accuracy: 0.7247

Epoch 00016: val_loss improved from 0.78990 to 0.77225, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 17/100
90/90 [==============================] - 6s 68ms/step - loss: 0.7121 - accuracy: 0.7554 - val_loss: 0.7904 - val_accuracy: 0.7163

Epoch 00017: val_loss did not improve from 0.77225
Epoch 18/100
90/90 [==============================] - 6s 68ms/step - loss: 0.6972 - accuracy: 0.7637 - val_loss: 0.7905 - val_accuracy: 0.7152

Epoch 00018: val_loss did not improve from 0.77225
Epoch 19/100
90/90 [==============================] - 6s 68ms/step - loss: 0.6890 - accuracy: 0.7675 - val_loss: 0.7955 - val_accuracy: 0.7134

Epoch 00019: val_loss did not improve from 0.77225
Epoch 20/100
90/90 [==============================] - 6s 68ms/step - loss: 0.6830 - accuracy: 0.7711 - val_loss: 0.7699 - val_accuracy: 0.7270

Epoch 00020: val_loss improved from 0.77225 to 0.76990, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 21/100
90/90 [==============================] - 6s 68ms/step - loss: 0.6738 - accuracy: 0.7761 - val_loss: 0.7693 - val_accuracy: 0.7290

Epoch 00021: val_loss improved from 0.76990 to 0.76928, saving model to /home/samhuang/ML/best_model/best_model_ternary_T-CNN_event_kappa0.23/Try/0
Epoch 22/100
90/90 [==============================] - 6s 68ms/step - loss: 0.6607 - accuracy: 0.7850 - val_loss: 0.7792 - val_accuracy: 0.7269

Epoch 00022: val_loss did not improve from 0.76928
Epoch 23/100
90/90 [==============================] - 6s 68ms/step - loss: 0.6468 - accuracy: 0.7930 - val_loss: 0.7944 - val_accuracy: 0.7212

Epoch 00023: val_loss did not improve from 0.76928
Epoch 24/100
90/90 [==============================] - 6s 68ms/step - loss: 0.6365 - accuracy: 0.7998 - val_loss: 0.7990 - val_accuracy: 0.7202

Epoch 00024: val_loss did not improve from 0.76928
Epoch 25/100
90/90 [==============================] - 6s 68ms/step - loss: 0.6267 - accuracy: 0.8060 - val_loss: 0.8130 - val_accuracy: 0.7192

Epoch 00025: val_loss did not improve from 0.76928
Epoch 26/100
90/90 [==============================] - 6s 68ms/step - loss: 0.6175 - accuracy: 0.8127 - val_loss: 0.8201 - val_accuracy: 0.7155

Epoch 00026: val_loss did not improve from 0.76928
Epoch 27/100
90/90 [==============================] - 6s 68ms/step - loss: 0.5959 - accuracy: 0.8264 - val_loss: 0.8435 - val_accuracy: 0.7125

Epoch 00027: val_loss did not improve from 0.76928
Epoch 28/100
90/90 [==============================] - 6s 68ms/step - loss: 0.5872 - accuracy: 0.8329 - val_loss: 0.8366 - val_accuracy: 0.7174

Epoch 00028: val_loss did not improve from 0.76928
Epoch 29/100
90/90 [==============================] - 6s 68ms/step - loss: 0.5763 - accuracy: 0.8398 - val_loss: 0.8511 - val_accuracy: 0.7160

Epoch 00029: val_loss did not improve from 0.76928
Epoch 30/100
90/90 [==============================] - 6s 68ms/step - loss: 0.5573 - accuracy: 0.8507 - val_loss: 0.8500 - val_accuracy: 0.7195

Epoch 00030: val_loss did not improve from 0.76928
Epoch 31/100
90/90 [==============================] - 6s 68ms/step - loss: 0.5473 - accuracy: 0.8576 - val_loss: 0.8728 - val_accuracy: 0.7155

Epoch 00031: val_loss did not improve from 0.76928
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
14530/14530 [==============================] - 69s 5ms/step - loss: 0.7744 - accuracy: 0.7225
Testing Loss = 0.774356, Testing Accuracy = 0.722505
The data set contains images
[[0.3888266384601593, 0.30547213554382324, 0.30570125579833984], [0.014595418237149715, 0.3205840289592743, 0.6648205518722534], [0.015434040687978268, 0.7830973267555237, 0.20146866142749786], [0.8977092504501343, 0.02093590423464775, 0.08135484904050827], [0.4436433017253876, 0.06339778006076813, 0.4929589331150055], [0.6492337584495544, 0.10556618869304657, 0.2452000379562378], [0.07784724980592728, 0.8537682890892029, 0.06838446110486984], [0.4741927981376648, 0.0569118857383728, 0.4688953161239624], [0.07295508682727814, 0.5158601403236389, 0.41118472814559937], [0.49765151739120483, 0.28351178765296936, 0.2188366800546646]]
N of classes 3
$W^+/W^+$ (auc = 90.28 +- 0.0000 %)
$W^-/W^-$ (auc = 89.93 +- 0.0000 %)
$Z/Z$ (auc = 84.31 +- 0.0000 %)
N of classes 3
$W^+/W^+$ (acc = 73.19 +- 0.0000 %
$W^-/W^-$ (acc = 73.04 +- 0.0000 %
$Z/Z$ (acc = 70.31 +- 0.0000 %
The summarized testing accuracy = 72.25 +- 0.0000 %, with the loss = 0.7744 +- 0.000000
