

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-20 15:02:45.646456
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
562/562 [==============================] - 59s 88ms/step - loss: 4.2200 - accuracy: 0.6619 - val_loss: 1.4084 - val_accuracy: 0.7251

Epoch 00001: val_loss improved from inf to 1.40843, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 2/500
562/562 [==============================] - 41s 73ms/step - loss: 0.9981 - accuracy: 0.7291 - val_loss: 0.7936 - val_accuracy: 0.7288

Epoch 00002: val_loss improved from 1.40843 to 0.79364, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 3/500
562/562 [==============================] - 38s 68ms/step - loss: 0.7387 - accuracy: 0.7378 - val_loss: 0.7226 - val_accuracy: 0.7307

Epoch 00003: val_loss improved from 0.79364 to 0.72259, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 4/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6977 - accuracy: 0.7421 - val_loss: 0.6940 - val_accuracy: 0.7380

Epoch 00004: val_loss improved from 0.72259 to 0.69397, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 5/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6823 - accuracy: 0.7445 - val_loss: 0.6830 - val_accuracy: 0.7403

Epoch 00005: val_loss improved from 0.69397 to 0.68297, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 6/500
562/562 [==============================] - 39s 68ms/step - loss: 0.6736 - accuracy: 0.7475 - val_loss: 0.6780 - val_accuracy: 0.7417

Epoch 00006: val_loss improved from 0.68297 to 0.67796, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 7/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6668 - accuracy: 0.7497 - val_loss: 0.6724 - val_accuracy: 0.7444

Epoch 00007: val_loss improved from 0.67796 to 0.67243, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 8/500
562/562 [==============================] - 39s 70ms/step - loss: 0.6616 - accuracy: 0.7512 - val_loss: 0.6712 - val_accuracy: 0.7428

Epoch 00008: val_loss improved from 0.67243 to 0.67116, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 9/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6574 - accuracy: 0.7526 - val_loss: 0.6586 - val_accuracy: 0.7491

Epoch 00009: val_loss improved from 0.67116 to 0.65860, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 10/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6530 - accuracy: 0.7539 - val_loss: 0.6591 - val_accuracy: 0.7489

Epoch 00010: val_loss did not improve from 0.65860
Epoch 11/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6495 - accuracy: 0.7554 - val_loss: 0.6587 - val_accuracy: 0.7475

Epoch 00011: val_loss did not improve from 0.65860
Epoch 12/500
562/562 [==============================] - 39s 70ms/step - loss: 0.6459 - accuracy: 0.7568 - val_loss: 0.6546 - val_accuracy: 0.7501

Epoch 00012: val_loss improved from 0.65860 to 0.65463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 13/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6432 - accuracy: 0.7577 - val_loss: 0.6535 - val_accuracy: 0.7506

Epoch 00013: val_loss improved from 0.65463 to 0.65346, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 14/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6402 - accuracy: 0.7593 - val_loss: 0.6496 - val_accuracy: 0.7507

Epoch 00014: val_loss improved from 0.65346 to 0.64956, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 15/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6372 - accuracy: 0.7607 - val_loss: 0.6492 - val_accuracy: 0.7509

Epoch 00015: val_loss improved from 0.64956 to 0.64919, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 16/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6337 - accuracy: 0.7618 - val_loss: 0.6512 - val_accuracy: 0.7493

Epoch 00016: val_loss did not improve from 0.64919
Epoch 17/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6314 - accuracy: 0.7632 - val_loss: 0.6526 - val_accuracy: 0.7486

Epoch 00017: val_loss did not improve from 0.64919
Epoch 18/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6281 - accuracy: 0.7654 - val_loss: 0.6498 - val_accuracy: 0.7503

Epoch 00018: val_loss did not improve from 0.64919
Epoch 19/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6247 - accuracy: 0.7660 - val_loss: 0.6493 - val_accuracy: 0.7507

Epoch 00019: val_loss did not improve from 0.64919
Epoch 20/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6228 - accuracy: 0.7675 - val_loss: 0.6496 - val_accuracy: 0.7511

Epoch 00020: val_loss did not improve from 0.64919
Epoch 21/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6187 - accuracy: 0.7701 - val_loss: 0.6494 - val_accuracy: 0.7508

Epoch 00021: val_loss did not improve from 0.64919
Epoch 22/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6155 - accuracy: 0.7719 - val_loss: 0.6487 - val_accuracy: 0.7511

Epoch 00022: val_loss improved from 0.64919 to 0.64874, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 23/500
562/562 [==============================] - 39s 70ms/step - loss: 0.6110 - accuracy: 0.7749 - val_loss: 0.6492 - val_accuracy: 0.7510

Epoch 00023: val_loss did not improve from 0.64874
Epoch 24/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6066 - accuracy: 0.7771 - val_loss: 0.6534 - val_accuracy: 0.7492

Epoch 00024: val_loss did not improve from 0.64874
Epoch 25/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6027 - accuracy: 0.7799 - val_loss: 0.6557 - val_accuracy: 0.7487

Epoch 00025: val_loss did not improve from 0.64874
Epoch 26/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5982 - accuracy: 0.7823 - val_loss: 0.6567 - val_accuracy: 0.7494

Epoch 00026: val_loss did not improve from 0.64874
Epoch 27/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5932 - accuracy: 0.7862 - val_loss: 0.6606 - val_accuracy: 0.7482

Epoch 00027: val_loss did not improve from 0.64874
Epoch 28/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5879 - accuracy: 0.7894 - val_loss: 0.6666 - val_accuracy: 0.7455

Epoch 00028: val_loss did not improve from 0.64874
Epoch 29/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5826 - accuracy: 0.7925 - val_loss: 0.6704 - val_accuracy: 0.7462

Epoch 00029: val_loss did not improve from 0.64874
Epoch 30/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5773 - accuracy: 0.7964 - val_loss: 0.6776 - val_accuracy: 0.7426

Epoch 00030: val_loss did not improve from 0.64874
Epoch 31/500
562/562 [==============================] - 39s 69ms/step - loss: 0.5696 - accuracy: 0.8007 - val_loss: 0.6853 - val_accuracy: 0.7413

Epoch 00031: val_loss did not improve from 0.64874
Epoch 32/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5626 - accuracy: 0.8046 - val_loss: 0.6917 - val_accuracy: 0.7407

Epoch 00032: val_loss did not improve from 0.64874
Epoch 33/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5552 - accuracy: 0.8089 - val_loss: 0.6978 - val_accuracy: 0.7389

Epoch 00033: val_loss did not improve from 0.64874
Epoch 34/500
562/562 [==============================] - 39s 69ms/step - loss: 0.5474 - accuracy: 0.8134 - val_loss: 0.7138 - val_accuracy: 0.7371

Epoch 00034: val_loss did not improve from 0.64874
Epoch 35/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5385 - accuracy: 0.8182 - val_loss: 0.7167 - val_accuracy: 0.7366

Epoch 00035: val_loss did not improve from 0.64874
Epoch 36/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5288 - accuracy: 0.8236 - val_loss: 0.7287 - val_accuracy: 0.7324

Epoch 00036: val_loss did not improve from 0.64874
Epoch 37/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5219 - accuracy: 0.8283 - val_loss: 0.7344 - val_accuracy: 0.7350

Epoch 00037: val_loss did not improve from 0.64874
Epoch 38/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5260 - accuracy: 0.8251 - val_loss: 0.7626 - val_accuracy: 0.7237

Epoch 00038: val_loss did not improve from 0.64874
Epoch 39/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5164 - accuracy: 0.8297 - val_loss: 0.7613 - val_accuracy: 0.7270

Epoch 00039: val_loss did not improve from 0.64874
Epoch 40/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5056 - accuracy: 0.8358 - val_loss: 0.7599 - val_accuracy: 0.7287

Epoch 00040: val_loss did not improve from 0.64874
Epoch 41/500
562/562 [==============================] - 38s 68ms/step - loss: 0.4977 - accuracy: 0.8395 - val_loss: 0.7780 - val_accuracy: 0.7249

Epoch 00041: val_loss did not improve from 0.64874
Epoch 42/500
562/562 [==============================] - 38s 68ms/step - loss: 0.4871 - accuracy: 0.8452 - val_loss: 0.7982 - val_accuracy: 0.7227

Epoch 00042: val_loss did not improve from 0.64874
Epoch 00042: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
90000/90000 [==============================] - 372s 4ms/step - loss: 0.6515 - accuracy: 0.7484
Testing Loss = 0.651451, Testing Accuracy = 0.748422
The data set contains images
[[0.820674479007721, 0.13460126519203186, 0.04472425952553749], [0.19214090704917908, 0.008386745117604733, 0.7994723916053772], [0.898963451385498, 0.06034178286790848, 0.04069472849369049], [0.27268022298812866, 0.009148836135864258, 0.7181708812713623], [0.021175669506192207, 0.12358357012271881, 0.8552408218383789], [0.8152192831039429, 0.013935149647295475, 0.17084549367427826], [0.03360924497246742, 0.09089361131191254, 0.8754971027374268], [0.13081881403923035, 0.788874626159668, 0.08030658960342407], [0.1260085254907608, 0.740553617477417, 0.1334379017353058], [0.07068654149770737, 0.022723793983459473, 0.906589686870575]]
[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]
3
$W^+$ (auc = 0.9062)
$W^-$ (auc = 0.9063)
$Z$ (auc = 0.8892)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-20 15:44:51.676803
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
562/562 [==============================] - 44s 69ms/step - loss: 4.2575 - accuracy: 0.6677 - val_loss: 1.4234 - val_accuracy: 0.7258

Epoch 00001: val_loss improved from inf to 1.42337, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 2/500
562/562 [==============================] - 38s 68ms/step - loss: 1.0066 - accuracy: 0.7282 - val_loss: 0.7955 - val_accuracy: 0.7318

Epoch 00002: val_loss improved from 1.42337 to 0.79545, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 3/500
562/562 [==============================] - 39s 69ms/step - loss: 0.7410 - accuracy: 0.7377 - val_loss: 0.7334 - val_accuracy: 0.7269

Epoch 00003: val_loss improved from 0.79545 to 0.73336, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 4/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6988 - accuracy: 0.7420 - val_loss: 0.7035 - val_accuracy: 0.7369

Epoch 00004: val_loss improved from 0.73336 to 0.70353, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 5/500
562/562 [==============================] - 39s 70ms/step - loss: 0.6827 - accuracy: 0.7446 - val_loss: 0.6802 - val_accuracy: 0.7429

Epoch 00005: val_loss improved from 0.70353 to 0.68023, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 6/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6736 - accuracy: 0.7470 - val_loss: 0.6704 - val_accuracy: 0.7462

Epoch 00006: val_loss improved from 0.68023 to 0.67039, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 7/500
562/562 [==============================] - 39s 70ms/step - loss: 0.6670 - accuracy: 0.7490 - val_loss: 0.6704 - val_accuracy: 0.7453

Epoch 00007: val_loss improved from 0.67039 to 0.67037, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 8/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6623 - accuracy: 0.7502 - val_loss: 0.6670 - val_accuracy: 0.7474

Epoch 00008: val_loss improved from 0.67037 to 0.66699, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 9/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6584 - accuracy: 0.7519 - val_loss: 0.6602 - val_accuracy: 0.7495

Epoch 00009: val_loss improved from 0.66699 to 0.66021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 10/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6537 - accuracy: 0.7538 - val_loss: 0.6593 - val_accuracy: 0.7488

Epoch 00010: val_loss improved from 0.66021 to 0.65929, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 11/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6501 - accuracy: 0.7548 - val_loss: 0.6550 - val_accuracy: 0.7508

Epoch 00011: val_loss improved from 0.65929 to 0.65504, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 12/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6473 - accuracy: 0.7554 - val_loss: 0.6536 - val_accuracy: 0.7510

Epoch 00012: val_loss improved from 0.65504 to 0.65361, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 13/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6437 - accuracy: 0.7573 - val_loss: 0.6554 - val_accuracy: 0.7493

Epoch 00013: val_loss did not improve from 0.65361
Epoch 14/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6405 - accuracy: 0.7585 - val_loss: 0.6517 - val_accuracy: 0.7504

Epoch 00014: val_loss improved from 0.65361 to 0.65172, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 15/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6388 - accuracy: 0.7590 - val_loss: 0.6474 - val_accuracy: 0.7529

Epoch 00015: val_loss improved from 0.65172 to 0.64744, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 16/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6355 - accuracy: 0.7607 - val_loss: 0.6479 - val_accuracy: 0.7523

Epoch 00016: val_loss did not improve from 0.64744
Epoch 17/500
562/562 [==============================] - 39s 70ms/step - loss: 0.6328 - accuracy: 0.7619 - val_loss: 0.6463 - val_accuracy: 0.7522

Epoch 00017: val_loss improved from 0.64744 to 0.64631, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 18/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6302 - accuracy: 0.7627 - val_loss: 0.6462 - val_accuracy: 0.7528

Epoch 00018: val_loss improved from 0.64631 to 0.64624, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 19/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6275 - accuracy: 0.7641 - val_loss: 0.6451 - val_accuracy: 0.7526

Epoch 00019: val_loss improved from 0.64624 to 0.64515, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 20/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6247 - accuracy: 0.7663 - val_loss: 0.6449 - val_accuracy: 0.7526

Epoch 00020: val_loss improved from 0.64515 to 0.64493, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 21/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6221 - accuracy: 0.7669 - val_loss: 0.6464 - val_accuracy: 0.7524

Epoch 00021: val_loss did not improve from 0.64493
Epoch 22/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6201 - accuracy: 0.7689 - val_loss: 0.6464 - val_accuracy: 0.7525

Epoch 00022: val_loss did not improve from 0.64493
Epoch 23/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6164 - accuracy: 0.7701 - val_loss: 0.6464 - val_accuracy: 0.7514

Epoch 00023: val_loss did not improve from 0.64493
Epoch 24/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6135 - accuracy: 0.7723 - val_loss: 0.6440 - val_accuracy: 0.7531

Epoch 00024: val_loss improved from 0.64493 to 0.64397, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15_E/
Epoch 25/500
562/562 [==============================] - 39s 69ms/step - loss: 0.6100 - accuracy: 0.7741 - val_loss: 0.6463 - val_accuracy: 0.7523

Epoch 00025: val_loss did not improve from 0.64397
Epoch 26/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6066 - accuracy: 0.7766 - val_loss: 0.6467 - val_accuracy: 0.7532

Epoch 00026: val_loss did not improve from 0.64397
Epoch 27/500
562/562 [==============================] - 38s 68ms/step - loss: 0.6027 - accuracy: 0.7790 - val_loss: 0.6504 - val_accuracy: 0.7509

Epoch 00027: val_loss did not improve from 0.64397
Epoch 28/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5993 - accuracy: 0.7808 - val_loss: 0.6534 - val_accuracy: 0.7500

Epoch 00028: val_loss did not improve from 0.64397
Epoch 29/500
562/562 [==============================] - 39s 69ms/step - loss: 0.5950 - accuracy: 0.7835 - val_loss: 0.6589 - val_accuracy: 0.7471

Epoch 00029: val_loss did not improve from 0.64397
Epoch 30/500
562/562 [==============================] - 222s 396ms/step - loss: 0.5907 - accuracy: 0.7866 - val_loss: 0.6588 - val_accuracy: 0.7481

Epoch 00030: val_loss did not improve from 0.64397
Epoch 31/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5851 - accuracy: 0.7899 - val_loss: 0.6638 - val_accuracy: 0.7467

Epoch 00031: val_loss did not improve from 0.64397
Epoch 32/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5796 - accuracy: 0.7938 - val_loss: 0.6690 - val_accuracy: 0.7457

Epoch 00032: val_loss did not improve from 0.64397
Epoch 33/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5744 - accuracy: 0.7969 - val_loss: 0.6733 - val_accuracy: 0.7440

Epoch 00033: val_loss did not improve from 0.64397
Epoch 34/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5681 - accuracy: 0.8007 - val_loss: 0.6822 - val_accuracy: 0.7414

Epoch 00034: val_loss did not improve from 0.64397
Epoch 35/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5613 - accuracy: 0.8049 - val_loss: 0.6916 - val_accuracy: 0.7393

Epoch 00035: val_loss did not improve from 0.64397
Epoch 36/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5558 - accuracy: 0.8079 - val_loss: 0.6969 - val_accuracy: 0.7398

Epoch 00036: val_loss did not improve from 0.64397
Epoch 37/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5504 - accuracy: 0.8119 - val_loss: 0.7041 - val_accuracy: 0.7377

Epoch 00037: val_loss did not improve from 0.64397
Epoch 38/500
562/562 [==============================] - 39s 69ms/step - loss: 0.5441 - accuracy: 0.8149 - val_loss: 0.7109 - val_accuracy: 0.7370

Epoch 00038: val_loss did not improve from 0.64397
Epoch 39/500
562/562 [==============================] - 39s 69ms/step - loss: 0.5440 - accuracy: 0.8151 - val_loss: 0.7199 - val_accuracy: 0.7333

Epoch 00039: val_loss did not improve from 0.64397
Epoch 40/500
562/562 [==============================] - 39s 69ms/step - loss: 0.5364 - accuracy: 0.8193 - val_loss: 0.7370 - val_accuracy: 0.7308

Epoch 00040: val_loss did not improve from 0.64397
Epoch 41/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5287 - accuracy: 0.8234 - val_loss: 0.7462 - val_accuracy: 0.7282

Epoch 00041: val_loss did not improve from 0.64397
Epoch 42/500
562/562 [==============================] - 39s 69ms/step - loss: 0.5171 - accuracy: 0.8294 - val_loss: 0.7477 - val_accuracy: 0.7312

Epoch 00042: val_loss did not improve from 0.64397
Epoch 43/500
562/562 [==============================] - 39s 68ms/step - loss: 0.5081 - accuracy: 0.8346 - val_loss: 0.7561 - val_accuracy: 0.7287

Epoch 00043: val_loss did not improve from 0.64397
Epoch 44/500
562/562 [==============================] - 38s 68ms/step - loss: 0.5051 - accuracy: 0.8365 - val_loss: 0.7731 - val_accuracy: 0.7258

Epoch 00044: val_loss did not improve from 0.64397
Epoch 00044: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
90000/90000 [==============================] - 367s 4ms/step - loss: 0.6463 - accuracy: 0.7503
Testing Loss = 0.646264, Testing Accuracy = 0.750256
The data set contains images
[[0.802762508392334, 0.14818023145198822, 0.049057330936193466], [0.32539868354797363, 0.010102699510753155, 0.6644986271858215], [0.8854959011077881, 0.0736054852604866, 0.040898647159338], [0.3396748900413513, 0.006421509198844433, 0.653903603553772], [0.022932356223464012, 0.11423244327306747, 0.862835168838501], [0.7505007386207581, 0.014189191162586212, 0.23531006276607513], [0.03435350954532623, 0.13667450845241547, 0.8289719820022583], [0.15536755323410034, 0.7716889977455139, 0.07294345647096634], [0.15196092426776886, 0.6568120718002319, 0.1912270188331604], [0.06417752802371979, 0.022433677688241005, 0.913388729095459]]
[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]
3
$W^+$ (auc = 0.9070)
$W^-$ (auc = 0.9071)
$Z$ (auc = 0.8898)
