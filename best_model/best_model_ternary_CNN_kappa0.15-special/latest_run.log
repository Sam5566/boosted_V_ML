

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-30 21:32:13.065716
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 288000.
Epoch 1/100
562/562 [==============================] - 62s 101ms/step - loss: 4.3051 - accuracy: 0.5927 - val_loss: 1.4762 - val_accuracy: 0.6623

Epoch 00001: val_loss improved from inf to 1.47615, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 2/100
562/562 [==============================] - 38s 68ms/step - loss: 1.0920 - accuracy: 0.6539 - val_loss: 0.8632 - val_accuracy: 0.6773

Epoch 00002: val_loss improved from 1.47615 to 0.86318, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 3/100
562/562 [==============================] - 38s 67ms/step - loss: 0.8637 - accuracy: 0.6587 - val_loss: 0.8049 - val_accuracy: 0.6787

Epoch 00003: val_loss improved from 0.86318 to 0.80485, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 4/100
562/562 [==============================] - 39s 69ms/step - loss: 0.8328 - accuracy: 0.6616 - val_loss: 0.7897 - val_accuracy: 0.6808

Epoch 00004: val_loss improved from 0.80485 to 0.78973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 5/100
562/562 [==============================] - 39s 69ms/step - loss: 0.8222 - accuracy: 0.6646 - val_loss: 0.7805 - val_accuracy: 0.6835

Epoch 00005: val_loss improved from 0.78973 to 0.78051, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 6/100
562/562 [==============================] - 38s 68ms/step - loss: 0.8143 - accuracy: 0.6662 - val_loss: 0.7780 - val_accuracy: 0.6848

Epoch 00006: val_loss improved from 0.78051 to 0.77797, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 7/100
562/562 [==============================] - 38s 68ms/step - loss: 0.8086 - accuracy: 0.6693 - val_loss: 0.7730 - val_accuracy: 0.6862

Epoch 00007: val_loss improved from 0.77797 to 0.77300, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 8/100
562/562 [==============================] - 38s 68ms/step - loss: 0.8035 - accuracy: 0.6721 - val_loss: 0.7788 - val_accuracy: 0.6818

Epoch 00008: val_loss did not improve from 0.77300
Epoch 9/100
562/562 [==============================] - 39s 69ms/step - loss: 0.7965 - accuracy: 0.6754 - val_loss: 0.7689 - val_accuracy: 0.6885

Epoch 00009: val_loss improved from 0.77300 to 0.76893, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 10/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7926 - accuracy: 0.6779 - val_loss: 0.7653 - val_accuracy: 0.6895

Epoch 00010: val_loss improved from 0.76893 to 0.76530, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 11/100
562/562 [==============================] - 39s 68ms/step - loss: 0.7879 - accuracy: 0.6808 - val_loss: 0.7662 - val_accuracy: 0.6892

Epoch 00011: val_loss did not improve from 0.76530
Epoch 12/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7847 - accuracy: 0.6820 - val_loss: 0.7637 - val_accuracy: 0.6901

Epoch 00012: val_loss improved from 0.76530 to 0.76370, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 13/100
562/562 [==============================] - 39s 69ms/step - loss: 0.7811 - accuracy: 0.6843 - val_loss: 0.7588 - val_accuracy: 0.6932

Epoch 00013: val_loss improved from 0.76370 to 0.75876, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 14/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7782 - accuracy: 0.6860 - val_loss: 0.7567 - val_accuracy: 0.6946

Epoch 00014: val_loss improved from 0.75876 to 0.75669, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 15/100
562/562 [==============================] - 39s 68ms/step - loss: 0.7760 - accuracy: 0.6869 - val_loss: 0.7550 - val_accuracy: 0.6947

Epoch 00015: val_loss improved from 0.75669 to 0.75501, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 16/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7733 - accuracy: 0.6886 - val_loss: 0.7530 - val_accuracy: 0.6954

Epoch 00016: val_loss improved from 0.75501 to 0.75297, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 17/100
562/562 [==============================] - 39s 69ms/step - loss: 0.7710 - accuracy: 0.6893 - val_loss: 0.7588 - val_accuracy: 0.6912

Epoch 00017: val_loss did not improve from 0.75297
Epoch 18/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7681 - accuracy: 0.6914 - val_loss: 0.7550 - val_accuracy: 0.6948

Epoch 00018: val_loss did not improve from 0.75297
Epoch 19/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7666 - accuracy: 0.6924 - val_loss: 0.7541 - val_accuracy: 0.6951

Epoch 00019: val_loss did not improve from 0.75297
Epoch 20/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7636 - accuracy: 0.6945 - val_loss: 0.7489 - val_accuracy: 0.6981

Epoch 00020: val_loss improved from 0.75297 to 0.74891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special/Try/0
Epoch 21/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7622 - accuracy: 0.6950 - val_loss: 0.7515 - val_accuracy: 0.6964

Epoch 00021: val_loss did not improve from 0.74891
Epoch 22/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7603 - accuracy: 0.6964 - val_loss: 0.7496 - val_accuracy: 0.6979

Epoch 00022: val_loss did not improve from 0.74891
Epoch 23/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7588 - accuracy: 0.6973 - val_loss: 0.7544 - val_accuracy: 0.6944

Epoch 00023: val_loss did not improve from 0.74891
Epoch 24/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7569 - accuracy: 0.6996 - val_loss: 0.7520 - val_accuracy: 0.6967

Epoch 00024: val_loss did not improve from 0.74891
Epoch 25/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7546 - accuracy: 0.7005 - val_loss: 0.7523 - val_accuracy: 0.6970

Epoch 00025: val_loss did not improve from 0.74891
Epoch 26/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7520 - accuracy: 0.7022 - val_loss: 0.7539 - val_accuracy: 0.6953

Epoch 00026: val_loss did not improve from 0.74891
Epoch 27/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7499 - accuracy: 0.7039 - val_loss: 0.7560 - val_accuracy: 0.6950

Epoch 00027: val_loss did not improve from 0.74891
Epoch 28/100
562/562 [==============================] - 39s 68ms/step - loss: 0.7472 - accuracy: 0.7061 - val_loss: 0.7537 - val_accuracy: 0.6971

Epoch 00028: val_loss did not improve from 0.74891
Epoch 29/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7448 - accuracy: 0.7079 - val_loss: 0.7572 - val_accuracy: 0.6953

Epoch 00029: val_loss did not improve from 0.74891
Epoch 30/100
562/562 [==============================] - 39s 69ms/step - loss: 0.7423 - accuracy: 0.7094 - val_loss: 0.7585 - val_accuracy: 0.6956

Epoch 00030: val_loss did not improve from 0.74891
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
90000/90000 [==============================] - 370s 4ms/step - loss: 0.7375 - accuracy: 0.7046
Testing Loss = 0.737486, Testing Accuracy = 0.704556
The data set contains images
N of classes 3
$W^+$ (auc = 86.64 +- 0.0000 %)
$W^-$ (auc = 86.52 +- 0.0000 %)
$Z$ (auc = 87.45 +- 0.0000 %)
The summarized testing accuracy = 70.46 +- 0.0000 %, with the loss = 0.7375 +- 0.000000
