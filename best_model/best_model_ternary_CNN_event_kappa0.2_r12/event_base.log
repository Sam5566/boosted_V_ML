

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-27 17:41:16.478085
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 15s 126ms/step - loss: 12.1997 - accuracy: 0.2188 - val_loss: 8.4473 - val_accuracy: 0.2261

Epoch 00001: val_loss improved from inf to 8.44726, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 2/100
83/83 [==============================] - 10s 120ms/step - loss: 6.5876 - accuracy: 0.2775 - val_loss: 5.2799 - val_accuracy: 0.2954

Epoch 00002: val_loss improved from 8.44726 to 5.27988, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 3/100
83/83 [==============================] - 10s 123ms/step - loss: 4.5209 - accuracy: 0.2938 - val_loss: 3.9471 - val_accuracy: 0.3085

Epoch 00003: val_loss improved from 5.27988 to 3.94709, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 4/100
83/83 [==============================] - 10s 121ms/step - loss: 3.5548 - accuracy: 0.3050 - val_loss: 3.2201 - val_accuracy: 0.3119

Epoch 00004: val_loss improved from 3.94709 to 3.22015, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 5/100
83/83 [==============================] - 10s 126ms/step - loss: 2.9756 - accuracy: 0.3119 - val_loss: 2.7410 - val_accuracy: 0.3184

Epoch 00005: val_loss improved from 3.22015 to 2.74096, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 6/100
83/83 [==============================] - 11s 129ms/step - loss: 2.5845 - accuracy: 0.3125 - val_loss: 2.4188 - val_accuracy: 0.3225

Epoch 00006: val_loss improved from 2.74096 to 2.41882, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 7/100
83/83 [==============================] - 11s 129ms/step - loss: 2.3088 - accuracy: 0.3169 - val_loss: 2.1871 - val_accuracy: 0.3219

Epoch 00007: val_loss improved from 2.41882 to 2.18714, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 8/100
83/83 [==============================] - 11s 129ms/step - loss: 2.1126 - accuracy: 0.3212 - val_loss: 2.0237 - val_accuracy: 0.3276

Epoch 00008: val_loss improved from 2.18714 to 2.02368, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 9/100
83/83 [==============================] - 11s 132ms/step - loss: 1.9706 - accuracy: 0.3213 - val_loss: 1.9088 - val_accuracy: 0.3251

Epoch 00009: val_loss improved from 2.02368 to 1.90884, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 10/100
83/83 [==============================] - 11s 130ms/step - loss: 1.8725 - accuracy: 0.3216 - val_loss: 1.8278 - val_accuracy: 0.3258

Epoch 00010: val_loss improved from 1.90884 to 1.82783, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 11/100
83/83 [==============================] - 10s 126ms/step - loss: 1.7998 - accuracy: 0.3268 - val_loss: 1.7693 - val_accuracy: 0.3269

Epoch 00011: val_loss improved from 1.82783 to 1.76925, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 12/100
83/83 [==============================] - 11s 127ms/step - loss: 1.7478 - accuracy: 0.3289 - val_loss: 1.7278 - val_accuracy: 0.3276

Epoch 00012: val_loss improved from 1.76925 to 1.72776, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 13/100
83/83 [==============================] - 11s 127ms/step - loss: 1.7122 - accuracy: 0.3315 - val_loss: 1.7035 - val_accuracy: 0.3270

Epoch 00013: val_loss improved from 1.72776 to 1.70354, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 14/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6874 - accuracy: 0.3317 - val_loss: 1.6809 - val_accuracy: 0.3297

Epoch 00014: val_loss improved from 1.70354 to 1.68095, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 15/100
83/83 [==============================] - 10s 126ms/step - loss: 1.6672 - accuracy: 0.3343 - val_loss: 1.6693 - val_accuracy: 0.3260

Epoch 00015: val_loss improved from 1.68095 to 1.66934, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 16/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6539 - accuracy: 0.3373 - val_loss: 1.6573 - val_accuracy: 0.3292

Epoch 00016: val_loss improved from 1.66934 to 1.65732, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 17/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6426 - accuracy: 0.3373 - val_loss: 1.6470 - val_accuracy: 0.3320

Epoch 00017: val_loss improved from 1.65732 to 1.64697, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 18/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6342 - accuracy: 0.3403 - val_loss: 1.6498 - val_accuracy: 0.3308

Epoch 00018: val_loss did not improve from 1.64697
Epoch 19/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6276 - accuracy: 0.3433 - val_loss: 1.6425 - val_accuracy: 0.3308

Epoch 00019: val_loss improved from 1.64697 to 1.64253, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 20/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6232 - accuracy: 0.3446 - val_loss: 1.6415 - val_accuracy: 0.3313

Epoch 00020: val_loss improved from 1.64253 to 1.64153, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 21/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6196 - accuracy: 0.3453 - val_loss: 1.6360 - val_accuracy: 0.3315

Epoch 00021: val_loss improved from 1.64153 to 1.63601, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/0
Epoch 22/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6137 - accuracy: 0.3468 - val_loss: 1.6387 - val_accuracy: 0.3330

Epoch 00022: val_loss did not improve from 1.63601
Epoch 23/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6142 - accuracy: 0.3488 - val_loss: 1.6379 - val_accuracy: 0.3331

Epoch 00023: val_loss did not improve from 1.63601
Epoch 24/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6079 - accuracy: 0.3534 - val_loss: 1.6393 - val_accuracy: 0.3357

Epoch 00024: val_loss did not improve from 1.63601
Epoch 25/100
83/83 [==============================] - 7s 81ms/step - loss: 1.6074 - accuracy: 0.3518 - val_loss: 1.6425 - val_accuracy: 0.3343

Epoch 00025: val_loss did not improve from 1.63601
Epoch 26/100
83/83 [==============================] - 7s 81ms/step - loss: 1.6045 - accuracy: 0.3573 - val_loss: 1.6424 - val_accuracy: 0.3346

Epoch 00026: val_loss did not improve from 1.63601
Epoch 27/100
83/83 [==============================] - 7s 82ms/step - loss: 1.6014 - accuracy: 0.3580 - val_loss: 1.6457 - val_accuracy: 0.3329

Epoch 00027: val_loss did not improve from 1.63601
Epoch 28/100
83/83 [==============================] - 7s 81ms/step - loss: 1.6010 - accuracy: 0.3618 - val_loss: 1.6516 - val_accuracy: 0.3334

Epoch 00028: val_loss did not improve from 1.63601
Epoch 29/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5982 - accuracy: 0.3662 - val_loss: 1.6553 - val_accuracy: 0.3307

Epoch 00029: val_loss did not improve from 1.63601
Epoch 30/100
83/83 [==============================] - 7s 80ms/step - loss: 1.5935 - accuracy: 0.3713 - val_loss: 1.6602 - val_accuracy: 0.3310

Epoch 00030: val_loss did not improve from 1.63601
Epoch 31/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5944 - accuracy: 0.3731 - val_loss: 1.6636 - val_accuracy: 0.3294

Epoch 00031: val_loss did not improve from 1.63601
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 58s 4ms/step - loss: 1.6393 - accuracy: 0.3311
Testing Loss = 1.639314, Testing Accuracy = 0.331051
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 11s 124ms/step - loss: 12.2587 - accuracy: 0.2241 - val_loss: 8.5561 - val_accuracy: 0.2545

Epoch 00001: val_loss improved from inf to 8.55609, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 2/100
83/83 [==============================] - 10s 126ms/step - loss: 6.6921 - accuracy: 0.2801 - val_loss: 5.3676 - val_accuracy: 0.2919

Epoch 00002: val_loss improved from 8.55609 to 5.36758, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 3/100
83/83 [==============================] - 10s 118ms/step - loss: 4.5965 - accuracy: 0.2914 - val_loss: 4.0092 - val_accuracy: 0.3080

Epoch 00003: val_loss improved from 5.36758 to 4.00919, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 4/100
83/83 [==============================] - 10s 125ms/step - loss: 3.6040 - accuracy: 0.3022 - val_loss: 3.2568 - val_accuracy: 0.3137

Epoch 00004: val_loss improved from 4.00919 to 3.25677, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 5/100
83/83 [==============================] - 10s 121ms/step - loss: 3.0110 - accuracy: 0.3082 - val_loss: 2.7730 - val_accuracy: 0.3222

Epoch 00005: val_loss improved from 3.25677 to 2.77298, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 6/100
83/83 [==============================] - 10s 122ms/step - loss: 2.6100 - accuracy: 0.3129 - val_loss: 2.4387 - val_accuracy: 0.3220

Epoch 00006: val_loss improved from 2.77298 to 2.43866, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 7/100
83/83 [==============================] - 10s 126ms/step - loss: 2.3297 - accuracy: 0.3153 - val_loss: 2.2065 - val_accuracy: 0.3209

Epoch 00007: val_loss improved from 2.43866 to 2.20652, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 8/100
83/83 [==============================] - 10s 120ms/step - loss: 2.1282 - accuracy: 0.3189 - val_loss: 2.0367 - val_accuracy: 0.3245

Epoch 00008: val_loss improved from 2.20652 to 2.03666, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 9/100
83/83 [==============================] - 10s 122ms/step - loss: 1.9852 - accuracy: 0.3189 - val_loss: 1.9188 - val_accuracy: 0.3273

Epoch 00009: val_loss improved from 2.03666 to 1.91878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 10/100
83/83 [==============================] - 11s 129ms/step - loss: 1.8808 - accuracy: 0.3237 - val_loss: 1.8352 - val_accuracy: 0.3250

Epoch 00010: val_loss improved from 1.91878 to 1.83522, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 11/100
83/83 [==============================] - 10s 122ms/step - loss: 1.8090 - accuracy: 0.3251 - val_loss: 1.7761 - val_accuracy: 0.3238

Epoch 00011: val_loss improved from 1.83522 to 1.77609, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 12/100
83/83 [==============================] - 11s 128ms/step - loss: 1.7549 - accuracy: 0.3285 - val_loss: 1.7337 - val_accuracy: 0.3268

Epoch 00012: val_loss improved from 1.77609 to 1.73375, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 13/100
83/83 [==============================] - 10s 124ms/step - loss: 1.7176 - accuracy: 0.3325 - val_loss: 1.7039 - val_accuracy: 0.3261

Epoch 00013: val_loss improved from 1.73375 to 1.70389, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 14/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6901 - accuracy: 0.3329 - val_loss: 1.6806 - val_accuracy: 0.3283

Epoch 00014: val_loss improved from 1.70389 to 1.68058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 15/100
83/83 [==============================] - 10s 126ms/step - loss: 1.6689 - accuracy: 0.3345 - val_loss: 1.6669 - val_accuracy: 0.3285

Epoch 00015: val_loss improved from 1.68058 to 1.66691, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 16/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6557 - accuracy: 0.3371 - val_loss: 1.6550 - val_accuracy: 0.3287

Epoch 00016: val_loss improved from 1.66691 to 1.65497, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 17/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6434 - accuracy: 0.3390 - val_loss: 1.6485 - val_accuracy: 0.3326

Epoch 00017: val_loss improved from 1.65497 to 1.64854, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 18/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6355 - accuracy: 0.3388 - val_loss: 1.6438 - val_accuracy: 0.3286

Epoch 00018: val_loss improved from 1.64854 to 1.64383, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 19/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6283 - accuracy: 0.3410 - val_loss: 1.6396 - val_accuracy: 0.3294

Epoch 00019: val_loss improved from 1.64383 to 1.63959, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 20/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6223 - accuracy: 0.3458 - val_loss: 1.6379 - val_accuracy: 0.3314

Epoch 00020: val_loss improved from 1.63959 to 1.63790, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 21/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6185 - accuracy: 0.3478 - val_loss: 1.6351 - val_accuracy: 0.3325

Epoch 00021: val_loss improved from 1.63790 to 1.63507, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 22/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6157 - accuracy: 0.3493 - val_loss: 1.6349 - val_accuracy: 0.3312

Epoch 00022: val_loss improved from 1.63507 to 1.63487, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/1
Epoch 23/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6111 - accuracy: 0.3533 - val_loss: 1.6388 - val_accuracy: 0.3277

Epoch 00023: val_loss did not improve from 1.63487
Epoch 24/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6101 - accuracy: 0.3540 - val_loss: 1.6399 - val_accuracy: 0.3279

Epoch 00024: val_loss did not improve from 1.63487
Epoch 25/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6070 - accuracy: 0.3556 - val_loss: 1.6390 - val_accuracy: 0.3349

Epoch 00025: val_loss did not improve from 1.63487
Epoch 26/100
83/83 [==============================] - 11s 133ms/step - loss: 1.6059 - accuracy: 0.3556 - val_loss: 1.6443 - val_accuracy: 0.3354

Epoch 00026: val_loss did not improve from 1.63487
Epoch 27/100
83/83 [==============================] - 7s 81ms/step - loss: 1.6011 - accuracy: 0.3594 - val_loss: 1.6437 - val_accuracy: 0.3346

Epoch 00027: val_loss did not improve from 1.63487
Epoch 28/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5995 - accuracy: 0.3659 - val_loss: 1.6457 - val_accuracy: 0.3340

Epoch 00028: val_loss did not improve from 1.63487
Epoch 29/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5984 - accuracy: 0.3657 - val_loss: 1.6518 - val_accuracy: 0.3358

Epoch 00029: val_loss did not improve from 1.63487
Epoch 30/100
83/83 [==============================] - 7s 80ms/step - loss: 1.5966 - accuracy: 0.3683 - val_loss: 1.6574 - val_accuracy: 0.3362

Epoch 00030: val_loss did not improve from 1.63487
Epoch 31/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5928 - accuracy: 0.3706 - val_loss: 1.6648 - val_accuracy: 0.3317

Epoch 00031: val_loss did not improve from 1.63487
Epoch 32/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5945 - accuracy: 0.3758 - val_loss: 1.6705 - val_accuracy: 0.3332

Epoch 00032: val_loss did not improve from 1.63487
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 58s 4ms/step - loss: 1.6401 - accuracy: 0.3319
Testing Loss = 1.640147, Testing Accuracy = 0.331944
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 10s 111ms/step - loss: 12.3876 - accuracy: 0.2256 - val_loss: 8.7277 - val_accuracy: 0.2617

Epoch 00001: val_loss improved from inf to 8.72768, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 2/100
83/83 [==============================] - 8s 99ms/step - loss: 6.8197 - accuracy: 0.2758 - val_loss: 5.4603 - val_accuracy: 0.2928

Epoch 00002: val_loss improved from 8.72768 to 5.46033, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 3/100
83/83 [==============================] - 8s 96ms/step - loss: 4.6614 - accuracy: 0.2921 - val_loss: 4.0533 - val_accuracy: 0.3059

Epoch 00003: val_loss improved from 5.46033 to 4.05326, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 4/100
83/83 [==============================] - 8s 99ms/step - loss: 3.6351 - accuracy: 0.3009 - val_loss: 3.2803 - val_accuracy: 0.3157

Epoch 00004: val_loss improved from 4.05326 to 3.28026, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 5/100
83/83 [==============================] - 8s 100ms/step - loss: 3.0228 - accuracy: 0.3074 - val_loss: 2.7816 - val_accuracy: 0.3187

Epoch 00005: val_loss improved from 3.28026 to 2.78156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 6/100
83/83 [==============================] - 8s 96ms/step - loss: 2.6184 - accuracy: 0.3120 - val_loss: 2.4455 - val_accuracy: 0.3210

Epoch 00006: val_loss improved from 2.78156 to 2.44550, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 7/100
83/83 [==============================] - 9s 104ms/step - loss: 2.3319 - accuracy: 0.3156 - val_loss: 2.2058 - val_accuracy: 0.3234

Epoch 00007: val_loss improved from 2.44550 to 2.20577, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 8/100
83/83 [==============================] - 8s 98ms/step - loss: 2.1296 - accuracy: 0.3204 - val_loss: 2.0415 - val_accuracy: 0.3217

Epoch 00008: val_loss improved from 2.20577 to 2.04152, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 9/100
83/83 [==============================] - 8s 100ms/step - loss: 1.9837 - accuracy: 0.3212 - val_loss: 1.9182 - val_accuracy: 0.3274

Epoch 00009: val_loss improved from 2.04152 to 1.91815, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 10/100
83/83 [==============================] - 8s 101ms/step - loss: 1.8816 - accuracy: 0.3250 - val_loss: 1.8370 - val_accuracy: 0.3259

Epoch 00010: val_loss improved from 1.91815 to 1.83699, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 11/100
83/83 [==============================] - 8s 97ms/step - loss: 1.8076 - accuracy: 0.3245 - val_loss: 1.7754 - val_accuracy: 0.3267

Epoch 00011: val_loss improved from 1.83699 to 1.77539, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 12/100
83/83 [==============================] - 9s 102ms/step - loss: 1.7538 - accuracy: 0.3268 - val_loss: 1.7304 - val_accuracy: 0.3271

Epoch 00012: val_loss improved from 1.77539 to 1.73044, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 13/100
83/83 [==============================] - 9s 103ms/step - loss: 1.7169 - accuracy: 0.3290 - val_loss: 1.7034 - val_accuracy: 0.3270

Epoch 00013: val_loss improved from 1.73044 to 1.70336, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 14/100
83/83 [==============================] - 8s 98ms/step - loss: 1.6894 - accuracy: 0.3333 - val_loss: 1.6830 - val_accuracy: 0.3287

Epoch 00014: val_loss improved from 1.70336 to 1.68295, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 15/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6713 - accuracy: 0.3323 - val_loss: 1.6732 - val_accuracy: 0.3254

Epoch 00015: val_loss improved from 1.68295 to 1.67322, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 16/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6566 - accuracy: 0.3361 - val_loss: 1.6593 - val_accuracy: 0.3290

Epoch 00016: val_loss improved from 1.67322 to 1.65932, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 17/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6450 - accuracy: 0.3397 - val_loss: 1.6519 - val_accuracy: 0.3297

Epoch 00017: val_loss improved from 1.65932 to 1.65189, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 18/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6351 - accuracy: 0.3403 - val_loss: 1.6510 - val_accuracy: 0.3278

Epoch 00018: val_loss improved from 1.65189 to 1.65102, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 19/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6295 - accuracy: 0.3425 - val_loss: 1.6412 - val_accuracy: 0.3268

Epoch 00019: val_loss improved from 1.65102 to 1.64119, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 20/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6244 - accuracy: 0.3450 - val_loss: 1.6387 - val_accuracy: 0.3288

Epoch 00020: val_loss improved from 1.64119 to 1.63865, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/2
Epoch 21/100
83/83 [==============================] - 10s 126ms/step - loss: 1.6192 - accuracy: 0.3482 - val_loss: 1.6397 - val_accuracy: 0.3283

Epoch 00021: val_loss did not improve from 1.63865
Epoch 22/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6161 - accuracy: 0.3497 - val_loss: 1.6417 - val_accuracy: 0.3284

Epoch 00022: val_loss did not improve from 1.63865
Epoch 23/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6120 - accuracy: 0.3525 - val_loss: 1.6431 - val_accuracy: 0.3304

Epoch 00023: val_loss did not improve from 1.63865
Epoch 24/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6116 - accuracy: 0.3523 - val_loss: 1.6456 - val_accuracy: 0.3293

Epoch 00024: val_loss did not improve from 1.63865
Epoch 25/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6082 - accuracy: 0.3545 - val_loss: 1.6439 - val_accuracy: 0.3322

Epoch 00025: val_loss did not improve from 1.63865
Epoch 26/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6065 - accuracy: 0.3560 - val_loss: 1.6484 - val_accuracy: 0.3318

Epoch 00026: val_loss did not improve from 1.63865
Epoch 27/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6037 - accuracy: 0.3586 - val_loss: 1.6517 - val_accuracy: 0.3329

Epoch 00027: val_loss did not improve from 1.63865
Epoch 28/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6012 - accuracy: 0.3632 - val_loss: 1.6512 - val_accuracy: 0.3329

Epoch 00028: val_loss did not improve from 1.63865
Epoch 29/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5998 - accuracy: 0.3690 - val_loss: 1.6579 - val_accuracy: 0.3314

Epoch 00029: val_loss did not improve from 1.63865
Epoch 30/100
83/83 [==============================] - 11s 131ms/step - loss: 1.5952 - accuracy: 0.3725 - val_loss: 1.6639 - val_accuracy: 0.3370

Epoch 00030: val_loss did not improve from 1.63865
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.6434 - accuracy: 0.3328
Testing Loss = 1.643366, Testing Accuracy = 0.332763
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 80ms/step - loss: 12.1911 - accuracy: 0.2255 - val_loss: 8.4610 - val_accuracy: 0.2612

Epoch 00001: val_loss improved from inf to 8.46101, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 2/100
83/83 [==============================] - 7s 78ms/step - loss: 6.6210 - accuracy: 0.2808 - val_loss: 5.3119 - val_accuracy: 0.2931

Epoch 00002: val_loss improved from 8.46101 to 5.31191, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 3/100
83/83 [==============================] - 7s 78ms/step - loss: 4.5553 - accuracy: 0.2872 - val_loss: 3.9744 - val_accuracy: 0.3042

Epoch 00003: val_loss improved from 5.31191 to 3.97436, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 4/100
83/83 [==============================] - 8s 100ms/step - loss: 3.5778 - accuracy: 0.3010 - val_loss: 3.2347 - val_accuracy: 0.3176

Epoch 00004: val_loss improved from 3.97436 to 3.23472, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 5/100
83/83 [==============================] - 9s 102ms/step - loss: 2.9920 - accuracy: 0.3059 - val_loss: 2.7564 - val_accuracy: 0.3209

Epoch 00005: val_loss improved from 3.23472 to 2.75640, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 6/100
83/83 [==============================] - 9s 102ms/step - loss: 2.5979 - accuracy: 0.3120 - val_loss: 2.4269 - val_accuracy: 0.3251

Epoch 00006: val_loss improved from 2.75640 to 2.42694, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 7/100
83/83 [==============================] - 8s 98ms/step - loss: 2.3186 - accuracy: 0.3180 - val_loss: 2.1939 - val_accuracy: 0.3244

Epoch 00007: val_loss improved from 2.42694 to 2.19389, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 8/100
83/83 [==============================] - 8s 100ms/step - loss: 2.1207 - accuracy: 0.3213 - val_loss: 2.0297 - val_accuracy: 0.3265

Epoch 00008: val_loss improved from 2.19389 to 2.02974, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 9/100
83/83 [==============================] - 8s 96ms/step - loss: 1.9782 - accuracy: 0.3232 - val_loss: 1.9159 - val_accuracy: 0.3230

Epoch 00009: val_loss improved from 2.02974 to 1.91586, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 10/100
83/83 [==============================] - 9s 104ms/step - loss: 1.8777 - accuracy: 0.3237 - val_loss: 1.8303 - val_accuracy: 0.3249

Epoch 00010: val_loss improved from 1.91586 to 1.83027, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 11/100
83/83 [==============================] - 9s 101ms/step - loss: 1.8053 - accuracy: 0.3239 - val_loss: 1.7717 - val_accuracy: 0.3260

Epoch 00011: val_loss improved from 1.83027 to 1.77166, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 12/100
83/83 [==============================] - 8s 96ms/step - loss: 1.7527 - accuracy: 0.3263 - val_loss: 1.7329 - val_accuracy: 0.3247

Epoch 00012: val_loss improved from 1.77166 to 1.73291, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 13/100
83/83 [==============================] - 8s 102ms/step - loss: 1.7156 - accuracy: 0.3303 - val_loss: 1.6996 - val_accuracy: 0.3271

Epoch 00013: val_loss improved from 1.73291 to 1.69964, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 14/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6894 - accuracy: 0.3334 - val_loss: 1.6810 - val_accuracy: 0.3290

Epoch 00014: val_loss improved from 1.69964 to 1.68101, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 15/100
83/83 [==============================] - 8s 95ms/step - loss: 1.6690 - accuracy: 0.3373 - val_loss: 1.6657 - val_accuracy: 0.3310

Epoch 00015: val_loss improved from 1.68101 to 1.66570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 16/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6549 - accuracy: 0.3359 - val_loss: 1.6566 - val_accuracy: 0.3299

Epoch 00016: val_loss improved from 1.66570 to 1.65664, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 17/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6443 - accuracy: 0.3380 - val_loss: 1.6503 - val_accuracy: 0.3290

Epoch 00017: val_loss improved from 1.65664 to 1.65027, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 18/100
83/83 [==============================] - 8s 97ms/step - loss: 1.6350 - accuracy: 0.3392 - val_loss: 1.6440 - val_accuracy: 0.3287

Epoch 00018: val_loss improved from 1.65027 to 1.64398, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 19/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6300 - accuracy: 0.3402 - val_loss: 1.6426 - val_accuracy: 0.3288

Epoch 00019: val_loss improved from 1.64398 to 1.64258, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 20/100
83/83 [==============================] - 8s 99ms/step - loss: 1.6243 - accuracy: 0.3441 - val_loss: 1.6423 - val_accuracy: 0.3305

Epoch 00020: val_loss improved from 1.64258 to 1.64228, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 21/100
83/83 [==============================] - 8s 98ms/step - loss: 1.6187 - accuracy: 0.3462 - val_loss: 1.6367 - val_accuracy: 0.3278

Epoch 00021: val_loss improved from 1.64228 to 1.63670, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 22/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6158 - accuracy: 0.3476 - val_loss: 1.6378 - val_accuracy: 0.3307

Epoch 00022: val_loss did not improve from 1.63670
Epoch 23/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6123 - accuracy: 0.3507 - val_loss: 1.6359 - val_accuracy: 0.3320

Epoch 00023: val_loss improved from 1.63670 to 1.63593, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/3
Epoch 24/100
83/83 [==============================] - 8s 95ms/step - loss: 1.6104 - accuracy: 0.3537 - val_loss: 1.6385 - val_accuracy: 0.3308

Epoch 00024: val_loss did not improve from 1.63593
Epoch 25/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6080 - accuracy: 0.3533 - val_loss: 1.6388 - val_accuracy: 0.3324

Epoch 00025: val_loss did not improve from 1.63593
Epoch 26/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6044 - accuracy: 0.3583 - val_loss: 1.6421 - val_accuracy: 0.3352

Epoch 00026: val_loss did not improve from 1.63593
Epoch 27/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6022 - accuracy: 0.3619 - val_loss: 1.6455 - val_accuracy: 0.3349

Epoch 00027: val_loss did not improve from 1.63593
Epoch 28/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6020 - accuracy: 0.3632 - val_loss: 1.6505 - val_accuracy: 0.3327

Epoch 00028: val_loss did not improve from 1.63593
Epoch 29/100
83/83 [==============================] - 11s 134ms/step - loss: 1.5994 - accuracy: 0.3658 - val_loss: 1.6541 - val_accuracy: 0.3327

Epoch 00029: val_loss did not improve from 1.63593
Epoch 30/100
83/83 [==============================] - 11s 128ms/step - loss: 1.5966 - accuracy: 0.3687 - val_loss: 1.6614 - val_accuracy: 0.3326

Epoch 00030: val_loss did not improve from 1.63593
Epoch 31/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5933 - accuracy: 0.3735 - val_loss: 1.6654 - val_accuracy: 0.3340

Epoch 00031: val_loss did not improve from 1.63593
Epoch 32/100
83/83 [==============================] - 11s 133ms/step - loss: 1.5914 - accuracy: 0.3794 - val_loss: 1.6745 - val_accuracy: 0.3294

Epoch 00032: val_loss did not improve from 1.63593
Epoch 33/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5904 - accuracy: 0.3819 - val_loss: 1.6856 - val_accuracy: 0.3303

Epoch 00033: val_loss did not improve from 1.63593
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.6400 - accuracy: 0.3322
Testing Loss = 1.639972, Testing Accuracy = 0.332242
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 8s 80ms/step - loss: 12.3019 - accuracy: 0.2226 - val_loss: 8.5912 - val_accuracy: 0.2584

Epoch 00001: val_loss improved from inf to 8.59121, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 2/100
83/83 [==============================] - 7s 79ms/step - loss: 6.7242 - accuracy: 0.2782 - val_loss: 5.3873 - val_accuracy: 0.2931

Epoch 00002: val_loss improved from 8.59121 to 5.38727, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 3/100
83/83 [==============================] - 7s 79ms/step - loss: 4.6075 - accuracy: 0.2926 - val_loss: 4.0133 - val_accuracy: 0.3063

Epoch 00003: val_loss improved from 5.38727 to 4.01326, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 4/100
83/83 [==============================] - 6s 76ms/step - loss: 3.6011 - accuracy: 0.3016 - val_loss: 3.2550 - val_accuracy: 0.3131

Epoch 00004: val_loss improved from 4.01326 to 3.25498, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 5/100
83/83 [==============================] - 9s 102ms/step - loss: 3.0072 - accuracy: 0.3085 - val_loss: 2.7690 - val_accuracy: 0.3172

Epoch 00005: val_loss improved from 3.25498 to 2.76905, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 6/100
83/83 [==============================] - 9s 104ms/step - loss: 2.6074 - accuracy: 0.3108 - val_loss: 2.4393 - val_accuracy: 0.3196

Epoch 00006: val_loss improved from 2.76905 to 2.43933, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 7/100
83/83 [==============================] - 9s 102ms/step - loss: 2.3257 - accuracy: 0.3176 - val_loss: 2.2024 - val_accuracy: 0.3224

Epoch 00007: val_loss improved from 2.43933 to 2.20238, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 8/100
83/83 [==============================] - 9s 105ms/step - loss: 2.1266 - accuracy: 0.3173 - val_loss: 2.0363 - val_accuracy: 0.3255

Epoch 00008: val_loss improved from 2.20238 to 2.03629, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 9/100
83/83 [==============================] - 9s 109ms/step - loss: 1.9832 - accuracy: 0.3231 - val_loss: 1.9186 - val_accuracy: 0.3234

Epoch 00009: val_loss improved from 2.03629 to 1.91860, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 10/100
83/83 [==============================] - 9s 102ms/step - loss: 1.8820 - accuracy: 0.3259 - val_loss: 1.8379 - val_accuracy: 0.3230

Epoch 00010: val_loss improved from 1.91860 to 1.83794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 11/100
83/83 [==============================] - 9s 114ms/step - loss: 1.8076 - accuracy: 0.3238 - val_loss: 1.7778 - val_accuracy: 0.3240

Epoch 00011: val_loss improved from 1.83794 to 1.77776, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 12/100
83/83 [==============================] - 9s 106ms/step - loss: 1.7561 - accuracy: 0.3253 - val_loss: 1.7392 - val_accuracy: 0.3217

Epoch 00012: val_loss improved from 1.77776 to 1.73921, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 13/100
83/83 [==============================] - 10s 115ms/step - loss: 1.7180 - accuracy: 0.3293 - val_loss: 1.7061 - val_accuracy: 0.3234

Epoch 00013: val_loss improved from 1.73921 to 1.70611, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 14/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6920 - accuracy: 0.3313 - val_loss: 1.6849 - val_accuracy: 0.3257

Epoch 00014: val_loss improved from 1.70611 to 1.68493, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 15/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6717 - accuracy: 0.3332 - val_loss: 1.6714 - val_accuracy: 0.3243

Epoch 00015: val_loss improved from 1.68493 to 1.67137, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 16/100
83/83 [==============================] - 10s 120ms/step - loss: 1.6570 - accuracy: 0.3349 - val_loss: 1.6589 - val_accuracy: 0.3241

Epoch 00016: val_loss improved from 1.67137 to 1.65890, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 17/100
83/83 [==============================] - 10s 120ms/step - loss: 1.6478 - accuracy: 0.3360 - val_loss: 1.6524 - val_accuracy: 0.3248

Epoch 00017: val_loss improved from 1.65890 to 1.65241, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 18/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6395 - accuracy: 0.3379 - val_loss: 1.6489 - val_accuracy: 0.3249

Epoch 00018: val_loss improved from 1.65241 to 1.64886, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 19/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6310 - accuracy: 0.3401 - val_loss: 1.6446 - val_accuracy: 0.3277

Epoch 00019: val_loss improved from 1.64886 to 1.64456, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 20/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6260 - accuracy: 0.3429 - val_loss: 1.6416 - val_accuracy: 0.3270

Epoch 00020: val_loss improved from 1.64456 to 1.64156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 21/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6202 - accuracy: 0.3460 - val_loss: 1.6366 - val_accuracy: 0.3310

Epoch 00021: val_loss improved from 1.64156 to 1.63663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/4
Epoch 22/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6176 - accuracy: 0.3478 - val_loss: 1.6384 - val_accuracy: 0.3311

Epoch 00022: val_loss did not improve from 1.63663
Epoch 23/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6156 - accuracy: 0.3473 - val_loss: 1.6381 - val_accuracy: 0.3319

Epoch 00023: val_loss did not improve from 1.63663
Epoch 24/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6126 - accuracy: 0.3527 - val_loss: 1.6393 - val_accuracy: 0.3321

Epoch 00024: val_loss did not improve from 1.63663
Epoch 25/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6082 - accuracy: 0.3534 - val_loss: 1.6432 - val_accuracy: 0.3311

Epoch 00025: val_loss did not improve from 1.63663
Epoch 26/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6072 - accuracy: 0.3551 - val_loss: 1.6454 - val_accuracy: 0.3334

Epoch 00026: val_loss did not improve from 1.63663
Epoch 27/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6062 - accuracy: 0.3604 - val_loss: 1.6485 - val_accuracy: 0.3305

Epoch 00027: val_loss did not improve from 1.63663
Epoch 28/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6036 - accuracy: 0.3614 - val_loss: 1.6496 - val_accuracy: 0.3316

Epoch 00028: val_loss did not improve from 1.63663
Epoch 29/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6006 - accuracy: 0.3649 - val_loss: 1.6509 - val_accuracy: 0.3343

Epoch 00029: val_loss did not improve from 1.63663
Epoch 30/100
83/83 [==============================] - 11s 128ms/step - loss: 1.5986 - accuracy: 0.3654 - val_loss: 1.6583 - val_accuracy: 0.3328

Epoch 00030: val_loss did not improve from 1.63663
Epoch 31/100
83/83 [==============================] - 11s 130ms/step - loss: 1.5973 - accuracy: 0.3705 - val_loss: 1.6615 - val_accuracy: 0.3364

Epoch 00031: val_loss did not improve from 1.63663
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.6412 - accuracy: 0.3318
Testing Loss = 1.641213, Testing Accuracy = 0.331795
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 8s 76ms/step - loss: 12.2390 - accuracy: 0.2270 - val_loss: 8.5310 - val_accuracy: 0.2636

Epoch 00001: val_loss improved from inf to 8.53097, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 2/100
83/83 [==============================] - 7s 79ms/step - loss: 6.6682 - accuracy: 0.2782 - val_loss: 5.3492 - val_accuracy: 0.2958

Epoch 00002: val_loss improved from 8.53097 to 5.34924, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 3/100
83/83 [==============================] - 7s 79ms/step - loss: 4.5745 - accuracy: 0.2941 - val_loss: 3.9857 - val_accuracy: 0.3116

Epoch 00003: val_loss improved from 5.34924 to 3.98571, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 4/100
83/83 [==============================] - 7s 80ms/step - loss: 3.5846 - accuracy: 0.3001 - val_loss: 3.2392 - val_accuracy: 0.3191

Epoch 00004: val_loss improved from 3.98571 to 3.23924, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 5/100
83/83 [==============================] - 7s 80ms/step - loss: 2.9938 - accuracy: 0.3098 - val_loss: 2.7615 - val_accuracy: 0.3197

Epoch 00005: val_loss improved from 3.23924 to 2.76147, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 6/100
83/83 [==============================] - 7s 79ms/step - loss: 2.5986 - accuracy: 0.3138 - val_loss: 2.4314 - val_accuracy: 0.3232

Epoch 00006: val_loss improved from 2.76147 to 2.43141, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 7/100
83/83 [==============================] - 8s 100ms/step - loss: 2.3191 - accuracy: 0.3197 - val_loss: 2.1986 - val_accuracy: 0.3235

Epoch 00007: val_loss improved from 2.43141 to 2.19860, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 8/100
83/83 [==============================] - 9s 104ms/step - loss: 2.1205 - accuracy: 0.3185 - val_loss: 2.0366 - val_accuracy: 0.3205

Epoch 00008: val_loss improved from 2.19860 to 2.03659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 9/100
83/83 [==============================] - 8s 101ms/step - loss: 1.9800 - accuracy: 0.3219 - val_loss: 1.9180 - val_accuracy: 0.3205

Epoch 00009: val_loss improved from 2.03659 to 1.91795, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 10/100
83/83 [==============================] - 8s 100ms/step - loss: 1.8768 - accuracy: 0.3265 - val_loss: 1.8328 - val_accuracy: 0.3243

Epoch 00010: val_loss improved from 1.91795 to 1.83281, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 11/100
83/83 [==============================] - 9s 103ms/step - loss: 1.8053 - accuracy: 0.3261 - val_loss: 1.7746 - val_accuracy: 0.3262

Epoch 00011: val_loss improved from 1.83281 to 1.77463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 12/100
83/83 [==============================] - 9s 102ms/step - loss: 1.7547 - accuracy: 0.3284 - val_loss: 1.7355 - val_accuracy: 0.3240

Epoch 00012: val_loss improved from 1.77463 to 1.73551, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 13/100
83/83 [==============================] - 8s 97ms/step - loss: 1.7164 - accuracy: 0.3332 - val_loss: 1.7046 - val_accuracy: 0.3261

Epoch 00013: val_loss improved from 1.73551 to 1.70461, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 14/100
83/83 [==============================] - 9s 106ms/step - loss: 1.6888 - accuracy: 0.3341 - val_loss: 1.6826 - val_accuracy: 0.3275

Epoch 00014: val_loss improved from 1.70461 to 1.68256, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 15/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6704 - accuracy: 0.3366 - val_loss: 1.6681 - val_accuracy: 0.3297

Epoch 00015: val_loss improved from 1.68256 to 1.66812, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 16/100
83/83 [==============================] - 8s 102ms/step - loss: 1.6561 - accuracy: 0.3334 - val_loss: 1.6575 - val_accuracy: 0.3284

Epoch 00016: val_loss improved from 1.66812 to 1.65745, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 17/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6439 - accuracy: 0.3379 - val_loss: 1.6525 - val_accuracy: 0.3294

Epoch 00017: val_loss improved from 1.65745 to 1.65249, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 18/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6355 - accuracy: 0.3432 - val_loss: 1.6481 - val_accuracy: 0.3275

Epoch 00018: val_loss improved from 1.65249 to 1.64809, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 19/100
83/83 [==============================] - 8s 97ms/step - loss: 1.6295 - accuracy: 0.3430 - val_loss: 1.6446 - val_accuracy: 0.3290

Epoch 00019: val_loss improved from 1.64809 to 1.64462, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 20/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6261 - accuracy: 0.3434 - val_loss: 1.6423 - val_accuracy: 0.3307

Epoch 00020: val_loss improved from 1.64462 to 1.64229, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 21/100
83/83 [==============================] - 9s 106ms/step - loss: 1.6210 - accuracy: 0.3445 - val_loss: 1.6416 - val_accuracy: 0.3275

Epoch 00021: val_loss improved from 1.64229 to 1.64163, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 22/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6163 - accuracy: 0.3466 - val_loss: 1.6395 - val_accuracy: 0.3323

Epoch 00022: val_loss improved from 1.64163 to 1.63948, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 23/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6121 - accuracy: 0.3509 - val_loss: 1.6394 - val_accuracy: 0.3303

Epoch 00023: val_loss improved from 1.63948 to 1.63942, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/5
Epoch 24/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6103 - accuracy: 0.3509 - val_loss: 1.6406 - val_accuracy: 0.3297

Epoch 00024: val_loss did not improve from 1.63942
Epoch 25/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6076 - accuracy: 0.3547 - val_loss: 1.6394 - val_accuracy: 0.3337

Epoch 00025: val_loss did not improve from 1.63942
Epoch 26/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6048 - accuracy: 0.3595 - val_loss: 1.6442 - val_accuracy: 0.3344

Epoch 00026: val_loss did not improve from 1.63942
Epoch 27/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6021 - accuracy: 0.3607 - val_loss: 1.6467 - val_accuracy: 0.3348

Epoch 00027: val_loss did not improve from 1.63942
Epoch 28/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6002 - accuracy: 0.3611 - val_loss: 1.6495 - val_accuracy: 0.3314

Epoch 00028: val_loss did not improve from 1.63942
Epoch 29/100
83/83 [==============================] - 11s 128ms/step - loss: 1.5989 - accuracy: 0.3659 - val_loss: 1.6568 - val_accuracy: 0.3316

Epoch 00029: val_loss did not improve from 1.63942
Epoch 30/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5978 - accuracy: 0.3668 - val_loss: 1.6596 - val_accuracy: 0.3300

Epoch 00030: val_loss did not improve from 1.63942
Epoch 31/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5942 - accuracy: 0.3729 - val_loss: 1.6690 - val_accuracy: 0.3309

Epoch 00031: val_loss did not improve from 1.63942
Epoch 32/100
83/83 [==============================] - 11s 131ms/step - loss: 1.5915 - accuracy: 0.3781 - val_loss: 1.6779 - val_accuracy: 0.3273

Epoch 00032: val_loss did not improve from 1.63942
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.6430 - accuracy: 0.3312
Testing Loss = 1.642971, Testing Accuracy = 0.331200
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 78ms/step - loss: 12.2690 - accuracy: 0.2264 - val_loss: 8.5819 - val_accuracy: 0.2616

Epoch 00001: val_loss improved from inf to 8.58186, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 2/100
83/83 [==============================] - 7s 79ms/step - loss: 6.7160 - accuracy: 0.2790 - val_loss: 5.3878 - val_accuracy: 0.2973

Epoch 00002: val_loss improved from 8.58186 to 5.38780, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 3/100
83/83 [==============================] - 7s 79ms/step - loss: 4.6115 - accuracy: 0.2919 - val_loss: 4.0198 - val_accuracy: 0.3112

Epoch 00003: val_loss improved from 5.38780 to 4.01978, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 4/100
83/83 [==============================] - 7s 79ms/step - loss: 3.6112 - accuracy: 0.2998 - val_loss: 3.2632 - val_accuracy: 0.3181

Epoch 00004: val_loss improved from 4.01978 to 3.26324, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 5/100
83/83 [==============================] - 7s 79ms/step - loss: 3.0136 - accuracy: 0.3107 - val_loss: 2.7758 - val_accuracy: 0.3209

Epoch 00005: val_loss improved from 3.26324 to 2.77581, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 6/100
83/83 [==============================] - 7s 79ms/step - loss: 2.6128 - accuracy: 0.3129 - val_loss: 2.4413 - val_accuracy: 0.3239

Epoch 00006: val_loss improved from 2.77581 to 2.44132, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 7/100
83/83 [==============================] - 7s 81ms/step - loss: 2.3292 - accuracy: 0.3155 - val_loss: 2.2071 - val_accuracy: 0.3232

Epoch 00007: val_loss improved from 2.44132 to 2.20712, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 8/100
83/83 [==============================] - 9s 103ms/step - loss: 2.1271 - accuracy: 0.3198 - val_loss: 2.0430 - val_accuracy: 0.3204

Epoch 00008: val_loss improved from 2.20712 to 2.04298, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 9/100
83/83 [==============================] - 8s 96ms/step - loss: 1.9856 - accuracy: 0.3220 - val_loss: 1.9241 - val_accuracy: 0.3205

Epoch 00009: val_loss improved from 2.04298 to 1.92409, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 10/100
83/83 [==============================] - 9s 102ms/step - loss: 1.8802 - accuracy: 0.3251 - val_loss: 1.8366 - val_accuracy: 0.3248

Epoch 00010: val_loss improved from 1.92409 to 1.83659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 11/100
83/83 [==============================] - 9s 104ms/step - loss: 1.8072 - accuracy: 0.3289 - val_loss: 1.7782 - val_accuracy: 0.3244

Epoch 00011: val_loss improved from 1.83659 to 1.77823, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 12/100
83/83 [==============================] - 8s 97ms/step - loss: 1.7557 - accuracy: 0.3279 - val_loss: 1.7369 - val_accuracy: 0.3216

Epoch 00012: val_loss improved from 1.77823 to 1.73694, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 13/100
83/83 [==============================] - 9s 103ms/step - loss: 1.7172 - accuracy: 0.3300 - val_loss: 1.7038 - val_accuracy: 0.3286

Epoch 00013: val_loss improved from 1.73694 to 1.70380, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 14/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6901 - accuracy: 0.3352 - val_loss: 1.6863 - val_accuracy: 0.3238

Epoch 00014: val_loss improved from 1.70380 to 1.68626, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 15/100
83/83 [==============================] - 8s 99ms/step - loss: 1.6702 - accuracy: 0.3360 - val_loss: 1.6703 - val_accuracy: 0.3260

Epoch 00015: val_loss improved from 1.68626 to 1.67034, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 16/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6571 - accuracy: 0.3387 - val_loss: 1.6635 - val_accuracy: 0.3232

Epoch 00016: val_loss improved from 1.67034 to 1.66348, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 17/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6455 - accuracy: 0.3379 - val_loss: 1.6511 - val_accuracy: 0.3274

Epoch 00017: val_loss improved from 1.66348 to 1.65115, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 18/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6376 - accuracy: 0.3415 - val_loss: 1.6504 - val_accuracy: 0.3253

Epoch 00018: val_loss improved from 1.65115 to 1.65037, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 19/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6301 - accuracy: 0.3457 - val_loss: 1.6450 - val_accuracy: 0.3248

Epoch 00019: val_loss improved from 1.65037 to 1.64503, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 20/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6235 - accuracy: 0.3429 - val_loss: 1.6415 - val_accuracy: 0.3289

Epoch 00020: val_loss improved from 1.64503 to 1.64149, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 21/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6193 - accuracy: 0.3462 - val_loss: 1.6387 - val_accuracy: 0.3284

Epoch 00021: val_loss improved from 1.64149 to 1.63870, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 22/100
83/83 [==============================] - 9s 106ms/step - loss: 1.6161 - accuracy: 0.3498 - val_loss: 1.6387 - val_accuracy: 0.3268

Epoch 00022: val_loss did not improve from 1.63870
Epoch 23/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6133 - accuracy: 0.3498 - val_loss: 1.6382 - val_accuracy: 0.3308

Epoch 00023: val_loss improved from 1.63870 to 1.63823, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/6
Epoch 24/100
83/83 [==============================] - 10s 126ms/step - loss: 1.6109 - accuracy: 0.3525 - val_loss: 1.6385 - val_accuracy: 0.3305

Epoch 00024: val_loss did not improve from 1.63823
Epoch 25/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6070 - accuracy: 0.3535 - val_loss: 1.6437 - val_accuracy: 0.3305

Epoch 00025: val_loss did not improve from 1.63823
Epoch 26/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6075 - accuracy: 0.3577 - val_loss: 1.6472 - val_accuracy: 0.3309

Epoch 00026: val_loss did not improve from 1.63823
Epoch 27/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6036 - accuracy: 0.3616 - val_loss: 1.6492 - val_accuracy: 0.3313

Epoch 00027: val_loss did not improve from 1.63823
Epoch 28/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6029 - accuracy: 0.3630 - val_loss: 1.6481 - val_accuracy: 0.3342

Epoch 00028: val_loss did not improve from 1.63823
Epoch 29/100
83/83 [==============================] - 9s 103ms/step - loss: 1.5991 - accuracy: 0.3657 - val_loss: 1.6544 - val_accuracy: 0.3331

Epoch 00029: val_loss did not improve from 1.63823
Epoch 30/100
83/83 [==============================] - 11s 130ms/step - loss: 1.5982 - accuracy: 0.3672 - val_loss: 1.6581 - val_accuracy: 0.3311

Epoch 00030: val_loss did not improve from 1.63823
Epoch 31/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5944 - accuracy: 0.3743 - val_loss: 1.6643 - val_accuracy: 0.3265

Epoch 00031: val_loss did not improve from 1.63823
Epoch 32/100
83/83 [==============================] - 11s 131ms/step - loss: 1.5949 - accuracy: 0.3758 - val_loss: 1.6715 - val_accuracy: 0.3293

Epoch 00032: val_loss did not improve from 1.63823
Epoch 33/100
83/83 [==============================] - 11s 133ms/step - loss: 1.5915 - accuracy: 0.3802 - val_loss: 1.6776 - val_accuracy: 0.3322

Epoch 00033: val_loss did not improve from 1.63823
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 63s 5ms/step - loss: 1.6422 - accuracy: 0.3342
Testing Loss = 1.642243, Testing Accuracy = 0.334177
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 77ms/step - loss: 12.2487 - accuracy: 0.2215 - val_loss: 8.5383 - val_accuracy: 0.2515

Epoch 00001: val_loss improved from inf to 8.53833, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 2/100
83/83 [==============================] - 7s 78ms/step - loss: 6.6764 - accuracy: 0.2796 - val_loss: 5.3565 - val_accuracy: 0.2968

Epoch 00002: val_loss improved from 8.53833 to 5.35652, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 3/100
83/83 [==============================] - 7s 78ms/step - loss: 4.5852 - accuracy: 0.2922 - val_loss: 3.9954 - val_accuracy: 0.3071

Epoch 00003: val_loss improved from 5.35652 to 3.99541, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 4/100
83/83 [==============================] - 7s 78ms/step - loss: 3.5923 - accuracy: 0.2997 - val_loss: 3.2495 - val_accuracy: 0.3124

Epoch 00004: val_loss improved from 3.99541 to 3.24953, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 5/100
83/83 [==============================] - 7s 78ms/step - loss: 2.9997 - accuracy: 0.3074 - val_loss: 2.7620 - val_accuracy: 0.3203

Epoch 00005: val_loss improved from 3.24953 to 2.76199, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 6/100
83/83 [==============================] - 7s 79ms/step - loss: 2.6033 - accuracy: 0.3091 - val_loss: 2.4314 - val_accuracy: 0.3179

Epoch 00006: val_loss improved from 2.76199 to 2.43143, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 7/100
83/83 [==============================] - 6s 77ms/step - loss: 2.3218 - accuracy: 0.3159 - val_loss: 2.1964 - val_accuracy: 0.3230

Epoch 00007: val_loss improved from 2.43143 to 2.19640, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 8/100
83/83 [==============================] - 8s 101ms/step - loss: 2.1218 - accuracy: 0.3192 - val_loss: 2.0319 - val_accuracy: 0.3224

Epoch 00008: val_loss improved from 2.19640 to 2.03188, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 9/100
83/83 [==============================] - 8s 98ms/step - loss: 1.9787 - accuracy: 0.3193 - val_loss: 1.9153 - val_accuracy: 0.3201

Epoch 00009: val_loss improved from 2.03188 to 1.91532, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 10/100
83/83 [==============================] - 9s 103ms/step - loss: 1.8766 - accuracy: 0.3232 - val_loss: 1.8318 - val_accuracy: 0.3233

Epoch 00010: val_loss improved from 1.91532 to 1.83181, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 11/100
83/83 [==============================] - 9s 105ms/step - loss: 1.8046 - accuracy: 0.3250 - val_loss: 1.7741 - val_accuracy: 0.3224

Epoch 00011: val_loss improved from 1.83181 to 1.77408, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 12/100
83/83 [==============================] - 8s 100ms/step - loss: 1.7530 - accuracy: 0.3291 - val_loss: 1.7288 - val_accuracy: 0.3271

Epoch 00012: val_loss improved from 1.77408 to 1.72879, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 13/100
83/83 [==============================] - 9s 105ms/step - loss: 1.7143 - accuracy: 0.3287 - val_loss: 1.6985 - val_accuracy: 0.3266

Epoch 00013: val_loss improved from 1.72879 to 1.69850, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 14/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6878 - accuracy: 0.3311 - val_loss: 1.6799 - val_accuracy: 0.3258

Epoch 00014: val_loss improved from 1.69850 to 1.67992, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 15/100
83/83 [==============================] - 9s 110ms/step - loss: 1.6708 - accuracy: 0.3320 - val_loss: 1.6655 - val_accuracy: 0.3260

Epoch 00015: val_loss improved from 1.67992 to 1.66546, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 16/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6544 - accuracy: 0.3335 - val_loss: 1.6577 - val_accuracy: 0.3244

Epoch 00016: val_loss improved from 1.66546 to 1.65767, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 17/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6446 - accuracy: 0.3367 - val_loss: 1.6491 - val_accuracy: 0.3268

Epoch 00017: val_loss improved from 1.65767 to 1.64910, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 18/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6372 - accuracy: 0.3362 - val_loss: 1.6419 - val_accuracy: 0.3316

Epoch 00018: val_loss improved from 1.64910 to 1.64189, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 19/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6292 - accuracy: 0.3389 - val_loss: 1.6399 - val_accuracy: 0.3296

Epoch 00019: val_loss improved from 1.64189 to 1.63990, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 20/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6234 - accuracy: 0.3405 - val_loss: 1.6361 - val_accuracy: 0.3308

Epoch 00020: val_loss improved from 1.63990 to 1.63611, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 21/100
83/83 [==============================] - 9s 114ms/step - loss: 1.6187 - accuracy: 0.3450 - val_loss: 1.6335 - val_accuracy: 0.3343

Epoch 00021: val_loss improved from 1.63611 to 1.63349, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 22/100
83/83 [==============================] - 10s 118ms/step - loss: 1.6181 - accuracy: 0.3454 - val_loss: 1.6320 - val_accuracy: 0.3327

Epoch 00022: val_loss improved from 1.63349 to 1.63201, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/7
Epoch 23/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6130 - accuracy: 0.3443 - val_loss: 1.6329 - val_accuracy: 0.3318

Epoch 00023: val_loss did not improve from 1.63201
Epoch 24/100
83/83 [==============================] - 10s 116ms/step - loss: 1.6102 - accuracy: 0.3514 - val_loss: 1.6337 - val_accuracy: 0.3315

Epoch 00024: val_loss did not improve from 1.63201
Epoch 25/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6076 - accuracy: 0.3505 - val_loss: 1.6363 - val_accuracy: 0.3317

Epoch 00025: val_loss did not improve from 1.63201
Epoch 26/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6068 - accuracy: 0.3548 - val_loss: 1.6397 - val_accuracy: 0.3304

Epoch 00026: val_loss did not improve from 1.63201
Epoch 27/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6045 - accuracy: 0.3549 - val_loss: 1.6394 - val_accuracy: 0.3305

Epoch 00027: val_loss did not improve from 1.63201
Epoch 28/100
83/83 [==============================] - 10s 118ms/step - loss: 1.6016 - accuracy: 0.3579 - val_loss: 1.6429 - val_accuracy: 0.3313

Epoch 00028: val_loss did not improve from 1.63201
Epoch 29/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6001 - accuracy: 0.3593 - val_loss: 1.6473 - val_accuracy: 0.3311

Epoch 00029: val_loss did not improve from 1.63201
Epoch 30/100
83/83 [==============================] - 9s 108ms/step - loss: 1.5979 - accuracy: 0.3660 - val_loss: 1.6501 - val_accuracy: 0.3285

Epoch 00030: val_loss did not improve from 1.63201
Epoch 31/100
83/83 [==============================] - 11s 127ms/step - loss: 1.5968 - accuracy: 0.3640 - val_loss: 1.6536 - val_accuracy: 0.3313

Epoch 00031: val_loss did not improve from 1.63201
Epoch 32/100
83/83 [==============================] - 11s 133ms/step - loss: 1.5933 - accuracy: 0.3721 - val_loss: 1.6581 - val_accuracy: 0.3296

Epoch 00032: val_loss did not improve from 1.63201
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 67s 5ms/step - loss: 1.6377 - accuracy: 0.3333
Testing Loss = 1.637671, Testing Accuracy = 0.333284
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 8s 82ms/step - loss: 12.2097 - accuracy: 0.2154 - val_loss: 8.4743 - val_accuracy: 0.2543

Epoch 00001: val_loss improved from inf to 8.47430, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 2/100
83/83 [==============================] - 7s 81ms/step - loss: 6.6180 - accuracy: 0.2746 - val_loss: 5.3102 - val_accuracy: 0.2952

Epoch 00002: val_loss improved from 8.47430 to 5.31024, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 3/100
83/83 [==============================] - 7s 80ms/step - loss: 4.5495 - accuracy: 0.2927 - val_loss: 3.9704 - val_accuracy: 0.3082

Epoch 00003: val_loss improved from 5.31024 to 3.97040, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 4/100
83/83 [==============================] - 7s 81ms/step - loss: 3.5757 - accuracy: 0.3002 - val_loss: 3.2364 - val_accuracy: 0.3196

Epoch 00004: val_loss improved from 3.97040 to 3.23638, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 5/100
83/83 [==============================] - 6s 76ms/step - loss: 2.9926 - accuracy: 0.3078 - val_loss: 2.7588 - val_accuracy: 0.3209

Epoch 00005: val_loss improved from 3.23638 to 2.75876, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 6/100
83/83 [==============================] - 7s 80ms/step - loss: 2.5993 - accuracy: 0.3109 - val_loss: 2.4330 - val_accuracy: 0.3178

Epoch 00006: val_loss improved from 2.75876 to 2.43299, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 7/100
83/83 [==============================] - 7s 80ms/step - loss: 2.3224 - accuracy: 0.3176 - val_loss: 2.1985 - val_accuracy: 0.3229

Epoch 00007: val_loss improved from 2.43299 to 2.19851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 8/100
83/83 [==============================] - 7s 79ms/step - loss: 2.1238 - accuracy: 0.3183 - val_loss: 2.0351 - val_accuracy: 0.3229

Epoch 00008: val_loss improved from 2.19851 to 2.03512, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 9/100
83/83 [==============================] - 7s 79ms/step - loss: 1.9820 - accuracy: 0.3196 - val_loss: 1.9190 - val_accuracy: 0.3244

Epoch 00009: val_loss improved from 2.03512 to 1.91898, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 10/100
83/83 [==============================] - 7s 79ms/step - loss: 1.8805 - accuracy: 0.3214 - val_loss: 1.8343 - val_accuracy: 0.3262

Epoch 00010: val_loss improved from 1.91898 to 1.83429, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 11/100
83/83 [==============================] - 8s 95ms/step - loss: 1.8077 - accuracy: 0.3271 - val_loss: 1.7747 - val_accuracy: 0.3259

Epoch 00011: val_loss improved from 1.83429 to 1.77474, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 12/100
83/83 [==============================] - 8s 94ms/step - loss: 1.7557 - accuracy: 0.3249 - val_loss: 1.7333 - val_accuracy: 0.3249

Epoch 00012: val_loss improved from 1.77474 to 1.73331, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 13/100
83/83 [==============================] - 9s 102ms/step - loss: 1.7167 - accuracy: 0.3299 - val_loss: 1.7040 - val_accuracy: 0.3239

Epoch 00013: val_loss improved from 1.73331 to 1.70398, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 14/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6917 - accuracy: 0.3305 - val_loss: 1.6812 - val_accuracy: 0.3285

Epoch 00014: val_loss improved from 1.70398 to 1.68118, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 15/100
83/83 [==============================] - 8s 95ms/step - loss: 1.6710 - accuracy: 0.3350 - val_loss: 1.6685 - val_accuracy: 0.3276

Epoch 00015: val_loss improved from 1.68118 to 1.66847, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 16/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6581 - accuracy: 0.3359 - val_loss: 1.6599 - val_accuracy: 0.3279

Epoch 00016: val_loss improved from 1.66847 to 1.65992, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 17/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6465 - accuracy: 0.3353 - val_loss: 1.6505 - val_accuracy: 0.3303

Epoch 00017: val_loss improved from 1.65992 to 1.65053, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 18/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6383 - accuracy: 0.3392 - val_loss: 1.6483 - val_accuracy: 0.3277

Epoch 00018: val_loss improved from 1.65053 to 1.64833, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 19/100
83/83 [==============================] - 8s 96ms/step - loss: 1.6322 - accuracy: 0.3422 - val_loss: 1.6409 - val_accuracy: 0.3282

Epoch 00019: val_loss improved from 1.64833 to 1.64094, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 20/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6254 - accuracy: 0.3437 - val_loss: 1.6407 - val_accuracy: 0.3293

Epoch 00020: val_loss improved from 1.64094 to 1.64069, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 21/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6214 - accuracy: 0.3457 - val_loss: 1.6362 - val_accuracy: 0.3340

Epoch 00021: val_loss improved from 1.64069 to 1.63621, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 22/100
83/83 [==============================] - 8s 96ms/step - loss: 1.6174 - accuracy: 0.3466 - val_loss: 1.6389 - val_accuracy: 0.3313

Epoch 00022: val_loss did not improve from 1.63621
Epoch 23/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6136 - accuracy: 0.3491 - val_loss: 1.6358 - val_accuracy: 0.3314

Epoch 00023: val_loss improved from 1.63621 to 1.63579, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/8
Epoch 24/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6105 - accuracy: 0.3530 - val_loss: 1.6423 - val_accuracy: 0.3297

Epoch 00024: val_loss did not improve from 1.63579
Epoch 25/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6095 - accuracy: 0.3527 - val_loss: 1.6421 - val_accuracy: 0.3333

Epoch 00025: val_loss did not improve from 1.63579
Epoch 26/100
83/83 [==============================] - 8s 94ms/step - loss: 1.6057 - accuracy: 0.3588 - val_loss: 1.6420 - val_accuracy: 0.3346

Epoch 00026: val_loss did not improve from 1.63579
Epoch 27/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6029 - accuracy: 0.3594 - val_loss: 1.6445 - val_accuracy: 0.3352

Epoch 00027: val_loss did not improve from 1.63579
Epoch 28/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6026 - accuracy: 0.3609 - val_loss: 1.6489 - val_accuracy: 0.3352

Epoch 00028: val_loss did not improve from 1.63579
Epoch 29/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6000 - accuracy: 0.3674 - val_loss: 1.6577 - val_accuracy: 0.3324

Epoch 00029: val_loss did not improve from 1.63579
Epoch 30/100
83/83 [==============================] - 10s 114ms/step - loss: 1.5977 - accuracy: 0.3694 - val_loss: 1.6601 - val_accuracy: 0.3330

Epoch 00030: val_loss did not improve from 1.63579
Epoch 31/100
83/83 [==============================] - 10s 118ms/step - loss: 1.5947 - accuracy: 0.3739 - val_loss: 1.6644 - val_accuracy: 0.3354

Epoch 00031: val_loss did not improve from 1.63579
Epoch 32/100
83/83 [==============================] - 9s 103ms/step - loss: 1.5937 - accuracy: 0.3769 - val_loss: 1.6689 - val_accuracy: 0.3339

Epoch 00032: val_loss did not improve from 1.63579
Epoch 33/100
83/83 [==============================] - 9s 110ms/step - loss: 1.5906 - accuracy: 0.3794 - val_loss: 1.6803 - val_accuracy: 0.3323

Epoch 00033: val_loss did not improve from 1.63579
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 66s 5ms/step - loss: 1.6410 - accuracy: 0.3329
Testing Loss = 1.641043, Testing Accuracy = 0.332912
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 8s 82ms/step - loss: 12.2668 - accuracy: 0.2238 - val_loss: 8.5568 - val_accuracy: 0.2592

Epoch 00001: val_loss improved from inf to 8.55683, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 2/100
83/83 [==============================] - 7s 80ms/step - loss: 6.6965 - accuracy: 0.2773 - val_loss: 5.3706 - val_accuracy: 0.2938

Epoch 00002: val_loss improved from 8.55683 to 5.37061, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 3/100
83/83 [==============================] - 7s 81ms/step - loss: 4.5966 - accuracy: 0.2919 - val_loss: 4.0065 - val_accuracy: 0.3066

Epoch 00003: val_loss improved from 5.37061 to 4.00647, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 4/100
83/83 [==============================] - 7s 80ms/step - loss: 3.6009 - accuracy: 0.3037 - val_loss: 3.2547 - val_accuracy: 0.3140

Epoch 00004: val_loss improved from 4.00647 to 3.25467, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 5/100
83/83 [==============================] - 7s 80ms/step - loss: 3.0098 - accuracy: 0.3056 - val_loss: 2.7704 - val_accuracy: 0.3201

Epoch 00005: val_loss improved from 3.25467 to 2.77042, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 6/100
83/83 [==============================] - 7s 81ms/step - loss: 2.6085 - accuracy: 0.3131 - val_loss: 2.4371 - val_accuracy: 0.3236

Epoch 00006: val_loss improved from 2.77042 to 2.43708, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 7/100
83/83 [==============================] - 7s 80ms/step - loss: 2.3278 - accuracy: 0.3171 - val_loss: 2.2004 - val_accuracy: 0.3280

Epoch 00007: val_loss improved from 2.43708 to 2.20038, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 8/100
83/83 [==============================] - 6s 75ms/step - loss: 2.1281 - accuracy: 0.3185 - val_loss: 2.0367 - val_accuracy: 0.3262

Epoch 00008: val_loss improved from 2.20038 to 2.03674, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 9/100
83/83 [==============================] - 7s 79ms/step - loss: 1.9841 - accuracy: 0.3200 - val_loss: 1.9214 - val_accuracy: 0.3229

Epoch 00009: val_loss improved from 2.03674 to 1.92140, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 10/100
83/83 [==============================] - 7s 79ms/step - loss: 1.8807 - accuracy: 0.3241 - val_loss: 1.8379 - val_accuracy: 0.3212

Epoch 00010: val_loss improved from 1.92140 to 1.83789, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 11/100
83/83 [==============================] - 7s 79ms/step - loss: 1.8097 - accuracy: 0.3246 - val_loss: 1.7758 - val_accuracy: 0.3248

Epoch 00011: val_loss improved from 1.83789 to 1.77585, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 12/100
83/83 [==============================] - 7s 78ms/step - loss: 1.7561 - accuracy: 0.3251 - val_loss: 1.7366 - val_accuracy: 0.3236

Epoch 00012: val_loss improved from 1.77585 to 1.73657, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 13/100
83/83 [==============================] - 7s 79ms/step - loss: 1.7195 - accuracy: 0.3293 - val_loss: 1.7059 - val_accuracy: 0.3271

Epoch 00013: val_loss improved from 1.73657 to 1.70595, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 14/100
83/83 [==============================] - 6s 76ms/step - loss: 1.6919 - accuracy: 0.3321 - val_loss: 1.6861 - val_accuracy: 0.3239

Epoch 00014: val_loss improved from 1.70595 to 1.68612, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 15/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6717 - accuracy: 0.3315 - val_loss: 1.6692 - val_accuracy: 0.3266

Epoch 00015: val_loss improved from 1.68612 to 1.66918, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 16/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6566 - accuracy: 0.3355 - val_loss: 1.6624 - val_accuracy: 0.3243

Epoch 00016: val_loss improved from 1.66918 to 1.66241, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 17/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6469 - accuracy: 0.3356 - val_loss: 1.6524 - val_accuracy: 0.3305

Epoch 00017: val_loss improved from 1.66241 to 1.65236, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 18/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6381 - accuracy: 0.3377 - val_loss: 1.6482 - val_accuracy: 0.3271

Epoch 00018: val_loss improved from 1.65236 to 1.64816, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 19/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6324 - accuracy: 0.3411 - val_loss: 1.6447 - val_accuracy: 0.3298

Epoch 00019: val_loss improved from 1.64816 to 1.64466, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 20/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6256 - accuracy: 0.3425 - val_loss: 1.6415 - val_accuracy: 0.3315

Epoch 00020: val_loss improved from 1.64466 to 1.64148, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 21/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6206 - accuracy: 0.3466 - val_loss: 1.6429 - val_accuracy: 0.3299

Epoch 00021: val_loss did not improve from 1.64148
Epoch 22/100
83/83 [==============================] - 10s 116ms/step - loss: 1.6191 - accuracy: 0.3455 - val_loss: 1.6412 - val_accuracy: 0.3301

Epoch 00022: val_loss improved from 1.64148 to 1.64117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 23/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6137 - accuracy: 0.3500 - val_loss: 1.6419 - val_accuracy: 0.3325

Epoch 00023: val_loss did not improve from 1.64117
Epoch 24/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6141 - accuracy: 0.3506 - val_loss: 1.6407 - val_accuracy: 0.3316

Epoch 00024: val_loss improved from 1.64117 to 1.64069, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r12/Try/9
Epoch 25/100
83/83 [==============================] - 8s 97ms/step - loss: 1.6099 - accuracy: 0.3530 - val_loss: 1.6435 - val_accuracy: 0.3344

Epoch 00025: val_loss did not improve from 1.64069
Epoch 26/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6068 - accuracy: 0.3559 - val_loss: 1.6457 - val_accuracy: 0.3342

Epoch 00026: val_loss did not improve from 1.64069
Epoch 27/100
83/83 [==============================] - 10s 121ms/step - loss: 1.6045 - accuracy: 0.3590 - val_loss: 1.6501 - val_accuracy: 0.3333

Epoch 00027: val_loss did not improve from 1.64069
Epoch 28/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6048 - accuracy: 0.3600 - val_loss: 1.6534 - val_accuracy: 0.3333

Epoch 00028: val_loss did not improve from 1.64069
Epoch 29/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6012 - accuracy: 0.3652 - val_loss: 1.6609 - val_accuracy: 0.3321

Epoch 00029: val_loss did not improve from 1.64069
Epoch 30/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6002 - accuracy: 0.3660 - val_loss: 1.6610 - val_accuracy: 0.3349

Epoch 00030: val_loss did not improve from 1.64069
Epoch 31/100
83/83 [==============================] - 8s 96ms/step - loss: 1.5966 - accuracy: 0.3709 - val_loss: 1.6689 - val_accuracy: 0.3308

Epoch 00031: val_loss did not improve from 1.64069
Epoch 32/100
83/83 [==============================] - 9s 102ms/step - loss: 1.5961 - accuracy: 0.3742 - val_loss: 1.6764 - val_accuracy: 0.3311

Epoch 00032: val_loss did not improve from 1.64069
Epoch 33/100
83/83 [==============================] - 11s 130ms/step - loss: 1.5929 - accuracy: 0.3802 - val_loss: 1.6841 - val_accuracy: 0.3311

Epoch 00033: val_loss did not improve from 1.64069
Epoch 34/100
83/83 [==============================] - 8s 102ms/step - loss: 1.5895 - accuracy: 0.3860 - val_loss: 1.6926 - val_accuracy: 0.3318

Epoch 00034: val_loss did not improve from 1.64069
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 66s 5ms/step - loss: 1.6451 - accuracy: 0.3329
Testing Loss = 1.645148, Testing Accuracy = 0.332912
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 81.34 +- 0.0740 %)
$W^-/W^-$ (auc = 80.63 +- 0.0742 %)
$Z/Z$ (auc = 64.23 +- 0.1631 %)
$W^+/W^-$ (auc = 64.88 +- 0.0794 %)
$W^+/Z$$ (auc = 65.25 +- 0.0971 %)
$W^-/Z$ (auc = 67.52 +- 0.0557 %)
The summarized testing accuracy = 33.24 +- 0.0919 %, with the loss = 1.6413 +- 0.002075
