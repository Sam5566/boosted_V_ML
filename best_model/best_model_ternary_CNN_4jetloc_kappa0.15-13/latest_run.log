

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-20 23:03:26.202926
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 54s 468ms/step - loss: 40.6281 - accuracy: 0.2967 - val_loss: 25.5492 - val_accuracy: 0.2534

Epoch 00001: val_loss improved from inf to 25.54918, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 2/100
83/83 [==============================] - 38s 461ms/step - loss: 18.8330 - accuracy: 0.3239 - val_loss: 14.1732 - val_accuracy: 0.2988

Epoch 00002: val_loss improved from 25.54918 to 14.17319, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 3/100
83/83 [==============================] - 38s 460ms/step - loss: 11.6606 - accuracy: 0.3260 - val_loss: 9.7107 - val_accuracy: 0.3254

Epoch 00003: val_loss improved from 14.17319 to 9.71073, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 4/100
83/83 [==============================] - 39s 472ms/step - loss: 8.3440 - accuracy: 0.3298 - val_loss: 7.1639 - val_accuracy: 0.3444

Epoch 00004: val_loss improved from 9.71073 to 7.16394, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 5/100
83/83 [==============================] - 38s 459ms/step - loss: 6.2651 - accuracy: 0.3328 - val_loss: 5.4383 - val_accuracy: 0.3497

Epoch 00005: val_loss improved from 7.16394 to 5.43826, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 6/100
83/83 [==============================] - 38s 459ms/step - loss: 4.8185 - accuracy: 0.3325 - val_loss: 4.2253 - val_accuracy: 0.3488

Epoch 00006: val_loss improved from 5.43826 to 4.22535, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 7/100
83/83 [==============================] - 39s 464ms/step - loss: 3.7985 - accuracy: 0.3369 - val_loss: 3.3761 - val_accuracy: 0.3483

Epoch 00007: val_loss improved from 4.22535 to 3.37608, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 8/100
83/83 [==============================] - 38s 458ms/step - loss: 3.0874 - accuracy: 0.3370 - val_loss: 2.7858 - val_accuracy: 0.3507

Epoch 00008: val_loss improved from 3.37608 to 2.78583, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 9/100
83/83 [==============================] - 39s 466ms/step - loss: 2.5929 - accuracy: 0.3386 - val_loss: 2.3823 - val_accuracy: 0.3513

Epoch 00009: val_loss improved from 2.78583 to 2.38227, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 10/100
83/83 [==============================] - 38s 456ms/step - loss: 2.2584 - accuracy: 0.3390 - val_loss: 2.1096 - val_accuracy: 0.3521

Epoch 00010: val_loss improved from 2.38227 to 2.10957, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 11/100
83/83 [==============================] - 39s 470ms/step - loss: 2.0320 - accuracy: 0.3386 - val_loss: 1.9279 - val_accuracy: 0.3513

Epoch 00011: val_loss improved from 2.10957 to 1.92788, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 12/100
83/83 [==============================] - 44s 528ms/step - loss: 1.8805 - accuracy: 0.3396 - val_loss: 1.8079 - val_accuracy: 0.3521

Epoch 00012: val_loss improved from 1.92788 to 1.80790, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 13/100
83/83 [==============================] - 44s 525ms/step - loss: 1.7834 - accuracy: 0.3397 - val_loss: 1.7293 - val_accuracy: 0.3526

Epoch 00013: val_loss improved from 1.80790 to 1.72928, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 14/100
83/83 [==============================] - 44s 523ms/step - loss: 1.7195 - accuracy: 0.3392 - val_loss: 1.6784 - val_accuracy: 0.3517

Epoch 00014: val_loss improved from 1.72928 to 1.67842, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 15/100
83/83 [==============================] - 43s 512ms/step - loss: 1.6791 - accuracy: 0.3387 - val_loss: 1.6479 - val_accuracy: 0.3524

Epoch 00015: val_loss improved from 1.67842 to 1.64794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 16/100
83/83 [==============================] - 43s 512ms/step - loss: 1.6525 - accuracy: 0.3392 - val_loss: 1.6266 - val_accuracy: 0.3506

Epoch 00016: val_loss improved from 1.64794 to 1.62662, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 17/100
83/83 [==============================] - 47s 559ms/step - loss: 1.6358 - accuracy: 0.3395 - val_loss: 1.6130 - val_accuracy: 0.3525

Epoch 00017: val_loss improved from 1.62662 to 1.61299, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 18/100
83/83 [==============================] - 38s 456ms/step - loss: 1.6239 - accuracy: 0.3409 - val_loss: 1.6045 - val_accuracy: 0.3514

Epoch 00018: val_loss improved from 1.61299 to 1.60449, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 19/100
83/83 [==============================] - 38s 457ms/step - loss: 1.6174 - accuracy: 0.3393 - val_loss: 1.6005 - val_accuracy: 0.3512

Epoch 00019: val_loss improved from 1.60449 to 1.60048, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 20/100
83/83 [==============================] - 39s 465ms/step - loss: 1.6122 - accuracy: 0.3403 - val_loss: 1.5949 - val_accuracy: 0.3516

Epoch 00020: val_loss improved from 1.60048 to 1.59486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 21/100
83/83 [==============================] - 38s 455ms/step - loss: 1.6087 - accuracy: 0.3404 - val_loss: 1.5925 - val_accuracy: 0.3526

Epoch 00021: val_loss improved from 1.59486 to 1.59250, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 22/100
83/83 [==============================] - 46s 557ms/step - loss: 1.6048 - accuracy: 0.3413 - val_loss: 1.5888 - val_accuracy: 0.3514

Epoch 00022: val_loss improved from 1.59250 to 1.58884, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 23/100
83/83 [==============================] - 46s 558ms/step - loss: 1.6036 - accuracy: 0.3408 - val_loss: 1.5873 - val_accuracy: 0.3517

Epoch 00023: val_loss improved from 1.58884 to 1.58728, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 24/100
83/83 [==============================] - 46s 558ms/step - loss: 1.6020 - accuracy: 0.3419 - val_loss: 1.5863 - val_accuracy: 0.3524

Epoch 00024: val_loss improved from 1.58728 to 1.58630, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 25/100
83/83 [==============================] - 46s 558ms/step - loss: 1.6004 - accuracy: 0.3415 - val_loss: 1.5848 - val_accuracy: 0.3516

Epoch 00025: val_loss improved from 1.58630 to 1.58484, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 26/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5977 - accuracy: 0.3413 - val_loss: 1.5835 - val_accuracy: 0.3517

Epoch 00026: val_loss improved from 1.58484 to 1.58346, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 27/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5973 - accuracy: 0.3432 - val_loss: 1.5843 - val_accuracy: 0.3508

Epoch 00027: val_loss did not improve from 1.58346
Epoch 28/100
83/83 [==============================] - 46s 559ms/step - loss: 1.5963 - accuracy: 0.3409 - val_loss: 1.5819 - val_accuracy: 0.3525

Epoch 00028: val_loss improved from 1.58346 to 1.58191, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 29/100
83/83 [==============================] - 33s 392ms/step - loss: 1.5963 - accuracy: 0.3421 - val_loss: 1.5830 - val_accuracy: 0.3531

Epoch 00029: val_loss did not improve from 1.58191
Epoch 30/100
83/83 [==============================] - 33s 392ms/step - loss: 1.5948 - accuracy: 0.3421 - val_loss: 1.5813 - val_accuracy: 0.3508

Epoch 00030: val_loss improved from 1.58191 to 1.58133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 31/100
83/83 [==============================] - 32s 390ms/step - loss: 1.5939 - accuracy: 0.3427 - val_loss: 1.5807 - val_accuracy: 0.3512

Epoch 00031: val_loss improved from 1.58133 to 1.58074, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 32/100
83/83 [==============================] - 32s 390ms/step - loss: 1.5935 - accuracy: 0.3423 - val_loss: 1.5813 - val_accuracy: 0.3532

Epoch 00032: val_loss did not improve from 1.58074
Epoch 33/100
83/83 [==============================] - 31s 375ms/step - loss: 1.5933 - accuracy: 0.3424 - val_loss: 1.5805 - val_accuracy: 0.3534

Epoch 00033: val_loss improved from 1.58074 to 1.58046, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 34/100
83/83 [==============================] - 32s 380ms/step - loss: 1.5924 - accuracy: 0.3423 - val_loss: 1.5797 - val_accuracy: 0.3522

Epoch 00034: val_loss improved from 1.58046 to 1.57966, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 35/100
83/83 [==============================] - 32s 381ms/step - loss: 1.5909 - accuracy: 0.3445 - val_loss: 1.5785 - val_accuracy: 0.3519

Epoch 00035: val_loss improved from 1.57966 to 1.57849, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 36/100
83/83 [==============================] - 45s 540ms/step - loss: 1.5918 - accuracy: 0.3423 - val_loss: 1.5792 - val_accuracy: 0.3520

Epoch 00036: val_loss did not improve from 1.57849
Epoch 37/100
83/83 [==============================] - 39s 469ms/step - loss: 1.5908 - accuracy: 0.3437 - val_loss: 1.5782 - val_accuracy: 0.3527

Epoch 00037: val_loss improved from 1.57849 to 1.57821, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 38/100
83/83 [==============================] - 39s 475ms/step - loss: 1.5888 - accuracy: 0.3430 - val_loss: 1.5776 - val_accuracy: 0.3531

Epoch 00038: val_loss improved from 1.57821 to 1.57758, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 39/100
83/83 [==============================] - 40s 482ms/step - loss: 1.5892 - accuracy: 0.3435 - val_loss: 1.5779 - val_accuracy: 0.3532

Epoch 00039: val_loss did not improve from 1.57758
Epoch 40/100
83/83 [==============================] - 39s 471ms/step - loss: 1.5890 - accuracy: 0.3435 - val_loss: 1.5769 - val_accuracy: 0.3534

Epoch 00040: val_loss improved from 1.57758 to 1.57692, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 41/100
83/83 [==============================] - 38s 459ms/step - loss: 1.5887 - accuracy: 0.3449 - val_loss: 1.5765 - val_accuracy: 0.3525

Epoch 00041: val_loss improved from 1.57692 to 1.57653, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 42/100
83/83 [==============================] - 38s 461ms/step - loss: 1.5878 - accuracy: 0.3448 - val_loss: 1.5772 - val_accuracy: 0.3527

Epoch 00042: val_loss did not improve from 1.57653
Epoch 43/100
83/83 [==============================] - 38s 458ms/step - loss: 1.5877 - accuracy: 0.3438 - val_loss: 1.5760 - val_accuracy: 0.3538

Epoch 00043: val_loss improved from 1.57653 to 1.57605, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 44/100
83/83 [==============================] - 39s 470ms/step - loss: 1.5876 - accuracy: 0.3438 - val_loss: 1.5760 - val_accuracy: 0.3525

Epoch 00044: val_loss improved from 1.57605 to 1.57600, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 45/100
83/83 [==============================] - 38s 458ms/step - loss: 1.5865 - accuracy: 0.3448 - val_loss: 1.5756 - val_accuracy: 0.3555

Epoch 00045: val_loss improved from 1.57600 to 1.57558, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 46/100
83/83 [==============================] - 39s 462ms/step - loss: 1.5869 - accuracy: 0.3438 - val_loss: 1.5763 - val_accuracy: 0.3538

Epoch 00046: val_loss did not improve from 1.57558
Epoch 47/100
83/83 [==============================] - 38s 461ms/step - loss: 1.5862 - accuracy: 0.3442 - val_loss: 1.5753 - val_accuracy: 0.3539

Epoch 00047: val_loss improved from 1.57558 to 1.57529, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 48/100
83/83 [==============================] - 39s 469ms/step - loss: 1.5856 - accuracy: 0.3444 - val_loss: 1.5744 - val_accuracy: 0.3549

Epoch 00048: val_loss improved from 1.57529 to 1.57445, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 49/100
83/83 [==============================] - 38s 461ms/step - loss: 1.5857 - accuracy: 0.3444 - val_loss: 1.5757 - val_accuracy: 0.3532

Epoch 00049: val_loss did not improve from 1.57445
Epoch 50/100
83/83 [==============================] - 43s 510ms/step - loss: 1.5850 - accuracy: 0.3443 - val_loss: 1.5749 - val_accuracy: 0.3523

Epoch 00050: val_loss did not improve from 1.57445
Epoch 51/100
83/83 [==============================] - 43s 519ms/step - loss: 1.5846 - accuracy: 0.3448 - val_loss: 1.5753 - val_accuracy: 0.3541

Epoch 00051: val_loss did not improve from 1.57445
Epoch 52/100
83/83 [==============================] - 38s 461ms/step - loss: 1.5848 - accuracy: 0.3458 - val_loss: 1.5744 - val_accuracy: 0.3538

Epoch 00052: val_loss improved from 1.57445 to 1.57436, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 53/100
83/83 [==============================] - 39s 472ms/step - loss: 1.5838 - accuracy: 0.3455 - val_loss: 1.5742 - val_accuracy: 0.3539

Epoch 00053: val_loss improved from 1.57436 to 1.57425, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 54/100
83/83 [==============================] - 39s 474ms/step - loss: 1.5835 - accuracy: 0.3454 - val_loss: 1.5737 - val_accuracy: 0.3555

Epoch 00054: val_loss improved from 1.57425 to 1.57368, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 55/100
83/83 [==============================] - 40s 483ms/step - loss: 1.5840 - accuracy: 0.3462 - val_loss: 1.5740 - val_accuracy: 0.3543

Epoch 00055: val_loss did not improve from 1.57368
Epoch 56/100
83/83 [==============================] - 38s 458ms/step - loss: 1.5831 - accuracy: 0.3447 - val_loss: 1.5736 - val_accuracy: 0.3536

Epoch 00056: val_loss improved from 1.57368 to 1.57361, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 57/100
83/83 [==============================] - 39s 470ms/step - loss: 1.5834 - accuracy: 0.3469 - val_loss: 1.5742 - val_accuracy: 0.3546

Epoch 00057: val_loss did not improve from 1.57361
Epoch 58/100
83/83 [==============================] - 38s 458ms/step - loss: 1.5828 - accuracy: 0.3461 - val_loss: 1.5737 - val_accuracy: 0.3554

Epoch 00058: val_loss did not improve from 1.57361
Epoch 59/100
83/83 [==============================] - 41s 493ms/step - loss: 1.5823 - accuracy: 0.3442 - val_loss: 1.5741 - val_accuracy: 0.3535

Epoch 00059: val_loss did not improve from 1.57361
Epoch 60/100
83/83 [==============================] - 44s 534ms/step - loss: 1.5823 - accuracy: 0.3447 - val_loss: 1.5739 - val_accuracy: 0.3554

Epoch 00060: val_loss did not improve from 1.57361
Epoch 61/100
83/83 [==============================] - 38s 459ms/step - loss: 1.5809 - accuracy: 0.3462 - val_loss: 1.5737 - val_accuracy: 0.3534

Epoch 00061: val_loss did not improve from 1.57361
Epoch 62/100
83/83 [==============================] - 39s 470ms/step - loss: 1.5824 - accuracy: 0.3473 - val_loss: 1.5743 - val_accuracy: 0.3558

Epoch 00062: val_loss did not improve from 1.57361
Epoch 63/100
83/83 [==============================] - 38s 460ms/step - loss: 1.5819 - accuracy: 0.3463 - val_loss: 1.5737 - val_accuracy: 0.3547

Epoch 00063: val_loss did not improve from 1.57361
Epoch 64/100
83/83 [==============================] - 44s 531ms/step - loss: 1.5815 - accuracy: 0.3482 - val_loss: 1.5728 - val_accuracy: 0.3552

Epoch 00064: val_loss improved from 1.57361 to 1.57283, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 65/100
83/83 [==============================] - 44s 528ms/step - loss: 1.5809 - accuracy: 0.3487 - val_loss: 1.5736 - val_accuracy: 0.3556

Epoch 00065: val_loss did not improve from 1.57283
Epoch 66/100
83/83 [==============================] - 41s 498ms/step - loss: 1.5809 - accuracy: 0.3471 - val_loss: 1.5732 - val_accuracy: 0.3551

Epoch 00066: val_loss did not improve from 1.57283
Epoch 67/100
83/83 [==============================] - 39s 469ms/step - loss: 1.5810 - accuracy: 0.3473 - val_loss: 1.5734 - val_accuracy: 0.3536

Epoch 00067: val_loss did not improve from 1.57283
Epoch 68/100
83/83 [==============================] - 38s 454ms/step - loss: 1.5811 - accuracy: 0.3477 - val_loss: 1.5742 - val_accuracy: 0.3552

Epoch 00068: val_loss did not improve from 1.57283
Epoch 69/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5804 - accuracy: 0.3478 - val_loss: 1.5724 - val_accuracy: 0.3552

Epoch 00069: val_loss improved from 1.57283 to 1.57238, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 70/100
83/83 [==============================] - 38s 453ms/step - loss: 1.5795 - accuracy: 0.3482 - val_loss: 1.5727 - val_accuracy: 0.3561

Epoch 00070: val_loss did not improve from 1.57238
Epoch 71/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5797 - accuracy: 0.3487 - val_loss: 1.5735 - val_accuracy: 0.3542

Epoch 00071: val_loss did not improve from 1.57238
Epoch 72/100
83/83 [==============================] - 38s 453ms/step - loss: 1.5790 - accuracy: 0.3495 - val_loss: 1.5727 - val_accuracy: 0.3550

Epoch 00072: val_loss did not improve from 1.57238
Epoch 73/100
83/83 [==============================] - 45s 543ms/step - loss: 1.5793 - accuracy: 0.3482 - val_loss: 1.5723 - val_accuracy: 0.3552

Epoch 00073: val_loss improved from 1.57238 to 1.57226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 74/100
83/83 [==============================] - 44s 529ms/step - loss: 1.5795 - accuracy: 0.3484 - val_loss: 1.5724 - val_accuracy: 0.3537

Epoch 00074: val_loss did not improve from 1.57226
Epoch 75/100
83/83 [==============================] - 40s 486ms/step - loss: 1.5793 - accuracy: 0.3493 - val_loss: 1.5735 - val_accuracy: 0.3551

Epoch 00075: val_loss did not improve from 1.57226
Epoch 76/100
83/83 [==============================] - 38s 457ms/step - loss: 1.5788 - accuracy: 0.3475 - val_loss: 1.5724 - val_accuracy: 0.3556

Epoch 00076: val_loss did not improve from 1.57226
Epoch 77/100
83/83 [==============================] - 47s 559ms/step - loss: 1.5785 - accuracy: 0.3504 - val_loss: 1.5730 - val_accuracy: 0.3539

Epoch 00077: val_loss did not improve from 1.57226
Epoch 78/100
83/83 [==============================] - 38s 454ms/step - loss: 1.5784 - accuracy: 0.3498 - val_loss: 1.5719 - val_accuracy: 0.3537

Epoch 00078: val_loss improved from 1.57226 to 1.57188, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 79/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5774 - accuracy: 0.3507 - val_loss: 1.5729 - val_accuracy: 0.3546

Epoch 00079: val_loss did not improve from 1.57188
Epoch 80/100
83/83 [==============================] - 39s 466ms/step - loss: 1.5776 - accuracy: 0.3491 - val_loss: 1.5721 - val_accuracy: 0.3546

Epoch 00080: val_loss did not improve from 1.57188
Epoch 81/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5778 - accuracy: 0.3490 - val_loss: 1.5716 - val_accuracy: 0.3553

Epoch 00081: val_loss improved from 1.57188 to 1.57162, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 82/100
83/83 [==============================] - 46s 556ms/step - loss: 1.5780 - accuracy: 0.3491 - val_loss: 1.5726 - val_accuracy: 0.3531

Epoch 00082: val_loss did not improve from 1.57162
Epoch 83/100
83/83 [==============================] - 37s 448ms/step - loss: 1.5768 - accuracy: 0.3490 - val_loss: 1.5712 - val_accuracy: 0.3540

Epoch 00083: val_loss improved from 1.57162 to 1.57124, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 84/100
83/83 [==============================] - 46s 559ms/step - loss: 1.5763 - accuracy: 0.3506 - val_loss: 1.5717 - val_accuracy: 0.3553

Epoch 00084: val_loss did not improve from 1.57124
Epoch 85/100
83/83 [==============================] - 38s 450ms/step - loss: 1.5759 - accuracy: 0.3510 - val_loss: 1.5711 - val_accuracy: 0.3545

Epoch 00085: val_loss improved from 1.57124 to 1.57113, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/0
Epoch 86/100
83/83 [==============================] - 46s 555ms/step - loss: 1.5766 - accuracy: 0.3510 - val_loss: 1.5716 - val_accuracy: 0.3543

Epoch 00086: val_loss did not improve from 1.57113
Epoch 87/100
83/83 [==============================] - 46s 556ms/step - loss: 1.5762 - accuracy: 0.3504 - val_loss: 1.5721 - val_accuracy: 0.3537

Epoch 00087: val_loss did not improve from 1.57113
Epoch 88/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5757 - accuracy: 0.3511 - val_loss: 1.5721 - val_accuracy: 0.3534

Epoch 00088: val_loss did not improve from 1.57113
Epoch 89/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5764 - accuracy: 0.3494 - val_loss: 1.5720 - val_accuracy: 0.3545

Epoch 00089: val_loss did not improve from 1.57113
Epoch 90/100
83/83 [==============================] - 46s 553ms/step - loss: 1.5758 - accuracy: 0.3530 - val_loss: 1.5724 - val_accuracy: 0.3545

Epoch 00090: val_loss did not improve from 1.57113
Epoch 91/100
83/83 [==============================] - 46s 559ms/step - loss: 1.5760 - accuracy: 0.3503 - val_loss: 1.5722 - val_accuracy: 0.3526

Epoch 00091: val_loss did not improve from 1.57113
Epoch 92/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5772 - accuracy: 0.3499 - val_loss: 1.5719 - val_accuracy: 0.3545

Epoch 00092: val_loss did not improve from 1.57113
Epoch 93/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5750 - accuracy: 0.3506 - val_loss: 1.5718 - val_accuracy: 0.3544

Epoch 00093: val_loss did not improve from 1.57113
Epoch 00093: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_4jet"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  12294     [0m
[92m=================================================================[0m
[92mTotal params: 48,523,942[0m
[92mTrainable params: 48,523,926[0m
[92mNon-trainable params: 16[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwCpA07pAAAAAOkCAAAAqQCpAdoBeHIEAAAAcgQAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+0wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_2 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pAgAAAOkEAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+5QEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER3       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_5 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBAAAAOkGAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+9wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER4       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBgAAAOkIAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+CQIAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER5       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 147s 11ms/step - loss: 1.5750 - accuracy: 0.3497
Testing Loss = 1.574958, Testing Accuracy = 0.349658
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 42s 488ms/step - loss: 40.6159 - accuracy: 0.2997 - val_loss: 25.5350 - val_accuracy: 0.2501

Epoch 00001: val_loss improved from inf to 25.53499, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 2/100
83/83 [==============================] - 40s 481ms/step - loss: 18.8227 - accuracy: 0.3205 - val_loss: 14.1645 - val_accuracy: 0.2971

Epoch 00002: val_loss improved from 25.53499 to 14.16450, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 3/100
83/83 [==============================] - 41s 494ms/step - loss: 11.6501 - accuracy: 0.3283 - val_loss: 9.6975 - val_accuracy: 0.3286

Epoch 00003: val_loss improved from 14.16450 to 9.69754, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 4/100
83/83 [==============================] - 41s 495ms/step - loss: 8.3323 - accuracy: 0.3311 - val_loss: 7.1502 - val_accuracy: 0.3433

Epoch 00004: val_loss improved from 9.69754 to 7.15021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 5/100
83/83 [==============================] - 42s 502ms/step - loss: 6.2517 - accuracy: 0.3347 - val_loss: 5.4265 - val_accuracy: 0.3480

Epoch 00005: val_loss improved from 7.15021 to 5.42649, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 6/100
83/83 [==============================] - 43s 519ms/step - loss: 4.8078 - accuracy: 0.3350 - val_loss: 4.2145 - val_accuracy: 0.3498

Epoch 00006: val_loss improved from 5.42649 to 4.21446, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 7/100
83/83 [==============================] - 43s 514ms/step - loss: 3.7907 - accuracy: 0.3347 - val_loss: 3.3675 - val_accuracy: 0.3510

Epoch 00007: val_loss improved from 4.21446 to 3.36747, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 8/100
83/83 [==============================] - 43s 522ms/step - loss: 3.0793 - accuracy: 0.3354 - val_loss: 2.7797 - val_accuracy: 0.3506

Epoch 00008: val_loss improved from 3.36747 to 2.77970, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 9/100
83/83 [==============================] - 44s 534ms/step - loss: 2.5892 - accuracy: 0.3357 - val_loss: 2.3771 - val_accuracy: 0.3510

Epoch 00009: val_loss improved from 2.77970 to 2.37705, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 10/100
83/83 [==============================] - 44s 530ms/step - loss: 2.2527 - accuracy: 0.3369 - val_loss: 2.1051 - val_accuracy: 0.3527

Epoch 00010: val_loss improved from 2.37705 to 2.10507, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 11/100
83/83 [==============================] - 45s 546ms/step - loss: 2.0276 - accuracy: 0.3373 - val_loss: 1.9241 - val_accuracy: 0.3529

Epoch 00011: val_loss improved from 2.10507 to 1.92412, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 12/100
83/83 [==============================] - 45s 539ms/step - loss: 1.8795 - accuracy: 0.3383 - val_loss: 1.8047 - val_accuracy: 0.3525

Epoch 00012: val_loss improved from 1.92412 to 1.80469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 13/100
83/83 [==============================] - 45s 545ms/step - loss: 1.7817 - accuracy: 0.3378 - val_loss: 1.7271 - val_accuracy: 0.3542

Epoch 00013: val_loss improved from 1.80469 to 1.72712, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 14/100
83/83 [==============================] - 45s 545ms/step - loss: 1.7190 - accuracy: 0.3369 - val_loss: 1.6785 - val_accuracy: 0.3528

Epoch 00014: val_loss improved from 1.72712 to 1.67851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 15/100
83/83 [==============================] - 45s 546ms/step - loss: 1.6778 - accuracy: 0.3396 - val_loss: 1.6451 - val_accuracy: 0.3545

Epoch 00015: val_loss improved from 1.67851 to 1.64514, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 16/100
83/83 [==============================] - 44s 534ms/step - loss: 1.6521 - accuracy: 0.3403 - val_loss: 1.6261 - val_accuracy: 0.3543

Epoch 00016: val_loss improved from 1.64514 to 1.62606, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 17/100
83/83 [==============================] - 44s 523ms/step - loss: 1.6355 - accuracy: 0.3374 - val_loss: 1.6131 - val_accuracy: 0.3532

Epoch 00017: val_loss improved from 1.62606 to 1.61306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 18/100
83/83 [==============================] - 43s 522ms/step - loss: 1.6239 - accuracy: 0.3409 - val_loss: 1.6044 - val_accuracy: 0.3535

Epoch 00018: val_loss improved from 1.61306 to 1.60440, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 19/100
83/83 [==============================] - 42s 505ms/step - loss: 1.6164 - accuracy: 0.3427 - val_loss: 1.5985 - val_accuracy: 0.3544

Epoch 00019: val_loss improved from 1.60440 to 1.59852, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 20/100
83/83 [==============================] - 41s 492ms/step - loss: 1.6122 - accuracy: 0.3396 - val_loss: 1.5938 - val_accuracy: 0.3550

Epoch 00020: val_loss improved from 1.59852 to 1.59382, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 21/100
83/83 [==============================] - 40s 484ms/step - loss: 1.6086 - accuracy: 0.3406 - val_loss: 1.5909 - val_accuracy: 0.3529

Epoch 00021: val_loss improved from 1.59382 to 1.59085, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 22/100
83/83 [==============================] - 39s 470ms/step - loss: 1.6058 - accuracy: 0.3414 - val_loss: 1.5888 - val_accuracy: 0.3518

Epoch 00022: val_loss improved from 1.59085 to 1.58879, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 23/100
83/83 [==============================] - 40s 479ms/step - loss: 1.6025 - accuracy: 0.3426 - val_loss: 1.5873 - val_accuracy: 0.3529

Epoch 00023: val_loss improved from 1.58879 to 1.58729, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 24/100
83/83 [==============================] - 40s 476ms/step - loss: 1.6010 - accuracy: 0.3401 - val_loss: 1.5859 - val_accuracy: 0.3530

Epoch 00024: val_loss improved from 1.58729 to 1.58589, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 25/100
83/83 [==============================] - 39s 467ms/step - loss: 1.5985 - accuracy: 0.3435 - val_loss: 1.5842 - val_accuracy: 0.3523

Epoch 00025: val_loss improved from 1.58589 to 1.58424, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 26/100
83/83 [==============================] - 38s 457ms/step - loss: 1.5983 - accuracy: 0.3404 - val_loss: 1.5842 - val_accuracy: 0.3524

Epoch 00026: val_loss improved from 1.58424 to 1.58418, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 27/100
83/83 [==============================] - 38s 456ms/step - loss: 1.5970 - accuracy: 0.3430 - val_loss: 1.5832 - val_accuracy: 0.3543

Epoch 00027: val_loss improved from 1.58418 to 1.58320, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 28/100
83/83 [==============================] - 38s 450ms/step - loss: 1.5965 - accuracy: 0.3415 - val_loss: 1.5829 - val_accuracy: 0.3518

Epoch 00028: val_loss improved from 1.58320 to 1.58292, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 29/100
83/83 [==============================] - 38s 459ms/step - loss: 1.5950 - accuracy: 0.3420 - val_loss: 1.5820 - val_accuracy: 0.3535

Epoch 00029: val_loss improved from 1.58292 to 1.58200, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 30/100
83/83 [==============================] - 37s 439ms/step - loss: 1.5949 - accuracy: 0.3439 - val_loss: 1.5811 - val_accuracy: 0.3523

Epoch 00030: val_loss improved from 1.58200 to 1.58106, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 31/100
83/83 [==============================] - 37s 449ms/step - loss: 1.5930 - accuracy: 0.3418 - val_loss: 1.5811 - val_accuracy: 0.3519

Epoch 00031: val_loss did not improve from 1.58106
Epoch 32/100
83/83 [==============================] - 44s 526ms/step - loss: 1.5931 - accuracy: 0.3412 - val_loss: 1.5806 - val_accuracy: 0.3533

Epoch 00032: val_loss improved from 1.58106 to 1.58057, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 33/100
83/83 [==============================] - 43s 515ms/step - loss: 1.5919 - accuracy: 0.3430 - val_loss: 1.5795 - val_accuracy: 0.3511

Epoch 00033: val_loss improved from 1.58057 to 1.57948, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 34/100
83/83 [==============================] - 43s 510ms/step - loss: 1.5925 - accuracy: 0.3414 - val_loss: 1.5790 - val_accuracy: 0.3535

Epoch 00034: val_loss improved from 1.57948 to 1.57903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 35/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5905 - accuracy: 0.3422 - val_loss: 1.5789 - val_accuracy: 0.3535

Epoch 00035: val_loss improved from 1.57903 to 1.57886, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 36/100
83/83 [==============================] - 38s 458ms/step - loss: 1.5897 - accuracy: 0.3442 - val_loss: 1.5776 - val_accuracy: 0.3535

Epoch 00036: val_loss improved from 1.57886 to 1.57764, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 37/100
83/83 [==============================] - 37s 440ms/step - loss: 1.5896 - accuracy: 0.3461 - val_loss: 1.5782 - val_accuracy: 0.3531

Epoch 00037: val_loss did not improve from 1.57764
Epoch 38/100
83/83 [==============================] - 47s 561ms/step - loss: 1.5893 - accuracy: 0.3421 - val_loss: 1.5770 - val_accuracy: 0.3529

Epoch 00038: val_loss improved from 1.57764 to 1.57704, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 39/100
83/83 [==============================] - 37s 446ms/step - loss: 1.5896 - accuracy: 0.3435 - val_loss: 1.5774 - val_accuracy: 0.3527

Epoch 00039: val_loss did not improve from 1.57704
Epoch 40/100
83/83 [==============================] - 38s 450ms/step - loss: 1.5887 - accuracy: 0.3437 - val_loss: 1.5780 - val_accuracy: 0.3526

Epoch 00040: val_loss did not improve from 1.57704
Epoch 41/100
83/83 [==============================] - 45s 541ms/step - loss: 1.5879 - accuracy: 0.3444 - val_loss: 1.5767 - val_accuracy: 0.3525

Epoch 00041: val_loss improved from 1.57704 to 1.57668, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 42/100
83/83 [==============================] - 47s 561ms/step - loss: 1.5870 - accuracy: 0.3447 - val_loss: 1.5772 - val_accuracy: 0.3532

Epoch 00042: val_loss did not improve from 1.57668
Epoch 43/100
83/83 [==============================] - 42s 508ms/step - loss: 1.5868 - accuracy: 0.3460 - val_loss: 1.5769 - val_accuracy: 0.3525

Epoch 00043: val_loss did not improve from 1.57668
Epoch 44/100
83/83 [==============================] - 42s 511ms/step - loss: 1.5864 - accuracy: 0.3444 - val_loss: 1.5758 - val_accuracy: 0.3536

Epoch 00044: val_loss improved from 1.57668 to 1.57582, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 45/100
83/83 [==============================] - 40s 474ms/step - loss: 1.5855 - accuracy: 0.3459 - val_loss: 1.5761 - val_accuracy: 0.3509

Epoch 00045: val_loss did not improve from 1.57582
Epoch 46/100
83/83 [==============================] - 45s 547ms/step - loss: 1.5858 - accuracy: 0.3457 - val_loss: 1.5753 - val_accuracy: 0.3529

Epoch 00046: val_loss improved from 1.57582 to 1.57526, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 47/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5865 - accuracy: 0.3442 - val_loss: 1.5753 - val_accuracy: 0.3534

Epoch 00047: val_loss did not improve from 1.57526
Epoch 48/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5837 - accuracy: 0.3449 - val_loss: 1.5744 - val_accuracy: 0.3533

Epoch 00048: val_loss improved from 1.57526 to 1.57435, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 49/100
83/83 [==============================] - 47s 559ms/step - loss: 1.5845 - accuracy: 0.3448 - val_loss: 1.5754 - val_accuracy: 0.3531

Epoch 00049: val_loss did not improve from 1.57435
Epoch 50/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5844 - accuracy: 0.3449 - val_loss: 1.5748 - val_accuracy: 0.3546

Epoch 00050: val_loss did not improve from 1.57435
Epoch 51/100
83/83 [==============================] - 46s 559ms/step - loss: 1.5842 - accuracy: 0.3451 - val_loss: 1.5751 - val_accuracy: 0.3532

Epoch 00051: val_loss did not improve from 1.57435
Epoch 52/100
83/83 [==============================] - 47s 560ms/step - loss: 1.5832 - accuracy: 0.3448 - val_loss: 1.5753 - val_accuracy: 0.3541

Epoch 00052: val_loss did not improve from 1.57435
Epoch 53/100
83/83 [==============================] - 47s 559ms/step - loss: 1.5838 - accuracy: 0.3461 - val_loss: 1.5738 - val_accuracy: 0.3536

Epoch 00053: val_loss improved from 1.57435 to 1.57376, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 54/100
83/83 [==============================] - 35s 422ms/step - loss: 1.5833 - accuracy: 0.3465 - val_loss: 1.5750 - val_accuracy: 0.3523

Epoch 00054: val_loss did not improve from 1.57376
Epoch 55/100
83/83 [==============================] - 32s 390ms/step - loss: 1.5819 - accuracy: 0.3461 - val_loss: 1.5743 - val_accuracy: 0.3530

Epoch 00055: val_loss did not improve from 1.57376
Epoch 56/100
83/83 [==============================] - 32s 390ms/step - loss: 1.5834 - accuracy: 0.3456 - val_loss: 1.5742 - val_accuracy: 0.3526

Epoch 00056: val_loss did not improve from 1.57376
Epoch 57/100
83/83 [==============================] - 33s 391ms/step - loss: 1.5830 - accuracy: 0.3459 - val_loss: 1.5737 - val_accuracy: 0.3536

Epoch 00057: val_loss improved from 1.57376 to 1.57373, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 58/100
83/83 [==============================] - 32s 385ms/step - loss: 1.5820 - accuracy: 0.3474 - val_loss: 1.5742 - val_accuracy: 0.3520

Epoch 00058: val_loss did not improve from 1.57373
Epoch 59/100
83/83 [==============================] - 32s 381ms/step - loss: 1.5824 - accuracy: 0.3467 - val_loss: 1.5736 - val_accuracy: 0.3536

Epoch 00059: val_loss improved from 1.57373 to 1.57357, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 60/100
83/83 [==============================] - 32s 383ms/step - loss: 1.5815 - accuracy: 0.3465 - val_loss: 1.5735 - val_accuracy: 0.3526

Epoch 00060: val_loss improved from 1.57357 to 1.57349, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 61/100
83/83 [==============================] - 31s 376ms/step - loss: 1.5821 - accuracy: 0.3479 - val_loss: 1.5743 - val_accuracy: 0.3518

Epoch 00061: val_loss did not improve from 1.57349
Epoch 62/100
83/83 [==============================] - 45s 547ms/step - loss: 1.5822 - accuracy: 0.3464 - val_loss: 1.5727 - val_accuracy: 0.3527

Epoch 00062: val_loss improved from 1.57349 to 1.57265, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 63/100
83/83 [==============================] - 45s 544ms/step - loss: 1.5815 - accuracy: 0.3473 - val_loss: 1.5739 - val_accuracy: 0.3532

Epoch 00063: val_loss did not improve from 1.57265
Epoch 64/100
83/83 [==============================] - 39s 475ms/step - loss: 1.5803 - accuracy: 0.3469 - val_loss: 1.5740 - val_accuracy: 0.3535

Epoch 00064: val_loss did not improve from 1.57265
Epoch 65/100
83/83 [==============================] - 38s 457ms/step - loss: 1.5802 - accuracy: 0.3477 - val_loss: 1.5735 - val_accuracy: 0.3527

Epoch 00065: val_loss did not improve from 1.57265
Epoch 66/100
83/83 [==============================] - 38s 454ms/step - loss: 1.5810 - accuracy: 0.3475 - val_loss: 1.5741 - val_accuracy: 0.3546

Epoch 00066: val_loss did not improve from 1.57265
Epoch 67/100
83/83 [==============================] - 44s 530ms/step - loss: 1.5801 - accuracy: 0.3473 - val_loss: 1.5727 - val_accuracy: 0.3524

Epoch 00067: val_loss did not improve from 1.57265
Epoch 68/100
83/83 [==============================] - 42s 503ms/step - loss: 1.5797 - accuracy: 0.3494 - val_loss: 1.5729 - val_accuracy: 0.3528

Epoch 00068: val_loss did not improve from 1.57265
Epoch 69/100
83/83 [==============================] - 38s 454ms/step - loss: 1.5802 - accuracy: 0.3482 - val_loss: 1.5724 - val_accuracy: 0.3537

Epoch 00069: val_loss improved from 1.57265 to 1.57238, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 70/100
83/83 [==============================] - 39s 464ms/step - loss: 1.5796 - accuracy: 0.3480 - val_loss: 1.5717 - val_accuracy: 0.3547

Epoch 00070: val_loss improved from 1.57238 to 1.57167, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/1
Epoch 71/100
83/83 [==============================] - 38s 450ms/step - loss: 1.5793 - accuracy: 0.3487 - val_loss: 1.5724 - val_accuracy: 0.3525

Epoch 00071: val_loss did not improve from 1.57167
Epoch 72/100
83/83 [==============================] - 38s 454ms/step - loss: 1.5793 - accuracy: 0.3489 - val_loss: 1.5719 - val_accuracy: 0.3523

Epoch 00072: val_loss did not improve from 1.57167
Epoch 73/100
83/83 [==============================] - 40s 475ms/step - loss: 1.5791 - accuracy: 0.3478 - val_loss: 1.5722 - val_accuracy: 0.3521

Epoch 00073: val_loss did not improve from 1.57167
Epoch 74/100
83/83 [==============================] - 45s 546ms/step - loss: 1.5785 - accuracy: 0.3480 - val_loss: 1.5724 - val_accuracy: 0.3530

Epoch 00074: val_loss did not improve from 1.57167
Epoch 75/100
83/83 [==============================] - 40s 477ms/step - loss: 1.5783 - accuracy: 0.3490 - val_loss: 1.5720 - val_accuracy: 0.3532

Epoch 00075: val_loss did not improve from 1.57167
Epoch 76/100
83/83 [==============================] - 38s 455ms/step - loss: 1.5789 - accuracy: 0.3488 - val_loss: 1.5730 - val_accuracy: 0.3529

Epoch 00076: val_loss did not improve from 1.57167
Epoch 77/100
83/83 [==============================] - 38s 457ms/step - loss: 1.5786 - accuracy: 0.3497 - val_loss: 1.5726 - val_accuracy: 0.3526

Epoch 00077: val_loss did not improve from 1.57167
Epoch 78/100
83/83 [==============================] - 44s 529ms/step - loss: 1.5774 - accuracy: 0.3501 - val_loss: 1.5720 - val_accuracy: 0.3532

Epoch 00078: val_loss did not improve from 1.57167
Epoch 79/100
83/83 [==============================] - 42s 505ms/step - loss: 1.5776 - accuracy: 0.3486 - val_loss: 1.5727 - val_accuracy: 0.3538

Epoch 00079: val_loss did not improve from 1.57167
Epoch 80/100
83/83 [==============================] - 38s 451ms/step - loss: 1.5768 - accuracy: 0.3516 - val_loss: 1.5726 - val_accuracy: 0.3521

Epoch 00080: val_loss did not improve from 1.57167
Epoch 00080: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_4jet"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  12294     [0m
[92m=================================================================[0m
[92mTotal params: 48,523,942[0m
[92mTrainable params: 48,523,926[0m
[92mNon-trainable params: 16[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwCpA07pAAAAAOkCAAAAqQCpAdoBeHIEAAAAcgQAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+0wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_11 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pAgAAAOkEAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+5QEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER3       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_14 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBAAAAOkGAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+9wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER4       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBgAAAOkIAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+CQIAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER5       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 147s 11ms/step - loss: 1.5757 - accuracy: 0.3514
Testing Loss = 1.575731, Testing Accuracy = 0.351369
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 43s 479ms/step - loss: 40.6290 - accuracy: 0.3000 - val_loss: 25.5388 - val_accuracy: 0.2573

Epoch 00001: val_loss improved from inf to 25.53878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 2/100
83/83 [==============================] - 39s 463ms/step - loss: 18.8244 - accuracy: 0.3220 - val_loss: 14.1608 - val_accuracy: 0.2914

Epoch 00002: val_loss improved from 25.53878 to 14.16080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 3/100
83/83 [==============================] - 38s 455ms/step - loss: 11.6494 - accuracy: 0.3269 - val_loss: 9.6952 - val_accuracy: 0.3287

Epoch 00003: val_loss improved from 14.16080 to 9.69523, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 4/100
83/83 [==============================] - 39s 463ms/step - loss: 8.3337 - accuracy: 0.3275 - val_loss: 7.1533 - val_accuracy: 0.3463

Epoch 00004: val_loss improved from 9.69523 to 7.15333, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 5/100
83/83 [==============================] - 47s 559ms/step - loss: 6.2557 - accuracy: 0.3323 - val_loss: 5.4272 - val_accuracy: 0.3509

Epoch 00005: val_loss improved from 7.15333 to 5.42719, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 6/100
83/83 [==============================] - 38s 452ms/step - loss: 4.8099 - accuracy: 0.3357 - val_loss: 4.2189 - val_accuracy: 0.3521

Epoch 00006: val_loss improved from 5.42719 to 4.21893, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 7/100
83/83 [==============================] - 46s 552ms/step - loss: 3.7933 - accuracy: 0.3329 - val_loss: 3.3710 - val_accuracy: 0.3499

Epoch 00007: val_loss improved from 4.21893 to 3.37096, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 8/100
83/83 [==============================] - 45s 545ms/step - loss: 3.0816 - accuracy: 0.3377 - val_loss: 2.7826 - val_accuracy: 0.3508

Epoch 00008: val_loss improved from 3.37096 to 2.78257, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 9/100
83/83 [==============================] - 47s 559ms/step - loss: 2.5891 - accuracy: 0.3388 - val_loss: 2.3791 - val_accuracy: 0.3524

Epoch 00009: val_loss improved from 2.78257 to 2.37912, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 10/100
83/83 [==============================] - 37s 446ms/step - loss: 2.2561 - accuracy: 0.3372 - val_loss: 2.1078 - val_accuracy: 0.3506

Epoch 00010: val_loss improved from 2.37912 to 2.10780, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 11/100
83/83 [==============================] - 47s 560ms/step - loss: 2.0290 - accuracy: 0.3388 - val_loss: 1.9256 - val_accuracy: 0.3532

Epoch 00011: val_loss improved from 2.10780 to 1.92560, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 12/100
83/83 [==============================] - 38s 458ms/step - loss: 1.8804 - accuracy: 0.3401 - val_loss: 1.8076 - val_accuracy: 0.3516

Epoch 00012: val_loss improved from 1.92560 to 1.80758, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 13/100
83/83 [==============================] - 43s 521ms/step - loss: 1.7824 - accuracy: 0.3398 - val_loss: 1.7292 - val_accuracy: 0.3499

Epoch 00013: val_loss improved from 1.80758 to 1.72923, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 14/100
83/83 [==============================] - 47s 560ms/step - loss: 1.7189 - accuracy: 0.3400 - val_loss: 1.6793 - val_accuracy: 0.3515

Epoch 00014: val_loss improved from 1.72923 to 1.67929, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 15/100
83/83 [==============================] - 47s 561ms/step - loss: 1.6790 - accuracy: 0.3403 - val_loss: 1.6476 - val_accuracy: 0.3524

Epoch 00015: val_loss improved from 1.67929 to 1.64764, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 16/100
83/83 [==============================] - 39s 472ms/step - loss: 1.6519 - accuracy: 0.3403 - val_loss: 1.6269 - val_accuracy: 0.3503

Epoch 00016: val_loss improved from 1.64764 to 1.62691, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 17/100
83/83 [==============================] - 39s 475ms/step - loss: 1.6348 - accuracy: 0.3416 - val_loss: 1.6133 - val_accuracy: 0.3532

Epoch 00017: val_loss improved from 1.62691 to 1.61327, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 18/100
83/83 [==============================] - 47s 560ms/step - loss: 1.6248 - accuracy: 0.3413 - val_loss: 1.6047 - val_accuracy: 0.3519

Epoch 00018: val_loss improved from 1.61327 to 1.60469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 19/100
83/83 [==============================] - 47s 559ms/step - loss: 1.6172 - accuracy: 0.3397 - val_loss: 1.5984 - val_accuracy: 0.3537

Epoch 00019: val_loss improved from 1.60469 to 1.59844, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 20/100
83/83 [==============================] - 47s 562ms/step - loss: 1.6122 - accuracy: 0.3382 - val_loss: 1.5952 - val_accuracy: 0.3515

Epoch 00020: val_loss improved from 1.59844 to 1.59521, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 21/100
83/83 [==============================] - 39s 463ms/step - loss: 1.6087 - accuracy: 0.3427 - val_loss: 1.5926 - val_accuracy: 0.3511

Epoch 00021: val_loss improved from 1.59521 to 1.59255, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 22/100
83/83 [==============================] - 47s 561ms/step - loss: 1.6053 - accuracy: 0.3423 - val_loss: 1.5892 - val_accuracy: 0.3547

Epoch 00022: val_loss improved from 1.59255 to 1.58922, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 23/100
83/83 [==============================] - 47s 561ms/step - loss: 1.6026 - accuracy: 0.3411 - val_loss: 1.5873 - val_accuracy: 0.3545

Epoch 00023: val_loss improved from 1.58922 to 1.58727, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 24/100
83/83 [==============================] - 36s 435ms/step - loss: 1.6015 - accuracy: 0.3423 - val_loss: 1.5862 - val_accuracy: 0.3538

Epoch 00024: val_loss improved from 1.58727 to 1.58622, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 25/100
83/83 [==============================] - 33s 392ms/step - loss: 1.5999 - accuracy: 0.3422 - val_loss: 1.5859 - val_accuracy: 0.3529

Epoch 00025: val_loss improved from 1.58622 to 1.58594, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 26/100
83/83 [==============================] - 33s 392ms/step - loss: 1.5985 - accuracy: 0.3429 - val_loss: 1.5842 - val_accuracy: 0.3522

Epoch 00026: val_loss improved from 1.58594 to 1.58422, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 27/100
83/83 [==============================] - 32s 389ms/step - loss: 1.5968 - accuracy: 0.3416 - val_loss: 1.5837 - val_accuracy: 0.3523

Epoch 00027: val_loss improved from 1.58422 to 1.58365, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 28/100
83/83 [==============================] - 31s 375ms/step - loss: 1.5961 - accuracy: 0.3437 - val_loss: 1.5824 - val_accuracy: 0.3538

Epoch 00028: val_loss improved from 1.58365 to 1.58237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 29/100
83/83 [==============================] - 32s 380ms/step - loss: 1.5943 - accuracy: 0.3416 - val_loss: 1.5818 - val_accuracy: 0.3527

Epoch 00029: val_loss improved from 1.58237 to 1.58184, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 30/100
83/83 [==============================] - 32s 380ms/step - loss: 1.5951 - accuracy: 0.3417 - val_loss: 1.5801 - val_accuracy: 0.3546

Epoch 00030: val_loss improved from 1.58184 to 1.58005, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 31/100
83/83 [==============================] - 42s 501ms/step - loss: 1.5937 - accuracy: 0.3444 - val_loss: 1.5808 - val_accuracy: 0.3529

Epoch 00031: val_loss did not improve from 1.58005
Epoch 32/100
83/83 [==============================] - 43s 518ms/step - loss: 1.5924 - accuracy: 0.3432 - val_loss: 1.5811 - val_accuracy: 0.3540

Epoch 00032: val_loss did not improve from 1.58005
Epoch 33/100
83/83 [==============================] - 38s 460ms/step - loss: 1.5917 - accuracy: 0.3457 - val_loss: 1.5794 - val_accuracy: 0.3543

Epoch 00033: val_loss improved from 1.58005 to 1.57940, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 34/100
83/83 [==============================] - 37s 444ms/step - loss: 1.5908 - accuracy: 0.3432 - val_loss: 1.5784 - val_accuracy: 0.3538

Epoch 00034: val_loss improved from 1.57940 to 1.57840, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 35/100
83/83 [==============================] - 39s 466ms/step - loss: 1.5902 - accuracy: 0.3424 - val_loss: 1.5784 - val_accuracy: 0.3523

Epoch 00035: val_loss did not improve from 1.57840
Epoch 36/100
83/83 [==============================] - 37s 448ms/step - loss: 1.5902 - accuracy: 0.3425 - val_loss: 1.5779 - val_accuracy: 0.3553

Epoch 00036: val_loss improved from 1.57840 to 1.57794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 37/100
83/83 [==============================] - 38s 453ms/step - loss: 1.5898 - accuracy: 0.3431 - val_loss: 1.5780 - val_accuracy: 0.3552

Epoch 00037: val_loss did not improve from 1.57794
Epoch 38/100
83/83 [==============================] - 39s 471ms/step - loss: 1.5889 - accuracy: 0.3446 - val_loss: 1.5774 - val_accuracy: 0.3568

Epoch 00038: val_loss improved from 1.57794 to 1.57738, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 39/100
83/83 [==============================] - 38s 457ms/step - loss: 1.5894 - accuracy: 0.3432 - val_loss: 1.5767 - val_accuracy: 0.3542

Epoch 00039: val_loss improved from 1.57738 to 1.57671, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 40/100
83/83 [==============================] - 40s 477ms/step - loss: 1.5882 - accuracy: 0.3442 - val_loss: 1.5768 - val_accuracy: 0.3556

Epoch 00040: val_loss did not improve from 1.57671
Epoch 41/100
83/83 [==============================] - 44s 536ms/step - loss: 1.5874 - accuracy: 0.3456 - val_loss: 1.5768 - val_accuracy: 0.3544

Epoch 00041: val_loss did not improve from 1.57671
Epoch 42/100
83/83 [==============================] - 37s 444ms/step - loss: 1.5863 - accuracy: 0.3468 - val_loss: 1.5771 - val_accuracy: 0.3539

Epoch 00042: val_loss did not improve from 1.57671
Epoch 43/100
83/83 [==============================] - 38s 461ms/step - loss: 1.5871 - accuracy: 0.3442 - val_loss: 1.5771 - val_accuracy: 0.3550

Epoch 00043: val_loss did not improve from 1.57671
Epoch 44/100
83/83 [==============================] - 40s 474ms/step - loss: 1.5866 - accuracy: 0.3447 - val_loss: 1.5759 - val_accuracy: 0.3547

Epoch 00044: val_loss improved from 1.57671 to 1.57595, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 45/100
83/83 [==============================] - 39s 468ms/step - loss: 1.5864 - accuracy: 0.3442 - val_loss: 1.5762 - val_accuracy: 0.3528

Epoch 00045: val_loss did not improve from 1.57595
Epoch 46/100
83/83 [==============================] - 45s 544ms/step - loss: 1.5858 - accuracy: 0.3470 - val_loss: 1.5754 - val_accuracy: 0.3548

Epoch 00046: val_loss improved from 1.57595 to 1.57542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 47/100
83/83 [==============================] - 45s 544ms/step - loss: 1.5853 - accuracy: 0.3454 - val_loss: 1.5749 - val_accuracy: 0.3543

Epoch 00047: val_loss improved from 1.57542 to 1.57486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 48/100
83/83 [==============================] - 45s 543ms/step - loss: 1.5843 - accuracy: 0.3456 - val_loss: 1.5744 - val_accuracy: 0.3557

Epoch 00048: val_loss improved from 1.57486 to 1.57439, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 49/100
83/83 [==============================] - 45s 544ms/step - loss: 1.5854 - accuracy: 0.3448 - val_loss: 1.5744 - val_accuracy: 0.3550

Epoch 00049: val_loss did not improve from 1.57439
Epoch 50/100
83/83 [==============================] - 38s 462ms/step - loss: 1.5840 - accuracy: 0.3460 - val_loss: 1.5753 - val_accuracy: 0.3566

Epoch 00050: val_loss did not improve from 1.57439
Epoch 51/100
83/83 [==============================] - 37s 440ms/step - loss: 1.5843 - accuracy: 0.3464 - val_loss: 1.5750 - val_accuracy: 0.3533

Epoch 00051: val_loss did not improve from 1.57439
Epoch 52/100
83/83 [==============================] - 39s 473ms/step - loss: 1.5838 - accuracy: 0.3452 - val_loss: 1.5746 - val_accuracy: 0.3564

Epoch 00052: val_loss did not improve from 1.57439
Epoch 53/100
83/83 [==============================] - 45s 546ms/step - loss: 1.5833 - accuracy: 0.3480 - val_loss: 1.5743 - val_accuracy: 0.3559

Epoch 00053: val_loss improved from 1.57439 to 1.57433, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 54/100
83/83 [==============================] - 45s 544ms/step - loss: 1.5830 - accuracy: 0.3470 - val_loss: 1.5741 - val_accuracy: 0.3539

Epoch 00054: val_loss improved from 1.57433 to 1.57409, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 55/100
83/83 [==============================] - 45s 544ms/step - loss: 1.5823 - accuracy: 0.3468 - val_loss: 1.5743 - val_accuracy: 0.3552

Epoch 00055: val_loss did not improve from 1.57409
Epoch 56/100
83/83 [==============================] - 39s 476ms/step - loss: 1.5817 - accuracy: 0.3475 - val_loss: 1.5737 - val_accuracy: 0.3542

Epoch 00056: val_loss improved from 1.57409 to 1.57368, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 57/100
83/83 [==============================] - 40s 481ms/step - loss: 1.5831 - accuracy: 0.3469 - val_loss: 1.5734 - val_accuracy: 0.3555

Epoch 00057: val_loss improved from 1.57368 to 1.57340, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 58/100
83/83 [==============================] - 41s 491ms/step - loss: 1.5825 - accuracy: 0.3455 - val_loss: 1.5741 - val_accuracy: 0.3526

Epoch 00058: val_loss did not improve from 1.57340
Epoch 59/100
83/83 [==============================] - 37s 446ms/step - loss: 1.5818 - accuracy: 0.3471 - val_loss: 1.5730 - val_accuracy: 0.3554

Epoch 00059: val_loss improved from 1.57340 to 1.57300, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 60/100
83/83 [==============================] - 37s 447ms/step - loss: 1.5818 - accuracy: 0.3472 - val_loss: 1.5738 - val_accuracy: 0.3539

Epoch 00060: val_loss did not improve from 1.57300
Epoch 61/100
83/83 [==============================] - 39s 462ms/step - loss: 1.5821 - accuracy: 0.3477 - val_loss: 1.5730 - val_accuracy: 0.3539

Epoch 00061: val_loss improved from 1.57300 to 1.57297, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 62/100
83/83 [==============================] - 37s 447ms/step - loss: 1.5818 - accuracy: 0.3484 - val_loss: 1.5731 - val_accuracy: 0.3537

Epoch 00062: val_loss did not improve from 1.57297
Epoch 63/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5806 - accuracy: 0.3481 - val_loss: 1.5722 - val_accuracy: 0.3538

Epoch 00063: val_loss improved from 1.57297 to 1.57220, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 64/100
83/83 [==============================] - 37s 447ms/step - loss: 1.5803 - accuracy: 0.3474 - val_loss: 1.5725 - val_accuracy: 0.3558

Epoch 00064: val_loss did not improve from 1.57220
Epoch 65/100
83/83 [==============================] - 43s 511ms/step - loss: 1.5816 - accuracy: 0.3483 - val_loss: 1.5729 - val_accuracy: 0.3554

Epoch 00065: val_loss did not improve from 1.57220
Epoch 66/100
83/83 [==============================] - 43s 515ms/step - loss: 1.5804 - accuracy: 0.3478 - val_loss: 1.5721 - val_accuracy: 0.3564

Epoch 00066: val_loss improved from 1.57220 to 1.57207, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 67/100
83/83 [==============================] - 43s 515ms/step - loss: 1.5808 - accuracy: 0.3479 - val_loss: 1.5723 - val_accuracy: 0.3550

Epoch 00067: val_loss did not improve from 1.57207
Epoch 68/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5801 - accuracy: 0.3489 - val_loss: 1.5719 - val_accuracy: 0.3546

Epoch 00068: val_loss improved from 1.57207 to 1.57186, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 69/100
83/83 [==============================] - 44s 533ms/step - loss: 1.5796 - accuracy: 0.3487 - val_loss: 1.5724 - val_accuracy: 0.3546

Epoch 00069: val_loss did not improve from 1.57186
Epoch 70/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5805 - accuracy: 0.3489 - val_loss: 1.5722 - val_accuracy: 0.3564

Epoch 00070: val_loss did not improve from 1.57186
Epoch 71/100
83/83 [==============================] - 44s 534ms/step - loss: 1.5802 - accuracy: 0.3492 - val_loss: 1.5715 - val_accuracy: 0.3547

Epoch 00071: val_loss improved from 1.57186 to 1.57154, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 72/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5796 - accuracy: 0.3501 - val_loss: 1.5719 - val_accuracy: 0.3550

Epoch 00072: val_loss did not improve from 1.57154
Epoch 73/100
83/83 [==============================] - 42s 499ms/step - loss: 1.5789 - accuracy: 0.3494 - val_loss: 1.5712 - val_accuracy: 0.3546

Epoch 00073: val_loss improved from 1.57154 to 1.57123, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 74/100
83/83 [==============================] - 42s 504ms/step - loss: 1.5783 - accuracy: 0.3494 - val_loss: 1.5714 - val_accuracy: 0.3546

Epoch 00074: val_loss did not improve from 1.57123
Epoch 75/100
83/83 [==============================] - 43s 516ms/step - loss: 1.5781 - accuracy: 0.3500 - val_loss: 1.5711 - val_accuracy: 0.3552

Epoch 00075: val_loss improved from 1.57123 to 1.57113, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 76/100
83/83 [==============================] - 40s 478ms/step - loss: 1.5783 - accuracy: 0.3504 - val_loss: 1.5713 - val_accuracy: 0.3558

Epoch 00076: val_loss did not improve from 1.57113
Epoch 77/100
83/83 [==============================] - 44s 535ms/step - loss: 1.5786 - accuracy: 0.3504 - val_loss: 1.5712 - val_accuracy: 0.3550

Epoch 00077: val_loss did not improve from 1.57113
Epoch 78/100
83/83 [==============================] - 39s 461ms/step - loss: 1.5781 - accuracy: 0.3494 - val_loss: 1.5718 - val_accuracy: 0.3533

Epoch 00078: val_loss did not improve from 1.57113
Epoch 79/100
83/83 [==============================] - 37s 447ms/step - loss: 1.5783 - accuracy: 0.3493 - val_loss: 1.5710 - val_accuracy: 0.3544

Epoch 00079: val_loss improved from 1.57113 to 1.57095, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 80/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5771 - accuracy: 0.3497 - val_loss: 1.5715 - val_accuracy: 0.3556

Epoch 00080: val_loss did not improve from 1.57095
Epoch 81/100
83/83 [==============================] - 47s 560ms/step - loss: 1.5776 - accuracy: 0.3492 - val_loss: 1.5709 - val_accuracy: 0.3555

Epoch 00081: val_loss improved from 1.57095 to 1.57091, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 82/100
83/83 [==============================] - 42s 499ms/step - loss: 1.5772 - accuracy: 0.3514 - val_loss: 1.5712 - val_accuracy: 0.3556

Epoch 00082: val_loss did not improve from 1.57091
Epoch 83/100
83/83 [==============================] - 44s 528ms/step - loss: 1.5760 - accuracy: 0.3512 - val_loss: 1.5705 - val_accuracy: 0.3545

Epoch 00083: val_loss improved from 1.57091 to 1.57052, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 84/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5759 - accuracy: 0.3515 - val_loss: 1.5708 - val_accuracy: 0.3556

Epoch 00084: val_loss did not improve from 1.57052
Epoch 85/100
83/83 [==============================] - 47s 560ms/step - loss: 1.5769 - accuracy: 0.3520 - val_loss: 1.5704 - val_accuracy: 0.3553

Epoch 00085: val_loss improved from 1.57052 to 1.57042, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 86/100
83/83 [==============================] - 47s 560ms/step - loss: 1.5764 - accuracy: 0.3509 - val_loss: 1.5705 - val_accuracy: 0.3552

Epoch 00086: val_loss did not improve from 1.57042
Epoch 87/100
83/83 [==============================] - 46s 557ms/step - loss: 1.5757 - accuracy: 0.3505 - val_loss: 1.5712 - val_accuracy: 0.3541

Epoch 00087: val_loss did not improve from 1.57042
Epoch 88/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5764 - accuracy: 0.3510 - val_loss: 1.5705 - val_accuracy: 0.3549

Epoch 00088: val_loss did not improve from 1.57042
Epoch 89/100
83/83 [==============================] - 44s 528ms/step - loss: 1.5755 - accuracy: 0.3511 - val_loss: 1.5696 - val_accuracy: 0.3543

Epoch 00089: val_loss improved from 1.57042 to 1.56961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/2
Epoch 90/100
83/83 [==============================] - 47s 559ms/step - loss: 1.5742 - accuracy: 0.3500 - val_loss: 1.5708 - val_accuracy: 0.3537

Epoch 00090: val_loss did not improve from 1.56961
Epoch 91/100
83/83 [==============================] - 47s 562ms/step - loss: 1.5760 - accuracy: 0.3520 - val_loss: 1.5703 - val_accuracy: 0.3557

Epoch 00091: val_loss did not improve from 1.56961
Epoch 92/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5761 - accuracy: 0.3511 - val_loss: 1.5711 - val_accuracy: 0.3564

Epoch 00092: val_loss did not improve from 1.56961
Epoch 93/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5756 - accuracy: 0.3516 - val_loss: 1.5714 - val_accuracy: 0.3548

Epoch 00093: val_loss did not improve from 1.56961
Epoch 94/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5747 - accuracy: 0.3506 - val_loss: 1.5707 - val_accuracy: 0.3542

Epoch 00094: val_loss did not improve from 1.56961
Epoch 95/100
83/83 [==============================] - 47s 559ms/step - loss: 1.5746 - accuracy: 0.3535 - val_loss: 1.5708 - val_accuracy: 0.3557

Epoch 00095: val_loss did not improve from 1.56961
Epoch 96/100
83/83 [==============================] - 47s 559ms/step - loss: 1.5747 - accuracy: 0.3522 - val_loss: 1.5707 - val_accuracy: 0.3549

Epoch 00096: val_loss did not improve from 1.56961
Epoch 97/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5741 - accuracy: 0.3521 - val_loss: 1.5710 - val_accuracy: 0.3564

Epoch 00097: val_loss did not improve from 1.56961
Epoch 98/100
83/83 [==============================] - 46s 558ms/step - loss: 1.5735 - accuracy: 0.3549 - val_loss: 1.5703 - val_accuracy: 0.3565

Epoch 00098: val_loss did not improve from 1.56961
Epoch 99/100
83/83 [==============================] - 35s 416ms/step - loss: 1.5731 - accuracy: 0.3541 - val_loss: 1.5699 - val_accuracy: 0.3557

Epoch 00099: val_loss did not improve from 1.56961
Epoch 00099: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_4jet"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_10 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_11 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  12294     [0m
[92m=================================================================[0m
[92mTotal params: 48,523,942[0m
[92mTrainable params: 48,523,926[0m
[92mNon-trainable params: 16[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwCpA07pAAAAAOkCAAAAqQCpAdoBeHIEAAAAcgQAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+0wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_20 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pAgAAAOkEAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+5QEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER3       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_10"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_10 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_10 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_30 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_30 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_31 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_31 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_32 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_32 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_30 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_10 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_31 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_23 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_32 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_10', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_10_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_10', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBAAAAOkGAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+9wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_10', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_30', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_30', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_31', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_31', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_32', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_32', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_30', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_10', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_31', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_32', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER4       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_11"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_11 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_11 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_33 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_33 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_34 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_34 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_35 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_35 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_33 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_11 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_34 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_35 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_11', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_11_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_11', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBgAAAOkIAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+CQIAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_11', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_33', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_33', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_34', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_34', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_35', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_35', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_33', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_11', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_34', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_35', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER5       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 145s 11ms/step - loss: 1.5746 - accuracy: 0.3518
Testing Loss = 1.574621, Testing Accuracy = 0.351816
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 26s 296ms/step - loss: 40.7960 - accuracy: 0.2982 - val_loss: 25.7354 - val_accuracy: 0.2738

Epoch 00001: val_loss improved from inf to 25.73542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 2/100
83/83 [==============================] - 24s 294ms/step - loss: 18.9867 - accuracy: 0.3199 - val_loss: 14.2777 - val_accuracy: 0.3086

Epoch 00002: val_loss improved from 25.73542 to 14.27767, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 3/100
83/83 [==============================] - 24s 294ms/step - loss: 11.7396 - accuracy: 0.3285 - val_loss: 9.7574 - val_accuracy: 0.3336

Epoch 00003: val_loss improved from 14.27767 to 9.75741, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 4/100
83/83 [==============================] - 24s 294ms/step - loss: 8.3838 - accuracy: 0.3305 - val_loss: 7.1879 - val_accuracy: 0.3467

Epoch 00004: val_loss improved from 9.75741 to 7.18789, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 5/100
83/83 [==============================] - 25s 294ms/step - loss: 6.2856 - accuracy: 0.3347 - val_loss: 5.4533 - val_accuracy: 0.3473

Epoch 00005: val_loss improved from 7.18789 to 5.45326, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 6/100
83/83 [==============================] - 25s 294ms/step - loss: 4.8304 - accuracy: 0.3353 - val_loss: 4.2343 - val_accuracy: 0.3477

Epoch 00006: val_loss improved from 5.45326 to 4.23430, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 7/100
83/83 [==============================] - 24s 293ms/step - loss: 3.8086 - accuracy: 0.3343 - val_loss: 3.3840 - val_accuracy: 0.3484

Epoch 00007: val_loss improved from 4.23430 to 3.38401, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 8/100
83/83 [==============================] - 25s 296ms/step - loss: 3.0923 - accuracy: 0.3354 - val_loss: 2.7921 - val_accuracy: 0.3484

Epoch 00008: val_loss improved from 3.38401 to 2.79212, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 9/100
83/83 [==============================] - 24s 293ms/step - loss: 2.5975 - accuracy: 0.3375 - val_loss: 2.3856 - val_accuracy: 0.3498

Epoch 00009: val_loss improved from 2.79212 to 2.38564, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 10/100
83/83 [==============================] - 25s 294ms/step - loss: 2.2605 - accuracy: 0.3377 - val_loss: 2.1119 - val_accuracy: 0.3503

Epoch 00010: val_loss improved from 2.38564 to 2.11185, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 11/100
83/83 [==============================] - 25s 294ms/step - loss: 2.0334 - accuracy: 0.3383 - val_loss: 1.9297 - val_accuracy: 0.3512

Epoch 00011: val_loss improved from 2.11185 to 1.92973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 12/100
83/83 [==============================] - 24s 294ms/step - loss: 1.8831 - accuracy: 0.3398 - val_loss: 1.8092 - val_accuracy: 0.3496

Epoch 00012: val_loss improved from 1.92973 to 1.80925, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 13/100
83/83 [==============================] - 25s 295ms/step - loss: 1.7851 - accuracy: 0.3389 - val_loss: 1.7301 - val_accuracy: 0.3527

Epoch 00013: val_loss improved from 1.80925 to 1.73009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 14/100
83/83 [==============================] - 25s 294ms/step - loss: 1.7206 - accuracy: 0.3373 - val_loss: 1.6797 - val_accuracy: 0.3517

Epoch 00014: val_loss improved from 1.73009 to 1.67969, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 15/100
83/83 [==============================] - 24s 294ms/step - loss: 1.6790 - accuracy: 0.3394 - val_loss: 1.6474 - val_accuracy: 0.3523

Epoch 00015: val_loss improved from 1.67969 to 1.64744, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 16/100
83/83 [==============================] - 24s 294ms/step - loss: 1.6529 - accuracy: 0.3390 - val_loss: 1.6260 - val_accuracy: 0.3523

Epoch 00016: val_loss improved from 1.64744 to 1.62601, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 17/100
83/83 [==============================] - 24s 294ms/step - loss: 1.6357 - accuracy: 0.3409 - val_loss: 1.6128 - val_accuracy: 0.3528

Epoch 00017: val_loss improved from 1.62601 to 1.61280, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 18/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6244 - accuracy: 0.3404 - val_loss: 1.6039 - val_accuracy: 0.3522

Epoch 00018: val_loss improved from 1.61280 to 1.60391, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 19/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6163 - accuracy: 0.3407 - val_loss: 1.5973 - val_accuracy: 0.3539

Epoch 00019: val_loss improved from 1.60391 to 1.59725, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 20/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6108 - accuracy: 0.3401 - val_loss: 1.5935 - val_accuracy: 0.3525

Epoch 00020: val_loss improved from 1.59725 to 1.59346, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 21/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6074 - accuracy: 0.3413 - val_loss: 1.5914 - val_accuracy: 0.3508

Epoch 00021: val_loss improved from 1.59346 to 1.59141, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 22/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6049 - accuracy: 0.3390 - val_loss: 1.5888 - val_accuracy: 0.3528

Epoch 00022: val_loss improved from 1.59141 to 1.58876, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 23/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6027 - accuracy: 0.3427 - val_loss: 1.5870 - val_accuracy: 0.3523

Epoch 00023: val_loss improved from 1.58876 to 1.58698, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 24/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6009 - accuracy: 0.3417 - val_loss: 1.5857 - val_accuracy: 0.3515

Epoch 00024: val_loss improved from 1.58698 to 1.58567, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 25/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5986 - accuracy: 0.3412 - val_loss: 1.5837 - val_accuracy: 0.3524

Epoch 00025: val_loss improved from 1.58567 to 1.58375, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 26/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5968 - accuracy: 0.3435 - val_loss: 1.5829 - val_accuracy: 0.3509

Epoch 00026: val_loss improved from 1.58375 to 1.58286, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 27/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5959 - accuracy: 0.3432 - val_loss: 1.5828 - val_accuracy: 0.3527

Epoch 00027: val_loss improved from 1.58286 to 1.58278, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 28/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5943 - accuracy: 0.3434 - val_loss: 1.5808 - val_accuracy: 0.3511

Epoch 00028: val_loss improved from 1.58278 to 1.58077, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 29/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5943 - accuracy: 0.3431 - val_loss: 1.5815 - val_accuracy: 0.3524

Epoch 00029: val_loss did not improve from 1.58077
Epoch 30/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5927 - accuracy: 0.3450 - val_loss: 1.5801 - val_accuracy: 0.3507

Epoch 00030: val_loss improved from 1.58077 to 1.58006, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 31/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5920 - accuracy: 0.3445 - val_loss: 1.5786 - val_accuracy: 0.3529

Epoch 00031: val_loss improved from 1.58006 to 1.57860, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 32/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5912 - accuracy: 0.3437 - val_loss: 1.5786 - val_accuracy: 0.3510

Epoch 00032: val_loss improved from 1.57860 to 1.57859, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 33/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5903 - accuracy: 0.3451 - val_loss: 1.5775 - val_accuracy: 0.3524

Epoch 00033: val_loss improved from 1.57859 to 1.57746, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 34/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5896 - accuracy: 0.3454 - val_loss: 1.5772 - val_accuracy: 0.3513

Epoch 00034: val_loss improved from 1.57746 to 1.57721, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 35/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5892 - accuracy: 0.3446 - val_loss: 1.5781 - val_accuracy: 0.3521

Epoch 00035: val_loss did not improve from 1.57721
Epoch 36/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5884 - accuracy: 0.3448 - val_loss: 1.5771 - val_accuracy: 0.3535

Epoch 00036: val_loss improved from 1.57721 to 1.57707, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 37/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5889 - accuracy: 0.3437 - val_loss: 1.5773 - val_accuracy: 0.3539

Epoch 00037: val_loss did not improve from 1.57707
Epoch 38/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5880 - accuracy: 0.3439 - val_loss: 1.5763 - val_accuracy: 0.3534

Epoch 00038: val_loss improved from 1.57707 to 1.57629, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 39/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5870 - accuracy: 0.3450 - val_loss: 1.5761 - val_accuracy: 0.3541

Epoch 00039: val_loss improved from 1.57629 to 1.57610, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 40/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5867 - accuracy: 0.3466 - val_loss: 1.5755 - val_accuracy: 0.3547

Epoch 00040: val_loss improved from 1.57610 to 1.57555, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 41/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5870 - accuracy: 0.3459 - val_loss: 1.5763 - val_accuracy: 0.3548

Epoch 00041: val_loss did not improve from 1.57555
Epoch 42/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5860 - accuracy: 0.3449 - val_loss: 1.5750 - val_accuracy: 0.3543

Epoch 00042: val_loss improved from 1.57555 to 1.57503, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 43/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5855 - accuracy: 0.3466 - val_loss: 1.5749 - val_accuracy: 0.3538

Epoch 00043: val_loss improved from 1.57503 to 1.57490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 44/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5841 - accuracy: 0.3467 - val_loss: 1.5737 - val_accuracy: 0.3545

Epoch 00044: val_loss improved from 1.57490 to 1.57370, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 45/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5851 - accuracy: 0.3463 - val_loss: 1.5745 - val_accuracy: 0.3529

Epoch 00045: val_loss did not improve from 1.57370
Epoch 46/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5834 - accuracy: 0.3469 - val_loss: 1.5723 - val_accuracy: 0.3548

Epoch 00046: val_loss improved from 1.57370 to 1.57233, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/3
Epoch 47/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5832 - accuracy: 0.3457 - val_loss: 1.5742 - val_accuracy: 0.3548

Epoch 00047: val_loss did not improve from 1.57233
Epoch 48/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5838 - accuracy: 0.3468 - val_loss: 1.5736 - val_accuracy: 0.3543

Epoch 00048: val_loss did not improve from 1.57233
Epoch 49/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5836 - accuracy: 0.3473 - val_loss: 1.5737 - val_accuracy: 0.3548

Epoch 00049: val_loss did not improve from 1.57233
Epoch 50/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5837 - accuracy: 0.3474 - val_loss: 1.5743 - val_accuracy: 0.3537

Epoch 00050: val_loss did not improve from 1.57233
Epoch 51/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5822 - accuracy: 0.3483 - val_loss: 1.5739 - val_accuracy: 0.3547

Epoch 00051: val_loss did not improve from 1.57233
Epoch 52/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5830 - accuracy: 0.3483 - val_loss: 1.5729 - val_accuracy: 0.3560

Epoch 00052: val_loss did not improve from 1.57233
Epoch 53/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5816 - accuracy: 0.3486 - val_loss: 1.5728 - val_accuracy: 0.3535

Epoch 00053: val_loss did not improve from 1.57233
Epoch 54/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5823 - accuracy: 0.3482 - val_loss: 1.5725 - val_accuracy: 0.3542

Epoch 00054: val_loss did not improve from 1.57233
Epoch 55/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5814 - accuracy: 0.3485 - val_loss: 1.5732 - val_accuracy: 0.3559

Epoch 00055: val_loss did not improve from 1.57233
Epoch 56/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5807 - accuracy: 0.3485 - val_loss: 1.5728 - val_accuracy: 0.3560

Epoch 00056: val_loss did not improve from 1.57233
Epoch 00056: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_4jet"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_12 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_13 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_14 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_15 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_35 (Dense)             multiple                  12294     [0m
[92m=================================================================[0m
[92mTotal params: 48,523,942[0m
[92mTrainable params: 48,523,926[0m
[92mNon-trainable params: 16[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_12"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_12 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_12 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_36 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_36 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_37 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_37 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_38 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_38 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_36 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_12 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_37 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_38 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_12', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_12_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_12', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwCpA07pAAAAAOkCAAAAqQCpAdoBeHIEAAAAcgQAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+0wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_12', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_36', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_36', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_37', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_37', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_38', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_38', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_36', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_12', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_37', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_38', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_13"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_13 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_13 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_39 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_39 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_40 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_40 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_41 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_41 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_39 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_13 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_29 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_40 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_30 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_41 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_13', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_13_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_13', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pAgAAAOkEAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+5QEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_13', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_39', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_39', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_40', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_40', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_41', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_41', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_39', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_13', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_40', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_30', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_41', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER3       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_14"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_14 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_14 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_42 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_42 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_43 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_43 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_44 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_44 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_42 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_14 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_31 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_43 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_32 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_44 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_14', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_14_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_14', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBAAAAOkGAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+9wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_14', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_42', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_42', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_43', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_43', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_44', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_44', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_42', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_14', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_31', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_43', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_32', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_44', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER4       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_15"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_15 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_15 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_45 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_45 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_46 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_46 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_47 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_47 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_45 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_15 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_33 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_46 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_34 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_47 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_15', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_15_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_15', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBgAAAOkIAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+CQIAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_15', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_45', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_45', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_46', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_46', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_47', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_47', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_45', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_15', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_33', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_46', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_34', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_47', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER5       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_35', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 149s 11ms/step - loss: 1.5768 - accuracy: 0.3500
Testing Loss = 1.576799, Testing Accuracy = 0.350030
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 26s 294ms/step - loss: 40.6513 - accuracy: 0.2954 - val_loss: 25.5726 - val_accuracy: 0.2522

Epoch 00001: val_loss improved from inf to 25.57262, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 2/100
83/83 [==============================] - 24s 292ms/step - loss: 18.8410 - accuracy: 0.3224 - val_loss: 14.1686 - val_accuracy: 0.2886

Epoch 00002: val_loss improved from 25.57262 to 14.16863, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 3/100
83/83 [==============================] - 24s 293ms/step - loss: 11.6494 - accuracy: 0.3302 - val_loss: 9.6948 - val_accuracy: 0.3256

Epoch 00003: val_loss improved from 14.16863 to 9.69484, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 4/100
83/83 [==============================] - 24s 294ms/step - loss: 8.3307 - accuracy: 0.3320 - val_loss: 7.1509 - val_accuracy: 0.3427

Epoch 00004: val_loss improved from 9.69484 to 7.15091, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 5/100
83/83 [==============================] - 24s 293ms/step - loss: 6.2503 - accuracy: 0.3336 - val_loss: 5.4249 - val_accuracy: 0.3481

Epoch 00005: val_loss improved from 7.15091 to 5.42491, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 6/100
83/83 [==============================] - 24s 293ms/step - loss: 4.8071 - accuracy: 0.3341 - val_loss: 4.2155 - val_accuracy: 0.3489

Epoch 00006: val_loss improved from 5.42491 to 4.21554, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 7/100
83/83 [==============================] - 25s 294ms/step - loss: 3.7912 - accuracy: 0.3370 - val_loss: 3.3695 - val_accuracy: 0.3491

Epoch 00007: val_loss improved from 4.21554 to 3.36950, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 8/100
83/83 [==============================] - 25s 294ms/step - loss: 3.0808 - accuracy: 0.3359 - val_loss: 2.7824 - val_accuracy: 0.3495

Epoch 00008: val_loss improved from 3.36950 to 2.78237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 9/100
83/83 [==============================] - 24s 293ms/step - loss: 2.5906 - accuracy: 0.3377 - val_loss: 2.3786 - val_accuracy: 0.3520

Epoch 00009: val_loss improved from 2.78237 to 2.37857, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 10/100
83/83 [==============================] - 24s 294ms/step - loss: 2.2548 - accuracy: 0.3377 - val_loss: 2.1078 - val_accuracy: 0.3523

Epoch 00010: val_loss improved from 2.37857 to 2.10781, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 11/100
83/83 [==============================] - 25s 294ms/step - loss: 2.0307 - accuracy: 0.3368 - val_loss: 1.9265 - val_accuracy: 0.3519

Epoch 00011: val_loss improved from 2.10781 to 1.92654, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 12/100
83/83 [==============================] - 24s 294ms/step - loss: 1.8811 - accuracy: 0.3351 - val_loss: 1.8065 - val_accuracy: 0.3533

Epoch 00012: val_loss improved from 1.92654 to 1.80650, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 13/100
83/83 [==============================] - 24s 293ms/step - loss: 1.7834 - accuracy: 0.3388 - val_loss: 1.7297 - val_accuracy: 0.3511

Epoch 00013: val_loss improved from 1.80650 to 1.72967, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 14/100
83/83 [==============================] - 25s 294ms/step - loss: 1.7194 - accuracy: 0.3389 - val_loss: 1.6792 - val_accuracy: 0.3518

Epoch 00014: val_loss improved from 1.72967 to 1.67916, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 15/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6795 - accuracy: 0.3391 - val_loss: 1.6476 - val_accuracy: 0.3532

Epoch 00015: val_loss improved from 1.67916 to 1.64758, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 16/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6529 - accuracy: 0.3403 - val_loss: 1.6268 - val_accuracy: 0.3515

Epoch 00016: val_loss improved from 1.64758 to 1.62679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 17/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6358 - accuracy: 0.3400 - val_loss: 1.6135 - val_accuracy: 0.3513

Epoch 00017: val_loss improved from 1.62679 to 1.61354, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 18/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6243 - accuracy: 0.3388 - val_loss: 1.6057 - val_accuracy: 0.3519

Epoch 00018: val_loss improved from 1.61354 to 1.60574, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 19/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6173 - accuracy: 0.3386 - val_loss: 1.5991 - val_accuracy: 0.3525

Epoch 00019: val_loss improved from 1.60574 to 1.59905, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 20/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6120 - accuracy: 0.3415 - val_loss: 1.5942 - val_accuracy: 0.3524

Epoch 00020: val_loss improved from 1.59905 to 1.59425, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 21/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6084 - accuracy: 0.3409 - val_loss: 1.5917 - val_accuracy: 0.3532

Epoch 00021: val_loss improved from 1.59425 to 1.59170, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 22/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6058 - accuracy: 0.3414 - val_loss: 1.5892 - val_accuracy: 0.3528

Epoch 00022: val_loss improved from 1.59170 to 1.58918, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 23/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6039 - accuracy: 0.3413 - val_loss: 1.5874 - val_accuracy: 0.3537

Epoch 00023: val_loss improved from 1.58918 to 1.58736, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 24/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6020 - accuracy: 0.3428 - val_loss: 1.5864 - val_accuracy: 0.3525

Epoch 00024: val_loss improved from 1.58736 to 1.58643, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 25/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5995 - accuracy: 0.3409 - val_loss: 1.5838 - val_accuracy: 0.3520

Epoch 00025: val_loss improved from 1.58643 to 1.58382, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 26/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5997 - accuracy: 0.3418 - val_loss: 1.5839 - val_accuracy: 0.3520

Epoch 00026: val_loss did not improve from 1.58382
Epoch 27/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5976 - accuracy: 0.3419 - val_loss: 1.5825 - val_accuracy: 0.3541

Epoch 00027: val_loss improved from 1.58382 to 1.58254, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 28/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5967 - accuracy: 0.3416 - val_loss: 1.5819 - val_accuracy: 0.3521

Epoch 00028: val_loss improved from 1.58254 to 1.58185, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 29/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5946 - accuracy: 0.3423 - val_loss: 1.5810 - val_accuracy: 0.3521

Epoch 00029: val_loss improved from 1.58185 to 1.58100, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 30/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5952 - accuracy: 0.3441 - val_loss: 1.5809 - val_accuracy: 0.3527

Epoch 00030: val_loss improved from 1.58100 to 1.58094, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 31/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5935 - accuracy: 0.3430 - val_loss: 1.5801 - val_accuracy: 0.3539

Epoch 00031: val_loss improved from 1.58094 to 1.58011, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 32/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5926 - accuracy: 0.3441 - val_loss: 1.5791 - val_accuracy: 0.3534

Epoch 00032: val_loss improved from 1.58011 to 1.57907, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 33/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5923 - accuracy: 0.3432 - val_loss: 1.5790 - val_accuracy: 0.3527

Epoch 00033: val_loss improved from 1.57907 to 1.57900, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 34/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5911 - accuracy: 0.3448 - val_loss: 1.5780 - val_accuracy: 0.3541

Epoch 00034: val_loss improved from 1.57900 to 1.57796, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 35/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5915 - accuracy: 0.3441 - val_loss: 1.5785 - val_accuracy: 0.3555

Epoch 00035: val_loss did not improve from 1.57796
Epoch 36/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5900 - accuracy: 0.3450 - val_loss: 1.5779 - val_accuracy: 0.3539

Epoch 00036: val_loss improved from 1.57796 to 1.57787, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 37/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5894 - accuracy: 0.3432 - val_loss: 1.5769 - val_accuracy: 0.3535

Epoch 00037: val_loss improved from 1.57787 to 1.57692, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 38/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5893 - accuracy: 0.3448 - val_loss: 1.5764 - val_accuracy: 0.3534

Epoch 00038: val_loss improved from 1.57692 to 1.57639, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 39/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5871 - accuracy: 0.3444 - val_loss: 1.5772 - val_accuracy: 0.3538

Epoch 00039: val_loss did not improve from 1.57639
Epoch 40/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5888 - accuracy: 0.3434 - val_loss: 1.5754 - val_accuracy: 0.3548

Epoch 00040: val_loss improved from 1.57639 to 1.57542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 41/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5883 - accuracy: 0.3456 - val_loss: 1.5744 - val_accuracy: 0.3544

Epoch 00041: val_loss improved from 1.57542 to 1.57436, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 42/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5874 - accuracy: 0.3455 - val_loss: 1.5759 - val_accuracy: 0.3551

Epoch 00042: val_loss did not improve from 1.57436
Epoch 43/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5865 - accuracy: 0.3464 - val_loss: 1.5750 - val_accuracy: 0.3543

Epoch 00043: val_loss did not improve from 1.57436
Epoch 44/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5865 - accuracy: 0.3438 - val_loss: 1.5751 - val_accuracy: 0.3540

Epoch 00044: val_loss did not improve from 1.57436
Epoch 45/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5865 - accuracy: 0.3470 - val_loss: 1.5731 - val_accuracy: 0.3541

Epoch 00045: val_loss improved from 1.57436 to 1.57311, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 46/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5851 - accuracy: 0.3450 - val_loss: 1.5731 - val_accuracy: 0.3551

Epoch 00046: val_loss improved from 1.57311 to 1.57307, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 47/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5856 - accuracy: 0.3462 - val_loss: 1.5736 - val_accuracy: 0.3561

Epoch 00047: val_loss did not improve from 1.57307
Epoch 48/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5857 - accuracy: 0.3453 - val_loss: 1.5738 - val_accuracy: 0.3546

Epoch 00048: val_loss did not improve from 1.57307
Epoch 49/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5850 - accuracy: 0.3469 - val_loss: 1.5737 - val_accuracy: 0.3560

Epoch 00049: val_loss did not improve from 1.57307
Epoch 50/100
83/83 [==============================] - 24s 292ms/step - loss: 1.5832 - accuracy: 0.3460 - val_loss: 1.5727 - val_accuracy: 0.3553

Epoch 00050: val_loss improved from 1.57307 to 1.57266, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 51/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5833 - accuracy: 0.3455 - val_loss: 1.5732 - val_accuracy: 0.3537

Epoch 00051: val_loss did not improve from 1.57266
Epoch 52/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5841 - accuracy: 0.3463 - val_loss: 1.5726 - val_accuracy: 0.3554

Epoch 00052: val_loss improved from 1.57266 to 1.57256, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 53/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5836 - accuracy: 0.3458 - val_loss: 1.5720 - val_accuracy: 0.3536

Epoch 00053: val_loss improved from 1.57256 to 1.57196, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 54/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5829 - accuracy: 0.3481 - val_loss: 1.5722 - val_accuracy: 0.3544

Epoch 00054: val_loss did not improve from 1.57196
Epoch 55/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5832 - accuracy: 0.3462 - val_loss: 1.5727 - val_accuracy: 0.3567

Epoch 00055: val_loss did not improve from 1.57196
Epoch 56/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5817 - accuracy: 0.3474 - val_loss: 1.5723 - val_accuracy: 0.3562

Epoch 00056: val_loss did not improve from 1.57196
Epoch 57/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5813 - accuracy: 0.3485 - val_loss: 1.5722 - val_accuracy: 0.3555

Epoch 00057: val_loss did not improve from 1.57196
Epoch 58/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5809 - accuracy: 0.3478 - val_loss: 1.5720 - val_accuracy: 0.3562

Epoch 00058: val_loss did not improve from 1.57196
Epoch 59/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5815 - accuracy: 0.3470 - val_loss: 1.5728 - val_accuracy: 0.3556

Epoch 00059: val_loss did not improve from 1.57196
Epoch 60/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5812 - accuracy: 0.3463 - val_loss: 1.5714 - val_accuracy: 0.3562

Epoch 00060: val_loss improved from 1.57196 to 1.57142, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 61/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5814 - accuracy: 0.3471 - val_loss: 1.5716 - val_accuracy: 0.3559

Epoch 00061: val_loss did not improve from 1.57142
Epoch 62/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5815 - accuracy: 0.3468 - val_loss: 1.5716 - val_accuracy: 0.3549

Epoch 00062: val_loss did not improve from 1.57142
Epoch 63/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5811 - accuracy: 0.3468 - val_loss: 1.5707 - val_accuracy: 0.3558

Epoch 00063: val_loss improved from 1.57142 to 1.57072, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 64/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5800 - accuracy: 0.3474 - val_loss: 1.5711 - val_accuracy: 0.3548

Epoch 00064: val_loss did not improve from 1.57072
Epoch 65/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5798 - accuracy: 0.3491 - val_loss: 1.5714 - val_accuracy: 0.3549

Epoch 00065: val_loss did not improve from 1.57072
Epoch 66/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5799 - accuracy: 0.3466 - val_loss: 1.5707 - val_accuracy: 0.3555

Epoch 00066: val_loss improved from 1.57072 to 1.57069, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 67/100
83/83 [==============================] - 24s 292ms/step - loss: 1.5790 - accuracy: 0.3506 - val_loss: 1.5705 - val_accuracy: 0.3549

Epoch 00067: val_loss improved from 1.57069 to 1.57051, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 68/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5797 - accuracy: 0.3477 - val_loss: 1.5709 - val_accuracy: 0.3548

Epoch 00068: val_loss did not improve from 1.57051
Epoch 69/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5793 - accuracy: 0.3490 - val_loss: 1.5704 - val_accuracy: 0.3553

Epoch 00069: val_loss improved from 1.57051 to 1.57044, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 70/100
83/83 [==============================] - 24s 292ms/step - loss: 1.5789 - accuracy: 0.3491 - val_loss: 1.5706 - val_accuracy: 0.3540

Epoch 00070: val_loss did not improve from 1.57044
Epoch 71/100
83/83 [==============================] - 24s 292ms/step - loss: 1.5782 - accuracy: 0.3483 - val_loss: 1.5698 - val_accuracy: 0.3553

Epoch 00071: val_loss improved from 1.57044 to 1.56979, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 72/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5788 - accuracy: 0.3501 - val_loss: 1.5706 - val_accuracy: 0.3546

Epoch 00072: val_loss did not improve from 1.56979
Epoch 73/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5780 - accuracy: 0.3504 - val_loss: 1.5693 - val_accuracy: 0.3559

Epoch 00073: val_loss improved from 1.56979 to 1.56930, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 74/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5784 - accuracy: 0.3525 - val_loss: 1.5693 - val_accuracy: 0.3552

Epoch 00074: val_loss did not improve from 1.56930
Epoch 75/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5774 - accuracy: 0.3507 - val_loss: 1.5700 - val_accuracy: 0.3548

Epoch 00075: val_loss did not improve from 1.56930
Epoch 76/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5781 - accuracy: 0.3511 - val_loss: 1.5697 - val_accuracy: 0.3548

Epoch 00076: val_loss did not improve from 1.56930
Epoch 77/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5771 - accuracy: 0.3522 - val_loss: 1.5693 - val_accuracy: 0.3548

Epoch 00077: val_loss did not improve from 1.56930
Epoch 78/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5770 - accuracy: 0.3520 - val_loss: 1.5689 - val_accuracy: 0.3562

Epoch 00078: val_loss improved from 1.56930 to 1.56886, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 79/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5768 - accuracy: 0.3510 - val_loss: 1.5686 - val_accuracy: 0.3562

Epoch 00079: val_loss improved from 1.56886 to 1.56863, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 80/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5764 - accuracy: 0.3518 - val_loss: 1.5689 - val_accuracy: 0.3548

Epoch 00080: val_loss did not improve from 1.56863
Epoch 81/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5764 - accuracy: 0.3526 - val_loss: 1.5693 - val_accuracy: 0.3541

Epoch 00081: val_loss did not improve from 1.56863
Epoch 82/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5761 - accuracy: 0.3517 - val_loss: 1.5691 - val_accuracy: 0.3547

Epoch 00082: val_loss did not improve from 1.56863
Epoch 83/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5745 - accuracy: 0.3520 - val_loss: 1.5686 - val_accuracy: 0.3566

Epoch 00083: val_loss improved from 1.56863 to 1.56858, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/4
Epoch 84/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5757 - accuracy: 0.3514 - val_loss: 1.5692 - val_accuracy: 0.3553

Epoch 00084: val_loss did not improve from 1.56858
Epoch 85/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5751 - accuracy: 0.3518 - val_loss: 1.5693 - val_accuracy: 0.3537

Epoch 00085: val_loss did not improve from 1.56858
Epoch 86/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5747 - accuracy: 0.3528 - val_loss: 1.5690 - val_accuracy: 0.3548

Epoch 00086: val_loss did not improve from 1.56858
Epoch 87/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5753 - accuracy: 0.3513 - val_loss: 1.5696 - val_accuracy: 0.3546

Epoch 00087: val_loss did not improve from 1.56858
Epoch 88/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5752 - accuracy: 0.3533 - val_loss: 1.5688 - val_accuracy: 0.3546

Epoch 00088: val_loss did not improve from 1.56858
Epoch 89/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5736 - accuracy: 0.3536 - val_loss: 1.5693 - val_accuracy: 0.3547

Epoch 00089: val_loss did not improve from 1.56858
Epoch 00089: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_4jet"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_16 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_17 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_18 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_19 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_44 (Dense)             multiple                  12294     [0m
[92m=================================================================[0m
[92mTotal params: 48,523,942[0m
[92mTrainable params: 48,523,926[0m
[92mNon-trainable params: 16[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_16"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_16 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_16 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_48 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_48 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_49 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_49 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_50 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_50 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_48 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_16 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_36 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_49 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_37 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_50 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_16', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_16_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_16', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwCpA07pAAAAAOkCAAAAqQCpAdoBeHIEAAAAcgQAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+0wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_16', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_48', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_48', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_49', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_49', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_50', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_50', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_48', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_16', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_36', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_49', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_37', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_50', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_17"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_17 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_17 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_51 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_51 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_52 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_52 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_53 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_53 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_51 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_17 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_38 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_52 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_39 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_53 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_17', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_17_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_17', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pAgAAAOkEAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+5QEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_17', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_51', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_51', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_52', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_52', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_53', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_53', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_51', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_17', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_38', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_52', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_39', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_53', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER3       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_18"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_18 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_18 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_54 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_54 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_55 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_55 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_56 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_56 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_54 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_18 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_40 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_55 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_41 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_56 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_18', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_18_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_18', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBAAAAOkGAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+9wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_18', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_54', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_54', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_55', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_55', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_56', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_56', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_54', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_18', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_40', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_55', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_41', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_56', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER4       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_19"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_19 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_19 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_57 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_57 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_58 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_58 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_59 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_59 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_57 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_19 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_42 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_58 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_43 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_59 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_19', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_19_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_19', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBgAAAOkIAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+CQIAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_19', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_57', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_57', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_58', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_58', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_59', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_59', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_57', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_19', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_42', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_58', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_43', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_59', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER5       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_44', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 148s 11ms/step - loss: 1.5739 - accuracy: 0.3521
Testing Loss = 1.573909, Testing Accuracy = 0.352114
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 26s 296ms/step - loss: 40.6218 - accuracy: 0.2951 - val_loss: 25.5410 - val_accuracy: 0.2609

Epoch 00001: val_loss improved from inf to 25.54100, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 2/100
83/83 [==============================] - 24s 294ms/step - loss: 18.8310 - accuracy: 0.3221 - val_loss: 14.1678 - val_accuracy: 0.3020

Epoch 00002: val_loss improved from 25.54100 to 14.16779, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 3/100
83/83 [==============================] - 25s 294ms/step - loss: 11.6562 - accuracy: 0.3280 - val_loss: 9.6995 - val_accuracy: 0.3337

Epoch 00003: val_loss improved from 14.16779 to 9.69952, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 4/100
83/83 [==============================] - 24s 294ms/step - loss: 8.3377 - accuracy: 0.3280 - val_loss: 7.1559 - val_accuracy: 0.3440

Epoch 00004: val_loss improved from 9.69952 to 7.15595, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 5/100
83/83 [==============================] - 25s 294ms/step - loss: 6.2565 - accuracy: 0.3321 - val_loss: 5.4307 - val_accuracy: 0.3491

Epoch 00005: val_loss improved from 7.15595 to 5.43066, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 6/100
83/83 [==============================] - 25s 295ms/step - loss: 4.8113 - accuracy: 0.3361 - val_loss: 4.2180 - val_accuracy: 0.3506

Epoch 00006: val_loss improved from 5.43066 to 4.21803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 7/100
83/83 [==============================] - 24s 294ms/step - loss: 3.7924 - accuracy: 0.3363 - val_loss: 3.3709 - val_accuracy: 0.3500

Epoch 00007: val_loss improved from 4.21803 to 3.37091, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 8/100
83/83 [==============================] - 25s 295ms/step - loss: 3.0813 - accuracy: 0.3373 - val_loss: 2.7834 - val_accuracy: 0.3500

Epoch 00008: val_loss improved from 3.37091 to 2.78343, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 9/100
83/83 [==============================] - 25s 294ms/step - loss: 2.5902 - accuracy: 0.3365 - val_loss: 2.3790 - val_accuracy: 0.3511

Epoch 00009: val_loss improved from 2.78343 to 2.37903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 10/100
83/83 [==============================] - 25s 294ms/step - loss: 2.2546 - accuracy: 0.3375 - val_loss: 2.1064 - val_accuracy: 0.3506

Epoch 00010: val_loss improved from 2.37903 to 2.10636, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 11/100
83/83 [==============================] - 25s 294ms/step - loss: 2.0289 - accuracy: 0.3380 - val_loss: 1.9251 - val_accuracy: 0.3522

Epoch 00011: val_loss improved from 2.10636 to 1.92506, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 12/100
83/83 [==============================] - 25s 295ms/step - loss: 1.8796 - accuracy: 0.3399 - val_loss: 1.8053 - val_accuracy: 0.3496

Epoch 00012: val_loss improved from 1.92506 to 1.80532, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 13/100
83/83 [==============================] - 25s 294ms/step - loss: 1.7832 - accuracy: 0.3392 - val_loss: 1.7281 - val_accuracy: 0.3534

Epoch 00013: val_loss improved from 1.80532 to 1.72813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 14/100
83/83 [==============================] - 25s 295ms/step - loss: 1.7181 - accuracy: 0.3404 - val_loss: 1.6769 - val_accuracy: 0.3525

Epoch 00014: val_loss improved from 1.72813 to 1.67693, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 15/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6778 - accuracy: 0.3386 - val_loss: 1.6459 - val_accuracy: 0.3538

Epoch 00015: val_loss improved from 1.67693 to 1.64593, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 16/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6518 - accuracy: 0.3395 - val_loss: 1.6262 - val_accuracy: 0.3524

Epoch 00016: val_loss improved from 1.64593 to 1.62615, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 17/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6352 - accuracy: 0.3427 - val_loss: 1.6123 - val_accuracy: 0.3523

Epoch 00017: val_loss improved from 1.62615 to 1.61228, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 18/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6236 - accuracy: 0.3402 - val_loss: 1.6036 - val_accuracy: 0.3521

Epoch 00018: val_loss improved from 1.61228 to 1.60364, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 19/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6167 - accuracy: 0.3397 - val_loss: 1.5976 - val_accuracy: 0.3521

Epoch 00019: val_loss improved from 1.60364 to 1.59760, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 20/100
83/83 [==============================] - 25s 295ms/step - loss: 1.6113 - accuracy: 0.3418 - val_loss: 1.5946 - val_accuracy: 0.3536

Epoch 00020: val_loss improved from 1.59760 to 1.59463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 21/100
83/83 [==============================] - 25s 295ms/step - loss: 1.6070 - accuracy: 0.3428 - val_loss: 1.5910 - val_accuracy: 0.3515

Epoch 00021: val_loss improved from 1.59463 to 1.59099, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 22/100
83/83 [==============================] - 25s 295ms/step - loss: 1.6046 - accuracy: 0.3445 - val_loss: 1.5892 - val_accuracy: 0.3526

Epoch 00022: val_loss improved from 1.59099 to 1.58923, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 23/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6030 - accuracy: 0.3411 - val_loss: 1.5878 - val_accuracy: 0.3517

Epoch 00023: val_loss improved from 1.58923 to 1.58781, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 24/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5999 - accuracy: 0.3429 - val_loss: 1.5846 - val_accuracy: 0.3514

Epoch 00024: val_loss improved from 1.58781 to 1.58461, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 25/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5997 - accuracy: 0.3421 - val_loss: 1.5847 - val_accuracy: 0.3523

Epoch 00025: val_loss did not improve from 1.58461
Epoch 26/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5977 - accuracy: 0.3417 - val_loss: 1.5845 - val_accuracy: 0.3519

Epoch 00026: val_loss improved from 1.58461 to 1.58446, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 27/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5960 - accuracy: 0.3427 - val_loss: 1.5829 - val_accuracy: 0.3521

Epoch 00027: val_loss improved from 1.58446 to 1.58289, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 28/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5961 - accuracy: 0.3440 - val_loss: 1.5827 - val_accuracy: 0.3518

Epoch 00028: val_loss improved from 1.58289 to 1.58268, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 29/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5954 - accuracy: 0.3426 - val_loss: 1.5817 - val_accuracy: 0.3521

Epoch 00029: val_loss improved from 1.58268 to 1.58169, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 30/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5949 - accuracy: 0.3420 - val_loss: 1.5812 - val_accuracy: 0.3515

Epoch 00030: val_loss improved from 1.58169 to 1.58118, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 31/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5930 - accuracy: 0.3449 - val_loss: 1.5795 - val_accuracy: 0.3519

Epoch 00031: val_loss improved from 1.58118 to 1.57946, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 32/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5932 - accuracy: 0.3435 - val_loss: 1.5796 - val_accuracy: 0.3523

Epoch 00032: val_loss did not improve from 1.57946
Epoch 33/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5921 - accuracy: 0.3437 - val_loss: 1.5803 - val_accuracy: 0.3528

Epoch 00033: val_loss did not improve from 1.57946
Epoch 34/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5909 - accuracy: 0.3449 - val_loss: 1.5794 - val_accuracy: 0.3535

Epoch 00034: val_loss improved from 1.57946 to 1.57939, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 35/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5905 - accuracy: 0.3441 - val_loss: 1.5781 - val_accuracy: 0.3537

Epoch 00035: val_loss improved from 1.57939 to 1.57812, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 36/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5895 - accuracy: 0.3428 - val_loss: 1.5781 - val_accuracy: 0.3547

Epoch 00036: val_loss improved from 1.57812 to 1.57805, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 37/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5886 - accuracy: 0.3446 - val_loss: 1.5775 - val_accuracy: 0.3538

Epoch 00037: val_loss improved from 1.57805 to 1.57753, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 38/100
83/83 [==============================] - 24s 292ms/step - loss: 1.5886 - accuracy: 0.3451 - val_loss: 1.5774 - val_accuracy: 0.3539

Epoch 00038: val_loss improved from 1.57753 to 1.57744, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 39/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5876 - accuracy: 0.3439 - val_loss: 1.5781 - val_accuracy: 0.3554

Epoch 00039: val_loss did not improve from 1.57744
Epoch 40/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5872 - accuracy: 0.3447 - val_loss: 1.5769 - val_accuracy: 0.3520

Epoch 00040: val_loss improved from 1.57744 to 1.57693, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 41/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5878 - accuracy: 0.3450 - val_loss: 1.5763 - val_accuracy: 0.3551

Epoch 00041: val_loss improved from 1.57693 to 1.57632, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 42/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5868 - accuracy: 0.3450 - val_loss: 1.5769 - val_accuracy: 0.3547

Epoch 00042: val_loss did not improve from 1.57632
Epoch 43/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5857 - accuracy: 0.3448 - val_loss: 1.5761 - val_accuracy: 0.3536

Epoch 00043: val_loss improved from 1.57632 to 1.57607, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 44/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5860 - accuracy: 0.3458 - val_loss: 1.5752 - val_accuracy: 0.3539

Epoch 00044: val_loss improved from 1.57607 to 1.57525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 45/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5850 - accuracy: 0.3465 - val_loss: 1.5750 - val_accuracy: 0.3542

Epoch 00045: val_loss improved from 1.57525 to 1.57505, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 46/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5845 - accuracy: 0.3469 - val_loss: 1.5751 - val_accuracy: 0.3528

Epoch 00046: val_loss did not improve from 1.57505
Epoch 47/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5854 - accuracy: 0.3452 - val_loss: 1.5756 - val_accuracy: 0.3532

Epoch 00047: val_loss did not improve from 1.57505
Epoch 48/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5849 - accuracy: 0.3458 - val_loss: 1.5753 - val_accuracy: 0.3542

Epoch 00048: val_loss did not improve from 1.57505
Epoch 49/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5837 - accuracy: 0.3465 - val_loss: 1.5753 - val_accuracy: 0.3529

Epoch 00049: val_loss did not improve from 1.57505
Epoch 50/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5847 - accuracy: 0.3482 - val_loss: 1.5761 - val_accuracy: 0.3542

Epoch 00050: val_loss did not improve from 1.57505
Epoch 51/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5835 - accuracy: 0.3459 - val_loss: 1.5740 - val_accuracy: 0.3528

Epoch 00051: val_loss improved from 1.57505 to 1.57396, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 52/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5835 - accuracy: 0.3466 - val_loss: 1.5743 - val_accuracy: 0.3536

Epoch 00052: val_loss did not improve from 1.57396
Epoch 53/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5836 - accuracy: 0.3470 - val_loss: 1.5747 - val_accuracy: 0.3538

Epoch 00053: val_loss did not improve from 1.57396
Epoch 54/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5827 - accuracy: 0.3461 - val_loss: 1.5747 - val_accuracy: 0.3554

Epoch 00054: val_loss did not improve from 1.57396
Epoch 55/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5825 - accuracy: 0.3487 - val_loss: 1.5753 - val_accuracy: 0.3553

Epoch 00055: val_loss did not improve from 1.57396
Epoch 56/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5823 - accuracy: 0.3478 - val_loss: 1.5737 - val_accuracy: 0.3529

Epoch 00056: val_loss improved from 1.57396 to 1.57374, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 57/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5826 - accuracy: 0.3452 - val_loss: 1.5743 - val_accuracy: 0.3533

Epoch 00057: val_loss did not improve from 1.57374
Epoch 58/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5809 - accuracy: 0.3468 - val_loss: 1.5742 - val_accuracy: 0.3543

Epoch 00058: val_loss did not improve from 1.57374
Epoch 59/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5826 - accuracy: 0.3459 - val_loss: 1.5740 - val_accuracy: 0.3558

Epoch 00059: val_loss did not improve from 1.57374
Epoch 60/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5821 - accuracy: 0.3481 - val_loss: 1.5739 - val_accuracy: 0.3560

Epoch 00060: val_loss did not improve from 1.57374
Epoch 61/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5812 - accuracy: 0.3474 - val_loss: 1.5731 - val_accuracy: 0.3540

Epoch 00061: val_loss improved from 1.57374 to 1.57308, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 62/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5812 - accuracy: 0.3490 - val_loss: 1.5745 - val_accuracy: 0.3539

Epoch 00062: val_loss did not improve from 1.57308
Epoch 63/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5811 - accuracy: 0.3481 - val_loss: 1.5734 - val_accuracy: 0.3550

Epoch 00063: val_loss did not improve from 1.57308
Epoch 64/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5800 - accuracy: 0.3492 - val_loss: 1.5735 - val_accuracy: 0.3550

Epoch 00064: val_loss did not improve from 1.57308
Epoch 65/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5806 - accuracy: 0.3499 - val_loss: 1.5735 - val_accuracy: 0.3544

Epoch 00065: val_loss did not improve from 1.57308
Epoch 66/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5807 - accuracy: 0.3479 - val_loss: 1.5734 - val_accuracy: 0.3550

Epoch 00066: val_loss did not improve from 1.57308
Epoch 67/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5799 - accuracy: 0.3484 - val_loss: 1.5728 - val_accuracy: 0.3539

Epoch 00067: val_loss improved from 1.57308 to 1.57280, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 68/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5783 - accuracy: 0.3495 - val_loss: 1.5728 - val_accuracy: 0.3545

Epoch 00068: val_loss improved from 1.57280 to 1.57277, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 69/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5795 - accuracy: 0.3495 - val_loss: 1.5726 - val_accuracy: 0.3551

Epoch 00069: val_loss improved from 1.57277 to 1.57265, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 70/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5793 - accuracy: 0.3497 - val_loss: 1.5729 - val_accuracy: 0.3535

Epoch 00070: val_loss did not improve from 1.57265
Epoch 71/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5800 - accuracy: 0.3503 - val_loss: 1.5723 - val_accuracy: 0.3558

Epoch 00071: val_loss improved from 1.57265 to 1.57230, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 72/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5788 - accuracy: 0.3500 - val_loss: 1.5720 - val_accuracy: 0.3550

Epoch 00072: val_loss improved from 1.57230 to 1.57196, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 73/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5789 - accuracy: 0.3495 - val_loss: 1.5729 - val_accuracy: 0.3548

Epoch 00073: val_loss did not improve from 1.57196
Epoch 74/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5783 - accuracy: 0.3511 - val_loss: 1.5726 - val_accuracy: 0.3545

Epoch 00074: val_loss did not improve from 1.57196
Epoch 75/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5775 - accuracy: 0.3499 - val_loss: 1.5720 - val_accuracy: 0.3551

Epoch 00075: val_loss did not improve from 1.57196
Epoch 76/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5773 - accuracy: 0.3512 - val_loss: 1.5720 - val_accuracy: 0.3549

Epoch 00076: val_loss did not improve from 1.57196
Epoch 77/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5781 - accuracy: 0.3511 - val_loss: 1.5715 - val_accuracy: 0.3539

Epoch 00077: val_loss improved from 1.57196 to 1.57153, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/5
Epoch 78/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5776 - accuracy: 0.3510 - val_loss: 1.5724 - val_accuracy: 0.3549

Epoch 00078: val_loss did not improve from 1.57153
Epoch 79/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5770 - accuracy: 0.3514 - val_loss: 1.5718 - val_accuracy: 0.3532

Epoch 00079: val_loss did not improve from 1.57153
Epoch 80/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5770 - accuracy: 0.3503 - val_loss: 1.5721 - val_accuracy: 0.3538

Epoch 00080: val_loss did not improve from 1.57153
Epoch 81/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5774 - accuracy: 0.3509 - val_loss: 1.5725 - val_accuracy: 0.3533

Epoch 00081: val_loss did not improve from 1.57153
Epoch 82/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5769 - accuracy: 0.3507 - val_loss: 1.5734 - val_accuracy: 0.3540

Epoch 00082: val_loss did not improve from 1.57153
Epoch 83/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5763 - accuracy: 0.3521 - val_loss: 1.5723 - val_accuracy: 0.3527

Epoch 00083: val_loss did not improve from 1.57153
Epoch 84/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5767 - accuracy: 0.3510 - val_loss: 1.5723 - val_accuracy: 0.3537

Epoch 00084: val_loss did not improve from 1.57153
Epoch 85/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5755 - accuracy: 0.3536 - val_loss: 1.5728 - val_accuracy: 0.3529

Epoch 00085: val_loss did not improve from 1.57153
Epoch 86/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5758 - accuracy: 0.3526 - val_loss: 1.5724 - val_accuracy: 0.3537

Epoch 00086: val_loss did not improve from 1.57153
Epoch 87/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5761 - accuracy: 0.3517 - val_loss: 1.5726 - val_accuracy: 0.3538

Epoch 00087: val_loss did not improve from 1.57153
Epoch 00087: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_4jet"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_20 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_21 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_22 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_23 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_53 (Dense)             multiple                  12294     [0m
[92m=================================================================[0m
[92mTotal params: 48,523,942[0m
[92mTrainable params: 48,523,926[0m
[92mNon-trainable params: 16[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_20"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_20 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_20 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_60 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_60 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_61 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_61 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_62 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_62 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_60 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_20 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_45 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_61 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_46 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_62 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_20', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_20_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_20', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwCpA07pAAAAAOkCAAAAqQCpAdoBeHIEAAAAcgQAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+0wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_20', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_60', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_60', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_61', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_61', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_62', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_62', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_60', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_20', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_45', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_61', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_46', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_62', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_21"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_21 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_21 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_63 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_63 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_64 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_64 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_65 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_65 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_63 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_21 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_47 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_64 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_48 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_65 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_21', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_21_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_21', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pAgAAAOkEAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+5QEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_21', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_63', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_63', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_64', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_64', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_65', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_65', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_63', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_21', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_47', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_64', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_48', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_65', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER3       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_22"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_22 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_22 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_66 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_66 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_67 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_67 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_68 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_68 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_66 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_22 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_49 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_67 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_50 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_68 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_22', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_22_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_22', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBAAAAOkGAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+9wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_22', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_66', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_66', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_67', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_67', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_68', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_68', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_66', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_22', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_49', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_67', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_50', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_68', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER4       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_23"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_23 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_23 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_69 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_69 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_70 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_70 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_71 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_71 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_69 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_23 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_51 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_70 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_52 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_71 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_23', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_23_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_23', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBgAAAOkIAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+CQIAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_23', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_69', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_69', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_70', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_70', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_71', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_71', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_69', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_23', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_51', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_70', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_52', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_71', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER5       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_53', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 150s 11ms/step - loss: 1.5765 - accuracy: 0.3503
Testing Loss = 1.576453, Testing Accuracy = 0.350327
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 26s 295ms/step - loss: 40.7101 - accuracy: 0.2949 - val_loss: 25.6358 - val_accuracy: 0.2505

Epoch 00001: val_loss improved from inf to 25.63575, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 2/100
83/83 [==============================] - 24s 293ms/step - loss: 18.8891 - accuracy: 0.3217 - val_loss: 14.2007 - val_accuracy: 0.2925

Epoch 00002: val_loss improved from 25.63575 to 14.20075, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 3/100
83/83 [==============================] - 25s 294ms/step - loss: 11.6739 - accuracy: 0.3281 - val_loss: 9.7096 - val_accuracy: 0.3255

Epoch 00003: val_loss improved from 14.20075 to 9.70962, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 4/100
83/83 [==============================] - 25s 295ms/step - loss: 8.3398 - accuracy: 0.3319 - val_loss: 7.1564 - val_accuracy: 0.3413

Epoch 00004: val_loss improved from 9.70962 to 7.15637, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 5/100
83/83 [==============================] - 25s 295ms/step - loss: 6.2551 - accuracy: 0.3352 - val_loss: 5.4291 - val_accuracy: 0.3468

Epoch 00005: val_loss improved from 7.15637 to 5.42910, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 6/100
83/83 [==============================] - 25s 295ms/step - loss: 4.8106 - accuracy: 0.3355 - val_loss: 4.2192 - val_accuracy: 0.3501

Epoch 00006: val_loss improved from 5.42910 to 4.21920, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 7/100
83/83 [==============================] - 25s 294ms/step - loss: 3.7919 - accuracy: 0.3359 - val_loss: 3.3713 - val_accuracy: 0.3499

Epoch 00007: val_loss improved from 4.21920 to 3.37135, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 8/100
83/83 [==============================] - 24s 293ms/step - loss: 3.0810 - accuracy: 0.3377 - val_loss: 2.7821 - val_accuracy: 0.3521

Epoch 00008: val_loss improved from 3.37135 to 2.78215, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 9/100
83/83 [==============================] - 25s 294ms/step - loss: 2.5894 - accuracy: 0.3376 - val_loss: 2.3789 - val_accuracy: 0.3507

Epoch 00009: val_loss improved from 2.78215 to 2.37894, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 10/100
83/83 [==============================] - 24s 293ms/step - loss: 2.2535 - accuracy: 0.3381 - val_loss: 2.1064 - val_accuracy: 0.3525

Epoch 00010: val_loss improved from 2.37894 to 2.10637, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 11/100
83/83 [==============================] - 25s 294ms/step - loss: 2.0298 - accuracy: 0.3369 - val_loss: 1.9252 - val_accuracy: 0.3511

Epoch 00011: val_loss improved from 2.10637 to 1.92517, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 12/100
83/83 [==============================] - 25s 294ms/step - loss: 1.8799 - accuracy: 0.3397 - val_loss: 1.8056 - val_accuracy: 0.3520

Epoch 00012: val_loss improved from 1.92517 to 1.80559, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 13/100
83/83 [==============================] - 24s 294ms/step - loss: 1.7823 - accuracy: 0.3406 - val_loss: 1.7281 - val_accuracy: 0.3519

Epoch 00013: val_loss improved from 1.80559 to 1.72807, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 14/100
83/83 [==============================] - 24s 294ms/step - loss: 1.7176 - accuracy: 0.3396 - val_loss: 1.6779 - val_accuracy: 0.3531

Epoch 00014: val_loss improved from 1.72807 to 1.67795, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 15/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6775 - accuracy: 0.3397 - val_loss: 1.6455 - val_accuracy: 0.3526

Epoch 00015: val_loss improved from 1.67795 to 1.64549, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 16/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6520 - accuracy: 0.3396 - val_loss: 1.6260 - val_accuracy: 0.3550

Epoch 00016: val_loss improved from 1.64549 to 1.62595, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 17/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6358 - accuracy: 0.3388 - val_loss: 1.6122 - val_accuracy: 0.3549

Epoch 00017: val_loss improved from 1.62595 to 1.61222, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 18/100
83/83 [==============================] - 25s 295ms/step - loss: 1.6232 - accuracy: 0.3401 - val_loss: 1.6038 - val_accuracy: 0.3533

Epoch 00018: val_loss improved from 1.61222 to 1.60376, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 19/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6170 - accuracy: 0.3394 - val_loss: 1.5985 - val_accuracy: 0.3536

Epoch 00019: val_loss improved from 1.60376 to 1.59846, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 20/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6114 - accuracy: 0.3410 - val_loss: 1.5941 - val_accuracy: 0.3529

Epoch 00020: val_loss improved from 1.59846 to 1.59409, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 21/100
83/83 [==============================] - 24s 294ms/step - loss: 1.6074 - accuracy: 0.3403 - val_loss: 1.5908 - val_accuracy: 0.3536

Epoch 00021: val_loss improved from 1.59409 to 1.59080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 22/100
83/83 [==============================] - 25s 295ms/step - loss: 1.6053 - accuracy: 0.3409 - val_loss: 1.5888 - val_accuracy: 0.3531

Epoch 00022: val_loss improved from 1.59080 to 1.58882, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 23/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6021 - accuracy: 0.3410 - val_loss: 1.5869 - val_accuracy: 0.3524

Epoch 00023: val_loss improved from 1.58882 to 1.58694, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 24/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6004 - accuracy: 0.3409 - val_loss: 1.5849 - val_accuracy: 0.3524

Epoch 00024: val_loss improved from 1.58694 to 1.58491, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 25/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5994 - accuracy: 0.3418 - val_loss: 1.5838 - val_accuracy: 0.3538

Epoch 00025: val_loss improved from 1.58491 to 1.58382, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 26/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5981 - accuracy: 0.3425 - val_loss: 1.5836 - val_accuracy: 0.3529

Epoch 00026: val_loss improved from 1.58382 to 1.58356, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 27/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5967 - accuracy: 0.3410 - val_loss: 1.5820 - val_accuracy: 0.3531

Epoch 00027: val_loss improved from 1.58356 to 1.58201, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 28/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5959 - accuracy: 0.3417 - val_loss: 1.5820 - val_accuracy: 0.3520

Epoch 00028: val_loss did not improve from 1.58201
Epoch 29/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5936 - accuracy: 0.3439 - val_loss: 1.5806 - val_accuracy: 0.3538

Epoch 00029: val_loss improved from 1.58201 to 1.58059, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 30/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5940 - accuracy: 0.3419 - val_loss: 1.5810 - val_accuracy: 0.3538

Epoch 00030: val_loss did not improve from 1.58059
Epoch 31/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5934 - accuracy: 0.3444 - val_loss: 1.5792 - val_accuracy: 0.3514

Epoch 00031: val_loss improved from 1.58059 to 1.57922, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 32/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5924 - accuracy: 0.3438 - val_loss: 1.5790 - val_accuracy: 0.3537

Epoch 00032: val_loss improved from 1.57922 to 1.57897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 33/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5912 - accuracy: 0.3442 - val_loss: 1.5783 - val_accuracy: 0.3528

Epoch 00033: val_loss improved from 1.57897 to 1.57828, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 34/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5912 - accuracy: 0.3442 - val_loss: 1.5782 - val_accuracy: 0.3545

Epoch 00034: val_loss improved from 1.57828 to 1.57821, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 35/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5909 - accuracy: 0.3431 - val_loss: 1.5776 - val_accuracy: 0.3557

Epoch 00035: val_loss improved from 1.57821 to 1.57763, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 36/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5898 - accuracy: 0.3424 - val_loss: 1.5766 - val_accuracy: 0.3537

Epoch 00036: val_loss improved from 1.57763 to 1.57656, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 37/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5892 - accuracy: 0.3439 - val_loss: 1.5770 - val_accuracy: 0.3538

Epoch 00037: val_loss did not improve from 1.57656
Epoch 38/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5889 - accuracy: 0.3444 - val_loss: 1.5763 - val_accuracy: 0.3554

Epoch 00038: val_loss improved from 1.57656 to 1.57633, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 39/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5891 - accuracy: 0.3437 - val_loss: 1.5759 - val_accuracy: 0.3541

Epoch 00039: val_loss improved from 1.57633 to 1.57595, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 40/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5878 - accuracy: 0.3460 - val_loss: 1.5751 - val_accuracy: 0.3540

Epoch 00040: val_loss improved from 1.57595 to 1.57514, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 41/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5867 - accuracy: 0.3452 - val_loss: 1.5752 - val_accuracy: 0.3565

Epoch 00041: val_loss did not improve from 1.57514
Epoch 42/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5868 - accuracy: 0.3445 - val_loss: 1.5756 - val_accuracy: 0.3565

Epoch 00042: val_loss did not improve from 1.57514
Epoch 43/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5861 - accuracy: 0.3450 - val_loss: 1.5739 - val_accuracy: 0.3559

Epoch 00043: val_loss improved from 1.57514 to 1.57394, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 44/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5861 - accuracy: 0.3457 - val_loss: 1.5742 - val_accuracy: 0.3535

Epoch 00044: val_loss did not improve from 1.57394
Epoch 45/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5855 - accuracy: 0.3457 - val_loss: 1.5739 - val_accuracy: 0.3553

Epoch 00045: val_loss improved from 1.57394 to 1.57391, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 46/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5844 - accuracy: 0.3458 - val_loss: 1.5736 - val_accuracy: 0.3546

Epoch 00046: val_loss improved from 1.57391 to 1.57357, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 47/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5848 - accuracy: 0.3460 - val_loss: 1.5736 - val_accuracy: 0.3532

Epoch 00047: val_loss did not improve from 1.57357
Epoch 48/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5849 - accuracy: 0.3476 - val_loss: 1.5738 - val_accuracy: 0.3569

Epoch 00048: val_loss did not improve from 1.57357
Epoch 49/100
83/83 [==============================] - 25s 296ms/step - loss: 1.5836 - accuracy: 0.3476 - val_loss: 1.5719 - val_accuracy: 0.3561

Epoch 00049: val_loss improved from 1.57357 to 1.57193, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 50/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5843 - accuracy: 0.3464 - val_loss: 1.5721 - val_accuracy: 0.3555

Epoch 00050: val_loss did not improve from 1.57193
Epoch 51/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5828 - accuracy: 0.3482 - val_loss: 1.5711 - val_accuracy: 0.3555

Epoch 00051: val_loss improved from 1.57193 to 1.57110, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 52/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5831 - accuracy: 0.3466 - val_loss: 1.5725 - val_accuracy: 0.3559

Epoch 00052: val_loss did not improve from 1.57110
Epoch 53/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5827 - accuracy: 0.3484 - val_loss: 1.5727 - val_accuracy: 0.3549

Epoch 00053: val_loss did not improve from 1.57110
Epoch 54/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5822 - accuracy: 0.3478 - val_loss: 1.5712 - val_accuracy: 0.3563

Epoch 00054: val_loss did not improve from 1.57110
Epoch 55/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5820 - accuracy: 0.3482 - val_loss: 1.5711 - val_accuracy: 0.3563

Epoch 00055: val_loss did not improve from 1.57110
Epoch 56/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5809 - accuracy: 0.3492 - val_loss: 1.5709 - val_accuracy: 0.3554

Epoch 00056: val_loss improved from 1.57110 to 1.57087, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 57/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5817 - accuracy: 0.3481 - val_loss: 1.5710 - val_accuracy: 0.3552

Epoch 00057: val_loss did not improve from 1.57087
Epoch 58/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5814 - accuracy: 0.3487 - val_loss: 1.5711 - val_accuracy: 0.3537

Epoch 00058: val_loss did not improve from 1.57087
Epoch 59/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5806 - accuracy: 0.3496 - val_loss: 1.5707 - val_accuracy: 0.3562

Epoch 00059: val_loss improved from 1.57087 to 1.57066, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 60/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5807 - accuracy: 0.3482 - val_loss: 1.5702 - val_accuracy: 0.3568

Epoch 00060: val_loss improved from 1.57066 to 1.57017, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 61/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5802 - accuracy: 0.3492 - val_loss: 1.5699 - val_accuracy: 0.3565

Epoch 00061: val_loss improved from 1.57017 to 1.56993, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 62/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5799 - accuracy: 0.3493 - val_loss: 1.5698 - val_accuracy: 0.3538

Epoch 00062: val_loss improved from 1.56993 to 1.56983, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 63/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5793 - accuracy: 0.3502 - val_loss: 1.5699 - val_accuracy: 0.3552

Epoch 00063: val_loss did not improve from 1.56983
Epoch 64/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5794 - accuracy: 0.3493 - val_loss: 1.5705 - val_accuracy: 0.3550

Epoch 00064: val_loss did not improve from 1.56983
Epoch 65/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5786 - accuracy: 0.3490 - val_loss: 1.5697 - val_accuracy: 0.3555

Epoch 00065: val_loss improved from 1.56983 to 1.56974, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 66/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5789 - accuracy: 0.3508 - val_loss: 1.5699 - val_accuracy: 0.3560

Epoch 00066: val_loss did not improve from 1.56974
Epoch 67/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5779 - accuracy: 0.3518 - val_loss: 1.5693 - val_accuracy: 0.3556

Epoch 00067: val_loss improved from 1.56974 to 1.56930, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 68/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5780 - accuracy: 0.3508 - val_loss: 1.5687 - val_accuracy: 0.3558

Epoch 00068: val_loss improved from 1.56930 to 1.56871, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 69/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5777 - accuracy: 0.3502 - val_loss: 1.5695 - val_accuracy: 0.3562

Epoch 00069: val_loss did not improve from 1.56871
Epoch 70/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5779 - accuracy: 0.3498 - val_loss: 1.5699 - val_accuracy: 0.3563

Epoch 00070: val_loss did not improve from 1.56871
Epoch 71/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5775 - accuracy: 0.3519 - val_loss: 1.5696 - val_accuracy: 0.3562

Epoch 00071: val_loss did not improve from 1.56871
Epoch 72/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5782 - accuracy: 0.3522 - val_loss: 1.5689 - val_accuracy: 0.3563

Epoch 00072: val_loss did not improve from 1.56871
Epoch 73/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5766 - accuracy: 0.3508 - val_loss: 1.5686 - val_accuracy: 0.3547

Epoch 00073: val_loss improved from 1.56871 to 1.56857, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 74/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5761 - accuracy: 0.3527 - val_loss: 1.5697 - val_accuracy: 0.3554

Epoch 00074: val_loss did not improve from 1.56857
Epoch 75/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5766 - accuracy: 0.3513 - val_loss: 1.5691 - val_accuracy: 0.3562

Epoch 00075: val_loss did not improve from 1.56857
Epoch 76/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5770 - accuracy: 0.3524 - val_loss: 1.5683 - val_accuracy: 0.3564

Epoch 00076: val_loss improved from 1.56857 to 1.56825, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 77/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5763 - accuracy: 0.3515 - val_loss: 1.5698 - val_accuracy: 0.3562

Epoch 00077: val_loss did not improve from 1.56825
Epoch 78/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5761 - accuracy: 0.3518 - val_loss: 1.5682 - val_accuracy: 0.3545

Epoch 00078: val_loss improved from 1.56825 to 1.56820, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/6
Epoch 79/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5755 - accuracy: 0.3532 - val_loss: 1.5685 - val_accuracy: 0.3562

Epoch 00079: val_loss did not improve from 1.56820
Epoch 80/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5747 - accuracy: 0.3519 - val_loss: 1.5696 - val_accuracy: 0.3535

Epoch 00080: val_loss did not improve from 1.56820
Epoch 81/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5752 - accuracy: 0.3523 - val_loss: 1.5692 - val_accuracy: 0.3566

Epoch 00081: val_loss did not improve from 1.56820
Epoch 82/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5754 - accuracy: 0.3532 - val_loss: 1.5688 - val_accuracy: 0.3546

Epoch 00082: val_loss did not improve from 1.56820
Epoch 83/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5745 - accuracy: 0.3520 - val_loss: 1.5686 - val_accuracy: 0.3543

Epoch 00083: val_loss did not improve from 1.56820
Epoch 84/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5733 - accuracy: 0.3551 - val_loss: 1.5695 - val_accuracy: 0.3538

Epoch 00084: val_loss did not improve from 1.56820
Epoch 85/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5748 - accuracy: 0.3542 - val_loss: 1.5686 - val_accuracy: 0.3552

Epoch 00085: val_loss did not improve from 1.56820
Epoch 86/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5739 - accuracy: 0.3538 - val_loss: 1.5690 - val_accuracy: 0.3557

Epoch 00086: val_loss did not improve from 1.56820
Epoch 00086: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_4jet"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_24 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_25 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_26 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_27 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_62 (Dense)             multiple                  12294     [0m
[92m=================================================================[0m
[92mTotal params: 48,523,942[0m
[92mTrainable params: 48,523,926[0m
[92mNon-trainable params: 16[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_24"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_24 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_24 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_72 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_72 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_73 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_73 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_74 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_74 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_72 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_24 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_54 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_73 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_55 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_74 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_24', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_24_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_24', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwCpA07pAAAAAOkCAAAAqQCpAdoBeHIEAAAAcgQAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+0wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_24', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_72', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_72', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_73', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_73', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_74', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_74', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_72', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_24', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_54', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_73', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_55', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_74', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_25"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_25 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_25 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_75 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_75 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_76 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_76 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_77 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_77 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_75 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_25 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_56 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_76 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_57 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_77 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_25', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_25_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_25', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pAgAAAOkEAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+5QEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_25', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_75', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_75', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_76', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_76', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_77', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_77', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_75', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_25', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_56', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_76', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_57', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_77', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER3       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_26"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_26 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_26 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_78 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_78 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_79 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_79 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_80 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_80 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_78 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_26 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_58 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_79 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_59 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_80 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_26', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_26_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_26', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBAAAAOkGAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+9wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_26', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_78', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_78', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_79', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_79', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_80', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_80', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_78', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_26', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_58', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_79', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_59', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_80', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER4       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_27"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_27 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_27 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_81 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_81 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_82 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_82 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_83 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_83 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_81 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_27 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_60 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_82 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_61 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_83 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_27', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_27_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_27', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBgAAAOkIAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+CQIAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_27', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_81', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_81', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_82', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_82', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_83', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_83', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_81', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_27', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_60', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_82', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_61', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_83', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER5       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_62', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 149s 11ms/step - loss: 1.5726 - accuracy: 0.3516
Testing Loss = 1.572612, Testing Accuracy = 0.351593
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 26s 294ms/step - loss: 40.7519 - accuracy: 0.2993 - val_loss: 25.6912 - val_accuracy: 0.2621

Epoch 00001: val_loss improved from inf to 25.69125, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 2/100
83/83 [==============================] - 24s 293ms/step - loss: 18.9422 - accuracy: 0.3212 - val_loss: 14.2520 - val_accuracy: 0.3041

Epoch 00002: val_loss improved from 25.69125 to 14.25196, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 3/100
83/83 [==============================] - 24s 293ms/step - loss: 11.7172 - accuracy: 0.3255 - val_loss: 9.7475 - val_accuracy: 0.3235

Epoch 00003: val_loss improved from 14.25196 to 9.74754, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 4/100
83/83 [==============================] - 24s 294ms/step - loss: 8.3716 - accuracy: 0.3310 - val_loss: 7.1808 - val_accuracy: 0.3445

Epoch 00004: val_loss improved from 9.74754 to 7.18077, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 5/100
83/83 [==============================] - 24s 293ms/step - loss: 6.2781 - accuracy: 0.3317 - val_loss: 5.4477 - val_accuracy: 0.3465

Epoch 00005: val_loss improved from 7.18077 to 5.44771, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 6/100
83/83 [==============================] - 24s 293ms/step - loss: 4.8250 - accuracy: 0.3341 - val_loss: 4.2289 - val_accuracy: 0.3465

Epoch 00006: val_loss improved from 5.44771 to 4.22888, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 7/100
83/83 [==============================] - 24s 293ms/step - loss: 3.8018 - accuracy: 0.3356 - val_loss: 3.3784 - val_accuracy: 0.3492

Epoch 00007: val_loss improved from 4.22888 to 3.37840, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 8/100
83/83 [==============================] - 24s 294ms/step - loss: 3.0875 - accuracy: 0.3379 - val_loss: 2.7879 - val_accuracy: 0.3484

Epoch 00008: val_loss improved from 3.37840 to 2.78794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 9/100
83/83 [==============================] - 24s 294ms/step - loss: 2.5950 - accuracy: 0.3351 - val_loss: 2.3825 - val_accuracy: 0.3498

Epoch 00009: val_loss improved from 2.78794 to 2.38250, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 10/100
83/83 [==============================] - 24s 293ms/step - loss: 2.2571 - accuracy: 0.3378 - val_loss: 2.1096 - val_accuracy: 0.3497

Epoch 00010: val_loss improved from 2.38250 to 2.10964, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 11/100
83/83 [==============================] - 24s 294ms/step - loss: 2.0325 - accuracy: 0.3360 - val_loss: 1.9273 - val_accuracy: 0.3519

Epoch 00011: val_loss improved from 2.10964 to 1.92732, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 12/100
83/83 [==============================] - 24s 294ms/step - loss: 1.8808 - accuracy: 0.3379 - val_loss: 1.8056 - val_accuracy: 0.3519

Epoch 00012: val_loss improved from 1.92732 to 1.80563, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 13/100
83/83 [==============================] - 25s 294ms/step - loss: 1.7828 - accuracy: 0.3399 - val_loss: 1.7291 - val_accuracy: 0.3526

Epoch 00013: val_loss improved from 1.80563 to 1.72912, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 14/100
83/83 [==============================] - 24s 293ms/step - loss: 1.7188 - accuracy: 0.3386 - val_loss: 1.6780 - val_accuracy: 0.3522

Epoch 00014: val_loss improved from 1.72912 to 1.67804, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 15/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6779 - accuracy: 0.3407 - val_loss: 1.6459 - val_accuracy: 0.3527

Epoch 00015: val_loss improved from 1.67804 to 1.64591, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 16/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6521 - accuracy: 0.3413 - val_loss: 1.6257 - val_accuracy: 0.3513

Epoch 00016: val_loss improved from 1.64591 to 1.62572, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 17/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6351 - accuracy: 0.3404 - val_loss: 1.6130 - val_accuracy: 0.3544

Epoch 00017: val_loss improved from 1.62572 to 1.61299, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 18/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6242 - accuracy: 0.3400 - val_loss: 1.6039 - val_accuracy: 0.3539

Epoch 00018: val_loss improved from 1.61299 to 1.60391, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 19/100
83/83 [==============================] - 24s 294ms/step - loss: 1.6160 - accuracy: 0.3415 - val_loss: 1.5979 - val_accuracy: 0.3537

Epoch 00019: val_loss improved from 1.60391 to 1.59790, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 20/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6104 - accuracy: 0.3433 - val_loss: 1.5935 - val_accuracy: 0.3517

Epoch 00020: val_loss improved from 1.59790 to 1.59351, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 21/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6082 - accuracy: 0.3404 - val_loss: 1.5910 - val_accuracy: 0.3519

Epoch 00021: val_loss improved from 1.59351 to 1.59104, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 22/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6045 - accuracy: 0.3421 - val_loss: 1.5881 - val_accuracy: 0.3536

Epoch 00022: val_loss improved from 1.59104 to 1.58814, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 23/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6025 - accuracy: 0.3424 - val_loss: 1.5866 - val_accuracy: 0.3524

Epoch 00023: val_loss improved from 1.58814 to 1.58656, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 24/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6003 - accuracy: 0.3416 - val_loss: 1.5854 - val_accuracy: 0.3529

Epoch 00024: val_loss improved from 1.58656 to 1.58536, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 25/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5987 - accuracy: 0.3424 - val_loss: 1.5839 - val_accuracy: 0.3533

Epoch 00025: val_loss improved from 1.58536 to 1.58392, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 26/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5980 - accuracy: 0.3416 - val_loss: 1.5837 - val_accuracy: 0.3518

Epoch 00026: val_loss improved from 1.58392 to 1.58365, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 27/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5974 - accuracy: 0.3406 - val_loss: 1.5825 - val_accuracy: 0.3533

Epoch 00027: val_loss improved from 1.58365 to 1.58245, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 28/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5951 - accuracy: 0.3420 - val_loss: 1.5812 - val_accuracy: 0.3526

Epoch 00028: val_loss improved from 1.58245 to 1.58124, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 29/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5941 - accuracy: 0.3436 - val_loss: 1.5807 - val_accuracy: 0.3520

Epoch 00029: val_loss improved from 1.58124 to 1.58066, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 30/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5936 - accuracy: 0.3432 - val_loss: 1.5800 - val_accuracy: 0.3518

Epoch 00030: val_loss improved from 1.58066 to 1.57999, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 31/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5927 - accuracy: 0.3441 - val_loss: 1.5793 - val_accuracy: 0.3534

Epoch 00031: val_loss improved from 1.57999 to 1.57933, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 32/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5919 - accuracy: 0.3447 - val_loss: 1.5785 - val_accuracy: 0.3533

Epoch 00032: val_loss improved from 1.57933 to 1.57852, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 33/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5922 - accuracy: 0.3439 - val_loss: 1.5781 - val_accuracy: 0.3513

Epoch 00033: val_loss improved from 1.57852 to 1.57814, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 34/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5905 - accuracy: 0.3449 - val_loss: 1.5775 - val_accuracy: 0.3547

Epoch 00034: val_loss improved from 1.57814 to 1.57752, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 35/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5905 - accuracy: 0.3441 - val_loss: 1.5775 - val_accuracy: 0.3539

Epoch 00035: val_loss improved from 1.57752 to 1.57747, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 36/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5892 - accuracy: 0.3443 - val_loss: 1.5767 - val_accuracy: 0.3538

Epoch 00036: val_loss improved from 1.57747 to 1.57667, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 37/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5893 - accuracy: 0.3440 - val_loss: 1.5763 - val_accuracy: 0.3549

Epoch 00037: val_loss improved from 1.57667 to 1.57626, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 38/100
83/83 [==============================] - 24s 292ms/step - loss: 1.5891 - accuracy: 0.3450 - val_loss: 1.5753 - val_accuracy: 0.3539

Epoch 00038: val_loss improved from 1.57626 to 1.57533, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 39/100
83/83 [==============================] - 24s 292ms/step - loss: 1.5885 - accuracy: 0.3443 - val_loss: 1.5752 - val_accuracy: 0.3537

Epoch 00039: val_loss improved from 1.57533 to 1.57521, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 40/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5875 - accuracy: 0.3442 - val_loss: 1.5757 - val_accuracy: 0.3555

Epoch 00040: val_loss did not improve from 1.57521
Epoch 41/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5867 - accuracy: 0.3438 - val_loss: 1.5749 - val_accuracy: 0.3539

Epoch 00041: val_loss improved from 1.57521 to 1.57491, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 42/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5873 - accuracy: 0.3452 - val_loss: 1.5751 - val_accuracy: 0.3544

Epoch 00042: val_loss did not improve from 1.57491
Epoch 43/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5858 - accuracy: 0.3466 - val_loss: 1.5746 - val_accuracy: 0.3550

Epoch 00043: val_loss improved from 1.57491 to 1.57463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 44/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5857 - accuracy: 0.3447 - val_loss: 1.5737 - val_accuracy: 0.3547

Epoch 00044: val_loss improved from 1.57463 to 1.57367, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 45/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5849 - accuracy: 0.3459 - val_loss: 1.5748 - val_accuracy: 0.3542

Epoch 00045: val_loss did not improve from 1.57367
Epoch 46/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5851 - accuracy: 0.3458 - val_loss: 1.5739 - val_accuracy: 0.3549

Epoch 00046: val_loss did not improve from 1.57367
Epoch 47/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5845 - accuracy: 0.3469 - val_loss: 1.5739 - val_accuracy: 0.3539

Epoch 00047: val_loss did not improve from 1.57367
Epoch 48/100
83/83 [==============================] - 24s 292ms/step - loss: 1.5852 - accuracy: 0.3466 - val_loss: 1.5732 - val_accuracy: 0.3538

Epoch 00048: val_loss improved from 1.57367 to 1.57324, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 49/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5851 - accuracy: 0.3450 - val_loss: 1.5745 - val_accuracy: 0.3544

Epoch 00049: val_loss did not improve from 1.57324
Epoch 50/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5842 - accuracy: 0.3464 - val_loss: 1.5731 - val_accuracy: 0.3523

Epoch 00050: val_loss improved from 1.57324 to 1.57314, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 51/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5833 - accuracy: 0.3477 - val_loss: 1.5726 - val_accuracy: 0.3530

Epoch 00051: val_loss improved from 1.57314 to 1.57260, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 52/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5829 - accuracy: 0.3470 - val_loss: 1.5725 - val_accuracy: 0.3540

Epoch 00052: val_loss improved from 1.57260 to 1.57254, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 53/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5829 - accuracy: 0.3469 - val_loss: 1.5719 - val_accuracy: 0.3554

Epoch 00053: val_loss improved from 1.57254 to 1.57190, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 54/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5818 - accuracy: 0.3487 - val_loss: 1.5722 - val_accuracy: 0.3556

Epoch 00054: val_loss did not improve from 1.57190
Epoch 55/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5822 - accuracy: 0.3475 - val_loss: 1.5725 - val_accuracy: 0.3528

Epoch 00055: val_loss did not improve from 1.57190
Epoch 56/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5820 - accuracy: 0.3478 - val_loss: 1.5709 - val_accuracy: 0.3529

Epoch 00056: val_loss improved from 1.57190 to 1.57093, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 57/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5819 - accuracy: 0.3481 - val_loss: 1.5711 - val_accuracy: 0.3549

Epoch 00057: val_loss did not improve from 1.57093
Epoch 58/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5816 - accuracy: 0.3470 - val_loss: 1.5717 - val_accuracy: 0.3551

Epoch 00058: val_loss did not improve from 1.57093
Epoch 59/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5810 - accuracy: 0.3490 - val_loss: 1.5705 - val_accuracy: 0.3549

Epoch 00059: val_loss improved from 1.57093 to 1.57045, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 60/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5813 - accuracy: 0.3473 - val_loss: 1.5714 - val_accuracy: 0.3544

Epoch 00060: val_loss did not improve from 1.57045
Epoch 61/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5794 - accuracy: 0.3484 - val_loss: 1.5707 - val_accuracy: 0.3557

Epoch 00061: val_loss did not improve from 1.57045
Epoch 62/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5794 - accuracy: 0.3491 - val_loss: 1.5700 - val_accuracy: 0.3528

Epoch 00062: val_loss improved from 1.57045 to 1.57001, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 63/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5797 - accuracy: 0.3493 - val_loss: 1.5701 - val_accuracy: 0.3552

Epoch 00063: val_loss did not improve from 1.57001
Epoch 64/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5784 - accuracy: 0.3504 - val_loss: 1.5709 - val_accuracy: 0.3517

Epoch 00064: val_loss did not improve from 1.57001
Epoch 65/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5787 - accuracy: 0.3521 - val_loss: 1.5698 - val_accuracy: 0.3538

Epoch 00065: val_loss improved from 1.57001 to 1.56983, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 66/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5791 - accuracy: 0.3510 - val_loss: 1.5704 - val_accuracy: 0.3534

Epoch 00066: val_loss did not improve from 1.56983
Epoch 67/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5790 - accuracy: 0.3494 - val_loss: 1.5707 - val_accuracy: 0.3561

Epoch 00067: val_loss did not improve from 1.56983
Epoch 68/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5789 - accuracy: 0.3511 - val_loss: 1.5703 - val_accuracy: 0.3540

Epoch 00068: val_loss did not improve from 1.56983
Epoch 69/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5786 - accuracy: 0.3495 - val_loss: 1.5703 - val_accuracy: 0.3543

Epoch 00069: val_loss did not improve from 1.56983
Epoch 70/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5779 - accuracy: 0.3514 - val_loss: 1.5700 - val_accuracy: 0.3548

Epoch 00070: val_loss did not improve from 1.56983
Epoch 71/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5780 - accuracy: 0.3525 - val_loss: 1.5696 - val_accuracy: 0.3535

Epoch 00071: val_loss improved from 1.56983 to 1.56964, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 72/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5787 - accuracy: 0.3488 - val_loss: 1.5692 - val_accuracy: 0.3539

Epoch 00072: val_loss improved from 1.56964 to 1.56918, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 73/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5770 - accuracy: 0.3523 - val_loss: 1.5693 - val_accuracy: 0.3556

Epoch 00073: val_loss did not improve from 1.56918
Epoch 74/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5765 - accuracy: 0.3539 - val_loss: 1.5687 - val_accuracy: 0.3558

Epoch 00074: val_loss improved from 1.56918 to 1.56870, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 75/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5772 - accuracy: 0.3509 - val_loss: 1.5693 - val_accuracy: 0.3557

Epoch 00075: val_loss did not improve from 1.56870
Epoch 76/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5769 - accuracy: 0.3526 - val_loss: 1.5688 - val_accuracy: 0.3545

Epoch 00076: val_loss did not improve from 1.56870
Epoch 77/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5759 - accuracy: 0.3499 - val_loss: 1.5692 - val_accuracy: 0.3552

Epoch 00077: val_loss did not improve from 1.56870
Epoch 78/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5763 - accuracy: 0.3527 - val_loss: 1.5693 - val_accuracy: 0.3557

Epoch 00078: val_loss did not improve from 1.56870
Epoch 79/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5755 - accuracy: 0.3522 - val_loss: 1.5692 - val_accuracy: 0.3557

Epoch 00079: val_loss did not improve from 1.56870
Epoch 80/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5763 - accuracy: 0.3518 - val_loss: 1.5682 - val_accuracy: 0.3538

Epoch 00080: val_loss improved from 1.56870 to 1.56824, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/7
Epoch 81/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5756 - accuracy: 0.3510 - val_loss: 1.5689 - val_accuracy: 0.3553

Epoch 00081: val_loss did not improve from 1.56824
Epoch 82/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5751 - accuracy: 0.3510 - val_loss: 1.5687 - val_accuracy: 0.3553

Epoch 00082: val_loss did not improve from 1.56824
Epoch 83/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5744 - accuracy: 0.3539 - val_loss: 1.5690 - val_accuracy: 0.3556

Epoch 00083: val_loss did not improve from 1.56824
Epoch 84/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5739 - accuracy: 0.3524 - val_loss: 1.5686 - val_accuracy: 0.3561

Epoch 00084: val_loss did not improve from 1.56824
Epoch 85/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5743 - accuracy: 0.3537 - val_loss: 1.5687 - val_accuracy: 0.3569

Epoch 00085: val_loss did not improve from 1.56824
Epoch 86/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5742 - accuracy: 0.3518 - val_loss: 1.5690 - val_accuracy: 0.3556

Epoch 00086: val_loss did not improve from 1.56824
Epoch 87/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5741 - accuracy: 0.3531 - val_loss: 1.5689 - val_accuracy: 0.3552

Epoch 00087: val_loss did not improve from 1.56824
Epoch 88/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5732 - accuracy: 0.3531 - val_loss: 1.5690 - val_accuracy: 0.3554

Epoch 00088: val_loss did not improve from 1.56824
Epoch 89/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5729 - accuracy: 0.3529 - val_loss: 1.5690 - val_accuracy: 0.3545

Epoch 00089: val_loss did not improve from 1.56824
Epoch 90/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5742 - accuracy: 0.3531 - val_loss: 1.5688 - val_accuracy: 0.3559

Epoch 00090: val_loss did not improve from 1.56824
Epoch 00090: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_4jet"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_28 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_29 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_30 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_31 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_71 (Dense)             multiple                  12294     [0m
[92m=================================================================[0m
[92mTotal params: 48,523,942[0m
[92mTrainable params: 48,523,926[0m
[92mNon-trainable params: 16[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_28"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_28 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_28 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_84 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_84 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_85 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_85 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_86 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_86 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_84 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_28 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_63 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_85 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_64 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_86 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_28', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_28_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_28', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwCpA07pAAAAAOkCAAAAqQCpAdoBeHIEAAAAcgQAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+0wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_28', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_84', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_84', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_85', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_85', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_86', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_86', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_84', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_28', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_63', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_85', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_64', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_86', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_29"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_29 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_29 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_87 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_87 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_88 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_88 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_89 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_89 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_87 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_29 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_65 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_88 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_66 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_89 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_29', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_29_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_29', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pAgAAAOkEAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+5QEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_29', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_87', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_87', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_88', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_88', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_89', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_89', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_87', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_29', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_65', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_88', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_66', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_89', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER3       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_30"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_30 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_30 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_90 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_90 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_91 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_91 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_92 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_92 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_90 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_30 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_67 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_91 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_68 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_92 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_30', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_30_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_30', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBAAAAOkGAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+9wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_30', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_90', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_90', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_91', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_91', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_92', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_92', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_90', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_30', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_67', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_91', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_68', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_92', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER4       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_31"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_31 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_31 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_93 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_93 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_94 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_94 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_95 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_95 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_93 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_31 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_69 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_94 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_70 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_95 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_31', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_31_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_31', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBgAAAOkIAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+CQIAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_31', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_93', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_93', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_94', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_94', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_95', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_95', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_93', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_31', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_69', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_94', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_70', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_95', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER5       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_71', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 150s 11ms/step - loss: 1.5732 - accuracy: 0.3525
Testing Loss = 1.573246, Testing Accuracy = 0.352486
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 26s 296ms/step - loss: 40.6643 - accuracy: 0.2948 - val_loss: 25.6032 - val_accuracy: 0.2714

Epoch 00001: val_loss improved from inf to 25.60323, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 2/100
83/83 [==============================] - 24s 293ms/step - loss: 18.8838 - accuracy: 0.3229 - val_loss: 14.2112 - val_accuracy: 0.3081

Epoch 00002: val_loss improved from 25.60323 to 14.21121, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 3/100
83/83 [==============================] - 25s 294ms/step - loss: 11.6875 - accuracy: 0.3283 - val_loss: 9.7226 - val_accuracy: 0.3271

Epoch 00003: val_loss improved from 14.21121 to 9.72257, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 4/100
83/83 [==============================] - 24s 292ms/step - loss: 8.3555 - accuracy: 0.3309 - val_loss: 7.1690 - val_accuracy: 0.3477

Epoch 00004: val_loss improved from 9.72257 to 7.16897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 5/100
83/83 [==============================] - 24s 293ms/step - loss: 6.2687 - accuracy: 0.3323 - val_loss: 5.4370 - val_accuracy: 0.3503

Epoch 00005: val_loss improved from 7.16897 to 5.43696, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 6/100
83/83 [==============================] - 24s 293ms/step - loss: 4.8200 - accuracy: 0.3358 - val_loss: 4.2273 - val_accuracy: 0.3485

Epoch 00006: val_loss improved from 5.43696 to 4.22731, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 7/100
83/83 [==============================] - 25s 294ms/step - loss: 3.8007 - accuracy: 0.3351 - val_loss: 3.3779 - val_accuracy: 0.3496

Epoch 00007: val_loss improved from 4.22731 to 3.37790, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 8/100
83/83 [==============================] - 24s 294ms/step - loss: 3.0886 - accuracy: 0.3353 - val_loss: 2.7886 - val_accuracy: 0.3527

Epoch 00008: val_loss improved from 3.37790 to 2.78864, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 9/100
83/83 [==============================] - 24s 294ms/step - loss: 2.5940 - accuracy: 0.3399 - val_loss: 2.3835 - val_accuracy: 0.3518

Epoch 00009: val_loss improved from 2.78864 to 2.38348, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 10/100
83/83 [==============================] - 24s 294ms/step - loss: 2.2582 - accuracy: 0.3380 - val_loss: 2.1104 - val_accuracy: 0.3514

Epoch 00010: val_loss improved from 2.38348 to 2.11043, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 11/100
83/83 [==============================] - 25s 294ms/step - loss: 2.0329 - accuracy: 0.3369 - val_loss: 1.9283 - val_accuracy: 0.3525

Epoch 00011: val_loss improved from 2.11043 to 1.92830, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 12/100
83/83 [==============================] - 25s 294ms/step - loss: 1.8845 - accuracy: 0.3391 - val_loss: 1.8081 - val_accuracy: 0.3541

Epoch 00012: val_loss improved from 1.92830 to 1.80811, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 13/100
83/83 [==============================] - 24s 294ms/step - loss: 1.7846 - accuracy: 0.3391 - val_loss: 1.7299 - val_accuracy: 0.3537

Epoch 00013: val_loss improved from 1.80811 to 1.72987, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 14/100
83/83 [==============================] - 24s 294ms/step - loss: 1.7210 - accuracy: 0.3384 - val_loss: 1.6791 - val_accuracy: 0.3532

Epoch 00014: val_loss improved from 1.72987 to 1.67914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 15/100
83/83 [==============================] - 24s 294ms/step - loss: 1.6791 - accuracy: 0.3398 - val_loss: 1.6468 - val_accuracy: 0.3523

Epoch 00015: val_loss improved from 1.67914 to 1.64684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 16/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6530 - accuracy: 0.3401 - val_loss: 1.6255 - val_accuracy: 0.3537

Epoch 00016: val_loss improved from 1.64684 to 1.62552, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 17/100
83/83 [==============================] - 24s 294ms/step - loss: 1.6363 - accuracy: 0.3406 - val_loss: 1.6133 - val_accuracy: 0.3538

Epoch 00017: val_loss improved from 1.62552 to 1.61326, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 18/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6246 - accuracy: 0.3398 - val_loss: 1.6053 - val_accuracy: 0.3535

Epoch 00018: val_loss improved from 1.61326 to 1.60525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 19/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6178 - accuracy: 0.3400 - val_loss: 1.5989 - val_accuracy: 0.3525

Epoch 00019: val_loss improved from 1.60525 to 1.59887, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 20/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6117 - accuracy: 0.3408 - val_loss: 1.5947 - val_accuracy: 0.3525

Epoch 00020: val_loss improved from 1.59887 to 1.59467, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 21/100
83/83 [==============================] - 24s 294ms/step - loss: 1.6086 - accuracy: 0.3399 - val_loss: 1.5914 - val_accuracy: 0.3537

Epoch 00021: val_loss improved from 1.59467 to 1.59144, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 22/100
83/83 [==============================] - 25s 295ms/step - loss: 1.6050 - accuracy: 0.3424 - val_loss: 1.5892 - val_accuracy: 0.3551

Epoch 00022: val_loss improved from 1.59144 to 1.58921, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 23/100
83/83 [==============================] - 24s 294ms/step - loss: 1.6035 - accuracy: 0.3405 - val_loss: 1.5882 - val_accuracy: 0.3542

Epoch 00023: val_loss improved from 1.58921 to 1.58824, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 24/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6014 - accuracy: 0.3426 - val_loss: 1.5868 - val_accuracy: 0.3539

Epoch 00024: val_loss improved from 1.58824 to 1.58676, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 25/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5999 - accuracy: 0.3420 - val_loss: 1.5853 - val_accuracy: 0.3531

Epoch 00025: val_loss improved from 1.58676 to 1.58533, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 26/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5989 - accuracy: 0.3425 - val_loss: 1.5835 - val_accuracy: 0.3555

Epoch 00026: val_loss improved from 1.58533 to 1.58355, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 27/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5967 - accuracy: 0.3436 - val_loss: 1.5830 - val_accuracy: 0.3539

Epoch 00027: val_loss improved from 1.58355 to 1.58304, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 28/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5964 - accuracy: 0.3435 - val_loss: 1.5811 - val_accuracy: 0.3552

Epoch 00028: val_loss improved from 1.58304 to 1.58107, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 29/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5949 - accuracy: 0.3434 - val_loss: 1.5812 - val_accuracy: 0.3532

Epoch 00029: val_loss did not improve from 1.58107
Epoch 30/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5937 - accuracy: 0.3444 - val_loss: 1.5804 - val_accuracy: 0.3535

Epoch 00030: val_loss improved from 1.58107 to 1.58039, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 31/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5935 - accuracy: 0.3421 - val_loss: 1.5796 - val_accuracy: 0.3539

Epoch 00031: val_loss improved from 1.58039 to 1.57961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 32/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5925 - accuracy: 0.3434 - val_loss: 1.5793 - val_accuracy: 0.3540

Epoch 00032: val_loss improved from 1.57961 to 1.57929, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 33/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5924 - accuracy: 0.3435 - val_loss: 1.5791 - val_accuracy: 0.3539

Epoch 00033: val_loss improved from 1.57929 to 1.57907, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 34/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5903 - accuracy: 0.3426 - val_loss: 1.5790 - val_accuracy: 0.3547

Epoch 00034: val_loss improved from 1.57907 to 1.57903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 35/100
83/83 [==============================] - 24s 292ms/step - loss: 1.5907 - accuracy: 0.3440 - val_loss: 1.5784 - val_accuracy: 0.3527

Epoch 00035: val_loss improved from 1.57903 to 1.57836, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 36/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5895 - accuracy: 0.3449 - val_loss: 1.5773 - val_accuracy: 0.3560

Epoch 00036: val_loss improved from 1.57836 to 1.57733, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 37/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5900 - accuracy: 0.3433 - val_loss: 1.5769 - val_accuracy: 0.3532

Epoch 00037: val_loss improved from 1.57733 to 1.57688, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 38/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5891 - accuracy: 0.3454 - val_loss: 1.5772 - val_accuracy: 0.3552

Epoch 00038: val_loss did not improve from 1.57688
Epoch 39/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5878 - accuracy: 0.3439 - val_loss: 1.5763 - val_accuracy: 0.3535

Epoch 00039: val_loss improved from 1.57688 to 1.57632, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 40/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5876 - accuracy: 0.3461 - val_loss: 1.5768 - val_accuracy: 0.3533

Epoch 00040: val_loss did not improve from 1.57632
Epoch 41/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5873 - accuracy: 0.3450 - val_loss: 1.5757 - val_accuracy: 0.3535

Epoch 00041: val_loss improved from 1.57632 to 1.57573, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 42/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5865 - accuracy: 0.3468 - val_loss: 1.5748 - val_accuracy: 0.3548

Epoch 00042: val_loss improved from 1.57573 to 1.57477, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 43/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5872 - accuracy: 0.3468 - val_loss: 1.5757 - val_accuracy: 0.3539

Epoch 00043: val_loss did not improve from 1.57477
Epoch 44/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5869 - accuracy: 0.3481 - val_loss: 1.5749 - val_accuracy: 0.3525

Epoch 00044: val_loss did not improve from 1.57477
Epoch 45/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5862 - accuracy: 0.3452 - val_loss: 1.5750 - val_accuracy: 0.3530

Epoch 00045: val_loss did not improve from 1.57477
Epoch 46/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5856 - accuracy: 0.3458 - val_loss: 1.5749 - val_accuracy: 0.3531

Epoch 00046: val_loss did not improve from 1.57477
Epoch 47/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5852 - accuracy: 0.3451 - val_loss: 1.5751 - val_accuracy: 0.3531

Epoch 00047: val_loss did not improve from 1.57477
Epoch 48/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5851 - accuracy: 0.3459 - val_loss: 1.5744 - val_accuracy: 0.3539

Epoch 00048: val_loss improved from 1.57477 to 1.57442, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 49/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5843 - accuracy: 0.3461 - val_loss: 1.5741 - val_accuracy: 0.3534

Epoch 00049: val_loss improved from 1.57442 to 1.57406, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 50/100
83/83 [==============================] - 24s 292ms/step - loss: 1.5844 - accuracy: 0.3477 - val_loss: 1.5741 - val_accuracy: 0.3547

Epoch 00050: val_loss did not improve from 1.57406
Epoch 51/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5839 - accuracy: 0.3471 - val_loss: 1.5741 - val_accuracy: 0.3543

Epoch 00051: val_loss did not improve from 1.57406
Epoch 52/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5836 - accuracy: 0.3450 - val_loss: 1.5739 - val_accuracy: 0.3538

Epoch 00052: val_loss improved from 1.57406 to 1.57393, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 53/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5834 - accuracy: 0.3474 - val_loss: 1.5732 - val_accuracy: 0.3541

Epoch 00053: val_loss improved from 1.57393 to 1.57323, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 54/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5824 - accuracy: 0.3466 - val_loss: 1.5731 - val_accuracy: 0.3546

Epoch 00054: val_loss improved from 1.57323 to 1.57313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 55/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5820 - accuracy: 0.3477 - val_loss: 1.5731 - val_accuracy: 0.3546

Epoch 00055: val_loss improved from 1.57313 to 1.57310, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 56/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5828 - accuracy: 0.3481 - val_loss: 1.5722 - val_accuracy: 0.3538

Epoch 00056: val_loss improved from 1.57310 to 1.57222, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 57/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5830 - accuracy: 0.3476 - val_loss: 1.5721 - val_accuracy: 0.3532

Epoch 00057: val_loss improved from 1.57222 to 1.57211, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 58/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5816 - accuracy: 0.3501 - val_loss: 1.5723 - val_accuracy: 0.3543

Epoch 00058: val_loss did not improve from 1.57211
Epoch 59/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5814 - accuracy: 0.3492 - val_loss: 1.5717 - val_accuracy: 0.3551

Epoch 00059: val_loss improved from 1.57211 to 1.57168, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 60/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5806 - accuracy: 0.3471 - val_loss: 1.5721 - val_accuracy: 0.3539

Epoch 00060: val_loss did not improve from 1.57168
Epoch 61/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5811 - accuracy: 0.3479 - val_loss: 1.5723 - val_accuracy: 0.3529

Epoch 00061: val_loss did not improve from 1.57168
Epoch 62/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5811 - accuracy: 0.3478 - val_loss: 1.5716 - val_accuracy: 0.3537

Epoch 00062: val_loss improved from 1.57168 to 1.57157, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 63/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5802 - accuracy: 0.3489 - val_loss: 1.5720 - val_accuracy: 0.3528

Epoch 00063: val_loss did not improve from 1.57157
Epoch 64/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5802 - accuracy: 0.3483 - val_loss: 1.5713 - val_accuracy: 0.3541

Epoch 00064: val_loss improved from 1.57157 to 1.57126, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 65/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5799 - accuracy: 0.3504 - val_loss: 1.5713 - val_accuracy: 0.3557

Epoch 00065: val_loss did not improve from 1.57126
Epoch 66/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5792 - accuracy: 0.3522 - val_loss: 1.5711 - val_accuracy: 0.3540

Epoch 00066: val_loss improved from 1.57126 to 1.57110, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 67/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5795 - accuracy: 0.3496 - val_loss: 1.5719 - val_accuracy: 0.3536

Epoch 00067: val_loss did not improve from 1.57110
Epoch 68/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5797 - accuracy: 0.3493 - val_loss: 1.5711 - val_accuracy: 0.3545

Epoch 00068: val_loss did not improve from 1.57110
Epoch 69/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5791 - accuracy: 0.3491 - val_loss: 1.5709 - val_accuracy: 0.3552

Epoch 00069: val_loss improved from 1.57110 to 1.57088, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 70/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5778 - accuracy: 0.3495 - val_loss: 1.5717 - val_accuracy: 0.3540

Epoch 00070: val_loss did not improve from 1.57088
Epoch 71/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5788 - accuracy: 0.3504 - val_loss: 1.5719 - val_accuracy: 0.3545

Epoch 00071: val_loss did not improve from 1.57088
Epoch 72/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5790 - accuracy: 0.3494 - val_loss: 1.5718 - val_accuracy: 0.3550

Epoch 00072: val_loss did not improve from 1.57088
Epoch 73/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5784 - accuracy: 0.3504 - val_loss: 1.5718 - val_accuracy: 0.3531

Epoch 00073: val_loss did not improve from 1.57088
Epoch 74/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5781 - accuracy: 0.3511 - val_loss: 1.5707 - val_accuracy: 0.3549

Epoch 00074: val_loss improved from 1.57088 to 1.57068, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 75/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5782 - accuracy: 0.3501 - val_loss: 1.5712 - val_accuracy: 0.3531

Epoch 00075: val_loss did not improve from 1.57068
Epoch 76/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5773 - accuracy: 0.3505 - val_loss: 1.5707 - val_accuracy: 0.3539

Epoch 00076: val_loss did not improve from 1.57068
Epoch 77/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5774 - accuracy: 0.3527 - val_loss: 1.5710 - val_accuracy: 0.3544

Epoch 00077: val_loss did not improve from 1.57068
Epoch 78/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5766 - accuracy: 0.3521 - val_loss: 1.5707 - val_accuracy: 0.3539

Epoch 00078: val_loss did not improve from 1.57068
Epoch 79/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5764 - accuracy: 0.3521 - val_loss: 1.5714 - val_accuracy: 0.3537

Epoch 00079: val_loss did not improve from 1.57068
Epoch 80/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5765 - accuracy: 0.3502 - val_loss: 1.5704 - val_accuracy: 0.3538

Epoch 00080: val_loss improved from 1.57068 to 1.57045, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 81/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5758 - accuracy: 0.3519 - val_loss: 1.5700 - val_accuracy: 0.3546

Epoch 00081: val_loss improved from 1.57045 to 1.57004, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 82/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5761 - accuracy: 0.3526 - val_loss: 1.5694 - val_accuracy: 0.3552

Epoch 00082: val_loss improved from 1.57004 to 1.56944, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/8
Epoch 83/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5753 - accuracy: 0.3517 - val_loss: 1.5698 - val_accuracy: 0.3537

Epoch 00083: val_loss did not improve from 1.56944
Epoch 84/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5748 - accuracy: 0.3541 - val_loss: 1.5698 - val_accuracy: 0.3540

Epoch 00084: val_loss did not improve from 1.56944
Epoch 85/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5757 - accuracy: 0.3524 - val_loss: 1.5706 - val_accuracy: 0.3540

Epoch 00085: val_loss did not improve from 1.56944
Epoch 86/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5753 - accuracy: 0.3541 - val_loss: 1.5703 - val_accuracy: 0.3537

Epoch 00086: val_loss did not improve from 1.56944
Epoch 87/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5751 - accuracy: 0.3518 - val_loss: 1.5703 - val_accuracy: 0.3532

Epoch 00087: val_loss did not improve from 1.56944
Epoch 88/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5741 - accuracy: 0.3527 - val_loss: 1.5702 - val_accuracy: 0.3543

Epoch 00088: val_loss did not improve from 1.56944
Epoch 89/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5744 - accuracy: 0.3530 - val_loss: 1.5699 - val_accuracy: 0.3532

Epoch 00089: val_loss did not improve from 1.56944
Epoch 90/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5747 - accuracy: 0.3537 - val_loss: 1.5708 - val_accuracy: 0.3541

Epoch 00090: val_loss did not improve from 1.56944
Epoch 91/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5743 - accuracy: 0.3540 - val_loss: 1.5711 - val_accuracy: 0.3546

Epoch 00091: val_loss did not improve from 1.56944
Epoch 92/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5737 - accuracy: 0.3535 - val_loss: 1.5706 - val_accuracy: 0.3528

Epoch 00092: val_loss did not improve from 1.56944
Epoch 00092: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_4jet"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_32 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_33 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_34 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_35 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_80 (Dense)             multiple                  12294     [0m
[92m=================================================================[0m
[92mTotal params: 48,523,942[0m
[92mTrainable params: 48,523,926[0m
[92mNon-trainable params: 16[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_32"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_32 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_32 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_96 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_96 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_97 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_97 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_98 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_98 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_96 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_32 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_72 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_97 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_73 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_98 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_32', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_32_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_32', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwCpA07pAAAAAOkCAAAAqQCpAdoBeHIEAAAAcgQAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+0wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_32', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_96', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_96', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_97', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_97', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_98', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_98', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_96', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_32', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_72', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_97', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_73', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_98', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_33"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_33 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_33 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_99 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_99 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_100 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_100 (MaxPoolin (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_101 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_101 (MaxPoolin (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_99 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_33 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_74 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_100 (Dropout)        (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_75 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_101 (Dropout)        (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_33', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_33_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_33', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pAgAAAOkEAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+5QEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_33', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_99', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_99', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_100', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_100', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_101', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_101', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_99', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_33', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_74', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_100', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_75', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_101', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER3       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_34"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_34 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_34 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_102 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_102 (MaxPoolin (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_103 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_103 (MaxPoolin (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_104 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_104 (MaxPoolin (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_102 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_34 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_76 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_103 (Dropout)        (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_77 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_104 (Dropout)        (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_34', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_34_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_34', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBAAAAOkGAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+9wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_34', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_102', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_102', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_103', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_103', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_104', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_104', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_102', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_34', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_76', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_103', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_77', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_104', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER4       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_35"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_35 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_35 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_105 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_105 (MaxPoolin (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_106 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_106 (MaxPoolin (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_107 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_107 (MaxPoolin (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_105 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_35 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_78 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_106 (Dropout)        (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_79 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_107 (Dropout)        (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_35', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_35_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_35', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBgAAAOkIAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+CQIAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_35', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_105', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_105', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_106', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_106', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_107', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_107', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_105', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_35', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_78', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_106', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_79', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_107', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER5       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_80', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 149s 11ms/step - loss: 1.5751 - accuracy: 0.3498
Testing Loss = 1.575052, Testing Accuracy = 0.349806
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 26s 294ms/step - loss: 40.6700 - accuracy: 0.2953 - val_loss: 25.5905 - val_accuracy: 0.2509

Epoch 00001: val_loss improved from inf to 25.59047, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 2/100
83/83 [==============================] - 24s 293ms/step - loss: 18.8621 - accuracy: 0.3231 - val_loss: 14.1864 - val_accuracy: 0.2975

Epoch 00002: val_loss improved from 25.59047 to 14.18643, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 3/100
83/83 [==============================] - 24s 294ms/step - loss: 11.6698 - accuracy: 0.3275 - val_loss: 9.7103 - val_accuracy: 0.3268

Epoch 00003: val_loss improved from 14.18643 to 9.71026, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 4/100
83/83 [==============================] - 25s 294ms/step - loss: 8.3469 - accuracy: 0.3289 - val_loss: 7.1656 - val_accuracy: 0.3400

Epoch 00004: val_loss improved from 9.71026 to 7.16558, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 5/100
83/83 [==============================] - 24s 292ms/step - loss: 6.2653 - accuracy: 0.3332 - val_loss: 5.4387 - val_accuracy: 0.3485

Epoch 00005: val_loss improved from 7.16558 to 5.43865, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 6/100
83/83 [==============================] - 25s 294ms/step - loss: 4.8210 - accuracy: 0.3346 - val_loss: 4.2280 - val_accuracy: 0.3486

Epoch 00006: val_loss improved from 5.43865 to 4.22801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 7/100
83/83 [==============================] - 24s 294ms/step - loss: 3.8016 - accuracy: 0.3349 - val_loss: 3.3784 - val_accuracy: 0.3500

Epoch 00007: val_loss improved from 4.22801 to 3.37836, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 8/100
83/83 [==============================] - 24s 293ms/step - loss: 3.0889 - accuracy: 0.3368 - val_loss: 2.7892 - val_accuracy: 0.3521

Epoch 00008: val_loss improved from 3.37836 to 2.78920, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 9/100
83/83 [==============================] - 24s 292ms/step - loss: 2.5967 - accuracy: 0.3362 - val_loss: 2.3850 - val_accuracy: 0.3525

Epoch 00009: val_loss improved from 2.78920 to 2.38504, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 10/100
83/83 [==============================] - 25s 294ms/step - loss: 2.2598 - accuracy: 0.3382 - val_loss: 2.1114 - val_accuracy: 0.3524

Epoch 00010: val_loss improved from 2.38504 to 2.11143, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 11/100
83/83 [==============================] - 25s 294ms/step - loss: 2.0338 - accuracy: 0.3377 - val_loss: 1.9294 - val_accuracy: 0.3515

Epoch 00011: val_loss improved from 2.11143 to 1.92937, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 12/100
83/83 [==============================] - 25s 295ms/step - loss: 1.8840 - accuracy: 0.3377 - val_loss: 1.8092 - val_accuracy: 0.3537

Epoch 00012: val_loss improved from 1.92937 to 1.80918, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 13/100
83/83 [==============================] - 25s 294ms/step - loss: 1.7853 - accuracy: 0.3392 - val_loss: 1.7307 - val_accuracy: 0.3516

Epoch 00013: val_loss improved from 1.80918 to 1.73067, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 14/100
83/83 [==============================] - 24s 294ms/step - loss: 1.7211 - accuracy: 0.3403 - val_loss: 1.6800 - val_accuracy: 0.3509

Epoch 00014: val_loss improved from 1.73067 to 1.68001, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 15/100
83/83 [==============================] - 25s 295ms/step - loss: 1.6794 - accuracy: 0.3405 - val_loss: 1.6476 - val_accuracy: 0.3523

Epoch 00015: val_loss improved from 1.68001 to 1.64759, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 16/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6534 - accuracy: 0.3401 - val_loss: 1.6275 - val_accuracy: 0.3544

Epoch 00016: val_loss improved from 1.64759 to 1.62747, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 17/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6368 - accuracy: 0.3393 - val_loss: 1.6144 - val_accuracy: 0.3517

Epoch 00017: val_loss improved from 1.62747 to 1.61437, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 18/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6261 - accuracy: 0.3416 - val_loss: 1.6056 - val_accuracy: 0.3530

Epoch 00018: val_loss improved from 1.61437 to 1.60557, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 19/100
83/83 [==============================] - 24s 293ms/step - loss: 1.6173 - accuracy: 0.3397 - val_loss: 1.5997 - val_accuracy: 0.3537

Epoch 00019: val_loss improved from 1.60557 to 1.59974, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 20/100
83/83 [==============================] - 24s 294ms/step - loss: 1.6123 - accuracy: 0.3423 - val_loss: 1.5959 - val_accuracy: 0.3546

Epoch 00020: val_loss improved from 1.59974 to 1.59591, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 21/100
83/83 [==============================] - 25s 295ms/step - loss: 1.6090 - accuracy: 0.3403 - val_loss: 1.5919 - val_accuracy: 0.3528

Epoch 00021: val_loss improved from 1.59591 to 1.59187, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 22/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6060 - accuracy: 0.3411 - val_loss: 1.5898 - val_accuracy: 0.3536

Epoch 00022: val_loss improved from 1.59187 to 1.58983, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 23/100
83/83 [==============================] - 25s 294ms/step - loss: 1.6030 - accuracy: 0.3418 - val_loss: 1.5873 - val_accuracy: 0.3539

Epoch 00023: val_loss improved from 1.58983 to 1.58735, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 24/100
83/83 [==============================] - 25s 295ms/step - loss: 1.6010 - accuracy: 0.3425 - val_loss: 1.5867 - val_accuracy: 0.3528

Epoch 00024: val_loss improved from 1.58735 to 1.58669, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 25/100
83/83 [==============================] - 24s 294ms/step - loss: 1.6005 - accuracy: 0.3434 - val_loss: 1.5848 - val_accuracy: 0.3537

Epoch 00025: val_loss improved from 1.58669 to 1.58484, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 26/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5987 - accuracy: 0.3421 - val_loss: 1.5839 - val_accuracy: 0.3542

Epoch 00026: val_loss improved from 1.58484 to 1.58391, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 27/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5969 - accuracy: 0.3419 - val_loss: 1.5831 - val_accuracy: 0.3531

Epoch 00027: val_loss improved from 1.58391 to 1.58307, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 28/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5964 - accuracy: 0.3434 - val_loss: 1.5815 - val_accuracy: 0.3538

Epoch 00028: val_loss improved from 1.58307 to 1.58149, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 29/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5951 - accuracy: 0.3426 - val_loss: 1.5816 - val_accuracy: 0.3535

Epoch 00029: val_loss did not improve from 1.58149
Epoch 30/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5943 - accuracy: 0.3445 - val_loss: 1.5814 - val_accuracy: 0.3544

Epoch 00030: val_loss improved from 1.58149 to 1.58141, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 31/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5932 - accuracy: 0.3431 - val_loss: 1.5804 - val_accuracy: 0.3543

Epoch 00031: val_loss improved from 1.58141 to 1.58041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 32/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5938 - accuracy: 0.3435 - val_loss: 1.5794 - val_accuracy: 0.3538

Epoch 00032: val_loss improved from 1.58041 to 1.57936, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 33/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5914 - accuracy: 0.3426 - val_loss: 1.5798 - val_accuracy: 0.3550

Epoch 00033: val_loss did not improve from 1.57936
Epoch 34/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5906 - accuracy: 0.3447 - val_loss: 1.5791 - val_accuracy: 0.3525

Epoch 00034: val_loss improved from 1.57936 to 1.57909, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 35/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5903 - accuracy: 0.3439 - val_loss: 1.5785 - val_accuracy: 0.3535

Epoch 00035: val_loss improved from 1.57909 to 1.57854, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 36/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5910 - accuracy: 0.3438 - val_loss: 1.5782 - val_accuracy: 0.3560

Epoch 00036: val_loss improved from 1.57854 to 1.57821, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 37/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5892 - accuracy: 0.3434 - val_loss: 1.5777 - val_accuracy: 0.3557

Epoch 00037: val_loss improved from 1.57821 to 1.57770, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 38/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5889 - accuracy: 0.3446 - val_loss: 1.5770 - val_accuracy: 0.3554

Epoch 00038: val_loss improved from 1.57770 to 1.57697, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 39/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5883 - accuracy: 0.3477 - val_loss: 1.5770 - val_accuracy: 0.3540

Epoch 00039: val_loss did not improve from 1.57697
Epoch 40/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5884 - accuracy: 0.3440 - val_loss: 1.5762 - val_accuracy: 0.3548

Epoch 00040: val_loss improved from 1.57697 to 1.57618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 41/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5875 - accuracy: 0.3438 - val_loss: 1.5758 - val_accuracy: 0.3535

Epoch 00041: val_loss improved from 1.57618 to 1.57581, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 42/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5872 - accuracy: 0.3444 - val_loss: 1.5763 - val_accuracy: 0.3559

Epoch 00042: val_loss did not improve from 1.57581
Epoch 43/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5866 - accuracy: 0.3450 - val_loss: 1.5757 - val_accuracy: 0.3575

Epoch 00043: val_loss improved from 1.57581 to 1.57571, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 44/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5861 - accuracy: 0.3456 - val_loss: 1.5764 - val_accuracy: 0.3560

Epoch 00044: val_loss did not improve from 1.57571
Epoch 45/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5859 - accuracy: 0.3442 - val_loss: 1.5746 - val_accuracy: 0.3565

Epoch 00045: val_loss improved from 1.57571 to 1.57462, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 46/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5848 - accuracy: 0.3467 - val_loss: 1.5744 - val_accuracy: 0.3555

Epoch 00046: val_loss improved from 1.57462 to 1.57439, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 47/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5840 - accuracy: 0.3469 - val_loss: 1.5736 - val_accuracy: 0.3549

Epoch 00047: val_loss improved from 1.57439 to 1.57363, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 48/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5853 - accuracy: 0.3454 - val_loss: 1.5742 - val_accuracy: 0.3568

Epoch 00048: val_loss did not improve from 1.57363
Epoch 49/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5842 - accuracy: 0.3459 - val_loss: 1.5742 - val_accuracy: 0.3553

Epoch 00049: val_loss did not improve from 1.57363
Epoch 50/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5843 - accuracy: 0.3453 - val_loss: 1.5737 - val_accuracy: 0.3546

Epoch 00050: val_loss did not improve from 1.57363
Epoch 51/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5835 - accuracy: 0.3474 - val_loss: 1.5742 - val_accuracy: 0.3559

Epoch 00051: val_loss did not improve from 1.57363
Epoch 52/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5834 - accuracy: 0.3460 - val_loss: 1.5728 - val_accuracy: 0.3560

Epoch 00052: val_loss improved from 1.57363 to 1.57279, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 53/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5829 - accuracy: 0.3474 - val_loss: 1.5734 - val_accuracy: 0.3563

Epoch 00053: val_loss did not improve from 1.57279
Epoch 54/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5831 - accuracy: 0.3490 - val_loss: 1.5729 - val_accuracy: 0.3549

Epoch 00054: val_loss did not improve from 1.57279
Epoch 55/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5825 - accuracy: 0.3478 - val_loss: 1.5731 - val_accuracy: 0.3562

Epoch 00055: val_loss did not improve from 1.57279
Epoch 56/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5822 - accuracy: 0.3466 - val_loss: 1.5727 - val_accuracy: 0.3561

Epoch 00056: val_loss improved from 1.57279 to 1.57270, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 57/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5815 - accuracy: 0.3486 - val_loss: 1.5722 - val_accuracy: 0.3554

Epoch 00057: val_loss improved from 1.57270 to 1.57224, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 58/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5816 - accuracy: 0.3486 - val_loss: 1.5728 - val_accuracy: 0.3562

Epoch 00058: val_loss did not improve from 1.57224
Epoch 59/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5811 - accuracy: 0.3483 - val_loss: 1.5722 - val_accuracy: 0.3556

Epoch 00059: val_loss improved from 1.57224 to 1.57220, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 60/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5810 - accuracy: 0.3491 - val_loss: 1.5734 - val_accuracy: 0.3563

Epoch 00060: val_loss did not improve from 1.57220
Epoch 61/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5811 - accuracy: 0.3477 - val_loss: 1.5723 - val_accuracy: 0.3559

Epoch 00061: val_loss did not improve from 1.57220
Epoch 62/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5802 - accuracy: 0.3476 - val_loss: 1.5724 - val_accuracy: 0.3548

Epoch 00062: val_loss did not improve from 1.57220
Epoch 63/100
83/83 [==============================] - 25s 295ms/step - loss: 1.5800 - accuracy: 0.3495 - val_loss: 1.5722 - val_accuracy: 0.3555

Epoch 00063: val_loss did not improve from 1.57220
Epoch 64/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5801 - accuracy: 0.3494 - val_loss: 1.5713 - val_accuracy: 0.3573

Epoch 00064: val_loss improved from 1.57220 to 1.57134, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 65/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5805 - accuracy: 0.3492 - val_loss: 1.5711 - val_accuracy: 0.3558

Epoch 00065: val_loss improved from 1.57134 to 1.57107, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 66/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5803 - accuracy: 0.3495 - val_loss: 1.5721 - val_accuracy: 0.3565

Epoch 00066: val_loss did not improve from 1.57107
Epoch 67/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5794 - accuracy: 0.3492 - val_loss: 1.5731 - val_accuracy: 0.3559

Epoch 00067: val_loss did not improve from 1.57107
Epoch 68/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5797 - accuracy: 0.3492 - val_loss: 1.5716 - val_accuracy: 0.3563

Epoch 00068: val_loss did not improve from 1.57107
Epoch 69/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5786 - accuracy: 0.3487 - val_loss: 1.5708 - val_accuracy: 0.3558

Epoch 00069: val_loss improved from 1.57107 to 1.57081, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_4jetloc_kappa0.15-13/Try/9
Epoch 70/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5783 - accuracy: 0.3529 - val_loss: 1.5723 - val_accuracy: 0.3558

Epoch 00070: val_loss did not improve from 1.57081
Epoch 71/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5784 - accuracy: 0.3507 - val_loss: 1.5718 - val_accuracy: 0.3560

Epoch 00071: val_loss did not improve from 1.57081
Epoch 72/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5791 - accuracy: 0.3507 - val_loss: 1.5714 - val_accuracy: 0.3562

Epoch 00072: val_loss did not improve from 1.57081
Epoch 73/100
83/83 [==============================] - 24s 294ms/step - loss: 1.5787 - accuracy: 0.3503 - val_loss: 1.5714 - val_accuracy: 0.3538

Epoch 00073: val_loss did not improve from 1.57081
Epoch 74/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5786 - accuracy: 0.3488 - val_loss: 1.5714 - val_accuracy: 0.3553

Epoch 00074: val_loss did not improve from 1.57081
Epoch 75/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5777 - accuracy: 0.3509 - val_loss: 1.5720 - val_accuracy: 0.3544

Epoch 00075: val_loss did not improve from 1.57081
Epoch 76/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5773 - accuracy: 0.3512 - val_loss: 1.5710 - val_accuracy: 0.3546

Epoch 00076: val_loss did not improve from 1.57081
Epoch 77/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5776 - accuracy: 0.3517 - val_loss: 1.5712 - val_accuracy: 0.3553

Epoch 00077: val_loss did not improve from 1.57081
Epoch 78/100
83/83 [==============================] - 25s 294ms/step - loss: 1.5770 - accuracy: 0.3520 - val_loss: 1.5721 - val_accuracy: 0.3558

Epoch 00078: val_loss did not improve from 1.57081
Epoch 79/100
83/83 [==============================] - 24s 293ms/step - loss: 1.5768 - accuracy: 0.3515 - val_loss: 1.5721 - val_accuracy: 0.3560

Epoch 00079: val_loss did not improve from 1.57081
Epoch 00079: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_4jet"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_36 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_37 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_38 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92msequential_39 (Sequential)   (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_89 (Dense)             multiple                  12294     [0m
[92m=================================================================[0m
[92mTotal params: 48,523,942[0m
[92mTrainable params: 48,523,926[0m
[92mNon-trainable params: 16[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_36"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_36 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_36 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_108 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_108 (MaxPoolin (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_109 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_109 (MaxPoolin (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_110 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_110 (MaxPoolin (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_108 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_36 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_81 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_109 (Dropout)        (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_82 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_110 (Dropout)        (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_36', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_36_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_36', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwCpA07pAAAAAOkCAAAAqQCpAdoBeHIEAAAAcgQAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+0wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_36', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_108', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_108', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_109', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_109', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_110', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_110', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_108', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_36', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_81', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_109', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_82', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_110', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_37"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_37 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_37 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_111 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_111 (MaxPoolin (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_112 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_112 (MaxPoolin (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_113 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_113 (MaxPoolin (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_111 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_37 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_83 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_112 (Dropout)        (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_84 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_113 (Dropout)        (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_37', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_37_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_37', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pAgAAAOkEAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+5QEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_37', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_111', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_111', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_112', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_112', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_113', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_113', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_111', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_37', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_83', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_112', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_84', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_113', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER3       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_38"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_38 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_38 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_114 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_114 (MaxPoolin (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_115 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_115 (MaxPoolin (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_116 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_116 (MaxPoolin (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_114 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_38 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_85 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_115 (Dropout)        (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_86 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_116 (Dropout)        (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_38', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_38_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_38', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBAAAAOkGAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+9wEAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_38', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_114', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_114', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_115', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_115', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_116', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_116', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_114', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_38', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_85', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_115', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_86', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_116', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER4       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_39"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_39 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_39 (Batc (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_117 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_117 (MaxPoolin (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_118 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_118 (MaxPoolin (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_119 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_119 (MaxPoolin (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_117 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_39 (Flatten)         (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_87 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_118 (Dropout)        (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_88 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_119 (Dropout)        (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_39', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 8), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_39_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_39', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAWQChQJm\nBBkAUwApA07pBgAAAOkIAAAAqQCpAdoBeHIDAAAAcgMAAAD6Hy9ob21lL3NhbWh1YW5nL01ML0NO\nTi9tb2RlbHMucHnaCDxsYW1iZGE+CQIAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_39', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_117', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_117', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_118', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_118', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_119', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_119', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_117', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_39', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_87', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_118', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_88', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_119', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER5       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_89', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 150s 11ms/step - loss: 1.5763 - accuracy: 0.3504
Testing Loss = 1.576342, Testing Accuracy = 0.350402
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 80.31 +- 0.0393 %)
$W^-/W^-$ (auc = 79.22 +- 0.0765 %)
$Z/Z$ (auc = 60.03 +- 0.1191 %)
$W^+/W^-$ (auc = 61.66 +- 0.1730 %)
$W^+/Z$ (auc = 71.73 +- 0.0692 %)
$W^-/Z$ (auc = 73.29 +- 0.0474 %)
The summarized testing accuracy = 35.10 +- 0.0978 %, with the loss = 1.5750 +- 0.001334
