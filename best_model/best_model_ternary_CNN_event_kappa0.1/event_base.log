

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-24 10:37:24.531468
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 18s 72ms/step - loss: 12.3789 - accuracy: 0.1954 - val_loss: 8.6329 - val_accuracy: 0.2156

Epoch 00001: val_loss improved from inf to 8.63290, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.7203 - accuracy: 0.2087 - val_loss: 5.2974 - val_accuracy: 0.2190

Epoch 00002: val_loss improved from 8.63290 to 5.29736, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5382 - accuracy: 0.2122 - val_loss: 3.9311 - val_accuracy: 0.2239

Epoch 00003: val_loss improved from 5.29736 to 3.93105, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4834 - accuracy: 0.2544 - val_loss: 3.1411 - val_accuracy: 0.2935

Epoch 00004: val_loss improved from 3.93105 to 3.14112, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8655 - accuracy: 0.2905 - val_loss: 2.6615 - val_accuracy: 0.3076

Epoch 00005: val_loss improved from 3.14112 to 2.66149, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.4879 - accuracy: 0.2980 - val_loss: 2.3392 - val_accuracy: 0.3121

Epoch 00006: val_loss improved from 2.66149 to 2.33922, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2250 - accuracy: 0.3078 - val_loss: 2.1129 - val_accuracy: 0.3250

Epoch 00007: val_loss improved from 2.33922 to 2.11291, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0431 - accuracy: 0.3151 - val_loss: 1.9584 - val_accuracy: 0.3312

Epoch 00008: val_loss improved from 2.11291 to 1.95840, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9132 - accuracy: 0.3240 - val_loss: 1.8497 - val_accuracy: 0.3325

Epoch 00009: val_loss improved from 1.95840 to 1.84971, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8193 - accuracy: 0.3301 - val_loss: 1.7758 - val_accuracy: 0.3410

Epoch 00010: val_loss improved from 1.84971 to 1.77579, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7541 - accuracy: 0.3383 - val_loss: 1.7248 - val_accuracy: 0.3440

Epoch 00011: val_loss improved from 1.77579 to 1.72476, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7062 - accuracy: 0.3481 - val_loss: 1.6832 - val_accuracy: 0.3543

Epoch 00012: val_loss improved from 1.72476 to 1.68320, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6705 - accuracy: 0.3553 - val_loss: 1.6585 - val_accuracy: 0.3651

Epoch 00013: val_loss improved from 1.68320 to 1.65850, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6445 - accuracy: 0.3619 - val_loss: 1.6311 - val_accuracy: 0.3673

Epoch 00014: val_loss improved from 1.65850 to 1.63112, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6184 - accuracy: 0.3747 - val_loss: 1.6226 - val_accuracy: 0.3767

Epoch 00015: val_loss improved from 1.63112 to 1.62256, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6010 - accuracy: 0.3808 - val_loss: 1.5998 - val_accuracy: 0.3809

Epoch 00016: val_loss improved from 1.62256 to 1.59983, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5841 - accuracy: 0.3877 - val_loss: 1.6073 - val_accuracy: 0.3785

Epoch 00017: val_loss did not improve from 1.59983
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5713 - accuracy: 0.3950 - val_loss: 1.6144 - val_accuracy: 0.3772

Epoch 00018: val_loss did not improve from 1.59983
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5576 - accuracy: 0.4034 - val_loss: 1.6057 - val_accuracy: 0.3833

Epoch 00019: val_loss did not improve from 1.59983
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5492 - accuracy: 0.4062 - val_loss: 1.6040 - val_accuracy: 0.3848

Epoch 00020: val_loss did not improve from 1.59983
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5430 - accuracy: 0.4131 - val_loss: 1.6019 - val_accuracy: 0.3851

Epoch 00021: val_loss did not improve from 1.59983
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5343 - accuracy: 0.4133 - val_loss: 1.5927 - val_accuracy: 0.3896

Epoch 00022: val_loss improved from 1.59983 to 1.59268, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5284 - accuracy: 0.4180 - val_loss: 1.5781 - val_accuracy: 0.3921

Epoch 00023: val_loss improved from 1.59268 to 1.57805, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/0
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5216 - accuracy: 0.4238 - val_loss: 1.5788 - val_accuracy: 0.3919

Epoch 00024: val_loss did not improve from 1.57805
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5114 - accuracy: 0.4336 - val_loss: 1.5827 - val_accuracy: 0.3904

Epoch 00025: val_loss did not improve from 1.57805
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5006 - accuracy: 0.4396 - val_loss: 1.5952 - val_accuracy: 0.3914

Epoch 00026: val_loss did not improve from 1.57805
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4900 - accuracy: 0.4475 - val_loss: 1.6058 - val_accuracy: 0.3904

Epoch 00027: val_loss did not improve from 1.57805
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4797 - accuracy: 0.4546 - val_loss: 1.6041 - val_accuracy: 0.3920

Epoch 00028: val_loss did not improve from 1.57805
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4751 - accuracy: 0.4577 - val_loss: 1.6211 - val_accuracy: 0.3909

Epoch 00029: val_loss did not improve from 1.57805
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4613 - accuracy: 0.4665 - val_loss: 1.6372 - val_accuracy: 0.3862

Epoch 00030: val_loss did not improve from 1.57805
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4529 - accuracy: 0.4728 - val_loss: 1.6567 - val_accuracy: 0.3845

Epoch 00031: val_loss did not improve from 1.57805
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4385 - accuracy: 0.4819 - val_loss: 1.6532 - val_accuracy: 0.3883

Epoch 00032: val_loss did not improve from 1.57805
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4302 - accuracy: 0.4902 - val_loss: 1.7027 - val_accuracy: 0.3844

Epoch 00033: val_loss did not improve from 1.57805
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5892 - accuracy: 0.3886
Testing Loss = 1.589175, Testing Accuracy = 0.388583
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4416 - accuracy: 0.2041 - val_loss: 8.7063 - val_accuracy: 0.2176

Epoch 00001: val_loss improved from inf to 8.70628, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7831 - accuracy: 0.2088 - val_loss: 5.3517 - val_accuracy: 0.2191

Epoch 00002: val_loss improved from 8.70628 to 5.35167, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5770 - accuracy: 0.2190 - val_loss: 3.9651 - val_accuracy: 0.2198

Epoch 00003: val_loss improved from 5.35167 to 3.96512, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4897 - accuracy: 0.2759 - val_loss: 3.1684 - val_accuracy: 0.2906

Epoch 00004: val_loss improved from 3.96512 to 3.16835, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8905 - accuracy: 0.2922 - val_loss: 2.6890 - val_accuracy: 0.3058

Epoch 00005: val_loss improved from 3.16835 to 2.68898, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5060 - accuracy: 0.3016 - val_loss: 2.3583 - val_accuracy: 0.3136

Epoch 00006: val_loss improved from 2.68898 to 2.35833, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2409 - accuracy: 0.3109 - val_loss: 2.1271 - val_accuracy: 0.3215

Epoch 00007: val_loss improved from 2.35833 to 2.12711, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0537 - accuracy: 0.3139 - val_loss: 1.9689 - val_accuracy: 0.3286

Epoch 00008: val_loss improved from 2.12711 to 1.96894, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9227 - accuracy: 0.3232 - val_loss: 1.8599 - val_accuracy: 0.3339

Epoch 00009: val_loss improved from 1.96894 to 1.85986, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8281 - accuracy: 0.3281 - val_loss: 1.7823 - val_accuracy: 0.3349

Epoch 00010: val_loss improved from 1.85986 to 1.78235, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7631 - accuracy: 0.3333 - val_loss: 1.7274 - val_accuracy: 0.3432

Epoch 00011: val_loss improved from 1.78235 to 1.72736, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7157 - accuracy: 0.3391 - val_loss: 1.6898 - val_accuracy: 0.3462

Epoch 00012: val_loss improved from 1.72736 to 1.68978, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6796 - accuracy: 0.3481 - val_loss: 1.6601 - val_accuracy: 0.3566

Epoch 00013: val_loss improved from 1.68978 to 1.66006, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6498 - accuracy: 0.3561 - val_loss: 1.6409 - val_accuracy: 0.3637

Epoch 00014: val_loss improved from 1.66006 to 1.64095, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6288 - accuracy: 0.3643 - val_loss: 1.6189 - val_accuracy: 0.3729

Epoch 00015: val_loss improved from 1.64095 to 1.61895, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6098 - accuracy: 0.3755 - val_loss: 1.6099 - val_accuracy: 0.3749

Epoch 00016: val_loss improved from 1.61895 to 1.60989, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5923 - accuracy: 0.3837 - val_loss: 1.6115 - val_accuracy: 0.3761

Epoch 00017: val_loss did not improve from 1.60989
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5791 - accuracy: 0.3907 - val_loss: 1.6026 - val_accuracy: 0.3822

Epoch 00018: val_loss improved from 1.60989 to 1.60259, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5701 - accuracy: 0.3959 - val_loss: 1.5912 - val_accuracy: 0.3839

Epoch 00019: val_loss improved from 1.60259 to 1.59117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5582 - accuracy: 0.4036 - val_loss: 1.5825 - val_accuracy: 0.3850

Epoch 00020: val_loss improved from 1.59117 to 1.58246, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5483 - accuracy: 0.4060 - val_loss: 1.5844 - val_accuracy: 0.3883

Epoch 00021: val_loss did not improve from 1.58246
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5372 - accuracy: 0.4141 - val_loss: 1.5907 - val_accuracy: 0.3843

Epoch 00022: val_loss did not improve from 1.58246
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5342 - accuracy: 0.4161 - val_loss: 1.5822 - val_accuracy: 0.3896

Epoch 00023: val_loss improved from 1.58246 to 1.58219, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/1
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5217 - accuracy: 0.4222 - val_loss: 1.5826 - val_accuracy: 0.3888

Epoch 00024: val_loss did not improve from 1.58219
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5191 - accuracy: 0.4272 - val_loss: 1.5887 - val_accuracy: 0.3909

Epoch 00025: val_loss did not improve from 1.58219
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5095 - accuracy: 0.4318 - val_loss: 1.5837 - val_accuracy: 0.3929

Epoch 00026: val_loss did not improve from 1.58219
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5009 - accuracy: 0.4369 - val_loss: 1.5840 - val_accuracy: 0.3917

Epoch 00027: val_loss did not improve from 1.58219
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4945 - accuracy: 0.4418 - val_loss: 1.6009 - val_accuracy: 0.3903

Epoch 00028: val_loss did not improve from 1.58219
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4884 - accuracy: 0.4481 - val_loss: 1.6127 - val_accuracy: 0.3906

Epoch 00029: val_loss did not improve from 1.58219
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4805 - accuracy: 0.4546 - val_loss: 1.6293 - val_accuracy: 0.3874

Epoch 00030: val_loss did not improve from 1.58219
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4753 - accuracy: 0.4569 - val_loss: 1.6304 - val_accuracy: 0.3876

Epoch 00031: val_loss did not improve from 1.58219
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4643 - accuracy: 0.4682 - val_loss: 1.6449 - val_accuracy: 0.3864

Epoch 00032: val_loss did not improve from 1.58219
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4495 - accuracy: 0.4742 - val_loss: 1.6380 - val_accuracy: 0.3884

Epoch 00033: val_loss did not improve from 1.58219
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.5991 - accuracy: 0.3804
Testing Loss = 1.599120, Testing Accuracy = 0.380396
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.5840 - accuracy: 0.1996 - val_loss: 8.8987 - val_accuracy: 0.2174

Epoch 00001: val_loss improved from inf to 8.89869, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.9492 - accuracy: 0.2067 - val_loss: 5.4783 - val_accuracy: 0.2205

Epoch 00002: val_loss improved from 8.89869 to 5.47829, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6767 - accuracy: 0.2089 - val_loss: 4.0326 - val_accuracy: 0.2239

Epoch 00003: val_loss improved from 5.47829 to 4.03257, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5731 - accuracy: 0.2446 - val_loss: 3.1969 - val_accuracy: 0.2892

Epoch 00004: val_loss improved from 4.03257 to 3.19687, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9101 - accuracy: 0.2903 - val_loss: 2.6967 - val_accuracy: 0.3043

Epoch 00005: val_loss improved from 3.19687 to 2.69665, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5139 - accuracy: 0.3015 - val_loss: 2.3617 - val_accuracy: 0.3092

Epoch 00006: val_loss improved from 2.69665 to 2.36168, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2443 - accuracy: 0.3074 - val_loss: 2.1303 - val_accuracy: 0.3194

Epoch 00007: val_loss improved from 2.36168 to 2.13028, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0550 - accuracy: 0.3171 - val_loss: 1.9712 - val_accuracy: 0.3283

Epoch 00008: val_loss improved from 2.13028 to 1.97117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9223 - accuracy: 0.3226 - val_loss: 1.8606 - val_accuracy: 0.3322

Epoch 00009: val_loss improved from 1.97117 to 1.86056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8275 - accuracy: 0.3287 - val_loss: 1.7861 - val_accuracy: 0.3330

Epoch 00010: val_loss improved from 1.86056 to 1.78606, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7621 - accuracy: 0.3341 - val_loss: 1.7313 - val_accuracy: 0.3382

Epoch 00011: val_loss improved from 1.78606 to 1.73134, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7129 - accuracy: 0.3409 - val_loss: 1.6887 - val_accuracy: 0.3483

Epoch 00012: val_loss improved from 1.73134 to 1.68874, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6776 - accuracy: 0.3482 - val_loss: 1.6599 - val_accuracy: 0.3566

Epoch 00013: val_loss improved from 1.68874 to 1.65993, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6488 - accuracy: 0.3562 - val_loss: 1.6442 - val_accuracy: 0.3617

Epoch 00014: val_loss improved from 1.65993 to 1.64421, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6255 - accuracy: 0.3709 - val_loss: 1.6210 - val_accuracy: 0.3691

Epoch 00015: val_loss improved from 1.64421 to 1.62096, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6099 - accuracy: 0.3734 - val_loss: 1.6156 - val_accuracy: 0.3696

Epoch 00016: val_loss improved from 1.62096 to 1.61565, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5877 - accuracy: 0.3853 - val_loss: 1.6079 - val_accuracy: 0.3762

Epoch 00017: val_loss improved from 1.61565 to 1.60788, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5752 - accuracy: 0.3914 - val_loss: 1.5872 - val_accuracy: 0.3869

Epoch 00018: val_loss improved from 1.60788 to 1.58716, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5661 - accuracy: 0.3971 - val_loss: 1.5810 - val_accuracy: 0.3890

Epoch 00019: val_loss improved from 1.58716 to 1.58104, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5564 - accuracy: 0.4003 - val_loss: 1.5815 - val_accuracy: 0.3885

Epoch 00020: val_loss did not improve from 1.58104
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5464 - accuracy: 0.4062 - val_loss: 1.5764 - val_accuracy: 0.3915

Epoch 00021: val_loss improved from 1.58104 to 1.57640, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5381 - accuracy: 0.4108 - val_loss: 1.5756 - val_accuracy: 0.3935

Epoch 00022: val_loss improved from 1.57640 to 1.57564, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/2
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5285 - accuracy: 0.4185 - val_loss: 1.5849 - val_accuracy: 0.3886

Epoch 00023: val_loss did not improve from 1.57564
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5211 - accuracy: 0.4221 - val_loss: 1.5803 - val_accuracy: 0.3957

Epoch 00024: val_loss did not improve from 1.57564
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5141 - accuracy: 0.4300 - val_loss: 1.5939 - val_accuracy: 0.3913

Epoch 00025: val_loss did not improve from 1.57564
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5070 - accuracy: 0.4334 - val_loss: 1.5847 - val_accuracy: 0.3918

Epoch 00026: val_loss did not improve from 1.57564
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5027 - accuracy: 0.4360 - val_loss: 1.6040 - val_accuracy: 0.3884

Epoch 00027: val_loss did not improve from 1.57564
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4940 - accuracy: 0.4422 - val_loss: 1.6012 - val_accuracy: 0.3907

Epoch 00028: val_loss did not improve from 1.57564
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4846 - accuracy: 0.4476 - val_loss: 1.5936 - val_accuracy: 0.3908

Epoch 00029: val_loss did not improve from 1.57564
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4775 - accuracy: 0.4536 - val_loss: 1.5959 - val_accuracy: 0.3915

Epoch 00030: val_loss did not improve from 1.57564
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4678 - accuracy: 0.4643 - val_loss: 1.6091 - val_accuracy: 0.3885

Epoch 00031: val_loss did not improve from 1.57564
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4602 - accuracy: 0.4691 - val_loss: 1.6195 - val_accuracy: 0.3857

Epoch 00032: val_loss did not improve from 1.57564
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 62s 5ms/step - loss: 1.5919 - accuracy: 0.3824
Testing Loss = 1.591928, Testing Accuracy = 0.382405
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.5283 - accuracy: 0.2003 - val_loss: 8.8255 - val_accuracy: 0.2155

Epoch 00001: val_loss improved from inf to 8.82547, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8881 - accuracy: 0.2089 - val_loss: 5.4347 - val_accuracy: 0.2170

Epoch 00002: val_loss improved from 8.82547 to 5.43470, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6454 - accuracy: 0.2122 - val_loss: 4.0143 - val_accuracy: 0.2276

Epoch 00003: val_loss improved from 5.43470 to 4.01432, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5371 - accuracy: 0.2664 - val_loss: 3.1976 - val_accuracy: 0.2963

Epoch 00004: val_loss improved from 4.01432 to 3.19761, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9104 - accuracy: 0.2933 - val_loss: 2.7058 - val_accuracy: 0.3067

Epoch 00005: val_loss improved from 3.19761 to 2.70576, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5202 - accuracy: 0.3016 - val_loss: 2.3710 - val_accuracy: 0.3174

Epoch 00006: val_loss improved from 2.70576 to 2.37102, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2493 - accuracy: 0.3115 - val_loss: 2.1361 - val_accuracy: 0.3213

Epoch 00007: val_loss improved from 2.37102 to 2.13606, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0626 - accuracy: 0.3173 - val_loss: 1.9752 - val_accuracy: 0.3279

Epoch 00008: val_loss improved from 2.13606 to 1.97522, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9278 - accuracy: 0.3232 - val_loss: 1.8642 - val_accuracy: 0.3301

Epoch 00009: val_loss improved from 1.97522 to 1.86424, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8319 - accuracy: 0.3309 - val_loss: 1.7866 - val_accuracy: 0.3343

Epoch 00010: val_loss improved from 1.86424 to 1.78657, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7633 - accuracy: 0.3356 - val_loss: 1.7331 - val_accuracy: 0.3399

Epoch 00011: val_loss improved from 1.78657 to 1.73309, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7160 - accuracy: 0.3442 - val_loss: 1.6955 - val_accuracy: 0.3484

Epoch 00012: val_loss improved from 1.73309 to 1.69545, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6799 - accuracy: 0.3473 - val_loss: 1.6640 - val_accuracy: 0.3598

Epoch 00013: val_loss improved from 1.69545 to 1.66401, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 14/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6526 - accuracy: 0.3555 - val_loss: 1.6453 - val_accuracy: 0.3626

Epoch 00014: val_loss improved from 1.66401 to 1.64530, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6279 - accuracy: 0.3668 - val_loss: 1.6379 - val_accuracy: 0.3613

Epoch 00015: val_loss improved from 1.64530 to 1.63793, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6094 - accuracy: 0.3741 - val_loss: 1.6183 - val_accuracy: 0.3712

Epoch 00016: val_loss improved from 1.63793 to 1.61827, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5956 - accuracy: 0.3817 - val_loss: 1.5994 - val_accuracy: 0.3785

Epoch 00017: val_loss improved from 1.61827 to 1.59943, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5809 - accuracy: 0.3862 - val_loss: 1.5943 - val_accuracy: 0.3806

Epoch 00018: val_loss improved from 1.59943 to 1.59429, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5688 - accuracy: 0.3953 - val_loss: 1.5956 - val_accuracy: 0.3846

Epoch 00019: val_loss did not improve from 1.59429
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5586 - accuracy: 0.3987 - val_loss: 1.6001 - val_accuracy: 0.3812

Epoch 00020: val_loss did not improve from 1.59429
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5490 - accuracy: 0.4056 - val_loss: 1.5999 - val_accuracy: 0.3812

Epoch 00021: val_loss did not improve from 1.59429
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5397 - accuracy: 0.4138 - val_loss: 1.6077 - val_accuracy: 0.3791

Epoch 00022: val_loss did not improve from 1.59429
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5325 - accuracy: 0.4178 - val_loss: 1.6015 - val_accuracy: 0.3846

Epoch 00023: val_loss did not improve from 1.59429
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5252 - accuracy: 0.4239 - val_loss: 1.5965 - val_accuracy: 0.3892

Epoch 00024: val_loss did not improve from 1.59429
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5158 - accuracy: 0.4285 - val_loss: 1.5916 - val_accuracy: 0.3919

Epoch 00025: val_loss improved from 1.59429 to 1.59164, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/3
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5085 - accuracy: 0.4347 - val_loss: 1.5961 - val_accuracy: 0.3938

Epoch 00026: val_loss did not improve from 1.59164
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5030 - accuracy: 0.4373 - val_loss: 1.5922 - val_accuracy: 0.3936

Epoch 00027: val_loss did not improve from 1.59164
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4945 - accuracy: 0.4441 - val_loss: 1.6024 - val_accuracy: 0.3910

Epoch 00028: val_loss did not improve from 1.59164
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4834 - accuracy: 0.4548 - val_loss: 1.6083 - val_accuracy: 0.3893

Epoch 00029: val_loss did not improve from 1.59164
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4766 - accuracy: 0.4573 - val_loss: 1.6213 - val_accuracy: 0.3868

Epoch 00030: val_loss did not improve from 1.59164
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4691 - accuracy: 0.4637 - val_loss: 1.6405 - val_accuracy: 0.3859

Epoch 00031: val_loss did not improve from 1.59164
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4556 - accuracy: 0.4728 - val_loss: 1.6474 - val_accuracy: 0.3871

Epoch 00032: val_loss did not improve from 1.59164
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4464 - accuracy: 0.4776 - val_loss: 1.6552 - val_accuracy: 0.3860

Epoch 00033: val_loss did not improve from 1.59164
Epoch 34/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4318 - accuracy: 0.4916 - val_loss: 1.6629 - val_accuracy: 0.3851

Epoch 00034: val_loss did not improve from 1.59164
Epoch 35/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4217 - accuracy: 0.4967 - val_loss: 1.6810 - val_accuracy: 0.3818

Epoch 00035: val_loss did not improve from 1.59164
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.6055 - accuracy: 0.3805
Testing Loss = 1.605450, Testing Accuracy = 0.380470
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4031 - accuracy: 0.2001 - val_loss: 8.6700 - val_accuracy: 0.2159

Epoch 00001: val_loss improved from inf to 8.67000, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7582 - accuracy: 0.2078 - val_loss: 5.3345 - val_accuracy: 0.2200

Epoch 00002: val_loss improved from 8.67000 to 5.33452, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5647 - accuracy: 0.2173 - val_loss: 3.9446 - val_accuracy: 0.2511

Epoch 00003: val_loss improved from 5.33452 to 3.94456, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4827 - accuracy: 0.2730 - val_loss: 3.1614 - val_accuracy: 0.2995

Epoch 00004: val_loss improved from 3.94456 to 3.16140, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8844 - accuracy: 0.2935 - val_loss: 2.6843 - val_accuracy: 0.3063

Epoch 00005: val_loss improved from 3.16140 to 2.68428, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5015 - accuracy: 0.3044 - val_loss: 2.3509 - val_accuracy: 0.3124

Epoch 00006: val_loss improved from 2.68428 to 2.35085, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2384 - accuracy: 0.3132 - val_loss: 2.1239 - val_accuracy: 0.3251

Epoch 00007: val_loss improved from 2.35085 to 2.12387, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0524 - accuracy: 0.3192 - val_loss: 1.9649 - val_accuracy: 0.3321

Epoch 00008: val_loss improved from 2.12387 to 1.96487, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9181 - accuracy: 0.3282 - val_loss: 1.8560 - val_accuracy: 0.3386

Epoch 00009: val_loss improved from 1.96487 to 1.85598, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8257 - accuracy: 0.3341 - val_loss: 1.7811 - val_accuracy: 0.3429

Epoch 00010: val_loss improved from 1.85598 to 1.78113, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7580 - accuracy: 0.3393 - val_loss: 1.7268 - val_accuracy: 0.3472

Epoch 00011: val_loss improved from 1.78113 to 1.72678, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7116 - accuracy: 0.3480 - val_loss: 1.6857 - val_accuracy: 0.3548

Epoch 00012: val_loss improved from 1.72678 to 1.68571, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6734 - accuracy: 0.3548 - val_loss: 1.6641 - val_accuracy: 0.3587

Epoch 00013: val_loss improved from 1.68571 to 1.66409, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6440 - accuracy: 0.3631 - val_loss: 1.6344 - val_accuracy: 0.3720

Epoch 00014: val_loss improved from 1.66409 to 1.63443, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6212 - accuracy: 0.3725 - val_loss: 1.6164 - val_accuracy: 0.3773

Epoch 00015: val_loss improved from 1.63443 to 1.61643, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6032 - accuracy: 0.3802 - val_loss: 1.6038 - val_accuracy: 0.3803

Epoch 00016: val_loss improved from 1.61643 to 1.60377, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5872 - accuracy: 0.3875 - val_loss: 1.5941 - val_accuracy: 0.3825

Epoch 00017: val_loss improved from 1.60377 to 1.59413, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5737 - accuracy: 0.3931 - val_loss: 1.6103 - val_accuracy: 0.3753

Epoch 00018: val_loss did not improve from 1.59413
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5622 - accuracy: 0.3985 - val_loss: 1.5979 - val_accuracy: 0.3828

Epoch 00019: val_loss did not improve from 1.59413
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5523 - accuracy: 0.4042 - val_loss: 1.5873 - val_accuracy: 0.3865

Epoch 00020: val_loss improved from 1.59413 to 1.58727, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5481 - accuracy: 0.4081 - val_loss: 1.6085 - val_accuracy: 0.3769

Epoch 00021: val_loss did not improve from 1.58727
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5372 - accuracy: 0.4106 - val_loss: 1.6003 - val_accuracy: 0.3823

Epoch 00022: val_loss did not improve from 1.58727
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5266 - accuracy: 0.4196 - val_loss: 1.5854 - val_accuracy: 0.3910

Epoch 00023: val_loss improved from 1.58727 to 1.58537, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/4
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5200 - accuracy: 0.4244 - val_loss: 1.5955 - val_accuracy: 0.3860

Epoch 00024: val_loss did not improve from 1.58537
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5130 - accuracy: 0.4279 - val_loss: 1.6082 - val_accuracy: 0.3817

Epoch 00025: val_loss did not improve from 1.58537
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5050 - accuracy: 0.4346 - val_loss: 1.6177 - val_accuracy: 0.3816

Epoch 00026: val_loss did not improve from 1.58537
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4969 - accuracy: 0.4418 - val_loss: 1.6109 - val_accuracy: 0.3843

Epoch 00027: val_loss did not improve from 1.58537
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4899 - accuracy: 0.4462 - val_loss: 1.6025 - val_accuracy: 0.3922

Epoch 00028: val_loss did not improve from 1.58537
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4787 - accuracy: 0.4533 - val_loss: 1.6135 - val_accuracy: 0.3873

Epoch 00029: val_loss did not improve from 1.58537
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4712 - accuracy: 0.4618 - val_loss: 1.6124 - val_accuracy: 0.3899

Epoch 00030: val_loss did not improve from 1.58537
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4598 - accuracy: 0.4671 - val_loss: 1.6217 - val_accuracy: 0.3874

Epoch 00031: val_loss did not improve from 1.58537
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4527 - accuracy: 0.4702 - val_loss: 1.6552 - val_accuracy: 0.3846

Epoch 00032: val_loss did not improve from 1.58537
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4403 - accuracy: 0.4818 - val_loss: 1.6581 - val_accuracy: 0.3839

Epoch 00033: val_loss did not improve from 1.58537
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.5974 - accuracy: 0.3860
Testing Loss = 1.597414, Testing Accuracy = 0.385978
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 75ms/step - loss: 12.4151 - accuracy: 0.1989 - val_loss: 8.7004 - val_accuracy: 0.2167

Epoch 00001: val_loss improved from inf to 8.70041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7813 - accuracy: 0.2066 - val_loss: 5.3483 - val_accuracy: 0.2183

Epoch 00002: val_loss improved from 8.70041 to 5.34827, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5750 - accuracy: 0.2172 - val_loss: 3.9572 - val_accuracy: 0.2333

Epoch 00003: val_loss improved from 5.34827 to 3.95720, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4926 - accuracy: 0.2700 - val_loss: 3.1671 - val_accuracy: 0.2883

Epoch 00004: val_loss improved from 3.95720 to 3.16712, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8920 - accuracy: 0.2921 - val_loss: 2.6871 - val_accuracy: 0.3025

Epoch 00005: val_loss improved from 3.16712 to 2.68712, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5079 - accuracy: 0.3010 - val_loss: 2.3612 - val_accuracy: 0.3111

Epoch 00006: val_loss improved from 2.68712 to 2.36121, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2436 - accuracy: 0.3047 - val_loss: 2.1293 - val_accuracy: 0.3167

Epoch 00007: val_loss improved from 2.36121 to 2.12931, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0574 - accuracy: 0.3139 - val_loss: 1.9708 - val_accuracy: 0.3281

Epoch 00008: val_loss improved from 2.12931 to 1.97081, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9239 - accuracy: 0.3234 - val_loss: 1.8627 - val_accuracy: 0.3317

Epoch 00009: val_loss improved from 1.97081 to 1.86272, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8315 - accuracy: 0.3262 - val_loss: 1.7848 - val_accuracy: 0.3369

Epoch 00010: val_loss improved from 1.86272 to 1.78482, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7646 - accuracy: 0.3320 - val_loss: 1.7327 - val_accuracy: 0.3370

Epoch 00011: val_loss improved from 1.78482 to 1.73266, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7177 - accuracy: 0.3395 - val_loss: 1.6934 - val_accuracy: 0.3436

Epoch 00012: val_loss improved from 1.73266 to 1.69337, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6830 - accuracy: 0.3456 - val_loss: 1.6654 - val_accuracy: 0.3516

Epoch 00013: val_loss improved from 1.69337 to 1.66539, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6534 - accuracy: 0.3542 - val_loss: 1.6460 - val_accuracy: 0.3560

Epoch 00014: val_loss improved from 1.66539 to 1.64605, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6339 - accuracy: 0.3590 - val_loss: 1.6355 - val_accuracy: 0.3565

Epoch 00015: val_loss improved from 1.64605 to 1.63555, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6142 - accuracy: 0.3701 - val_loss: 1.6118 - val_accuracy: 0.3667

Epoch 00016: val_loss improved from 1.63555 to 1.61180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5947 - accuracy: 0.3816 - val_loss: 1.6122 - val_accuracy: 0.3718

Epoch 00017: val_loss did not improve from 1.61180
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5810 - accuracy: 0.3902 - val_loss: 1.6165 - val_accuracy: 0.3706

Epoch 00018: val_loss did not improve from 1.61180
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5697 - accuracy: 0.3951 - val_loss: 1.6035 - val_accuracy: 0.3789

Epoch 00019: val_loss improved from 1.61180 to 1.60350, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5597 - accuracy: 0.3986 - val_loss: 1.6060 - val_accuracy: 0.3759

Epoch 00020: val_loss did not improve from 1.60350
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5502 - accuracy: 0.4028 - val_loss: 1.5944 - val_accuracy: 0.3801

Epoch 00021: val_loss improved from 1.60350 to 1.59435, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5398 - accuracy: 0.4115 - val_loss: 1.5912 - val_accuracy: 0.3879

Epoch 00022: val_loss improved from 1.59435 to 1.59119, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5297 - accuracy: 0.4178 - val_loss: 1.6079 - val_accuracy: 0.3828

Epoch 00023: val_loss did not improve from 1.59119
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5211 - accuracy: 0.4256 - val_loss: 1.5864 - val_accuracy: 0.3902

Epoch 00024: val_loss improved from 1.59119 to 1.58641, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/5
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5167 - accuracy: 0.4289 - val_loss: 1.5993 - val_accuracy: 0.3864

Epoch 00025: val_loss did not improve from 1.58641
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5097 - accuracy: 0.4294 - val_loss: 1.6123 - val_accuracy: 0.3846

Epoch 00026: val_loss did not improve from 1.58641
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4961 - accuracy: 0.4406 - val_loss: 1.6167 - val_accuracy: 0.3879

Epoch 00027: val_loss did not improve from 1.58641
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4908 - accuracy: 0.4483 - val_loss: 1.6194 - val_accuracy: 0.3857

Epoch 00028: val_loss did not improve from 1.58641
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4792 - accuracy: 0.4533 - val_loss: 1.6326 - val_accuracy: 0.3873

Epoch 00029: val_loss did not improve from 1.58641
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4649 - accuracy: 0.4652 - val_loss: 1.6337 - val_accuracy: 0.3883

Epoch 00030: val_loss did not improve from 1.58641
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4563 - accuracy: 0.4709 - val_loss: 1.6412 - val_accuracy: 0.3879

Epoch 00031: val_loss did not improve from 1.58641
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4447 - accuracy: 0.4765 - val_loss: 1.6579 - val_accuracy: 0.3861

Epoch 00032: val_loss did not improve from 1.58641
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4273 - accuracy: 0.4884 - val_loss: 1.6723 - val_accuracy: 0.3859

Epoch 00033: val_loss did not improve from 1.58641
Epoch 34/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4160 - accuracy: 0.4995 - val_loss: 1.6924 - val_accuracy: 0.3842

Epoch 00034: val_loss did not improve from 1.58641
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.6016 - accuracy: 0.3864
Testing Loss = 1.601603, Testing Accuracy = 0.386350
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4935 - accuracy: 0.2001 - val_loss: 8.7805 - val_accuracy: 0.2166

Epoch 00001: val_loss improved from inf to 8.78052, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8433 - accuracy: 0.2084 - val_loss: 5.3944 - val_accuracy: 0.2201

Epoch 00002: val_loss improved from 8.78052 to 5.39443, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6160 - accuracy: 0.2118 - val_loss: 3.9917 - val_accuracy: 0.2182

Epoch 00003: val_loss improved from 5.39443 to 3.99171, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5499 - accuracy: 0.2429 - val_loss: 3.1808 - val_accuracy: 0.2854

Epoch 00004: val_loss improved from 3.99171 to 3.18078, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8991 - accuracy: 0.2860 - val_loss: 2.6886 - val_accuracy: 0.3007

Epoch 00005: val_loss improved from 3.18078 to 2.68857, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5071 - accuracy: 0.2964 - val_loss: 2.3572 - val_accuracy: 0.3118

Epoch 00006: val_loss improved from 2.68857 to 2.35719, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2382 - accuracy: 0.3103 - val_loss: 2.1269 - val_accuracy: 0.3214

Epoch 00007: val_loss improved from 2.35719 to 2.12685, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0517 - accuracy: 0.3132 - val_loss: 1.9671 - val_accuracy: 0.3267

Epoch 00008: val_loss improved from 2.12685 to 1.96714, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9196 - accuracy: 0.3206 - val_loss: 1.8571 - val_accuracy: 0.3364

Epoch 00009: val_loss improved from 1.96714 to 1.85714, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8270 - accuracy: 0.3265 - val_loss: 1.7838 - val_accuracy: 0.3358

Epoch 00010: val_loss improved from 1.85714 to 1.78382, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7593 - accuracy: 0.3370 - val_loss: 1.7295 - val_accuracy: 0.3441

Epoch 00011: val_loss improved from 1.78382 to 1.72950, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7142 - accuracy: 0.3404 - val_loss: 1.6941 - val_accuracy: 0.3446

Epoch 00012: val_loss improved from 1.72950 to 1.69412, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6756 - accuracy: 0.3500 - val_loss: 1.6619 - val_accuracy: 0.3539

Epoch 00013: val_loss improved from 1.69412 to 1.66185, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6486 - accuracy: 0.3604 - val_loss: 1.6397 - val_accuracy: 0.3615

Epoch 00014: val_loss improved from 1.66185 to 1.63975, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6265 - accuracy: 0.3663 - val_loss: 1.6266 - val_accuracy: 0.3656

Epoch 00015: val_loss improved from 1.63975 to 1.62665, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6091 - accuracy: 0.3757 - val_loss: 1.6089 - val_accuracy: 0.3722

Epoch 00016: val_loss improved from 1.62665 to 1.60887, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5883 - accuracy: 0.3834 - val_loss: 1.6217 - val_accuracy: 0.3653

Epoch 00017: val_loss did not improve from 1.60887
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5758 - accuracy: 0.3928 - val_loss: 1.6102 - val_accuracy: 0.3727

Epoch 00018: val_loss did not improve from 1.60887
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5657 - accuracy: 0.3976 - val_loss: 1.6051 - val_accuracy: 0.3749

Epoch 00019: val_loss improved from 1.60887 to 1.60507, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5547 - accuracy: 0.4031 - val_loss: 1.6054 - val_accuracy: 0.3764

Epoch 00020: val_loss did not improve from 1.60507
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5480 - accuracy: 0.4052 - val_loss: 1.5820 - val_accuracy: 0.3915

Epoch 00021: val_loss improved from 1.60507 to 1.58196, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/6
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5344 - accuracy: 0.4131 - val_loss: 1.5995 - val_accuracy: 0.3808

Epoch 00022: val_loss did not improve from 1.58196
Epoch 23/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5290 - accuracy: 0.4169 - val_loss: 1.5962 - val_accuracy: 0.3825

Epoch 00023: val_loss did not improve from 1.58196
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5200 - accuracy: 0.4252 - val_loss: 1.6057 - val_accuracy: 0.3816

Epoch 00024: val_loss did not improve from 1.58196
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5114 - accuracy: 0.4318 - val_loss: 1.5945 - val_accuracy: 0.3866

Epoch 00025: val_loss did not improve from 1.58196
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5106 - accuracy: 0.4343 - val_loss: 1.6181 - val_accuracy: 0.3776

Epoch 00026: val_loss did not improve from 1.58196
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5048 - accuracy: 0.4350 - val_loss: 1.5933 - val_accuracy: 0.3902

Epoch 00027: val_loss did not improve from 1.58196
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4932 - accuracy: 0.4448 - val_loss: 1.6036 - val_accuracy: 0.3907

Epoch 00028: val_loss did not improve from 1.58196
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4845 - accuracy: 0.4481 - val_loss: 1.6147 - val_accuracy: 0.3892

Epoch 00029: val_loss did not improve from 1.58196
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4740 - accuracy: 0.4591 - val_loss: 1.6218 - val_accuracy: 0.3893

Epoch 00030: val_loss did not improve from 1.58196
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4679 - accuracy: 0.4611 - val_loss: 1.6448 - val_accuracy: 0.3798

Epoch 00031: val_loss did not improve from 1.58196
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.5926 - accuracy: 0.3800
Testing Loss = 1.592551, Testing Accuracy = 0.380024
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4413 - accuracy: 0.1992 - val_loss: 8.7072 - val_accuracy: 0.2149

Epoch 00001: val_loss improved from inf to 8.70718, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7847 - accuracy: 0.2069 - val_loss: 5.3511 - val_accuracy: 0.2173

Epoch 00002: val_loss improved from 8.70718 to 5.35112, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5792 - accuracy: 0.2161 - val_loss: 3.9603 - val_accuracy: 0.2336

Epoch 00003: val_loss improved from 5.35112 to 3.96026, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4910 - accuracy: 0.2713 - val_loss: 3.1696 - val_accuracy: 0.2924

Epoch 00004: val_loss improved from 3.96026 to 3.16960, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8897 - accuracy: 0.2956 - val_loss: 2.6891 - val_accuracy: 0.3028

Epoch 00005: val_loss improved from 3.16960 to 2.68914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5050 - accuracy: 0.3052 - val_loss: 2.3570 - val_accuracy: 0.3125

Epoch 00006: val_loss improved from 2.68914 to 2.35702, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2407 - accuracy: 0.3109 - val_loss: 2.1262 - val_accuracy: 0.3195

Epoch 00007: val_loss improved from 2.35702 to 2.12620, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0540 - accuracy: 0.3152 - val_loss: 1.9693 - val_accuracy: 0.3291

Epoch 00008: val_loss improved from 2.12620 to 1.96928, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9218 - accuracy: 0.3255 - val_loss: 1.8589 - val_accuracy: 0.3332

Epoch 00009: val_loss improved from 1.96928 to 1.85893, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8275 - accuracy: 0.3295 - val_loss: 1.7828 - val_accuracy: 0.3363

Epoch 00010: val_loss improved from 1.85893 to 1.78283, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7611 - accuracy: 0.3395 - val_loss: 1.7309 - val_accuracy: 0.3421

Epoch 00011: val_loss improved from 1.78283 to 1.73090, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7141 - accuracy: 0.3450 - val_loss: 1.6878 - val_accuracy: 0.3515

Epoch 00012: val_loss improved from 1.73090 to 1.68776, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6765 - accuracy: 0.3563 - val_loss: 1.6585 - val_accuracy: 0.3611

Epoch 00013: val_loss improved from 1.68776 to 1.65849, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6451 - accuracy: 0.3640 - val_loss: 1.6443 - val_accuracy: 0.3647

Epoch 00014: val_loss improved from 1.65849 to 1.64428, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6234 - accuracy: 0.3716 - val_loss: 1.6223 - val_accuracy: 0.3724

Epoch 00015: val_loss improved from 1.64428 to 1.62226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6036 - accuracy: 0.3804 - val_loss: 1.6194 - val_accuracy: 0.3687

Epoch 00016: val_loss improved from 1.62226 to 1.61936, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5889 - accuracy: 0.3858 - val_loss: 1.5941 - val_accuracy: 0.3866

Epoch 00017: val_loss improved from 1.61936 to 1.59406, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5751 - accuracy: 0.3928 - val_loss: 1.5858 - val_accuracy: 0.3909

Epoch 00018: val_loss improved from 1.59406 to 1.58582, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/7
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5620 - accuracy: 0.4016 - val_loss: 1.5919 - val_accuracy: 0.3863

Epoch 00019: val_loss did not improve from 1.58582
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5505 - accuracy: 0.4066 - val_loss: 1.5932 - val_accuracy: 0.3865

Epoch 00020: val_loss did not improve from 1.58582
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5419 - accuracy: 0.4101 - val_loss: 1.5889 - val_accuracy: 0.3899

Epoch 00021: val_loss did not improve from 1.58582
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5333 - accuracy: 0.4191 - val_loss: 1.5917 - val_accuracy: 0.3895

Epoch 00022: val_loss did not improve from 1.58582
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5243 - accuracy: 0.4220 - val_loss: 1.5871 - val_accuracy: 0.3911

Epoch 00023: val_loss did not improve from 1.58582
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5170 - accuracy: 0.4283 - val_loss: 1.5867 - val_accuracy: 0.3911

Epoch 00024: val_loss did not improve from 1.58582
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5112 - accuracy: 0.4315 - val_loss: 1.5938 - val_accuracy: 0.3927

Epoch 00025: val_loss did not improve from 1.58582
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5034 - accuracy: 0.4391 - val_loss: 1.6135 - val_accuracy: 0.3860

Epoch 00026: val_loss did not improve from 1.58582
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4961 - accuracy: 0.4427 - val_loss: 1.6264 - val_accuracy: 0.3829

Epoch 00027: val_loss did not improve from 1.58582
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4818 - accuracy: 0.4533 - val_loss: 1.6097 - val_accuracy: 0.3939

Epoch 00028: val_loss did not improve from 1.58582
Epoch 00028: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.5986 - accuracy: 0.3765
Testing Loss = 1.598635, Testing Accuracy = 0.376451
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.5250 - accuracy: 0.1985 - val_loss: 8.8263 - val_accuracy: 0.2163

Epoch 00001: val_loss improved from inf to 8.82629, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8818 - accuracy: 0.2049 - val_loss: 5.4196 - val_accuracy: 0.2173

Epoch 00002: val_loss improved from 8.82629 to 5.41963, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6314 - accuracy: 0.2102 - val_loss: 3.9974 - val_accuracy: 0.2199

Epoch 00003: val_loss improved from 5.41963 to 3.99742, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5963 - accuracy: 0.2132 - val_loss: 3.2471 - val_accuracy: 0.2256

Epoch 00004: val_loss improved from 3.99742 to 3.24712, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9589 - accuracy: 0.2411 - val_loss: 2.6901 - val_accuracy: 0.2980

Epoch 00005: val_loss improved from 3.24712 to 2.69008, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.4983 - accuracy: 0.2917 - val_loss: 2.3413 - val_accuracy: 0.3139

Epoch 00006: val_loss improved from 2.69008 to 2.34133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2264 - accuracy: 0.3044 - val_loss: 2.1109 - val_accuracy: 0.3207

Epoch 00007: val_loss improved from 2.34133 to 2.11088, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0384 - accuracy: 0.3144 - val_loss: 1.9523 - val_accuracy: 0.3284

Epoch 00008: val_loss improved from 2.11088 to 1.95225, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9077 - accuracy: 0.3234 - val_loss: 1.8428 - val_accuracy: 0.3392

Epoch 00009: val_loss improved from 1.95225 to 1.84281, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8155 - accuracy: 0.3284 - val_loss: 1.7681 - val_accuracy: 0.3405

Epoch 00010: val_loss improved from 1.84281 to 1.76815, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7505 - accuracy: 0.3371 - val_loss: 1.7141 - val_accuracy: 0.3552

Epoch 00011: val_loss improved from 1.76815 to 1.71412, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7029 - accuracy: 0.3471 - val_loss: 1.6741 - val_accuracy: 0.3629

Epoch 00012: val_loss improved from 1.71412 to 1.67407, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6639 - accuracy: 0.3590 - val_loss: 1.6429 - val_accuracy: 0.3681

Epoch 00013: val_loss improved from 1.67407 to 1.64291, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6364 - accuracy: 0.3677 - val_loss: 1.6203 - val_accuracy: 0.3755

Epoch 00014: val_loss improved from 1.64291 to 1.62031, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6127 - accuracy: 0.3745 - val_loss: 1.6066 - val_accuracy: 0.3798

Epoch 00015: val_loss improved from 1.62031 to 1.60663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5944 - accuracy: 0.3837 - val_loss: 1.6090 - val_accuracy: 0.3785

Epoch 00016: val_loss did not improve from 1.60663
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5812 - accuracy: 0.3874 - val_loss: 1.5970 - val_accuracy: 0.3808

Epoch 00017: val_loss improved from 1.60663 to 1.59697, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5700 - accuracy: 0.3923 - val_loss: 1.5789 - val_accuracy: 0.3919

Epoch 00018: val_loss improved from 1.59697 to 1.57895, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5588 - accuracy: 0.3986 - val_loss: 1.5799 - val_accuracy: 0.3880

Epoch 00019: val_loss did not improve from 1.57895
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5490 - accuracy: 0.4051 - val_loss: 1.5776 - val_accuracy: 0.3896

Epoch 00020: val_loss improved from 1.57895 to 1.57765, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5424 - accuracy: 0.4065 - val_loss: 1.5776 - val_accuracy: 0.3896

Epoch 00021: val_loss improved from 1.57765 to 1.57761, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/8
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5352 - accuracy: 0.4144 - val_loss: 1.5822 - val_accuracy: 0.3932

Epoch 00022: val_loss did not improve from 1.57761
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5274 - accuracy: 0.4166 - val_loss: 1.5859 - val_accuracy: 0.3923

Epoch 00023: val_loss did not improve from 1.57761
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5215 - accuracy: 0.4219 - val_loss: 1.5898 - val_accuracy: 0.3904

Epoch 00024: val_loss did not improve from 1.57761
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5153 - accuracy: 0.4251 - val_loss: 1.5931 - val_accuracy: 0.3937

Epoch 00025: val_loss did not improve from 1.57761
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5069 - accuracy: 0.4308 - val_loss: 1.5975 - val_accuracy: 0.3898

Epoch 00026: val_loss did not improve from 1.57761
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5014 - accuracy: 0.4344 - val_loss: 1.6007 - val_accuracy: 0.3902

Epoch 00027: val_loss did not improve from 1.57761
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4933 - accuracy: 0.4418 - val_loss: 1.6047 - val_accuracy: 0.3905

Epoch 00028: val_loss did not improve from 1.57761
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4871 - accuracy: 0.4458 - val_loss: 1.5880 - val_accuracy: 0.3973

Epoch 00029: val_loss did not improve from 1.57761
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4795 - accuracy: 0.4499 - val_loss: 1.5958 - val_accuracy: 0.3973

Epoch 00030: val_loss did not improve from 1.57761
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.5902 - accuracy: 0.3830
Testing Loss = 1.590223, Testing Accuracy = 0.383001
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4750 - accuracy: 0.2001 - val_loss: 8.7600 - val_accuracy: 0.2160

Epoch 00001: val_loss improved from inf to 8.76000, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8314 - accuracy: 0.2053 - val_loss: 5.3871 - val_accuracy: 0.2172

Epoch 00002: val_loss improved from 8.76000 to 5.38709, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6013 - accuracy: 0.2215 - val_loss: 3.9633 - val_accuracy: 0.2495

Epoch 00003: val_loss improved from 5.38709 to 3.96329, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4960 - accuracy: 0.2755 - val_loss: 3.1719 - val_accuracy: 0.2981

Epoch 00004: val_loss improved from 3.96329 to 3.17187, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8949 - accuracy: 0.2949 - val_loss: 2.6898 - val_accuracy: 0.3073

Epoch 00005: val_loss improved from 3.17187 to 2.68982, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5081 - accuracy: 0.3055 - val_loss: 2.3553 - val_accuracy: 0.3138

Epoch 00006: val_loss improved from 2.68982 to 2.35534, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2424 - accuracy: 0.3111 - val_loss: 2.1291 - val_accuracy: 0.3207

Epoch 00007: val_loss improved from 2.35534 to 2.12906, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0556 - accuracy: 0.3179 - val_loss: 1.9715 - val_accuracy: 0.3298

Epoch 00008: val_loss improved from 2.12906 to 1.97150, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9241 - accuracy: 0.3232 - val_loss: 1.8608 - val_accuracy: 0.3330

Epoch 00009: val_loss improved from 1.97150 to 1.86079, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8293 - accuracy: 0.3277 - val_loss: 1.7858 - val_accuracy: 0.3361

Epoch 00010: val_loss improved from 1.86079 to 1.78577, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7639 - accuracy: 0.3329 - val_loss: 1.7328 - val_accuracy: 0.3392

Epoch 00011: val_loss improved from 1.78577 to 1.73284, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7166 - accuracy: 0.3395 - val_loss: 1.6958 - val_accuracy: 0.3468

Epoch 00012: val_loss improved from 1.73284 to 1.69583, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6831 - accuracy: 0.3454 - val_loss: 1.6665 - val_accuracy: 0.3517

Epoch 00013: val_loss improved from 1.69583 to 1.66654, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6580 - accuracy: 0.3515 - val_loss: 1.6456 - val_accuracy: 0.3583

Epoch 00014: val_loss improved from 1.66654 to 1.64558, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6338 - accuracy: 0.3619 - val_loss: 1.6310 - val_accuracy: 0.3646

Epoch 00015: val_loss improved from 1.64558 to 1.63103, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6175 - accuracy: 0.3680 - val_loss: 1.6169 - val_accuracy: 0.3705

Epoch 00016: val_loss improved from 1.63103 to 1.61692, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6004 - accuracy: 0.3773 - val_loss: 1.6091 - val_accuracy: 0.3735

Epoch 00017: val_loss improved from 1.61692 to 1.60914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5855 - accuracy: 0.3862 - val_loss: 1.6060 - val_accuracy: 0.3762

Epoch 00018: val_loss improved from 1.60914 to 1.60598, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5735 - accuracy: 0.3917 - val_loss: 1.5984 - val_accuracy: 0.3819

Epoch 00019: val_loss improved from 1.60598 to 1.59839, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5617 - accuracy: 0.3986 - val_loss: 1.5889 - val_accuracy: 0.3848

Epoch 00020: val_loss improved from 1.59839 to 1.58885, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5518 - accuracy: 0.4045 - val_loss: 1.5991 - val_accuracy: 0.3847

Epoch 00021: val_loss did not improve from 1.58885
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5453 - accuracy: 0.4079 - val_loss: 1.5949 - val_accuracy: 0.3830

Epoch 00022: val_loss did not improve from 1.58885
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5347 - accuracy: 0.4137 - val_loss: 1.6001 - val_accuracy: 0.3854

Epoch 00023: val_loss did not improve from 1.58885
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5267 - accuracy: 0.4185 - val_loss: 1.5872 - val_accuracy: 0.3912

Epoch 00024: val_loss improved from 1.58885 to 1.58715, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.1/Try/9
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5209 - accuracy: 0.4244 - val_loss: 1.6031 - val_accuracy: 0.3875

Epoch 00025: val_loss did not improve from 1.58715
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5104 - accuracy: 0.4317 - val_loss: 1.6079 - val_accuracy: 0.3894

Epoch 00026: val_loss did not improve from 1.58715
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5077 - accuracy: 0.4334 - val_loss: 1.5962 - val_accuracy: 0.3907

Epoch 00027: val_loss did not improve from 1.58715
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4976 - accuracy: 0.4412 - val_loss: 1.6075 - val_accuracy: 0.3945

Epoch 00028: val_loss did not improve from 1.58715
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4882 - accuracy: 0.4468 - val_loss: 1.6124 - val_accuracy: 0.3921

Epoch 00029: val_loss did not improve from 1.58715
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4802 - accuracy: 0.4537 - val_loss: 1.6176 - val_accuracy: 0.3918

Epoch 00030: val_loss did not improve from 1.58715
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4713 - accuracy: 0.4589 - val_loss: 1.6282 - val_accuracy: 0.3901

Epoch 00031: val_loss did not improve from 1.58715
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4635 - accuracy: 0.4638 - val_loss: 1.6373 - val_accuracy: 0.3860

Epoch 00032: val_loss did not improve from 1.58715
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4493 - accuracy: 0.4736 - val_loss: 1.6401 - val_accuracy: 0.3812

Epoch 00033: val_loss did not improve from 1.58715
Epoch 34/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4417 - accuracy: 0.4847 - val_loss: 1.6470 - val_accuracy: 0.3874

Epoch 00034: val_loss did not improve from 1.58715
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.6060 - accuracy: 0.3806
Testing Loss = 1.606037, Testing Accuracy = 0.380619
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 83.62 +- 0.0713 %)
$W^-/W^-$ (auc = 82.82 +- 0.1406 %)
$Z/Z$ (auc = 75.76 +- 0.4148 %)
$W^+/W^-$ (auc = 69.93 +- 0.2332 %)
$W^+/Z$$ (auc = 66.93 +- 0.1685 %)
$W^-/Z$ (auc = 68.59 +- 0.1632 %)
The summarized testing accuracy = 38.24 +- 0.3449 %, with the loss = 1.5972 +- 0.005778
