

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-25 10:37:53.266339
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 33s 203ms/step - loss: 12.5000 - accuracy: 0.1975 - val_loss: 8.7861 - val_accuracy: 0.2071

Epoch 00001: val_loss improved from inf to 8.78615, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8447 - accuracy: 0.2065 - val_loss: 5.3959 - val_accuracy: 0.2077

Epoch 00002: val_loss improved from 8.78615 to 5.39591, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.5883 - accuracy: 0.2279 - val_loss: 3.9733 - val_accuracy: 0.2343

Epoch 00003: val_loss improved from 5.39591 to 3.97327, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.4880 - accuracy: 0.2803 - val_loss: 3.1945 - val_accuracy: 0.2811

Epoch 00004: val_loss improved from 3.97327 to 3.19448, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 5/100
83/83 [==============================] - 6s 66ms/step - loss: 2.8918 - accuracy: 0.2995 - val_loss: 2.7066 - val_accuracy: 0.3031

Epoch 00005: val_loss improved from 3.19448 to 2.70655, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 6/100
83/83 [==============================] - 6s 66ms/step - loss: 2.5050 - accuracy: 0.3031 - val_loss: 2.3659 - val_accuracy: 0.3162

Epoch 00006: val_loss improved from 2.70655 to 2.36585, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 7/100
83/83 [==============================] - 6s 67ms/step - loss: 2.2380 - accuracy: 0.3150 - val_loss: 2.1288 - val_accuracy: 0.3229

Epoch 00007: val_loss improved from 2.36585 to 2.12880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 8/100
83/83 [==============================] - 6s 66ms/step - loss: 2.0508 - accuracy: 0.3202 - val_loss: 1.9694 - val_accuracy: 0.3286

Epoch 00008: val_loss improved from 2.12880 to 1.96936, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 9/100
83/83 [==============================] - 6s 67ms/step - loss: 1.9167 - accuracy: 0.3266 - val_loss: 1.8559 - val_accuracy: 0.3354

Epoch 00009: val_loss improved from 1.96936 to 1.85590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 10/100
83/83 [==============================] - 6s 67ms/step - loss: 1.8239 - accuracy: 0.3329 - val_loss: 1.7822 - val_accuracy: 0.3413

Epoch 00010: val_loss improved from 1.85590 to 1.78224, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 11/100
83/83 [==============================] - 6s 66ms/step - loss: 1.7554 - accuracy: 0.3397 - val_loss: 1.7277 - val_accuracy: 0.3446

Epoch 00011: val_loss improved from 1.78224 to 1.72766, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7097 - accuracy: 0.3472 - val_loss: 1.6887 - val_accuracy: 0.3471

Epoch 00012: val_loss improved from 1.72766 to 1.68867, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 13/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6721 - accuracy: 0.3537 - val_loss: 1.6600 - val_accuracy: 0.3514

Epoch 00013: val_loss improved from 1.68867 to 1.65997, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 14/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6419 - accuracy: 0.3645 - val_loss: 1.6341 - val_accuracy: 0.3641

Epoch 00014: val_loss improved from 1.65997 to 1.63411, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 15/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6198 - accuracy: 0.3716 - val_loss: 1.6183 - val_accuracy: 0.3665

Epoch 00015: val_loss improved from 1.63411 to 1.61827, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 16/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6018 - accuracy: 0.3786 - val_loss: 1.5988 - val_accuracy: 0.3784

Epoch 00016: val_loss improved from 1.61827 to 1.59879, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 17/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5835 - accuracy: 0.3856 - val_loss: 1.5859 - val_accuracy: 0.3881

Epoch 00017: val_loss improved from 1.59879 to 1.58592, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 18/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5718 - accuracy: 0.3884 - val_loss: 1.5810 - val_accuracy: 0.3925

Epoch 00018: val_loss improved from 1.58592 to 1.58102, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 19/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5579 - accuracy: 0.3990 - val_loss: 1.5763 - val_accuracy: 0.3916

Epoch 00019: val_loss improved from 1.58102 to 1.57630, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5497 - accuracy: 0.4035 - val_loss: 1.5729 - val_accuracy: 0.3932

Epoch 00020: val_loss improved from 1.57630 to 1.57293, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5413 - accuracy: 0.4085 - val_loss: 1.5694 - val_accuracy: 0.3944

Epoch 00021: val_loss improved from 1.57293 to 1.56942, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5304 - accuracy: 0.4170 - val_loss: 1.5679 - val_accuracy: 0.3970

Epoch 00022: val_loss improved from 1.56942 to 1.56791, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5253 - accuracy: 0.4199 - val_loss: 1.5678 - val_accuracy: 0.4008

Epoch 00023: val_loss improved from 1.56791 to 1.56783, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/0
Epoch 24/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5171 - accuracy: 0.4228 - val_loss: 1.5686 - val_accuracy: 0.3985

Epoch 00024: val_loss did not improve from 1.56783
Epoch 25/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5137 - accuracy: 0.4271 - val_loss: 1.5685 - val_accuracy: 0.3963

Epoch 00025: val_loss did not improve from 1.56783
Epoch 26/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5029 - accuracy: 0.4357 - val_loss: 1.5728 - val_accuracy: 0.3988

Epoch 00026: val_loss did not improve from 1.56783
Epoch 27/100
83/83 [==============================] - 6s 72ms/step - loss: 1.4960 - accuracy: 0.4386 - val_loss: 1.5748 - val_accuracy: 0.3992

Epoch 00027: val_loss did not improve from 1.56783
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4887 - accuracy: 0.4429 - val_loss: 1.5774 - val_accuracy: 0.4009

Epoch 00028: val_loss did not improve from 1.56783
Epoch 29/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4806 - accuracy: 0.4492 - val_loss: 1.5836 - val_accuracy: 0.3975

Epoch 00029: val_loss did not improve from 1.56783
Epoch 30/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4719 - accuracy: 0.4536 - val_loss: 1.5930 - val_accuracy: 0.3980

Epoch 00030: val_loss did not improve from 1.56783
Epoch 31/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4650 - accuracy: 0.4613 - val_loss: 1.5980 - val_accuracy: 0.3953

Epoch 00031: val_loss did not improve from 1.56783
Epoch 32/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4575 - accuracy: 0.4680 - val_loss: 1.6014 - val_accuracy: 0.3977

Epoch 00032: val_loss did not improve from 1.56783
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 4ms/step - loss: 1.5735 - accuracy: 0.3918
Testing Loss = 1.573524, Testing Accuracy = 0.391783
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 67ms/step - loss: 12.4128 - accuracy: 0.1986 - val_loss: 8.6813 - val_accuracy: 0.2083

Epoch 00001: val_loss improved from inf to 8.68134, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 2/100
83/83 [==============================] - 6s 66ms/step - loss: 6.7616 - accuracy: 0.2071 - val_loss: 5.3357 - val_accuracy: 0.2121

Epoch 00002: val_loss improved from 8.68134 to 5.33570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 3/100
83/83 [==============================] - 6s 66ms/step - loss: 4.5647 - accuracy: 0.2173 - val_loss: 3.9515 - val_accuracy: 0.2275

Epoch 00003: val_loss improved from 5.33570 to 3.95152, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.4791 - accuracy: 0.2758 - val_loss: 3.1760 - val_accuracy: 0.2803

Epoch 00004: val_loss improved from 3.95152 to 3.17599, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 5/100
83/83 [==============================] - 6s 67ms/step - loss: 2.8782 - accuracy: 0.2960 - val_loss: 2.6937 - val_accuracy: 0.2987

Epoch 00005: val_loss improved from 3.17599 to 2.69372, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.4941 - accuracy: 0.3049 - val_loss: 2.3613 - val_accuracy: 0.3110

Epoch 00006: val_loss improved from 2.69372 to 2.36129, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 7/100
83/83 [==============================] - 6s 66ms/step - loss: 2.2308 - accuracy: 0.3127 - val_loss: 2.1261 - val_accuracy: 0.3279

Epoch 00007: val_loss improved from 2.36129 to 2.12609, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 8/100
83/83 [==============================] - 6s 66ms/step - loss: 2.0432 - accuracy: 0.3242 - val_loss: 1.9649 - val_accuracy: 0.3329

Epoch 00008: val_loss improved from 2.12609 to 1.96488, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 9/100
83/83 [==============================] - 6s 66ms/step - loss: 1.9125 - accuracy: 0.3288 - val_loss: 1.8578 - val_accuracy: 0.3346

Epoch 00009: val_loss improved from 1.96488 to 1.85780, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 10/100
83/83 [==============================] - 6s 66ms/step - loss: 1.8182 - accuracy: 0.3367 - val_loss: 1.7788 - val_accuracy: 0.3411

Epoch 00010: val_loss improved from 1.85780 to 1.77877, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 11/100
83/83 [==============================] - 6s 66ms/step - loss: 1.7517 - accuracy: 0.3432 - val_loss: 1.7253 - val_accuracy: 0.3420

Epoch 00011: val_loss improved from 1.77877 to 1.72531, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 12/100
83/83 [==============================] - 6s 66ms/step - loss: 1.7048 - accuracy: 0.3480 - val_loss: 1.6876 - val_accuracy: 0.3462

Epoch 00012: val_loss improved from 1.72531 to 1.68758, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 13/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6673 - accuracy: 0.3599 - val_loss: 1.6543 - val_accuracy: 0.3576

Epoch 00013: val_loss improved from 1.68758 to 1.65434, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 14/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6392 - accuracy: 0.3662 - val_loss: 1.6311 - val_accuracy: 0.3613

Epoch 00014: val_loss improved from 1.65434 to 1.63109, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 15/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6180 - accuracy: 0.3724 - val_loss: 1.6138 - val_accuracy: 0.3704

Epoch 00015: val_loss improved from 1.63109 to 1.61380, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 16/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5969 - accuracy: 0.3807 - val_loss: 1.6006 - val_accuracy: 0.3776

Epoch 00016: val_loss improved from 1.61380 to 1.60058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5829 - accuracy: 0.3877 - val_loss: 1.5929 - val_accuracy: 0.3756

Epoch 00017: val_loss improved from 1.60058 to 1.59289, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5704 - accuracy: 0.3922 - val_loss: 1.5828 - val_accuracy: 0.3859

Epoch 00018: val_loss improved from 1.59289 to 1.58275, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5582 - accuracy: 0.3993 - val_loss: 1.5825 - val_accuracy: 0.3842

Epoch 00019: val_loss improved from 1.58275 to 1.58253, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5480 - accuracy: 0.4050 - val_loss: 1.5768 - val_accuracy: 0.3919

Epoch 00020: val_loss improved from 1.58253 to 1.57675, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 21/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5389 - accuracy: 0.4102 - val_loss: 1.5766 - val_accuracy: 0.3914

Epoch 00021: val_loss improved from 1.57675 to 1.57659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 22/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5322 - accuracy: 0.4138 - val_loss: 1.5728 - val_accuracy: 0.3969

Epoch 00022: val_loss improved from 1.57659 to 1.57284, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/1
Epoch 23/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5202 - accuracy: 0.4229 - val_loss: 1.5743 - val_accuracy: 0.3993

Epoch 00023: val_loss did not improve from 1.57284
Epoch 24/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5154 - accuracy: 0.4257 - val_loss: 1.5755 - val_accuracy: 0.3956

Epoch 00024: val_loss did not improve from 1.57284
Epoch 25/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5113 - accuracy: 0.4279 - val_loss: 1.5737 - val_accuracy: 0.4000

Epoch 00025: val_loss did not improve from 1.57284
Epoch 26/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5032 - accuracy: 0.4364 - val_loss: 1.5763 - val_accuracy: 0.4037

Epoch 00026: val_loss did not improve from 1.57284
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4906 - accuracy: 0.4438 - val_loss: 1.5841 - val_accuracy: 0.4019

Epoch 00027: val_loss did not improve from 1.57284
Epoch 28/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4900 - accuracy: 0.4432 - val_loss: 1.5846 - val_accuracy: 0.4024

Epoch 00028: val_loss did not improve from 1.57284
Epoch 29/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4806 - accuracy: 0.4515 - val_loss: 1.5867 - val_accuracy: 0.4005

Epoch 00029: val_loss did not improve from 1.57284
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4703 - accuracy: 0.4583 - val_loss: 1.5928 - val_accuracy: 0.4021

Epoch 00030: val_loss did not improve from 1.57284
Epoch 31/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4612 - accuracy: 0.4648 - val_loss: 1.6021 - val_accuracy: 0.4010

Epoch 00031: val_loss did not improve from 1.57284
Epoch 32/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4479 - accuracy: 0.4709 - val_loss: 1.6115 - val_accuracy: 0.4014

Epoch 00032: val_loss did not improve from 1.57284
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.5780 - accuracy: 0.3938
Testing Loss = 1.577965, Testing Accuracy = 0.393793
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 67ms/step - loss: 12.4125 - accuracy: 0.2000 - val_loss: 8.6843 - val_accuracy: 0.2073

Epoch 00001: val_loss improved from inf to 8.68432, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 2/100
83/83 [==============================] - 6s 66ms/step - loss: 6.7685 - accuracy: 0.2089 - val_loss: 5.3453 - val_accuracy: 0.2096

Epoch 00002: val_loss improved from 8.68432 to 5.34527, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.5747 - accuracy: 0.2133 - val_loss: 3.9630 - val_accuracy: 0.2183

Epoch 00003: val_loss improved from 5.34527 to 3.96299, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4952 - accuracy: 0.2660 - val_loss: 3.1772 - val_accuracy: 0.2725

Epoch 00004: val_loss improved from 3.96299 to 3.17719, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8827 - accuracy: 0.2970 - val_loss: 2.6980 - val_accuracy: 0.2934

Epoch 00005: val_loss improved from 3.17719 to 2.69804, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.4979 - accuracy: 0.3042 - val_loss: 2.3645 - val_accuracy: 0.3143

Epoch 00006: val_loss improved from 2.69804 to 2.36454, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 7/100
83/83 [==============================] - 6s 67ms/step - loss: 2.2328 - accuracy: 0.3115 - val_loss: 2.1279 - val_accuracy: 0.3198

Epoch 00007: val_loss improved from 2.36454 to 2.12793, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 8/100
83/83 [==============================] - 6s 67ms/step - loss: 2.0452 - accuracy: 0.3200 - val_loss: 1.9662 - val_accuracy: 0.3287

Epoch 00008: val_loss improved from 2.12793 to 1.96621, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9152 - accuracy: 0.3254 - val_loss: 1.8535 - val_accuracy: 0.3366

Epoch 00009: val_loss improved from 1.96621 to 1.85354, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8193 - accuracy: 0.3371 - val_loss: 1.7774 - val_accuracy: 0.3397

Epoch 00010: val_loss improved from 1.85354 to 1.77744, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7545 - accuracy: 0.3419 - val_loss: 1.7240 - val_accuracy: 0.3419

Epoch 00011: val_loss improved from 1.77744 to 1.72395, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 12/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7050 - accuracy: 0.3506 - val_loss: 1.6922 - val_accuracy: 0.3449

Epoch 00012: val_loss improved from 1.72395 to 1.69216, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 13/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6704 - accuracy: 0.3529 - val_loss: 1.6617 - val_accuracy: 0.3458

Epoch 00013: val_loss improved from 1.69216 to 1.66173, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 14/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6422 - accuracy: 0.3631 - val_loss: 1.6429 - val_accuracy: 0.3551

Epoch 00014: val_loss improved from 1.66173 to 1.64287, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6193 - accuracy: 0.3692 - val_loss: 1.6153 - val_accuracy: 0.3676

Epoch 00015: val_loss improved from 1.64287 to 1.61526, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 16/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5984 - accuracy: 0.3794 - val_loss: 1.6052 - val_accuracy: 0.3673

Epoch 00016: val_loss improved from 1.61526 to 1.60524, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5834 - accuracy: 0.3842 - val_loss: 1.5892 - val_accuracy: 0.3814

Epoch 00017: val_loss improved from 1.60524 to 1.58923, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5730 - accuracy: 0.3899 - val_loss: 1.5860 - val_accuracy: 0.3795

Epoch 00018: val_loss improved from 1.58923 to 1.58602, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5579 - accuracy: 0.3992 - val_loss: 1.5788 - val_accuracy: 0.3854

Epoch 00019: val_loss improved from 1.58602 to 1.57879, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5505 - accuracy: 0.4036 - val_loss: 1.5742 - val_accuracy: 0.3899

Epoch 00020: val_loss improved from 1.57879 to 1.57416, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 21/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5389 - accuracy: 0.4105 - val_loss: 1.5724 - val_accuracy: 0.3905

Epoch 00021: val_loss improved from 1.57416 to 1.57244, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 22/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5298 - accuracy: 0.4165 - val_loss: 1.5718 - val_accuracy: 0.3884

Epoch 00022: val_loss improved from 1.57244 to 1.57180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 23/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5251 - accuracy: 0.4219 - val_loss: 1.5705 - val_accuracy: 0.3891

Epoch 00023: val_loss improved from 1.57180 to 1.57050, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/2
Epoch 24/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5164 - accuracy: 0.4248 - val_loss: 1.5705 - val_accuracy: 0.3931

Epoch 00024: val_loss did not improve from 1.57050
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5062 - accuracy: 0.4319 - val_loss: 1.5725 - val_accuracy: 0.3925

Epoch 00025: val_loss did not improve from 1.57050
Epoch 26/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4989 - accuracy: 0.4402 - val_loss: 1.5790 - val_accuracy: 0.3897

Epoch 00026: val_loss did not improve from 1.57050
Epoch 27/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4936 - accuracy: 0.4446 - val_loss: 1.5814 - val_accuracy: 0.3946

Epoch 00027: val_loss did not improve from 1.57050
Epoch 28/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4837 - accuracy: 0.4463 - val_loss: 1.5870 - val_accuracy: 0.3948

Epoch 00028: val_loss did not improve from 1.57050
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4798 - accuracy: 0.4499 - val_loss: 1.5888 - val_accuracy: 0.3955

Epoch 00029: val_loss did not improve from 1.57050
Epoch 30/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4702 - accuracy: 0.4591 - val_loss: 1.5961 - val_accuracy: 0.3950

Epoch 00030: val_loss did not improve from 1.57050
Epoch 31/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4622 - accuracy: 0.4644 - val_loss: 1.6076 - val_accuracy: 0.3955

Epoch 00031: val_loss did not improve from 1.57050
Epoch 32/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4506 - accuracy: 0.4709 - val_loss: 1.6130 - val_accuracy: 0.3918

Epoch 00032: val_loss did not improve from 1.57050
Epoch 33/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4415 - accuracy: 0.4779 - val_loss: 1.6367 - val_accuracy: 0.3941

Epoch 00033: val_loss did not improve from 1.57050
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5762 - accuracy: 0.3909
Testing Loss = 1.576218, Testing Accuracy = 0.390890
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 67ms/step - loss: 12.5369 - accuracy: 0.1985 - val_loss: 8.8442 - val_accuracy: 0.2089

Epoch 00001: val_loss improved from inf to 8.84418, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 2/100
83/83 [==============================] - 6s 66ms/step - loss: 6.8999 - accuracy: 0.2069 - val_loss: 5.4420 - val_accuracy: 0.2106

Epoch 00002: val_loss improved from 8.84418 to 5.44205, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 3/100
83/83 [==============================] - 6s 66ms/step - loss: 4.6501 - accuracy: 0.2120 - val_loss: 4.0177 - val_accuracy: 0.2151

Epoch 00003: val_loss improved from 5.44205 to 4.01769, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.5838 - accuracy: 0.2300 - val_loss: 3.2172 - val_accuracy: 0.2610

Epoch 00004: val_loss improved from 4.01769 to 3.21715, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 5/100
83/83 [==============================] - 6s 67ms/step - loss: 2.9020 - accuracy: 0.2875 - val_loss: 2.7021 - val_accuracy: 0.2973

Epoch 00005: val_loss improved from 3.21715 to 2.70211, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 6/100
83/83 [==============================] - 6s 67ms/step - loss: 2.5028 - accuracy: 0.3029 - val_loss: 2.3645 - val_accuracy: 0.3129

Epoch 00006: val_loss improved from 2.70211 to 2.36447, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 7/100
83/83 [==============================] - 6s 67ms/step - loss: 2.2335 - accuracy: 0.3082 - val_loss: 2.1290 - val_accuracy: 0.3255

Epoch 00007: val_loss improved from 2.36447 to 2.12903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 8/100
83/83 [==============================] - 6s 67ms/step - loss: 2.0428 - accuracy: 0.3206 - val_loss: 1.9626 - val_accuracy: 0.3365

Epoch 00008: val_loss improved from 2.12903 to 1.96264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 9/100
83/83 [==============================] - 6s 67ms/step - loss: 1.9097 - accuracy: 0.3297 - val_loss: 1.8488 - val_accuracy: 0.3429

Epoch 00009: val_loss improved from 1.96264 to 1.84883, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 10/100
83/83 [==============================] - 6s 67ms/step - loss: 1.8165 - accuracy: 0.3365 - val_loss: 1.7750 - val_accuracy: 0.3395

Epoch 00010: val_loss improved from 1.84883 to 1.77497, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 11/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7485 - accuracy: 0.3436 - val_loss: 1.7192 - val_accuracy: 0.3439

Epoch 00011: val_loss improved from 1.77497 to 1.71920, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 12/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6994 - accuracy: 0.3510 - val_loss: 1.6777 - val_accuracy: 0.3483

Epoch 00012: val_loss improved from 1.71920 to 1.67772, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 13/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6639 - accuracy: 0.3567 - val_loss: 1.6512 - val_accuracy: 0.3523

Epoch 00013: val_loss improved from 1.67772 to 1.65123, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 14/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6327 - accuracy: 0.3660 - val_loss: 1.6213 - val_accuracy: 0.3659

Epoch 00014: val_loss improved from 1.65123 to 1.62127, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 15/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6109 - accuracy: 0.3731 - val_loss: 1.6121 - val_accuracy: 0.3635

Epoch 00015: val_loss improved from 1.62127 to 1.61208, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 16/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5937 - accuracy: 0.3781 - val_loss: 1.5956 - val_accuracy: 0.3723

Epoch 00016: val_loss improved from 1.61208 to 1.59562, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 17/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5774 - accuracy: 0.3882 - val_loss: 1.5849 - val_accuracy: 0.3798

Epoch 00017: val_loss improved from 1.59562 to 1.58485, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 18/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5663 - accuracy: 0.3926 - val_loss: 1.5753 - val_accuracy: 0.3854

Epoch 00018: val_loss improved from 1.58485 to 1.57527, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5527 - accuracy: 0.4002 - val_loss: 1.5739 - val_accuracy: 0.3836

Epoch 00019: val_loss improved from 1.57527 to 1.57387, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 20/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5442 - accuracy: 0.4044 - val_loss: 1.5674 - val_accuracy: 0.3899

Epoch 00020: val_loss improved from 1.57387 to 1.56737, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5353 - accuracy: 0.4081 - val_loss: 1.5677 - val_accuracy: 0.3884

Epoch 00021: val_loss did not improve from 1.56737
Epoch 22/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5310 - accuracy: 0.4105 - val_loss: 1.5636 - val_accuracy: 0.3896

Epoch 00022: val_loss improved from 1.56737 to 1.56361, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 23/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5232 - accuracy: 0.4155 - val_loss: 1.5626 - val_accuracy: 0.3916

Epoch 00023: val_loss improved from 1.56361 to 1.56262, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/3
Epoch 24/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5157 - accuracy: 0.4231 - val_loss: 1.5642 - val_accuracy: 0.3950

Epoch 00024: val_loss did not improve from 1.56262
Epoch 25/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5108 - accuracy: 0.4224 - val_loss: 1.5657 - val_accuracy: 0.3954

Epoch 00025: val_loss did not improve from 1.56262
Epoch 26/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5024 - accuracy: 0.4295 - val_loss: 1.5669 - val_accuracy: 0.3975

Epoch 00026: val_loss did not improve from 1.56262
Epoch 27/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4956 - accuracy: 0.4342 - val_loss: 1.5689 - val_accuracy: 0.3979

Epoch 00027: val_loss did not improve from 1.56262
Epoch 28/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4926 - accuracy: 0.4390 - val_loss: 1.5730 - val_accuracy: 0.3951

Epoch 00028: val_loss did not improve from 1.56262
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4869 - accuracy: 0.4439 - val_loss: 1.5788 - val_accuracy: 0.3950

Epoch 00029: val_loss did not improve from 1.56262
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4824 - accuracy: 0.4469 - val_loss: 1.5739 - val_accuracy: 0.3955

Epoch 00030: val_loss did not improve from 1.56262
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4711 - accuracy: 0.4511 - val_loss: 1.5788 - val_accuracy: 0.3974

Epoch 00031: val_loss did not improve from 1.56262
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4658 - accuracy: 0.4573 - val_loss: 1.5828 - val_accuracy: 0.3987

Epoch 00032: val_loss did not improve from 1.56262
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4585 - accuracy: 0.4616 - val_loss: 1.5941 - val_accuracy: 0.3937

Epoch 00033: val_loss did not improve from 1.56262
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.5653 - accuracy: 0.3947
Testing Loss = 1.565348, Testing Accuracy = 0.394686
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 67ms/step - loss: 12.4256 - accuracy: 0.1989 - val_loss: 8.6979 - val_accuracy: 0.2089

Epoch 00001: val_loss improved from inf to 8.69788, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 2/100
83/83 [==============================] - 5s 65ms/step - loss: 6.7803 - accuracy: 0.2102 - val_loss: 5.3555 - val_accuracy: 0.2099

Epoch 00002: val_loss improved from 8.69788 to 5.35546, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 3/100
83/83 [==============================] - 5s 66ms/step - loss: 4.5680 - accuracy: 0.2246 - val_loss: 3.9521 - val_accuracy: 0.2396

Epoch 00003: val_loss improved from 5.35546 to 3.95211, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 4/100
83/83 [==============================] - 5s 66ms/step - loss: 3.4830 - accuracy: 0.2818 - val_loss: 3.1917 - val_accuracy: 0.2682

Epoch 00004: val_loss improved from 3.95211 to 3.19175, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 5/100
83/83 [==============================] - 5s 66ms/step - loss: 2.8922 - accuracy: 0.2979 - val_loss: 2.7083 - val_accuracy: 0.2970

Epoch 00005: val_loss improved from 3.19175 to 2.70827, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 6/100
83/83 [==============================] - 6s 66ms/step - loss: 2.5067 - accuracy: 0.3068 - val_loss: 2.3700 - val_accuracy: 0.3134

Epoch 00006: val_loss improved from 2.70827 to 2.36996, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 7/100
83/83 [==============================] - 5s 66ms/step - loss: 2.2396 - accuracy: 0.3140 - val_loss: 2.1329 - val_accuracy: 0.3229

Epoch 00007: val_loss improved from 2.36996 to 2.13290, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 8/100
83/83 [==============================] - 6s 66ms/step - loss: 2.0491 - accuracy: 0.3243 - val_loss: 1.9696 - val_accuracy: 0.3331

Epoch 00008: val_loss improved from 2.13290 to 1.96957, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 9/100
83/83 [==============================] - 6s 66ms/step - loss: 1.9171 - accuracy: 0.3286 - val_loss: 1.8552 - val_accuracy: 0.3413

Epoch 00009: val_loss improved from 1.96957 to 1.85519, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 10/100
83/83 [==============================] - 6s 67ms/step - loss: 1.8220 - accuracy: 0.3366 - val_loss: 1.7785 - val_accuracy: 0.3437

Epoch 00010: val_loss improved from 1.85519 to 1.77846, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 11/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7544 - accuracy: 0.3428 - val_loss: 1.7275 - val_accuracy: 0.3479

Epoch 00011: val_loss improved from 1.77846 to 1.72748, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 12/100
83/83 [==============================] - 6s 66ms/step - loss: 1.7041 - accuracy: 0.3490 - val_loss: 1.6814 - val_accuracy: 0.3555

Epoch 00012: val_loss improved from 1.72748 to 1.68140, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 13/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6669 - accuracy: 0.3571 - val_loss: 1.6514 - val_accuracy: 0.3604

Epoch 00013: val_loss improved from 1.68140 to 1.65143, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6368 - accuracy: 0.3680 - val_loss: 1.6307 - val_accuracy: 0.3643

Epoch 00014: val_loss improved from 1.65143 to 1.63068, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 15/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6151 - accuracy: 0.3746 - val_loss: 1.6097 - val_accuracy: 0.3724

Epoch 00015: val_loss improved from 1.63068 to 1.60971, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 16/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5946 - accuracy: 0.3851 - val_loss: 1.6025 - val_accuracy: 0.3835

Epoch 00016: val_loss improved from 1.60971 to 1.60248, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5782 - accuracy: 0.3915 - val_loss: 1.5886 - val_accuracy: 0.3883

Epoch 00017: val_loss improved from 1.60248 to 1.58864, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 18/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5670 - accuracy: 0.3969 - val_loss: 1.5770 - val_accuracy: 0.3883

Epoch 00018: val_loss improved from 1.58864 to 1.57698, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 19/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5554 - accuracy: 0.4009 - val_loss: 1.5765 - val_accuracy: 0.3911

Epoch 00019: val_loss improved from 1.57698 to 1.57650, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 20/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5425 - accuracy: 0.4093 - val_loss: 1.5730 - val_accuracy: 0.3938

Epoch 00020: val_loss improved from 1.57650 to 1.57299, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 21/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5340 - accuracy: 0.4135 - val_loss: 1.5760 - val_accuracy: 0.3927

Epoch 00021: val_loss did not improve from 1.57299
Epoch 22/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5263 - accuracy: 0.4188 - val_loss: 1.5695 - val_accuracy: 0.3951

Epoch 00022: val_loss improved from 1.57299 to 1.56948, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 23/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5192 - accuracy: 0.4255 - val_loss: 1.5686 - val_accuracy: 0.3956

Epoch 00023: val_loss improved from 1.56948 to 1.56857, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/4
Epoch 24/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5126 - accuracy: 0.4299 - val_loss: 1.5706 - val_accuracy: 0.3967

Epoch 00024: val_loss did not improve from 1.56857
Epoch 25/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5006 - accuracy: 0.4365 - val_loss: 1.5738 - val_accuracy: 0.3982

Epoch 00025: val_loss did not improve from 1.56857
Epoch 26/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4967 - accuracy: 0.4399 - val_loss: 1.5740 - val_accuracy: 0.3944

Epoch 00026: val_loss did not improve from 1.56857
Epoch 27/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4872 - accuracy: 0.4453 - val_loss: 1.5853 - val_accuracy: 0.3958

Epoch 00027: val_loss did not improve from 1.56857
Epoch 28/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4809 - accuracy: 0.4509 - val_loss: 1.5876 - val_accuracy: 0.3948

Epoch 00028: val_loss did not improve from 1.56857
Epoch 29/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4700 - accuracy: 0.4581 - val_loss: 1.5893 - val_accuracy: 0.3980

Epoch 00029: val_loss did not improve from 1.56857
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4660 - accuracy: 0.4614 - val_loss: 1.6000 - val_accuracy: 0.3960

Epoch 00030: val_loss did not improve from 1.56857
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4553 - accuracy: 0.4682 - val_loss: 1.6185 - val_accuracy: 0.3934

Epoch 00031: val_loss did not improve from 1.56857
Epoch 32/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4450 - accuracy: 0.4775 - val_loss: 1.6148 - val_accuracy: 0.3941

Epoch 00032: val_loss did not improve from 1.56857
Epoch 33/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4346 - accuracy: 0.4820 - val_loss: 1.6195 - val_accuracy: 0.3934

Epoch 00033: val_loss did not improve from 1.56857
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5732 - accuracy: 0.3947
Testing Loss = 1.573165, Testing Accuracy = 0.394686
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 67ms/step - loss: 12.4260 - accuracy: 0.2006 - val_loss: 8.6915 - val_accuracy: 0.2079

Epoch 00001: val_loss improved from inf to 8.69154, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 2/100
83/83 [==============================] - 6s 66ms/step - loss: 6.7701 - accuracy: 0.2078 - val_loss: 5.3453 - val_accuracy: 0.2109

Epoch 00002: val_loss improved from 8.69154 to 5.34526, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 3/100
83/83 [==============================] - 5s 65ms/step - loss: 4.5603 - accuracy: 0.2231 - val_loss: 3.9485 - val_accuracy: 0.2405

Epoch 00003: val_loss improved from 5.34526 to 3.94850, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 4/100
83/83 [==============================] - 5s 65ms/step - loss: 3.4767 - accuracy: 0.2810 - val_loss: 3.1934 - val_accuracy: 0.2758

Epoch 00004: val_loss improved from 3.94850 to 3.19338, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 5/100
83/83 [==============================] - 5s 65ms/step - loss: 2.8916 - accuracy: 0.2973 - val_loss: 2.7097 - val_accuracy: 0.3014

Epoch 00005: val_loss improved from 3.19338 to 2.70972, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 6/100
83/83 [==============================] - 6s 66ms/step - loss: 2.5101 - accuracy: 0.3017 - val_loss: 2.3738 - val_accuracy: 0.3107

Epoch 00006: val_loss improved from 2.70972 to 2.37383, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 7/100
83/83 [==============================] - 6s 67ms/step - loss: 2.2414 - accuracy: 0.3165 - val_loss: 2.1385 - val_accuracy: 0.3156

Epoch 00007: val_loss improved from 2.37383 to 2.13855, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0555 - accuracy: 0.3194 - val_loss: 1.9766 - val_accuracy: 0.3250

Epoch 00008: val_loss improved from 2.13855 to 1.97656, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 9/100
83/83 [==============================] - 6s 67ms/step - loss: 1.9222 - accuracy: 0.3246 - val_loss: 1.8647 - val_accuracy: 0.3269

Epoch 00009: val_loss improved from 1.97656 to 1.86472, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8271 - accuracy: 0.3321 - val_loss: 1.7852 - val_accuracy: 0.3358

Epoch 00010: val_loss improved from 1.86472 to 1.78520, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7587 - accuracy: 0.3390 - val_loss: 1.7315 - val_accuracy: 0.3425

Epoch 00011: val_loss improved from 1.78520 to 1.73154, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7140 - accuracy: 0.3420 - val_loss: 1.6910 - val_accuracy: 0.3412

Epoch 00012: val_loss improved from 1.73154 to 1.69099, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6774 - accuracy: 0.3454 - val_loss: 1.6656 - val_accuracy: 0.3441

Epoch 00013: val_loss improved from 1.69099 to 1.66562, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6489 - accuracy: 0.3547 - val_loss: 1.6460 - val_accuracy: 0.3491

Epoch 00014: val_loss improved from 1.66562 to 1.64601, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 15/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6288 - accuracy: 0.3633 - val_loss: 1.6265 - val_accuracy: 0.3587

Epoch 00015: val_loss improved from 1.64601 to 1.62645, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6079 - accuracy: 0.3698 - val_loss: 1.6072 - val_accuracy: 0.3671

Epoch 00016: val_loss improved from 1.62645 to 1.60722, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5952 - accuracy: 0.3774 - val_loss: 1.6003 - val_accuracy: 0.3758

Epoch 00017: val_loss improved from 1.60722 to 1.60030, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5782 - accuracy: 0.3859 - val_loss: 1.5865 - val_accuracy: 0.3802

Epoch 00018: val_loss improved from 1.60030 to 1.58653, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5686 - accuracy: 0.3900 - val_loss: 1.5812 - val_accuracy: 0.3806

Epoch 00019: val_loss improved from 1.58653 to 1.58115, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5589 - accuracy: 0.3959 - val_loss: 1.5815 - val_accuracy: 0.3807

Epoch 00020: val_loss did not improve from 1.58115
Epoch 21/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5479 - accuracy: 0.4018 - val_loss: 1.5743 - val_accuracy: 0.3879

Epoch 00021: val_loss improved from 1.58115 to 1.57426, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5439 - accuracy: 0.4042 - val_loss: 1.5720 - val_accuracy: 0.3883

Epoch 00022: val_loss improved from 1.57426 to 1.57196, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5316 - accuracy: 0.4136 - val_loss: 1.5707 - val_accuracy: 0.3919

Epoch 00023: val_loss improved from 1.57196 to 1.57067, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/5
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5256 - accuracy: 0.4176 - val_loss: 1.5718 - val_accuracy: 0.3893

Epoch 00024: val_loss did not improve from 1.57067
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5197 - accuracy: 0.4183 - val_loss: 1.5715 - val_accuracy: 0.3898

Epoch 00025: val_loss did not improve from 1.57067
Epoch 26/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5119 - accuracy: 0.4224 - val_loss: 1.5735 - val_accuracy: 0.3917

Epoch 00026: val_loss did not improve from 1.57067
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5094 - accuracy: 0.4292 - val_loss: 1.5710 - val_accuracy: 0.3928

Epoch 00027: val_loss did not improve from 1.57067
Epoch 28/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5005 - accuracy: 0.4343 - val_loss: 1.5751 - val_accuracy: 0.3957

Epoch 00028: val_loss did not improve from 1.57067
Epoch 29/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4937 - accuracy: 0.4388 - val_loss: 1.5792 - val_accuracy: 0.3966

Epoch 00029: val_loss did not improve from 1.57067
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4808 - accuracy: 0.4487 - val_loss: 1.5842 - val_accuracy: 0.3962

Epoch 00030: val_loss did not improve from 1.57067
Epoch 31/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4716 - accuracy: 0.4547 - val_loss: 1.5917 - val_accuracy: 0.3979

Epoch 00031: val_loss did not improve from 1.57067
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4676 - accuracy: 0.4574 - val_loss: 1.5973 - val_accuracy: 0.3948

Epoch 00032: val_loss did not improve from 1.57067
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4591 - accuracy: 0.4658 - val_loss: 1.6094 - val_accuracy: 0.3940

Epoch 00033: val_loss did not improve from 1.57067
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.5753 - accuracy: 0.3938
Testing Loss = 1.575296, Testing Accuracy = 0.393793
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 68ms/step - loss: 12.4537 - accuracy: 0.1992 - val_loss: 8.7268 - val_accuracy: 0.2091

Epoch 00001: val_loss improved from inf to 8.72681, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.7958 - accuracy: 0.2058 - val_loss: 5.3580 - val_accuracy: 0.2122

Epoch 00002: val_loss improved from 8.72681 to 5.35795, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.5643 - accuracy: 0.2263 - val_loss: 3.9379 - val_accuracy: 0.2451

Epoch 00003: val_loss improved from 5.35795 to 3.93787, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.4740 - accuracy: 0.2838 - val_loss: 3.1825 - val_accuracy: 0.2823

Epoch 00004: val_loss improved from 3.93787 to 3.18254, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 5/100
83/83 [==============================] - 6s 67ms/step - loss: 2.8894 - accuracy: 0.2993 - val_loss: 2.7045 - val_accuracy: 0.3027

Epoch 00005: val_loss improved from 3.18254 to 2.70452, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 6/100
83/83 [==============================] - 6s 67ms/step - loss: 2.5044 - accuracy: 0.3089 - val_loss: 2.3668 - val_accuracy: 0.3160

Epoch 00006: val_loss improved from 2.70452 to 2.36683, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 7/100
83/83 [==============================] - 6s 67ms/step - loss: 2.2387 - accuracy: 0.3177 - val_loss: 2.1311 - val_accuracy: 0.3246

Epoch 00007: val_loss improved from 2.36683 to 2.13112, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0498 - accuracy: 0.3249 - val_loss: 1.9690 - val_accuracy: 0.3335

Epoch 00008: val_loss improved from 2.13112 to 1.96901, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 9/100
83/83 [==============================] - 6s 67ms/step - loss: 1.9170 - accuracy: 0.3294 - val_loss: 1.8615 - val_accuracy: 0.3375

Epoch 00009: val_loss improved from 1.96901 to 1.86151, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8205 - accuracy: 0.3386 - val_loss: 1.7810 - val_accuracy: 0.3418

Epoch 00010: val_loss improved from 1.86151 to 1.78101, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 11/100
83/83 [==============================] - 6s 70ms/step - loss: 1.7534 - accuracy: 0.3477 - val_loss: 1.7273 - val_accuracy: 0.3421

Epoch 00011: val_loss improved from 1.78101 to 1.72728, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7043 - accuracy: 0.3531 - val_loss: 1.6872 - val_accuracy: 0.3468

Epoch 00012: val_loss improved from 1.72728 to 1.68718, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 13/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6629 - accuracy: 0.3638 - val_loss: 1.6473 - val_accuracy: 0.3672

Epoch 00013: val_loss improved from 1.68718 to 1.64732, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 14/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6352 - accuracy: 0.3697 - val_loss: 1.6254 - val_accuracy: 0.3703

Epoch 00014: val_loss improved from 1.64732 to 1.62539, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6090 - accuracy: 0.3807 - val_loss: 1.6068 - val_accuracy: 0.3820

Epoch 00015: val_loss improved from 1.62539 to 1.60679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 16/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5948 - accuracy: 0.3798 - val_loss: 1.6002 - val_accuracy: 0.3807

Epoch 00016: val_loss improved from 1.60679 to 1.60022, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 17/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5748 - accuracy: 0.3944 - val_loss: 1.5836 - val_accuracy: 0.3896

Epoch 00017: val_loss improved from 1.60022 to 1.58365, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 18/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5654 - accuracy: 0.3960 - val_loss: 1.5790 - val_accuracy: 0.3880

Epoch 00018: val_loss improved from 1.58365 to 1.57895, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 19/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5526 - accuracy: 0.4027 - val_loss: 1.5745 - val_accuracy: 0.3910

Epoch 00019: val_loss improved from 1.57895 to 1.57454, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 20/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5409 - accuracy: 0.4099 - val_loss: 1.5718 - val_accuracy: 0.3931

Epoch 00020: val_loss improved from 1.57454 to 1.57178, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5352 - accuracy: 0.4126 - val_loss: 1.5715 - val_accuracy: 0.3938

Epoch 00021: val_loss improved from 1.57178 to 1.57148, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5260 - accuracy: 0.4176 - val_loss: 1.5698 - val_accuracy: 0.3947

Epoch 00022: val_loss improved from 1.57148 to 1.56976, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5183 - accuracy: 0.4214 - val_loss: 1.5688 - val_accuracy: 0.3949

Epoch 00023: val_loss improved from 1.56976 to 1.56878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/6
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5085 - accuracy: 0.4292 - val_loss: 1.5729 - val_accuracy: 0.3946

Epoch 00024: val_loss did not improve from 1.56878
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5023 - accuracy: 0.4329 - val_loss: 1.5770 - val_accuracy: 0.3925

Epoch 00025: val_loss did not improve from 1.56878
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5004 - accuracy: 0.4368 - val_loss: 1.5730 - val_accuracy: 0.3958

Epoch 00026: val_loss did not improve from 1.56878
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4888 - accuracy: 0.4415 - val_loss: 1.5785 - val_accuracy: 0.3942

Epoch 00027: val_loss did not improve from 1.56878
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4839 - accuracy: 0.4472 - val_loss: 1.5841 - val_accuracy: 0.3937

Epoch 00028: val_loss did not improve from 1.56878
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4783 - accuracy: 0.4531 - val_loss: 1.5855 - val_accuracy: 0.3951

Epoch 00029: val_loss did not improve from 1.56878
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4686 - accuracy: 0.4583 - val_loss: 1.5899 - val_accuracy: 0.3978

Epoch 00030: val_loss did not improve from 1.56878
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4609 - accuracy: 0.4632 - val_loss: 1.5970 - val_accuracy: 0.3969

Epoch 00031: val_loss did not improve from 1.56878
Epoch 32/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4500 - accuracy: 0.4703 - val_loss: 1.6045 - val_accuracy: 0.3970

Epoch 00032: val_loss did not improve from 1.56878
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4410 - accuracy: 0.4765 - val_loss: 1.6171 - val_accuracy: 0.3935

Epoch 00033: val_loss did not improve from 1.56878
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5726 - accuracy: 0.3949
Testing Loss = 1.572641, Testing Accuracy = 0.394909
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 68ms/step - loss: 12.4693 - accuracy: 0.2014 - val_loss: 8.7396 - val_accuracy: 0.2082

Epoch 00001: val_loss improved from inf to 8.73957, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.8073 - accuracy: 0.2078 - val_loss: 5.3680 - val_accuracy: 0.2122

Epoch 00002: val_loss improved from 8.73957 to 5.36801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.5817 - accuracy: 0.2171 - val_loss: 3.9609 - val_accuracy: 0.2358

Epoch 00003: val_loss improved from 5.36801 to 3.96086, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.4809 - accuracy: 0.2797 - val_loss: 3.1853 - val_accuracy: 0.2739

Epoch 00004: val_loss improved from 3.96086 to 3.18528, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8869 - accuracy: 0.2992 - val_loss: 2.7020 - val_accuracy: 0.3026

Epoch 00005: val_loss improved from 3.18528 to 2.70197, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 6/100
83/83 [==============================] - 6s 67ms/step - loss: 2.5028 - accuracy: 0.3095 - val_loss: 2.3680 - val_accuracy: 0.3114

Epoch 00006: val_loss improved from 2.70197 to 2.36797, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 7/100
83/83 [==============================] - 6s 67ms/step - loss: 2.2368 - accuracy: 0.3160 - val_loss: 2.1337 - val_accuracy: 0.3253

Epoch 00007: val_loss improved from 2.36797 to 2.13371, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0494 - accuracy: 0.3230 - val_loss: 1.9689 - val_accuracy: 0.3288

Epoch 00008: val_loss improved from 2.13371 to 1.96891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9155 - accuracy: 0.3290 - val_loss: 1.8575 - val_accuracy: 0.3365

Epoch 00009: val_loss improved from 1.96891 to 1.85747, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8204 - accuracy: 0.3385 - val_loss: 1.7794 - val_accuracy: 0.3411

Epoch 00010: val_loss improved from 1.85747 to 1.77944, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7535 - accuracy: 0.3448 - val_loss: 1.7290 - val_accuracy: 0.3450

Epoch 00011: val_loss improved from 1.77944 to 1.72901, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7037 - accuracy: 0.3512 - val_loss: 1.6844 - val_accuracy: 0.3521

Epoch 00012: val_loss improved from 1.72901 to 1.68438, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6670 - accuracy: 0.3595 - val_loss: 1.6599 - val_accuracy: 0.3564

Epoch 00013: val_loss improved from 1.68438 to 1.65989, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6369 - accuracy: 0.3672 - val_loss: 1.6266 - val_accuracy: 0.3693

Epoch 00014: val_loss improved from 1.65989 to 1.62655, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6126 - accuracy: 0.3761 - val_loss: 1.6107 - val_accuracy: 0.3755

Epoch 00015: val_loss improved from 1.62655 to 1.61071, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5902 - accuracy: 0.3862 - val_loss: 1.5954 - val_accuracy: 0.3853

Epoch 00016: val_loss improved from 1.61071 to 1.59538, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5769 - accuracy: 0.3900 - val_loss: 1.5861 - val_accuracy: 0.3840

Epoch 00017: val_loss improved from 1.59538 to 1.58614, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5618 - accuracy: 0.4008 - val_loss: 1.5797 - val_accuracy: 0.3859

Epoch 00018: val_loss improved from 1.58614 to 1.57965, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5513 - accuracy: 0.4050 - val_loss: 1.5738 - val_accuracy: 0.3898

Epoch 00019: val_loss improved from 1.57965 to 1.57375, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5409 - accuracy: 0.4085 - val_loss: 1.5739 - val_accuracy: 0.3929

Epoch 00020: val_loss did not improve from 1.57375
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5321 - accuracy: 0.4153 - val_loss: 1.5713 - val_accuracy: 0.3929

Epoch 00021: val_loss improved from 1.57375 to 1.57129, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 22/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5247 - accuracy: 0.4201 - val_loss: 1.5718 - val_accuracy: 0.3915

Epoch 00022: val_loss did not improve from 1.57129
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5134 - accuracy: 0.4264 - val_loss: 1.5685 - val_accuracy: 0.3952

Epoch 00023: val_loss improved from 1.57129 to 1.56845, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/7
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5067 - accuracy: 0.4300 - val_loss: 1.5741 - val_accuracy: 0.3928

Epoch 00024: val_loss did not improve from 1.56845
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5004 - accuracy: 0.4343 - val_loss: 1.5727 - val_accuracy: 0.3962

Epoch 00025: val_loss did not improve from 1.56845
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4921 - accuracy: 0.4410 - val_loss: 1.5707 - val_accuracy: 0.4028

Epoch 00026: val_loss did not improve from 1.56845
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4840 - accuracy: 0.4472 - val_loss: 1.5812 - val_accuracy: 0.4002

Epoch 00027: val_loss did not improve from 1.56845
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4786 - accuracy: 0.4508 - val_loss: 1.5819 - val_accuracy: 0.3985

Epoch 00028: val_loss did not improve from 1.56845
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4704 - accuracy: 0.4528 - val_loss: 1.5927 - val_accuracy: 0.3946

Epoch 00029: val_loss did not improve from 1.56845
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4625 - accuracy: 0.4660 - val_loss: 1.5980 - val_accuracy: 0.3946

Epoch 00030: val_loss did not improve from 1.56845
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4513 - accuracy: 0.4712 - val_loss: 1.6036 - val_accuracy: 0.3958

Epoch 00031: val_loss did not improve from 1.56845
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4417 - accuracy: 0.4765 - val_loss: 1.6094 - val_accuracy: 0.3962

Epoch 00032: val_loss did not improve from 1.56845
Epoch 33/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4324 - accuracy: 0.4838 - val_loss: 1.6223 - val_accuracy: 0.3932

Epoch 00033: val_loss did not improve from 1.56845
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.5738 - accuracy: 0.3971
Testing Loss = 1.573762, Testing Accuracy = 0.397142
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.4735 - accuracy: 0.2033 - val_loss: 8.7497 - val_accuracy: 0.2079

Epoch 00001: val_loss improved from inf to 8.74968, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.8193 - accuracy: 0.2087 - val_loss: 5.3835 - val_accuracy: 0.2080

Epoch 00002: val_loss improved from 8.74968 to 5.38351, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.6060 - accuracy: 0.2127 - val_loss: 3.9895 - val_accuracy: 0.2177

Epoch 00003: val_loss improved from 5.38351 to 3.98953, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.5158 - accuracy: 0.2663 - val_loss: 3.2032 - val_accuracy: 0.2613

Epoch 00004: val_loss improved from 3.98953 to 3.20322, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 5/100
83/83 [==============================] - 6s 67ms/step - loss: 2.8956 - accuracy: 0.2965 - val_loss: 2.7106 - val_accuracy: 0.2921

Epoch 00005: val_loss improved from 3.20322 to 2.71058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 6/100
83/83 [==============================] - 6s 67ms/step - loss: 2.5069 - accuracy: 0.3041 - val_loss: 2.3722 - val_accuracy: 0.3110

Epoch 00006: val_loss improved from 2.71058 to 2.37225, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 7/100
83/83 [==============================] - 6s 67ms/step - loss: 2.2391 - accuracy: 0.3148 - val_loss: 2.1320 - val_accuracy: 0.3269

Epoch 00007: val_loss improved from 2.37225 to 2.13196, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 8/100
83/83 [==============================] - 6s 67ms/step - loss: 2.0509 - accuracy: 0.3211 - val_loss: 1.9676 - val_accuracy: 0.3339

Epoch 00008: val_loss improved from 2.13196 to 1.96756, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 9/100
83/83 [==============================] - 6s 67ms/step - loss: 1.9181 - accuracy: 0.3262 - val_loss: 1.8580 - val_accuracy: 0.3396

Epoch 00009: val_loss improved from 1.96756 to 1.85796, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 10/100
83/83 [==============================] - 6s 67ms/step - loss: 1.8243 - accuracy: 0.3335 - val_loss: 1.7811 - val_accuracy: 0.3438

Epoch 00010: val_loss improved from 1.85796 to 1.78108, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 11/100
83/83 [==============================] - 6s 66ms/step - loss: 1.7569 - accuracy: 0.3399 - val_loss: 1.7243 - val_accuracy: 0.3437

Epoch 00011: val_loss improved from 1.78108 to 1.72427, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 12/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7090 - accuracy: 0.3466 - val_loss: 1.6868 - val_accuracy: 0.3453

Epoch 00012: val_loss improved from 1.72427 to 1.68684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6723 - accuracy: 0.3535 - val_loss: 1.6631 - val_accuracy: 0.3491

Epoch 00013: val_loss improved from 1.68684 to 1.66307, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 14/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6461 - accuracy: 0.3604 - val_loss: 1.6385 - val_accuracy: 0.3566

Epoch 00014: val_loss improved from 1.66307 to 1.63850, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 15/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6218 - accuracy: 0.3679 - val_loss: 1.6154 - val_accuracy: 0.3651

Epoch 00015: val_loss improved from 1.63850 to 1.61537, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 16/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6018 - accuracy: 0.3780 - val_loss: 1.6047 - val_accuracy: 0.3732

Epoch 00016: val_loss improved from 1.61537 to 1.60469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5856 - accuracy: 0.3846 - val_loss: 1.5896 - val_accuracy: 0.3810

Epoch 00017: val_loss improved from 1.60469 to 1.58956, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 18/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5813 - accuracy: 0.3864 - val_loss: 1.5857 - val_accuracy: 0.3805

Epoch 00018: val_loss improved from 1.58956 to 1.58574, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5599 - accuracy: 0.3982 - val_loss: 1.5759 - val_accuracy: 0.3892

Epoch 00019: val_loss improved from 1.58574 to 1.57594, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 20/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5526 - accuracy: 0.4010 - val_loss: 1.5718 - val_accuracy: 0.3902

Epoch 00020: val_loss improved from 1.57594 to 1.57181, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5446 - accuracy: 0.4059 - val_loss: 1.5706 - val_accuracy: 0.3907

Epoch 00021: val_loss improved from 1.57181 to 1.57061, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5340 - accuracy: 0.4126 - val_loss: 1.5674 - val_accuracy: 0.3934

Epoch 00022: val_loss improved from 1.57061 to 1.56740, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/8
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5275 - accuracy: 0.4175 - val_loss: 1.5685 - val_accuracy: 0.3939

Epoch 00023: val_loss did not improve from 1.56740
Epoch 24/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5203 - accuracy: 0.4218 - val_loss: 1.5676 - val_accuracy: 0.3964

Epoch 00024: val_loss did not improve from 1.56740
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5152 - accuracy: 0.4251 - val_loss: 1.5684 - val_accuracy: 0.3969

Epoch 00025: val_loss did not improve from 1.56740
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5078 - accuracy: 0.4300 - val_loss: 1.5725 - val_accuracy: 0.3980

Epoch 00026: val_loss did not improve from 1.56740
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5008 - accuracy: 0.4361 - val_loss: 1.5736 - val_accuracy: 0.3978

Epoch 00027: val_loss did not improve from 1.56740
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4932 - accuracy: 0.4429 - val_loss: 1.5749 - val_accuracy: 0.3960

Epoch 00028: val_loss did not improve from 1.56740
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4896 - accuracy: 0.4423 - val_loss: 1.5794 - val_accuracy: 0.3968

Epoch 00029: val_loss did not improve from 1.56740
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4797 - accuracy: 0.4499 - val_loss: 1.5846 - val_accuracy: 0.3997

Epoch 00030: val_loss did not improve from 1.56740
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4709 - accuracy: 0.4572 - val_loss: 1.5939 - val_accuracy: 0.4020

Epoch 00031: val_loss did not improve from 1.56740
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4678 - accuracy: 0.4609 - val_loss: 1.5935 - val_accuracy: 0.3966

Epoch 00032: val_loss did not improve from 1.56740
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5742 - accuracy: 0.3936
Testing Loss = 1.574200, Testing Accuracy = 0.393570
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 68ms/step - loss: 12.4455 - accuracy: 0.1990 - val_loss: 8.7286 - val_accuracy: 0.2081

Epoch 00001: val_loss improved from inf to 8.72861, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.7980 - accuracy: 0.2086 - val_loss: 5.3609 - val_accuracy: 0.2120

Epoch 00002: val_loss improved from 8.72861 to 5.36089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.5597 - accuracy: 0.2306 - val_loss: 3.9457 - val_accuracy: 0.2432

Epoch 00003: val_loss improved from 5.36089 to 3.94568, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 4/100
83/83 [==============================] - 6s 66ms/step - loss: 3.4736 - accuracy: 0.2871 - val_loss: 3.1878 - val_accuracy: 0.2750

Epoch 00004: val_loss improved from 3.94568 to 3.18778, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 5/100
83/83 [==============================] - 6s 66ms/step - loss: 2.8897 - accuracy: 0.2990 - val_loss: 2.7080 - val_accuracy: 0.3014

Epoch 00005: val_loss improved from 3.18778 to 2.70804, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 6/100
83/83 [==============================] - 6s 67ms/step - loss: 2.5084 - accuracy: 0.3057 - val_loss: 2.3743 - val_accuracy: 0.3152

Epoch 00006: val_loss improved from 2.70804 to 2.37425, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2415 - accuracy: 0.3167 - val_loss: 2.1367 - val_accuracy: 0.3253

Epoch 00007: val_loss improved from 2.37425 to 2.13671, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 8/100
83/83 [==============================] - 6s 67ms/step - loss: 2.0557 - accuracy: 0.3219 - val_loss: 1.9769 - val_accuracy: 0.3320

Epoch 00008: val_loss improved from 2.13671 to 1.97689, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9234 - accuracy: 0.3286 - val_loss: 1.8649 - val_accuracy: 0.3342

Epoch 00009: val_loss improved from 1.97689 to 1.86488, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 10/100
83/83 [==============================] - 6s 67ms/step - loss: 1.8281 - accuracy: 0.3331 - val_loss: 1.7847 - val_accuracy: 0.3434

Epoch 00010: val_loss improved from 1.86488 to 1.78467, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 11/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7592 - accuracy: 0.3398 - val_loss: 1.7292 - val_accuracy: 0.3443

Epoch 00011: val_loss improved from 1.78467 to 1.72918, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 12/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7110 - accuracy: 0.3490 - val_loss: 1.6962 - val_accuracy: 0.3457

Epoch 00012: val_loss improved from 1.72918 to 1.69615, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6735 - accuracy: 0.3584 - val_loss: 1.6632 - val_accuracy: 0.3543

Epoch 00013: val_loss improved from 1.69615 to 1.66319, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 14/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6427 - accuracy: 0.3646 - val_loss: 1.6340 - val_accuracy: 0.3639

Epoch 00014: val_loss improved from 1.66319 to 1.63399, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6210 - accuracy: 0.3719 - val_loss: 1.6156 - val_accuracy: 0.3696

Epoch 00015: val_loss improved from 1.63399 to 1.61557, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6004 - accuracy: 0.3785 - val_loss: 1.6017 - val_accuracy: 0.3728

Epoch 00016: val_loss improved from 1.61557 to 1.60166, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5833 - accuracy: 0.3875 - val_loss: 1.5875 - val_accuracy: 0.3848

Epoch 00017: val_loss improved from 1.60166 to 1.58755, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5759 - accuracy: 0.3905 - val_loss: 1.5864 - val_accuracy: 0.3821

Epoch 00018: val_loss improved from 1.58755 to 1.58643, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5599 - accuracy: 0.3974 - val_loss: 1.5770 - val_accuracy: 0.3899

Epoch 00019: val_loss improved from 1.58643 to 1.57697, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5522 - accuracy: 0.4020 - val_loss: 1.5761 - val_accuracy: 0.3878

Epoch 00020: val_loss improved from 1.57697 to 1.57614, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5422 - accuracy: 0.4074 - val_loss: 1.5687 - val_accuracy: 0.3945

Epoch 00021: val_loss improved from 1.57614 to 1.56865, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 22/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5330 - accuracy: 0.4144 - val_loss: 1.5675 - val_accuracy: 0.3927

Epoch 00022: val_loss improved from 1.56865 to 1.56755, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5274 - accuracy: 0.4162 - val_loss: 1.5661 - val_accuracy: 0.3924

Epoch 00023: val_loss improved from 1.56755 to 1.56612, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 24/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5195 - accuracy: 0.4224 - val_loss: 1.5650 - val_accuracy: 0.3951

Epoch 00024: val_loss improved from 1.56612 to 1.56501, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2/Try/9
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5135 - accuracy: 0.4265 - val_loss: 1.5688 - val_accuracy: 0.3976

Epoch 00025: val_loss did not improve from 1.56501
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5053 - accuracy: 0.4343 - val_loss: 1.5711 - val_accuracy: 0.3964

Epoch 00026: val_loss did not improve from 1.56501
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4982 - accuracy: 0.4366 - val_loss: 1.5753 - val_accuracy: 0.3954

Epoch 00027: val_loss did not improve from 1.56501
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4941 - accuracy: 0.4399 - val_loss: 1.5761 - val_accuracy: 0.3952

Epoch 00028: val_loss did not improve from 1.56501
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4847 - accuracy: 0.4502 - val_loss: 1.5843 - val_accuracy: 0.3996

Epoch 00029: val_loss did not improve from 1.56501
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4781 - accuracy: 0.4518 - val_loss: 1.5869 - val_accuracy: 0.3992

Epoch 00030: val_loss did not improve from 1.56501
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4677 - accuracy: 0.4580 - val_loss: 1.5962 - val_accuracy: 0.3980

Epoch 00031: val_loss did not improve from 1.56501
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4657 - accuracy: 0.4619 - val_loss: 1.5995 - val_accuracy: 0.3984

Epoch 00032: val_loss did not improve from 1.56501
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4557 - accuracy: 0.4679 - val_loss: 1.6069 - val_accuracy: 0.3934

Epoch 00033: val_loss did not improve from 1.56501
Epoch 34/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4457 - accuracy: 0.4753 - val_loss: 1.6169 - val_accuracy: 0.3922

Epoch 00034: val_loss did not improve from 1.56501
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 58s 4ms/step - loss: 1.5712 - accuracy: 0.3944
Testing Loss = 1.571189, Testing Accuracy = 0.394388
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 84.08 +- 0.1085 %)
$W^-/W^-$ (auc = 83.67 +- 0.0905 %)
$Z/Z$ (auc = 76.13 +- 0.3577 %)
$W^+/W^-$ (auc = 70.56 +- 0.2746 %)
$W^+/Z$$ (auc = 67.46 +- 0.1029 %)
$W^-/Z$ (auc = 69.31 +- 0.1370 %)
The summarized testing accuracy = 39.40 +- 0.1632 %, with the loss = 1.5733 +- 0.003217
