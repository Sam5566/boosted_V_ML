

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 15:20:39.136000
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 15:27:19.291063
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
281/281 [==============================] - 65s 194ms/step - loss: 6.2761 - accuracy: 0.7150 - val_loss: 2.6557 - val_accuracy: 0.7370

Epoch 00001: val_loss improved from inf to 2.65566, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 2/500
281/281 [==============================] - 55s 196ms/step - loss: 1.7297 - accuracy: 0.7642 - val_loss: 1.1194 - val_accuracy: 0.7744

Epoch 00002: val_loss improved from 2.65566 to 1.11935, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 3/500
281/281 [==============================] - 65s 230ms/step - loss: 0.8528 - accuracy: 0.7740 - val_loss: 0.6643 - val_accuracy: 0.7803

Epoch 00003: val_loss improved from 1.11935 to 0.66429, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 4/500
281/281 [==============================] - 67s 240ms/step - loss: 0.5890 - accuracy: 0.7786 - val_loss: 0.5276 - val_accuracy: 0.7877

Epoch 00004: val_loss improved from 0.66429 to 0.52758, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 5/500
281/281 [==============================] - 67s 236ms/step - loss: 0.5129 - accuracy: 0.7819 - val_loss: 0.4909 - val_accuracy: 0.7875

Epoch 00005: val_loss improved from 0.52758 to 0.49094, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 6/500
281/281 [==============================] - 59s 211ms/step - loss: 0.4892 - accuracy: 0.7849 - val_loss: 0.4703 - val_accuracy: 0.7938

Epoch 00006: val_loss improved from 0.49094 to 0.47026, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 7/500
281/281 [==============================] - 57s 204ms/step - loss: 0.4783 - accuracy: 0.7869 - val_loss: 0.4652 - val_accuracy: 0.7948

Epoch 00007: val_loss improved from 0.47026 to 0.46524, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 8/500
281/281 [==============================] - 56s 198ms/step - loss: 0.4743 - accuracy: 0.7882 - val_loss: 0.4649 - val_accuracy: 0.7948

Epoch 00008: val_loss improved from 0.46524 to 0.46486, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 9/500
281/281 [==============================] - 59s 209ms/step - loss: 0.4707 - accuracy: 0.7895 - val_loss: 0.4624 - val_accuracy: 0.7958

Epoch 00009: val_loss improved from 0.46486 to 0.46237, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 10/500
281/281 [==============================] - 59s 211ms/step - loss: 0.4680 - accuracy: 0.7915 - val_loss: 0.4620 - val_accuracy: 0.7960

Epoch 00010: val_loss improved from 0.46237 to 0.46199, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 11/500
281/281 [==============================] - 66s 233ms/step - loss: 0.4653 - accuracy: 0.7922 - val_loss: 0.4615 - val_accuracy: 0.7966

Epoch 00011: val_loss improved from 0.46199 to 0.46152, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 12/500
281/281 [==============================] - 59s 209ms/step - loss: 0.4625 - accuracy: 0.7939 - val_loss: 0.4615 - val_accuracy: 0.7968

Epoch 00012: val_loss improved from 0.46152 to 0.46149, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 13/500
281/281 [==============================] - 59s 211ms/step - loss: 0.4607 - accuracy: 0.7948 - val_loss: 0.4608 - val_accuracy: 0.7966

Epoch 00013: val_loss improved from 0.46149 to 0.46082, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 14/500
281/281 [==============================] - 56s 201ms/step - loss: 0.4583 - accuracy: 0.7969 - val_loss: 0.4617 - val_accuracy: 0.7948

Epoch 00014: val_loss did not improve from 0.46082
Epoch 15/500
281/281 [==============================] - 59s 211ms/step - loss: 0.4553 - accuracy: 0.7989 - val_loss: 0.4646 - val_accuracy: 0.7949

Epoch 00015: val_loss did not improve from 0.46082
Epoch 16/500
281/281 [==============================] - 61s 215ms/step - loss: 0.4533 - accuracy: 0.8010 - val_loss: 0.4630 - val_accuracy: 0.7960

Epoch 00016: val_loss did not improve from 0.46082
Epoch 17/500
281/281 [==============================] - 66s 234ms/step - loss: 0.4502 - accuracy: 0.8031 - val_loss: 0.4657 - val_accuracy: 0.7949

Epoch 00017: val_loss did not improve from 0.46082
Epoch 18/500
281/281 [==============================] - 61s 216ms/step - loss: 0.4461 - accuracy: 0.8062 - val_loss: 0.4689 - val_accuracy: 0.7944

Epoch 00018: val_loss did not improve from 0.46082
Epoch 19/500
281/281 [==============================] - 59s 208ms/step - loss: 0.4429 - accuracy: 0.8083 - val_loss: 0.4696 - val_accuracy: 0.7944

Epoch 00019: val_loss did not improve from 0.46082
Epoch 20/500
281/281 [==============================] - 65s 232ms/step - loss: 0.4394 - accuracy: 0.8102 - val_loss: 0.4737 - val_accuracy: 0.7943

Epoch 00020: val_loss did not improve from 0.46082
Epoch 21/500
281/281 [==============================] - 68s 243ms/step - loss: 0.4347 - accuracy: 0.8143 - val_loss: 0.4777 - val_accuracy: 0.7937

Epoch 00021: val_loss did not improve from 0.46082
Epoch 22/500
281/281 [==============================] - 68s 243ms/step - loss: 0.4282 - accuracy: 0.8190 - val_loss: 0.4833 - val_accuracy: 0.7930

Epoch 00022: val_loss did not improve from 0.46082
Epoch 23/500
281/281 [==============================] - 61s 215ms/step - loss: 0.4232 - accuracy: 0.8244 - val_loss: 0.4872 - val_accuracy: 0.7910

Epoch 00023: val_loss did not improve from 0.46082
Epoch 24/500
281/281 [==============================] - 55s 197ms/step - loss: 0.4167 - accuracy: 0.8278 - val_loss: 0.4959 - val_accuracy: 0.7900

Epoch 00024: val_loss did not improve from 0.46082
Epoch 25/500
281/281 [==============================] - 59s 211ms/step - loss: 0.4087 - accuracy: 0.8338 - val_loss: 0.4996 - val_accuracy: 0.7881

Epoch 00025: val_loss did not improve from 0.46082
Epoch 26/500
281/281 [==============================] - 59s 209ms/step - loss: 0.4006 - accuracy: 0.8400 - val_loss: 0.5117 - val_accuracy: 0.7864

Epoch 00026: val_loss did not improve from 0.46082
Epoch 27/500
281/281 [==============================] - 70s 249ms/step - loss: 0.3990 - accuracy: 0.8410 - val_loss: 0.5112 - val_accuracy: 0.7800

Epoch 00027: val_loss did not improve from 0.46082
Epoch 28/500
281/281 [==============================] - 59s 208ms/step - loss: 0.3897 - accuracy: 0.8472 - val_loss: 0.5185 - val_accuracy: 0.7813

Epoch 00028: val_loss did not improve from 0.46082
Epoch 29/500
281/281 [==============================] - 61s 216ms/step - loss: 0.3788 - accuracy: 0.8541 - val_loss: 0.5456 - val_accuracy: 0.7710

Epoch 00029: val_loss did not improve from 0.46082
Epoch 30/500
281/281 [==============================] - 70s 248ms/step - loss: 0.3701 - accuracy: 0.8598 - val_loss: 0.5903 - val_accuracy: 0.7486

Epoch 00030: val_loss did not improve from 0.46082
Epoch 31/500
281/281 [==============================] - 60s 214ms/step - loss: 0.3608 - accuracy: 0.8643 - val_loss: 0.5819 - val_accuracy: 0.7579

Epoch 00031: val_loss did not improve from 0.46082
Epoch 32/500
281/281 [==============================] - 60s 213ms/step - loss: 0.3524 - accuracy: 0.8696 - val_loss: 0.6051 - val_accuracy: 0.7542

Epoch 00032: val_loss did not improve from 0.46082
Epoch 33/500
281/281 [==============================] - 59s 211ms/step - loss: 0.3403 - accuracy: 0.8769 - val_loss: 0.6015 - val_accuracy: 0.7620

Epoch 00033: val_loss did not improve from 0.46082
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Model: "CNN_binary"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
sequential (Sequential)      (None, 512)               12127912  
_________________________________________________________________
dense_2 (Dense)              multiple                  1026      
=================================================================
Total params: 12,128,938
Trainable params: 12,128,934
Non-trainable params: 4
_________________________________________________________________
[93mNone[0m
@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lambda (Lambda)              (None, 75, 75, 2)         0         
_________________________________________________________________
batch_normalization (BatchNo (None, 75, 75, 2)         8         
_________________________________________________________________
conv2d (Conv2D)              (None, 75, 75, 32)        2336      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         
_________________________________________________________________
dropout (Dropout)            (None, 9, 9, 256)         0         
_________________________________________________________________
flatten (Flatten)            (None, 20736)             0         
_________________________________________________________________
dense (Dense)                (None, 512)               10617344  
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               262656    
_________________________________________________________________
dropout_2 (Dropout)          (None, 512)               0         
=================================================================
Total params: 12,127,912
Trainable params: 12,127,908
Non-trainable params: 4
_________________________________________________________________
None
{'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQBhQJm\nBBkAUwCpAk7pAgAAAKkAqQHaAXhyAwAAAHIDAAAA+hsvaG9tZS9zYW1odWFuZy9NTC9tb2RlbHMu\ncHnaCDxsYW1iZGE+1AAAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}
@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
45063/45063 [==============================] - 126s 3ms/step - loss: 0.6056 - accuracy: 0.7586
Testing Loss = 0.605580, Testing Accuracy = 0.758560
The data set contains images
[[0.5080137848854065, 0.4919862151145935], [0.011435182765126228, 0.9885647892951965], [0.5252796411514282, 0.474720299243927], [0.947877824306488, 0.052122119814157486], [0.0039931354112923145, 0.9960069060325623], [0.91214519739151, 0.0878547802567482], [0.03208987042307854, 0.96791011095047], [0.9085429310798645, 0.09145708382129669], [0.16437235474586487, 0.8356276154518127], [0.8605545163154602, 0.1394454538822174]]
[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0]]
2
$W^+$ (auc = 0.85)
$Z$ (auc = 0.85)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 16:40:22.362174
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images

Epoch 00001: val_loss improved from inf to 2.66934, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00002: val_loss improved from 2.66934 to 1.11873, saving model to best_model_binary-WpZ_CNN_kappa0.15/


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 16:43:12.687705
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images

Epoch 00001: val_loss improved from inf to 2.65157, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00002: val_loss improved from 2.65157 to 1.10800, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00003: val_loss improved from 1.10800 to 0.65900, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00004: val_loss improved from 0.65900 to 0.52271, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00005: val_loss improved from 0.52271 to 0.49094, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00006: val_loss improved from 0.49094 to 0.48256, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00007: val_loss improved from 0.48256 to 0.47039, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00008: val_loss improved from 0.47039 to 0.46987, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00009: val_loss improved from 0.46987 to 0.46563, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00010: val_loss improved from 0.46563 to 0.46323, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00011: val_loss did not improve from 0.46323

Epoch 00012: val_loss improved from 0.46323 to 0.46197, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00013: val_loss did not improve from 0.46197

Epoch 00014: val_loss did not improve from 0.46197

Epoch 00015: val_loss did not improve from 0.46197

Epoch 00016: val_loss did not improve from 0.46197

Epoch 00017: val_loss did not improve from 0.46197

Epoch 00018: val_loss did not improve from 0.46197

Epoch 00019: val_loss did not improve from 0.46197

Epoch 00020: val_loss did not improve from 0.46197

Epoch 00021: val_loss did not improve from 0.46197

Epoch 00022: val_loss did not improve from 0.46197

Epoch 00023: val_loss did not improve from 0.46197

Epoch 00024: val_loss did not improve from 0.46197

Epoch 00025: val_loss did not improve from 0.46197

Epoch 00026: val_loss did not improve from 0.46197

Epoch 00027: val_loss did not improve from 0.46197

Epoch 00028: val_loss did not improve from 0.46197

Epoch 00029: val_loss did not improve from 0.46197

Epoch 00030: val_loss did not improve from 0.46197

Epoch 00031: val_loss did not improve from 0.46197

Epoch 00032: val_loss did not improve from 0.46197
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_binary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQBhQJm\nBBkAUwCpAk7pAgAAAKkAqQHaAXhyAwAAAHIDAAAA+hsvaG9tZS9zYW1odWFuZy9NTC9tb2RlbHMu\ncHnaCDxsYW1iZGE+1AAAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 0, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
45063/45063 [==============================] - 121s 3ms/step - loss: 0.5705 - accuracy: 0.7694
Testing Loss = 0.570549, Testing Accuracy = 0.769390
The data set contains images
[[0.661747395992279, 0.33825257420539856], [0.013488818891346455, 0.9865111112594604], [0.37953728437423706, 0.6204627752304077], [0.9592958688735962, 0.04070412367582321], [0.0021867193281650543, 0.9978132247924805], [0.9534160494804382, 0.046583984047174454], [0.0843101367354393, 0.9156898260116577], [0.5689941048622131, 0.43100592494010925], [0.47531619668006897, 0.5246838331222534], [0.9127362370491028, 0.08726374804973602]]
[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0]]
2
$W^+$ (auc = 0.85)
$Z$ (auc = 0.85)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-12 19:44:06.713411
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
322/322 [==============================] - 31s 77ms/step - loss: 1.3641 - accuracy: 0.7469 - val_loss: 0.5105 - val_accuracy: 0.7738

Epoch 00001: val_loss improved from inf to 0.51046, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 2/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4758 - accuracy: 0.7921 - val_loss: 0.4622 - val_accuracy: 0.7975

Epoch 00002: val_loss improved from 0.51046 to 0.46225, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 3/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4654 - accuracy: 0.7957 - val_loss: 0.4445 - val_accuracy: 0.8064

Epoch 00003: val_loss improved from 0.46225 to 0.44452, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 4/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4591 - accuracy: 0.8001 - val_loss: 0.4442 - val_accuracy: 0.8067

Epoch 00004: val_loss improved from 0.44452 to 0.44417, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 5/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4563 - accuracy: 0.8020 - val_loss: 0.4449 - val_accuracy: 0.8088

Epoch 00005: val_loss did not improve from 0.44417
Epoch 6/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4512 - accuracy: 0.8043 - val_loss: 0.4428 - val_accuracy: 0.8087

Epoch 00006: val_loss improved from 0.44417 to 0.44284, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 7/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4495 - accuracy: 0.8052 - val_loss: 0.4439 - val_accuracy: 0.8083

Epoch 00007: val_loss did not improve from 0.44284
Epoch 8/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4446 - accuracy: 0.8102 - val_loss: 0.4523 - val_accuracy: 0.8065

Epoch 00008: val_loss did not improve from 0.44284
Epoch 9/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4409 - accuracy: 0.8136 - val_loss: 0.4579 - val_accuracy: 0.8058

Epoch 00009: val_loss did not improve from 0.44284
Epoch 10/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4369 - accuracy: 0.8177 - val_loss: 0.4614 - val_accuracy: 0.8049

Epoch 00010: val_loss did not improve from 0.44284
Epoch 11/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4319 - accuracy: 0.8221 - val_loss: 0.4816 - val_accuracy: 0.8028

Epoch 00011: val_loss did not improve from 0.44284
Epoch 12/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4255 - accuracy: 0.8286 - val_loss: 0.4939 - val_accuracy: 0.7967

Epoch 00012: val_loss did not improve from 0.44284
Epoch 13/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4194 - accuracy: 0.8345 - val_loss: 0.4911 - val_accuracy: 0.7987

Epoch 00013: val_loss did not improve from 0.44284
Epoch 14/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4112 - accuracy: 0.8423 - val_loss: 0.5139 - val_accuracy: 0.7923

Epoch 00014: val_loss did not improve from 0.44284
Epoch 15/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4088 - accuracy: 0.8451 - val_loss: 0.5363 - val_accuracy: 0.7850

Epoch 00015: val_loss did not improve from 0.44284
Epoch 16/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4053 - accuracy: 0.8476 - val_loss: 0.5544 - val_accuracy: 0.7843

Epoch 00016: val_loss did not improve from 0.44284
Epoch 17/500
322/322 [==============================] - 21s 65ms/step - loss: 0.4020 - accuracy: 0.8520 - val_loss: 0.6337 - val_accuracy: 0.7462

Epoch 00017: val_loss did not improve from 0.44284
Epoch 18/500
322/322 [==============================] - 21s 65ms/step - loss: 0.3929 - accuracy: 0.8564 - val_loss: 0.5982 - val_accuracy: 0.7546

Epoch 00018: val_loss did not improve from 0.44284
Epoch 19/500
322/322 [==============================] - 21s 66ms/step - loss: 0.3795 - accuracy: 0.8661 - val_loss: 0.5910 - val_accuracy: 0.7576

Epoch 00019: val_loss did not improve from 0.44284
Epoch 20/500
322/322 [==============================] - 22s 67ms/step - loss: 0.3737 - accuracy: 0.8710 - val_loss: 0.5955 - val_accuracy: 0.7749

Epoch 00020: val_loss did not improve from 0.44284
Epoch 21/500
322/322 [==============================] - 21s 65ms/step - loss: 0.3532 - accuracy: 0.8818 - val_loss: 0.6323 - val_accuracy: 0.7747

Epoch 00021: val_loss did not improve from 0.44284
Epoch 22/500
322/322 [==============================] - 21s 65ms/step - loss: 0.3427 - accuracy: 0.8884 - val_loss: 0.6622 - val_accuracy: 0.7681

Epoch 00022: val_loss did not improve from 0.44284
Epoch 23/500
322/322 [==============================] - 21s 65ms/step - loss: 0.3386 - accuracy: 0.8906 - val_loss: 0.6709 - val_accuracy: 0.7661

Epoch 00023: val_loss did not improve from 0.44284
Epoch 24/500
322/322 [==============================] - 21s 65ms/step - loss: 0.3528 - accuracy: 0.8838 - val_loss: 0.6917 - val_accuracy: 0.7719

Epoch 00024: val_loss did not improve from 0.44284
Epoch 25/500
322/322 [==============================] - 21s 66ms/step - loss: 0.3464 - accuracy: 0.8871 - val_loss: 0.7314 - val_accuracy: 0.7682

Epoch 00025: val_loss did not improve from 0.44284
Epoch 26/500
322/322 [==============================] - 21s 66ms/step - loss: 0.3336 - accuracy: 0.8940 - val_loss: 0.8026 - val_accuracy: 0.7552

Epoch 00026: val_loss did not improve from 0.44284
Epoch 00026: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_binary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQBhQJm\nBBkAUwApAk7pAgAAAKkAqQHaAXhyAgAAAHICAAAA+h8vaG9tZS9zYW1odWFuZy9NTC9DTk4vbW9k\nZWxzLnB52gg8bGFtYmRhPjMAAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
51661/51661 [==============================] - 211s 4ms/step - loss: 0.4458 - accuracy: 0.8058
Testing Loss = 0.445771, Testing Accuracy = 0.805772
The data set contains images
[[0.338067889213562, 0.6619321703910828], [0.3476470708847046, 0.6523529291152954], [0.19024114310741425, 0.8097589015960693], [0.5928939580917358, 0.40710604190826416], [0.8921435475349426, 0.10785649716854095], [0.08759261667728424, 0.912407398223877], [0.3847154676914215, 0.6152845621109009], [0.25842928886413574, 0.7415707111358643], [0.9823697805404663, 0.0176301971077919], [0.27479714155197144, 0.7252028584480286]]
[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]]
2
$W^+$ (auc = 0.88)
$Z$ (auc = 0.88)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-12 20:52:15.762527
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
322/322 [==============================] - 30s 67ms/step - loss: 1.3501 - accuracy: 0.7540 - val_loss: 0.5262 - val_accuracy: 0.7608

Epoch 00001: val_loss improved from inf to 0.52621, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 2/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4755 - accuracy: 0.7921 - val_loss: 0.4568 - val_accuracy: 0.8009

Epoch 00002: val_loss improved from 0.52621 to 0.45684, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 3/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4635 - accuracy: 0.7980 - val_loss: 0.4462 - val_accuracy: 0.8045

Epoch 00003: val_loss improved from 0.45684 to 0.44621, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 4/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4603 - accuracy: 0.7994 - val_loss: 0.4533 - val_accuracy: 0.8034

Epoch 00004: val_loss did not improve from 0.44621
Epoch 5/500
322/322 [==============================] - 36s 111ms/step - loss: 0.4563 - accuracy: 0.8006 - val_loss: 0.4503 - val_accuracy: 0.8035

Epoch 00005: val_loss did not improve from 0.44621
Epoch 6/500
322/322 [==============================] - 66s 204ms/step - loss: 0.4535 - accuracy: 0.8029 - val_loss: 0.4571 - val_accuracy: 0.8003

Epoch 00006: val_loss did not improve from 0.44621
Epoch 7/500
322/322 [==============================] - 25s 77ms/step - loss: 0.4489 - accuracy: 0.8059 - val_loss: 0.4521 - val_accuracy: 0.8063

Epoch 00007: val_loss did not improve from 0.44621
Epoch 8/500
322/322 [==============================] - 22s 69ms/step - loss: 0.4459 - accuracy: 0.8083 - val_loss: 0.4547 - val_accuracy: 0.8053

Epoch 00008: val_loss did not improve from 0.44621
Epoch 9/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4417 - accuracy: 0.8121 - val_loss: 0.4500 - val_accuracy: 0.8073

Epoch 00009: val_loss did not improve from 0.44621
Epoch 10/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4361 - accuracy: 0.8169 - val_loss: 0.4605 - val_accuracy: 0.8045

Epoch 00010: val_loss did not improve from 0.44621
Epoch 11/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4328 - accuracy: 0.8199 - val_loss: 0.4665 - val_accuracy: 0.8027

Epoch 00011: val_loss did not improve from 0.44621
Epoch 12/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4257 - accuracy: 0.8259 - val_loss: 0.4810 - val_accuracy: 0.7994

Epoch 00012: val_loss did not improve from 0.44621
Epoch 13/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4204 - accuracy: 0.8306 - val_loss: 0.4811 - val_accuracy: 0.8015

Epoch 00013: val_loss did not improve from 0.44621
Epoch 14/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4138 - accuracy: 0.8363 - val_loss: 0.4897 - val_accuracy: 0.7999

Epoch 00014: val_loss did not improve from 0.44621
Epoch 15/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4138 - accuracy: 0.8376 - val_loss: 0.5488 - val_accuracy: 0.7628

Epoch 00015: val_loss did not improve from 0.44621
Epoch 16/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4056 - accuracy: 0.8426 - val_loss: 0.5181 - val_accuracy: 0.7851

Epoch 00016: val_loss did not improve from 0.44621
Epoch 17/500
322/322 [==============================] - 22s 67ms/step - loss: 0.3944 - accuracy: 0.8512 - val_loss: 0.5624 - val_accuracy: 0.7673

Epoch 00017: val_loss did not improve from 0.44621
Epoch 18/500
322/322 [==============================] - 22s 69ms/step - loss: 0.3950 - accuracy: 0.8522 - val_loss: 0.6104 - val_accuracy: 0.7415

Epoch 00018: val_loss did not improve from 0.44621
Epoch 19/500
322/322 [==============================] - 22s 67ms/step - loss: 0.3866 - accuracy: 0.8573 - val_loss: 0.5514 - val_accuracy: 0.7568

Epoch 00019: val_loss did not improve from 0.44621
Epoch 20/500
322/322 [==============================] - 22s 68ms/step - loss: 0.3806 - accuracy: 0.8616 - val_loss: 0.5518 - val_accuracy: 0.7823

Epoch 00020: val_loss did not improve from 0.44621
Epoch 21/500
322/322 [==============================] - 22s 68ms/step - loss: 0.3562 - accuracy: 0.8757 - val_loss: 0.6103 - val_accuracy: 0.7572

Epoch 00021: val_loss did not improve from 0.44621
Epoch 22/500
322/322 [==============================] - 22s 68ms/step - loss: 0.3554 - accuracy: 0.8770 - val_loss: 0.5871 - val_accuracy: 0.7796

Epoch 00022: val_loss did not improve from 0.44621
Epoch 23/500
322/322 [==============================] - 51s 160ms/step - loss: 0.3415 - accuracy: 0.8850 - val_loss: 0.6219 - val_accuracy: 0.7754

Epoch 00023: val_loss did not improve from 0.44621
Epoch 00023: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_binary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQBhQJm\nBBkAUwApAk7pAgAAAKkAqQHaAXhyAgAAAHICAAAA+h8vaG9tZS9zYW1odWFuZy9NTC9DTk4vbW9k\nZWxzLnB52gg8bGFtYmRhPjMAAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
51661/51661 [==============================] - 168s 3ms/step - loss: 0.4481 - accuracy: 0.8035
Testing Loss = 0.448067, Testing Accuracy = 0.803508
The data set contains images
[[0.15522247552871704, 0.844777524471283], [0.20152141153812408, 0.7984785437583923], [0.2477262169122696, 0.7522737979888916], [0.5610716938972473, 0.4389283061027527], [0.8452274203300476, 0.15477265417575836], [0.07536698132753372, 0.9246329665184021], [0.3891885280609131, 0.6108115315437317], [0.25056183338165283, 0.7494381666183472], [0.9642308950424194, 0.03576917573809624], [0.3774693012237549, 0.6225307583808899]]
[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]]
2
$W^+$ (auc = 0.88)
$Z$ (auc = 0.88)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-14 09:42:27.450634
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
338/338 [==============================] - 31s 72ms/step - loss: 1.5844 - accuracy: 0.7518 - val_loss: 0.5526 - val_accuracy: 0.7821

Epoch 00001: val_loss improved from inf to 0.55263, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 2/500
338/338 [==============================] - 23s 67ms/step - loss: 0.4851 - accuracy: 0.7983 - val_loss: 0.4641 - val_accuracy: 0.8017

Epoch 00002: val_loss improved from 0.55263 to 0.46410, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 3/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4577 - accuracy: 0.8030 - val_loss: 0.4532 - val_accuracy: 0.8033

Epoch 00003: val_loss improved from 0.46410 to 0.45324, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 4/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4510 - accuracy: 0.8052 - val_loss: 0.4444 - val_accuracy: 0.8110

Epoch 00004: val_loss improved from 0.45324 to 0.44443, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 5/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4469 - accuracy: 0.8084 - val_loss: 0.4439 - val_accuracy: 0.8107

Epoch 00005: val_loss improved from 0.44443 to 0.44385, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 6/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4431 - accuracy: 0.8117 - val_loss: 0.4453 - val_accuracy: 0.8098

Epoch 00006: val_loss did not improve from 0.44385
Epoch 7/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4412 - accuracy: 0.8116 - val_loss: 0.4457 - val_accuracy: 0.8082

Epoch 00007: val_loss did not improve from 0.44385
Epoch 8/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4371 - accuracy: 0.8145 - val_loss: 0.4523 - val_accuracy: 0.8024

Epoch 00008: val_loss did not improve from 0.44385
Epoch 9/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4365 - accuracy: 0.8154 - val_loss: 0.4607 - val_accuracy: 0.7960

Epoch 00009: val_loss did not improve from 0.44385
Epoch 10/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4342 - accuracy: 0.8178 - val_loss: 0.4472 - val_accuracy: 0.8066

Epoch 00010: val_loss did not improve from 0.44385
Epoch 11/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4527 - val_accuracy: 0.8047

Epoch 00011: val_loss did not improve from 0.44385
Epoch 12/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4214 - accuracy: 0.8279 - val_loss: 0.4584 - val_accuracy: 0.8040

Epoch 00012: val_loss did not improve from 0.44385
Epoch 13/500
338/338 [==============================] - 23s 67ms/step - loss: 0.4167 - accuracy: 0.8324 - val_loss: 0.4695 - val_accuracy: 0.7970

Epoch 00013: val_loss did not improve from 0.44385
Epoch 14/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4098 - accuracy: 0.8390 - val_loss: 0.4789 - val_accuracy: 0.7935

Epoch 00014: val_loss did not improve from 0.44385
Epoch 15/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4039 - accuracy: 0.8451 - val_loss: 0.5147 - val_accuracy: 0.7861

Epoch 00015: val_loss did not improve from 0.44385
Epoch 16/500
338/338 [==============================] - 23s 68ms/step - loss: 0.4080 - accuracy: 0.8427 - val_loss: 0.5033 - val_accuracy: 0.7947

Epoch 00016: val_loss did not improve from 0.44385
Epoch 17/500
338/338 [==============================] - 23s 68ms/step - loss: 0.3947 - accuracy: 0.8520 - val_loss: 0.5441 - val_accuracy: 0.7846

Epoch 00017: val_loss did not improve from 0.44385
Epoch 18/500
338/338 [==============================] - 23s 68ms/step - loss: 0.3840 - accuracy: 0.8590 - val_loss: 0.6112 - val_accuracy: 0.7638

Epoch 00018: val_loss did not improve from 0.44385
Epoch 19/500
338/338 [==============================] - 23s 68ms/step - loss: 0.3764 - accuracy: 0.8641 - val_loss: 0.6314 - val_accuracy: 0.7507

Epoch 00019: val_loss did not improve from 0.44385
Epoch 20/500
338/338 [==============================] - 23s 68ms/step - loss: 0.3729 - accuracy: 0.8671 - val_loss: 0.6382 - val_accuracy: 0.7628

Epoch 00020: val_loss did not improve from 0.44385
Epoch 21/500
338/338 [==============================] - 23s 68ms/step - loss: 0.3587 - accuracy: 0.8760 - val_loss: 0.5919 - val_accuracy: 0.7721

Epoch 00021: val_loss did not improve from 0.44385
Epoch 22/500
338/338 [==============================] - 23s 68ms/step - loss: 0.3553 - accuracy: 0.8771 - val_loss: 0.6068 - val_accuracy: 0.7733

Epoch 00022: val_loss did not improve from 0.44385
Epoch 23/500
338/338 [==============================] - 23s 68ms/step - loss: 0.3384 - accuracy: 0.8875 - val_loss: 0.6329 - val_accuracy: 0.7681

Epoch 00023: val_loss did not improve from 0.44385
Epoch 24/500
338/338 [==============================] - 23s 68ms/step - loss: 0.3243 - accuracy: 0.8952 - val_loss: 0.6143 - val_accuracy: 0.7708

Epoch 00024: val_loss did not improve from 0.44385
Epoch 25/500
338/338 [==============================] - 23s 68ms/step - loss: 0.3169 - accuracy: 0.8998 - val_loss: 0.6587 - val_accuracy: 0.7684

Epoch 00025: val_loss did not improve from 0.44385
Epoch 00025: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
54121/54121 [==============================] - 209s 4ms/step - loss: 0.4436 - accuracy: 0.8109
Testing Loss = 0.443649, Testing Accuracy = 0.810905
The data set contains images
[[0.8062036633491516, 0.19379635155200958], [0.13689278066158295, 0.8631072044372559], [0.1638585776090622, 0.8361414074897766], [0.14286524057388306, 0.8571347594261169], [0.046017780900001526, 0.9539822340011597], [0.012971466407179832, 0.9870284795761108], [0.08165130764245987, 0.9183486700057983], [0.3759825527667999, 0.6240174770355225], [0.674064576625824, 0.32593539357185364], [0.674064576625824, 0.32593539357185364]]
[[1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0]]
2
$W^+$ (auc = 0.88)
$Z$ (auc = 0.88)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-15 22:58:00.239959
Binary task for  ['$W^+$', '$Z$']
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
444/444 [==============================] - 91s 175ms/step - loss: 4.5254 - accuracy: 0.7521 - val_loss: 1.5096 - val_accuracy: 0.7751

Epoch 00001: val_loss improved from inf to 1.50957, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 2/500
444/444 [==============================] - 30s 68ms/step - loss: 0.9398 - accuracy: 0.7861 - val_loss: 0.6169 - val_accuracy: 0.7982

Epoch 00002: val_loss improved from 1.50957 to 0.61691, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 3/500
444/444 [==============================] - 30s 68ms/step - loss: 0.5499 - accuracy: 0.7920 - val_loss: 0.5073 - val_accuracy: 0.7941

Epoch 00003: val_loss improved from 0.61691 to 0.50726, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 4/500
444/444 [==============================] - 30s 68ms/step - loss: 0.4906 - accuracy: 0.7956 - val_loss: 0.4737 - val_accuracy: 0.8007

Epoch 00004: val_loss improved from 0.50726 to 0.47365, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 5/500
444/444 [==============================] - 31s 69ms/step - loss: 0.4751 - accuracy: 0.7983 - val_loss: 0.4631 - val_accuracy: 0.8031

Epoch 00005: val_loss improved from 0.47365 to 0.46312, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 6/500
444/444 [==============================] - 31s 69ms/step - loss: 0.4670 - accuracy: 0.8004 - val_loss: 0.4574 - val_accuracy: 0.8042

Epoch 00006: val_loss improved from 0.46312 to 0.45737, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 7/500
444/444 [==============================] - 30s 68ms/step - loss: 0.4621 - accuracy: 0.8018 - val_loss: 0.4585 - val_accuracy: 0.8035

Epoch 00007: val_loss did not improve from 0.45737
Epoch 8/500
444/444 [==============================] - 30s 69ms/step - loss: 0.4580 - accuracy: 0.8036 - val_loss: 0.4580 - val_accuracy: 0.8032

Epoch 00008: val_loss did not improve from 0.45737
Epoch 9/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4543 - accuracy: 0.8050 - val_loss: 0.4544 - val_accuracy: 0.8049

Epoch 00009: val_loss improved from 0.45737 to 0.45437, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 10/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4520 - accuracy: 0.8061 - val_loss: 0.4537 - val_accuracy: 0.8054

Epoch 00010: val_loss improved from 0.45437 to 0.45372, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 11/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4481 - accuracy: 0.8075 - val_loss: 0.4500 - val_accuracy: 0.8065

Epoch 00011: val_loss improved from 0.45372 to 0.44995, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 12/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4453 - accuracy: 0.8086 - val_loss: 0.4512 - val_accuracy: 0.8056

Epoch 00012: val_loss did not improve from 0.44995
Epoch 13/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4429 - accuracy: 0.8106 - val_loss: 0.4523 - val_accuracy: 0.8050

Epoch 00013: val_loss did not improve from 0.44995
Epoch 14/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4397 - accuracy: 0.8121 - val_loss: 0.4500 - val_accuracy: 0.8060

Epoch 00014: val_loss did not improve from 0.44995
Epoch 15/500
444/444 [==============================] - 30s 68ms/step - loss: 0.4372 - accuracy: 0.8142 - val_loss: 0.4524 - val_accuracy: 0.8046

Epoch 00015: val_loss did not improve from 0.44995
Epoch 16/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4339 - accuracy: 0.8156 - val_loss: 0.4518 - val_accuracy: 0.8053

Epoch 00016: val_loss did not improve from 0.44995
Epoch 17/500
444/444 [==============================] - 30s 68ms/step - loss: 0.4306 - accuracy: 0.8182 - val_loss: 0.4535 - val_accuracy: 0.8049

Epoch 00017: val_loss did not improve from 0.44995
Epoch 18/500
444/444 [==============================] - 30s 68ms/step - loss: 0.4266 - accuracy: 0.8216 - val_loss: 0.4584 - val_accuracy: 0.8032

Epoch 00018: val_loss did not improve from 0.44995
Epoch 19/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4227 - accuracy: 0.8244 - val_loss: 0.4615 - val_accuracy: 0.8018

Epoch 00019: val_loss did not improve from 0.44995
Epoch 20/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4181 - accuracy: 0.8280 - val_loss: 0.4673 - val_accuracy: 0.8001

Epoch 00020: val_loss did not improve from 0.44995
Epoch 21/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4126 - accuracy: 0.8321 - val_loss: 0.4782 - val_accuracy: 0.7958

Epoch 00021: val_loss did not improve from 0.44995
Epoch 22/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4069 - accuracy: 0.8363 - val_loss: 0.4800 - val_accuracy: 0.7971

Epoch 00022: val_loss did not improve from 0.44995
Epoch 23/500
444/444 [==============================] - 30s 67ms/step - loss: 0.4003 - accuracy: 0.8416 - val_loss: 0.4863 - val_accuracy: 0.7955

Epoch 00023: val_loss did not improve from 0.44995
Epoch 24/500
444/444 [==============================] - 30s 67ms/step - loss: 0.3908 - accuracy: 0.8482 - val_loss: 0.5022 - val_accuracy: 0.7917

Epoch 00024: val_loss did not improve from 0.44995
Epoch 25/500
444/444 [==============================] - 30s 67ms/step - loss: 0.3816 - accuracy: 0.8542 - val_loss: 0.5185 - val_accuracy: 0.7846

Epoch 00025: val_loss did not improve from 0.44995
Epoch 26/500
444/444 [==============================] - 30s 67ms/step - loss: 0.3721 - accuracy: 0.8612 - val_loss: 0.5177 - val_accuracy: 0.7892

Epoch 00026: val_loss did not improve from 0.44995
Epoch 27/500
444/444 [==============================] - 30s 68ms/step - loss: 0.3601 - accuracy: 0.8693 - val_loss: 0.5305 - val_accuracy: 0.7892

Epoch 00027: val_loss did not improve from 0.44995
Epoch 28/500
444/444 [==============================] - 30s 67ms/step - loss: 0.3585 - accuracy: 0.8700 - val_loss: 0.5284 - val_accuracy: 0.7875

Epoch 00028: val_loss did not improve from 0.44995
Epoch 29/500
444/444 [==============================] - 30s 67ms/step - loss: 0.3553 - accuracy: 0.8711 - val_loss: 0.5550 - val_accuracy: 0.7739

Epoch 00029: val_loss did not improve from 0.44995
Epoch 30/500
444/444 [==============================] - 30s 67ms/step - loss: 0.3414 - accuracy: 0.8799 - val_loss: 0.5733 - val_accuracy: 0.7754

Epoch 00030: val_loss did not improve from 0.44995
Epoch 31/500
444/444 [==============================] - 30s 67ms/step - loss: 0.3300 - accuracy: 0.8878 - val_loss: 0.5945 - val_accuracy: 0.7672

Epoch 00031: val_loss did not improve from 0.44995
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
71190/71190 [==============================] - 278s 4ms/step - loss: 0.4531 - accuracy: 0.8033
Testing Loss = 0.453050, Testing Accuracy = 0.803315
The data set contains images
[[0.984806478023529, 0.015193549916148186], [0.7858180999755859, 0.21418191492557526], [0.3974137604236603, 0.6025862693786621], [0.5228527188301086, 0.47714734077453613], [0.07870441675186157, 0.9212955832481384], [0.08923264592885971, 0.9107673168182373], [0.9167847633361816, 0.08321524411439896], [0.5841664671897888, 0.4158335030078888], [0.5841664671897888, 0.4158335030078888], [0.9763763546943665, 0.023623600602149963]]
[[0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0]]
2
$W^+$ (auc = 0.89)
$Z$ (auc = 0.89)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-16 17:24:06.648573
Binary task for  ['$W^+$', '$Z$']
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
217/217 [==============================] - 29s 107ms/step - loss: 6.9774 - accuracy: 0.7499 - val_loss: 3.2448 - val_accuracy: 0.7550

Epoch 00001: val_loss improved from inf to 3.24477, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 2/500
217/217 [==============================] - 15s 68ms/step - loss: 2.2236 - accuracy: 0.7915 - val_loss: 1.5456 - val_accuracy: 0.7829

Epoch 00002: val_loss improved from 3.24477 to 1.54557, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 3/500
217/217 [==============================] - 15s 68ms/step - loss: 1.1505 - accuracy: 0.8029 - val_loss: 0.8706 - val_accuracy: 0.8078

Epoch 00003: val_loss improved from 1.54557 to 0.87058, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 4/500
217/217 [==============================] - 15s 67ms/step - loss: 0.7230 - accuracy: 0.8072 - val_loss: 0.6134 - val_accuracy: 0.8111

Epoch 00004: val_loss improved from 0.87058 to 0.61339, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 5/500
217/217 [==============================] - 15s 69ms/step - loss: 0.5555 - accuracy: 0.8111 - val_loss: 0.5132 - val_accuracy: 0.8134

Epoch 00005: val_loss improved from 0.61339 to 0.51318, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 6/500
217/217 [==============================] - 15s 67ms/step - loss: 0.4901 - accuracy: 0.8136 - val_loss: 0.4732 - val_accuracy: 0.8172

Epoch 00006: val_loss improved from 0.51318 to 0.47322, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 7/500
217/217 [==============================] - 15s 68ms/step - loss: 0.4636 - accuracy: 0.8157 - val_loss: 0.4603 - val_accuracy: 0.8149

Epoch 00007: val_loss improved from 0.47322 to 0.46029, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 8/500
217/217 [==============================] - 15s 68ms/step - loss: 0.4523 - accuracy: 0.8157 - val_loss: 0.4701 - val_accuracy: 0.8048

Epoch 00008: val_loss did not improve from 0.46029
Epoch 9/500
217/217 [==============================] - 15s 69ms/step - loss: 0.4436 - accuracy: 0.8180 - val_loss: 0.4606 - val_accuracy: 0.8081

Epoch 00009: val_loss did not improve from 0.46029
Epoch 10/500
217/217 [==============================] - 15s 69ms/step - loss: 0.4368 - accuracy: 0.8208 - val_loss: 0.4580 - val_accuracy: 0.8073

Epoch 00010: val_loss improved from 0.46029 to 0.45804, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 11/500
217/217 [==============================] - 15s 69ms/step - loss: 0.4319 - accuracy: 0.8229 - val_loss: 0.4528 - val_accuracy: 0.8102

Epoch 00011: val_loss improved from 0.45804 to 0.45277, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 12/500
217/217 [==============================] - 15s 69ms/step - loss: 0.4272 - accuracy: 0.8244 - val_loss: 0.4457 - val_accuracy: 0.8139

Epoch 00012: val_loss improved from 0.45277 to 0.44574, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 13/500
217/217 [==============================] - 15s 70ms/step - loss: 0.4241 - accuracy: 0.8267 - val_loss: 0.4604 - val_accuracy: 0.8065

Epoch 00013: val_loss did not improve from 0.44574
Epoch 14/500
217/217 [==============================] - 15s 69ms/step - loss: 0.4207 - accuracy: 0.8292 - val_loss: 0.4609 - val_accuracy: 0.8062

Epoch 00014: val_loss did not improve from 0.44574
Epoch 15/500
217/217 [==============================] - 15s 70ms/step - loss: 0.4150 - accuracy: 0.8327 - val_loss: 0.4497 - val_accuracy: 0.8126

Epoch 00015: val_loss did not improve from 0.44574
Epoch 16/500
217/217 [==============================] - 15s 70ms/step - loss: 0.4086 - accuracy: 0.8363 - val_loss: 0.4500 - val_accuracy: 0.8127

Epoch 00016: val_loss did not improve from 0.44574
Epoch 17/500
217/217 [==============================] - 15s 69ms/step - loss: 0.4036 - accuracy: 0.8400 - val_loss: 0.4522 - val_accuracy: 0.8133

Epoch 00017: val_loss did not improve from 0.44574
Epoch 18/500
217/217 [==============================] - 15s 69ms/step - loss: 0.3969 - accuracy: 0.8450 - val_loss: 0.4600 - val_accuracy: 0.8123

Epoch 00018: val_loss did not improve from 0.44574
Epoch 19/500
217/217 [==============================] - 15s 70ms/step - loss: 0.3883 - accuracy: 0.8518 - val_loss: 0.4651 - val_accuracy: 0.8103

Epoch 00019: val_loss did not improve from 0.44574
Epoch 20/500
217/217 [==============================] - 15s 70ms/step - loss: 0.3796 - accuracy: 0.8586 - val_loss: 0.4747 - val_accuracy: 0.8080

Epoch 00020: val_loss did not improve from 0.44574
Epoch 21/500
217/217 [==============================] - 15s 69ms/step - loss: 0.3692 - accuracy: 0.8670 - val_loss: 0.4889 - val_accuracy: 0.8059

Epoch 00021: val_loss did not improve from 0.44574
Epoch 22/500
217/217 [==============================] - 15s 68ms/step - loss: 0.3549 - accuracy: 0.8758 - val_loss: 0.5010 - val_accuracy: 0.8032

Epoch 00022: val_loss did not improve from 0.44574
Epoch 23/500
217/217 [==============================] - 15s 70ms/step - loss: 0.3459 - accuracy: 0.8829 - val_loss: 0.5058 - val_accuracy: 0.8016

Epoch 00023: val_loss did not improve from 0.44574
Epoch 24/500
217/217 [==============================] - 15s 69ms/step - loss: 0.3415 - accuracy: 0.8855 - val_loss: 0.5587 - val_accuracy: 0.7850

Epoch 00024: val_loss did not improve from 0.44574
Epoch 25/500
217/217 [==============================] - 15s 69ms/step - loss: 0.3428 - accuracy: 0.8849 - val_loss: 0.5185 - val_accuracy: 0.7894

Epoch 00025: val_loss did not improve from 0.44574
Epoch 26/500
217/217 [==============================] - 15s 70ms/step - loss: 0.3271 - accuracy: 0.8939 - val_loss: 0.5413 - val_accuracy: 0.7834

Epoch 00026: val_loss did not improve from 0.44574
Epoch 27/500
217/217 [==============================] - 15s 68ms/step - loss: 0.3166 - accuracy: 0.9003 - val_loss: 0.5945 - val_accuracy: 0.7599

Epoch 00027: val_loss did not improve from 0.44574
Epoch 28/500
217/217 [==============================] - 15s 69ms/step - loss: 0.3039 - accuracy: 0.9067 - val_loss: 0.5751 - val_accuracy: 0.7838

Epoch 00028: val_loss did not improve from 0.44574
Epoch 29/500
217/217 [==============================] - 15s 70ms/step - loss: 0.2738 - accuracy: 0.9245 - val_loss: 0.5777 - val_accuracy: 0.7872

Epoch 00029: val_loss did not improve from 0.44574
Epoch 30/500
217/217 [==============================] - 15s 69ms/step - loss: 0.2571 - accuracy: 0.9338 - val_loss: 0.5996 - val_accuracy: 0.7830

Epoch 00030: val_loss did not improve from 0.44574
Epoch 31/500
217/217 [==============================] - 15s 70ms/step - loss: 0.2497 - accuracy: 0.9366 - val_loss: 0.6170 - val_accuracy: 0.7776

Epoch 00031: val_loss did not improve from 0.44574
Epoch 32/500
217/217 [==============================] - 15s 70ms/step - loss: 0.2568 - accuracy: 0.9315 - val_loss: 0.7486 - val_accuracy: 0.7429

Epoch 00032: val_loss did not improve from 0.44574
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
34798/34798 [==============================] - 138s 4ms/step - loss: 0.4479 - accuracy: 0.8136
Testing Loss = 0.447902, Testing Accuracy = 0.813552
The data set contains images
[[0.27081170678138733, 0.7291883230209351], [0.03883020952343941, 0.9611697196960449], [0.686453640460968, 0.31354638934135437], [0.9037679433822632, 0.09623201936483383], [0.9180179238319397, 0.0819820836186409], [0.010186250321567059, 0.9898137450218201], [0.012769961729645729, 0.9872300028800964], [0.01990778185427189, 0.9800921678543091], [0.0031239709351211786, 0.9968760013580322], [0.34996920824050903, 0.650030791759491]]
[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0]]
2
$W^+$ (auc = 0.89)
$Z$ (auc = 0.89)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-16 23:26:59.299741
Binary task for  ['$W^+$', '$Z$']
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
647/647 [==============================] - 328s 488ms/step - loss: 3.5286 - accuracy: 0.7708 - val_loss: 0.9136 - val_accuracy: 0.7898

Epoch 00001: val_loss improved from inf to 0.91360, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 2/500
647/647 [==============================] - 143s 222ms/step - loss: 0.6150 - accuracy: 0.7986 - val_loss: 0.4846 - val_accuracy: 0.8057

Epoch 00002: val_loss improved from 0.91360 to 0.48462, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 3/500
647/647 [==============================] - 140s 216ms/step - loss: 0.4709 - accuracy: 0.8037 - val_loss: 0.4516 - val_accuracy: 0.8092

Epoch 00003: val_loss improved from 0.48462 to 0.45162, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 4/500
647/647 [==============================] - 136s 210ms/step - loss: 0.4536 - accuracy: 0.8061 - val_loss: 0.4429 - val_accuracy: 0.8107

Epoch 00004: val_loss improved from 0.45162 to 0.44290, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 5/500
647/647 [==============================] - 90s 139ms/step - loss: 0.4468 - accuracy: 0.8075 - val_loss: 0.4391 - val_accuracy: 0.8122

Epoch 00005: val_loss improved from 0.44290 to 0.43906, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 6/500
647/647 [==============================] - 48s 74ms/step - loss: 0.4421 - accuracy: 0.8091 - val_loss: 0.4365 - val_accuracy: 0.8119

Epoch 00006: val_loss improved from 0.43906 to 0.43647, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 7/500
647/647 [==============================] - 46s 71ms/step - loss: 0.4381 - accuracy: 0.8110 - val_loss: 0.4341 - val_accuracy: 0.8131

Epoch 00007: val_loss improved from 0.43647 to 0.43410, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 8/500
647/647 [==============================] - 45s 69ms/step - loss: 0.4348 - accuracy: 0.8121 - val_loss: 0.4319 - val_accuracy: 0.8132

Epoch 00008: val_loss improved from 0.43410 to 0.43185, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 9/500
647/647 [==============================] - 46s 71ms/step - loss: 0.4316 - accuracy: 0.8134 - val_loss: 0.4313 - val_accuracy: 0.8132

Epoch 00009: val_loss improved from 0.43185 to 0.43125, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 10/500
647/647 [==============================] - 44s 68ms/step - loss: 0.4293 - accuracy: 0.8144 - val_loss: 0.4297 - val_accuracy: 0.8141

Epoch 00010: val_loss improved from 0.43125 to 0.42969, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 11/500
647/647 [==============================] - 44s 69ms/step - loss: 0.4269 - accuracy: 0.8152 - val_loss: 0.4290 - val_accuracy: 0.8141

Epoch 00011: val_loss improved from 0.42969 to 0.42896, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 12/500
647/647 [==============================] - 44s 68ms/step - loss: 0.4249 - accuracy: 0.8161 - val_loss: 0.4290 - val_accuracy: 0.8136

Epoch 00012: val_loss did not improve from 0.42896
Epoch 13/500
647/647 [==============================] - 44s 69ms/step - loss: 0.4224 - accuracy: 0.8175 - val_loss: 0.4305 - val_accuracy: 0.8133

Epoch 00013: val_loss did not improve from 0.42896
Epoch 14/500
647/647 [==============================] - 45s 69ms/step - loss: 0.4199 - accuracy: 0.8193 - val_loss: 0.4294 - val_accuracy: 0.8141

Epoch 00014: val_loss did not improve from 0.42896
Epoch 15/500
647/647 [==============================] - 44s 69ms/step - loss: 0.4182 - accuracy: 0.8197 - val_loss: 0.4291 - val_accuracy: 0.8133

Epoch 00015: val_loss did not improve from 0.42896
Epoch 16/500
647/647 [==============================] - 44s 69ms/step - loss: 0.4160 - accuracy: 0.8215 - val_loss: 0.4298 - val_accuracy: 0.8134

Epoch 00016: val_loss did not improve from 0.42896
Epoch 17/500
647/647 [==============================] - 44s 68ms/step - loss: 0.4136 - accuracy: 0.8233 - val_loss: 0.4315 - val_accuracy: 0.8136

Epoch 00017: val_loss did not improve from 0.42896
Epoch 18/500
647/647 [==============================] - 44s 68ms/step - loss: 0.4111 - accuracy: 0.8253 - val_loss: 0.4321 - val_accuracy: 0.8131

Epoch 00018: val_loss did not improve from 0.42896
Epoch 19/500
647/647 [==============================] - 44s 68ms/step - loss: 0.4090 - accuracy: 0.8267 - val_loss: 0.4374 - val_accuracy: 0.8120

Epoch 00019: val_loss did not improve from 0.42896
Epoch 20/500
647/647 [==============================] - 44s 69ms/step - loss: 0.4057 - accuracy: 0.8289 - val_loss: 0.4373 - val_accuracy: 0.8121

Epoch 00020: val_loss did not improve from 0.42896
Epoch 21/500
647/647 [==============================] - 45s 69ms/step - loss: 0.4019 - accuracy: 0.8323 - val_loss: 0.4410 - val_accuracy: 0.8113

Epoch 00021: val_loss did not improve from 0.42896
Epoch 22/500
647/647 [==============================] - 44s 68ms/step - loss: 0.3985 - accuracy: 0.8347 - val_loss: 0.4449 - val_accuracy: 0.8103

Epoch 00022: val_loss did not improve from 0.42896
Epoch 23/500
647/647 [==============================] - 44s 68ms/step - loss: 0.3938 - accuracy: 0.8386 - val_loss: 0.4493 - val_accuracy: 0.8096

Epoch 00023: val_loss did not improve from 0.42896
Epoch 24/500
647/647 [==============================] - 45s 69ms/step - loss: 0.3891 - accuracy: 0.8427 - val_loss: 0.4591 - val_accuracy: 0.8069

Epoch 00024: val_loss did not improve from 0.42896
Epoch 25/500
647/647 [==============================] - 44s 69ms/step - loss: 0.3835 - accuracy: 0.8465 - val_loss: 0.4627 - val_accuracy: 0.8051

Epoch 00025: val_loss did not improve from 0.42896
Epoch 26/500
647/647 [==============================] - 45s 69ms/step - loss: 0.3776 - accuracy: 0.8514 - val_loss: 0.4693 - val_accuracy: 0.8044

Epoch 00026: val_loss did not improve from 0.42896
Epoch 27/500
647/647 [==============================] - 45s 69ms/step - loss: 0.3703 - accuracy: 0.8565 - val_loss: 0.4871 - val_accuracy: 0.7994

Epoch 00027: val_loss did not improve from 0.42896
Epoch 28/500
647/647 [==============================] - 44s 69ms/step - loss: 0.3629 - accuracy: 0.8617 - val_loss: 0.4880 - val_accuracy: 0.7993

Epoch 00028: val_loss did not improve from 0.42896
Epoch 29/500
647/647 [==============================] - 44s 68ms/step - loss: 0.3595 - accuracy: 0.8644 - val_loss: 0.5037 - val_accuracy: 0.7967

Epoch 00029: val_loss did not improve from 0.42896
Epoch 30/500
647/647 [==============================] - 45s 69ms/step - loss: 0.3530 - accuracy: 0.8684 - val_loss: 0.5065 - val_accuracy: 0.7967

Epoch 00030: val_loss did not improve from 0.42896
Epoch 31/500
647/647 [==============================] - 44s 68ms/step - loss: 0.3481 - accuracy: 0.8719 - val_loss: 0.5176 - val_accuracy: 0.7963

Epoch 00031: val_loss did not improve from 0.42896
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
103546/103546 [==============================] - 239s 2ms/step - loss: 0.4297 - accuracy: 0.8127
Testing Loss = 0.429651, Testing Accuracy = 0.812740
The data set contains images
[[0.9862281084060669, 0.013771907426416874], [0.8636332750320435, 0.1363667994737625], [0.3774135410785675, 0.6225864887237549], [0.05676424875855446, 0.9432357549667358], [0.021481048315763474, 0.9785189628601074], [0.6491650342941284, 0.3508349359035492], [0.15216369926929474, 0.8478363156318665], [0.9465467929840088, 0.053453247994184494], [0.3555414080619812, 0.6444585919380188], [0.07235992699861526, 0.9276400208473206]]
[[1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0]]
2
$W^+$ (auc = 0.89)
$Z$ (auc = 0.89)
