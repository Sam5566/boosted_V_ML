

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 15:20:39.136000
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 15:27:19.291063
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
281/281 [==============================] - 65s 194ms/step - loss: 6.2761 - accuracy: 0.7150 - val_loss: 2.6557 - val_accuracy: 0.7370

Epoch 00001: val_loss improved from inf to 2.65566, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 2/500
281/281 [==============================] - 55s 196ms/step - loss: 1.7297 - accuracy: 0.7642 - val_loss: 1.1194 - val_accuracy: 0.7744

Epoch 00002: val_loss improved from 2.65566 to 1.11935, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 3/500
281/281 [==============================] - 65s 230ms/step - loss: 0.8528 - accuracy: 0.7740 - val_loss: 0.6643 - val_accuracy: 0.7803

Epoch 00003: val_loss improved from 1.11935 to 0.66429, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 4/500
281/281 [==============================] - 67s 240ms/step - loss: 0.5890 - accuracy: 0.7786 - val_loss: 0.5276 - val_accuracy: 0.7877

Epoch 00004: val_loss improved from 0.66429 to 0.52758, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 5/500
281/281 [==============================] - 67s 236ms/step - loss: 0.5129 - accuracy: 0.7819 - val_loss: 0.4909 - val_accuracy: 0.7875

Epoch 00005: val_loss improved from 0.52758 to 0.49094, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 6/500
281/281 [==============================] - 59s 211ms/step - loss: 0.4892 - accuracy: 0.7849 - val_loss: 0.4703 - val_accuracy: 0.7938

Epoch 00006: val_loss improved from 0.49094 to 0.47026, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 7/500
281/281 [==============================] - 57s 204ms/step - loss: 0.4783 - accuracy: 0.7869 - val_loss: 0.4652 - val_accuracy: 0.7948

Epoch 00007: val_loss improved from 0.47026 to 0.46524, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 8/500
281/281 [==============================] - 56s 198ms/step - loss: 0.4743 - accuracy: 0.7882 - val_loss: 0.4649 - val_accuracy: 0.7948

Epoch 00008: val_loss improved from 0.46524 to 0.46486, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 9/500
281/281 [==============================] - 59s 209ms/step - loss: 0.4707 - accuracy: 0.7895 - val_loss: 0.4624 - val_accuracy: 0.7958

Epoch 00009: val_loss improved from 0.46486 to 0.46237, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 10/500
281/281 [==============================] - 59s 211ms/step - loss: 0.4680 - accuracy: 0.7915 - val_loss: 0.4620 - val_accuracy: 0.7960

Epoch 00010: val_loss improved from 0.46237 to 0.46199, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 11/500
281/281 [==============================] - 66s 233ms/step - loss: 0.4653 - accuracy: 0.7922 - val_loss: 0.4615 - val_accuracy: 0.7966

Epoch 00011: val_loss improved from 0.46199 to 0.46152, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 12/500
281/281 [==============================] - 59s 209ms/step - loss: 0.4625 - accuracy: 0.7939 - val_loss: 0.4615 - val_accuracy: 0.7968

Epoch 00012: val_loss improved from 0.46152 to 0.46149, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 13/500
281/281 [==============================] - 59s 211ms/step - loss: 0.4607 - accuracy: 0.7948 - val_loss: 0.4608 - val_accuracy: 0.7966

Epoch 00013: val_loss improved from 0.46149 to 0.46082, saving model to best_model_binary-WpZ_CNN_kappa0.15/
Epoch 14/500
281/281 [==============================] - 56s 201ms/step - loss: 0.4583 - accuracy: 0.7969 - val_loss: 0.4617 - val_accuracy: 0.7948

Epoch 00014: val_loss did not improve from 0.46082
Epoch 15/500
281/281 [==============================] - 59s 211ms/step - loss: 0.4553 - accuracy: 0.7989 - val_loss: 0.4646 - val_accuracy: 0.7949

Epoch 00015: val_loss did not improve from 0.46082
Epoch 16/500
281/281 [==============================] - 61s 215ms/step - loss: 0.4533 - accuracy: 0.8010 - val_loss: 0.4630 - val_accuracy: 0.7960

Epoch 00016: val_loss did not improve from 0.46082
Epoch 17/500
281/281 [==============================] - 66s 234ms/step - loss: 0.4502 - accuracy: 0.8031 - val_loss: 0.4657 - val_accuracy: 0.7949

Epoch 00017: val_loss did not improve from 0.46082
Epoch 18/500
281/281 [==============================] - 61s 216ms/step - loss: 0.4461 - accuracy: 0.8062 - val_loss: 0.4689 - val_accuracy: 0.7944

Epoch 00018: val_loss did not improve from 0.46082
Epoch 19/500
281/281 [==============================] - 59s 208ms/step - loss: 0.4429 - accuracy: 0.8083 - val_loss: 0.4696 - val_accuracy: 0.7944

Epoch 00019: val_loss did not improve from 0.46082
Epoch 20/500
281/281 [==============================] - 65s 232ms/step - loss: 0.4394 - accuracy: 0.8102 - val_loss: 0.4737 - val_accuracy: 0.7943

Epoch 00020: val_loss did not improve from 0.46082
Epoch 21/500
281/281 [==============================] - 68s 243ms/step - loss: 0.4347 - accuracy: 0.8143 - val_loss: 0.4777 - val_accuracy: 0.7937

Epoch 00021: val_loss did not improve from 0.46082
Epoch 22/500
281/281 [==============================] - 68s 243ms/step - loss: 0.4282 - accuracy: 0.8190 - val_loss: 0.4833 - val_accuracy: 0.7930

Epoch 00022: val_loss did not improve from 0.46082
Epoch 23/500
281/281 [==============================] - 61s 215ms/step - loss: 0.4232 - accuracy: 0.8244 - val_loss: 0.4872 - val_accuracy: 0.7910

Epoch 00023: val_loss did not improve from 0.46082
Epoch 24/500
281/281 [==============================] - 55s 197ms/step - loss: 0.4167 - accuracy: 0.8278 - val_loss: 0.4959 - val_accuracy: 0.7900

Epoch 00024: val_loss did not improve from 0.46082
Epoch 25/500
281/281 [==============================] - 59s 211ms/step - loss: 0.4087 - accuracy: 0.8338 - val_loss: 0.4996 - val_accuracy: 0.7881

Epoch 00025: val_loss did not improve from 0.46082
Epoch 26/500
281/281 [==============================] - 59s 209ms/step - loss: 0.4006 - accuracy: 0.8400 - val_loss: 0.5117 - val_accuracy: 0.7864

Epoch 00026: val_loss did not improve from 0.46082
Epoch 27/500
281/281 [==============================] - 70s 249ms/step - loss: 0.3990 - accuracy: 0.8410 - val_loss: 0.5112 - val_accuracy: 0.7800

Epoch 00027: val_loss did not improve from 0.46082
Epoch 28/500
281/281 [==============================] - 59s 208ms/step - loss: 0.3897 - accuracy: 0.8472 - val_loss: 0.5185 - val_accuracy: 0.7813

Epoch 00028: val_loss did not improve from 0.46082
Epoch 29/500
281/281 [==============================] - 61s 216ms/step - loss: 0.3788 - accuracy: 0.8541 - val_loss: 0.5456 - val_accuracy: 0.7710

Epoch 00029: val_loss did not improve from 0.46082
Epoch 30/500
281/281 [==============================] - 70s 248ms/step - loss: 0.3701 - accuracy: 0.8598 - val_loss: 0.5903 - val_accuracy: 0.7486

Epoch 00030: val_loss did not improve from 0.46082
Epoch 31/500
281/281 [==============================] - 60s 214ms/step - loss: 0.3608 - accuracy: 0.8643 - val_loss: 0.5819 - val_accuracy: 0.7579

Epoch 00031: val_loss did not improve from 0.46082
Epoch 32/500
281/281 [==============================] - 60s 213ms/step - loss: 0.3524 - accuracy: 0.8696 - val_loss: 0.6051 - val_accuracy: 0.7542

Epoch 00032: val_loss did not improve from 0.46082
Epoch 33/500
281/281 [==============================] - 59s 211ms/step - loss: 0.3403 - accuracy: 0.8769 - val_loss: 0.6015 - val_accuracy: 0.7620

Epoch 00033: val_loss did not improve from 0.46082
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Model: "CNN_binary"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
sequential (Sequential)      (None, 512)               12127912  
_________________________________________________________________
dense_2 (Dense)              multiple                  1026      
=================================================================
Total params: 12,128,938
Trainable params: 12,128,934
Non-trainable params: 4
_________________________________________________________________
[93mNone[0m
@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lambda (Lambda)              (None, 75, 75, 2)         0         
_________________________________________________________________
batch_normalization (BatchNo (None, 75, 75, 2)         8         
_________________________________________________________________
conv2d (Conv2D)              (None, 75, 75, 32)        2336      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         
_________________________________________________________________
dropout (Dropout)            (None, 9, 9, 256)         0         
_________________________________________________________________
flatten (Flatten)            (None, 20736)             0         
_________________________________________________________________
dense (Dense)                (None, 512)               10617344  
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               262656    
_________________________________________________________________
dropout_2 (Dropout)          (None, 512)               0         
=================================================================
Total params: 12,127,912
Trainable params: 12,127,908
Non-trainable params: 4
_________________________________________________________________
None
{'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQBhQJm\nBBkAUwCpAk7pAgAAAKkAqQHaAXhyAwAAAHIDAAAA+hsvaG9tZS9zYW1odWFuZy9NTC9tb2RlbHMu\ncHnaCDxsYW1iZGE+1AAAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}
@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
{'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
45063/45063 [==============================] - 126s 3ms/step - loss: 0.6056 - accuracy: 0.7586
Testing Loss = 0.605580, Testing Accuracy = 0.758560
The data set contains images
[[0.5080137848854065, 0.4919862151145935], [0.011435182765126228, 0.9885647892951965], [0.5252796411514282, 0.474720299243927], [0.947877824306488, 0.052122119814157486], [0.0039931354112923145, 0.9960069060325623], [0.91214519739151, 0.0878547802567482], [0.03208987042307854, 0.96791011095047], [0.9085429310798645, 0.09145708382129669], [0.16437235474586487, 0.8356276154518127], [0.8605545163154602, 0.1394454538822174]]
[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0]]
2
$W^+$ (auc = 0.85)
$Z$ (auc = 0.85)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 16:40:22.362174
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images

Epoch 00001: val_loss improved from inf to 2.66934, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00002: val_loss improved from 2.66934 to 1.11873, saving model to best_model_binary-WpZ_CNN_kappa0.15/


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 16:43:12.687705
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images

Epoch 00001: val_loss improved from inf to 2.65157, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00002: val_loss improved from 2.65157 to 1.10800, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00003: val_loss improved from 1.10800 to 0.65900, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00004: val_loss improved from 0.65900 to 0.52271, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00005: val_loss improved from 0.52271 to 0.49094, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00006: val_loss improved from 0.49094 to 0.48256, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00007: val_loss improved from 0.48256 to 0.47039, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00008: val_loss improved from 0.47039 to 0.46987, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00009: val_loss improved from 0.46987 to 0.46563, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00010: val_loss improved from 0.46563 to 0.46323, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00011: val_loss did not improve from 0.46323

Epoch 00012: val_loss improved from 0.46323 to 0.46197, saving model to best_model_binary-WpZ_CNN_kappa0.15/

Epoch 00013: val_loss did not improve from 0.46197

Epoch 00014: val_loss did not improve from 0.46197

Epoch 00015: val_loss did not improve from 0.46197

Epoch 00016: val_loss did not improve from 0.46197

Epoch 00017: val_loss did not improve from 0.46197

Epoch 00018: val_loss did not improve from 0.46197

Epoch 00019: val_loss did not improve from 0.46197

Epoch 00020: val_loss did not improve from 0.46197

Epoch 00021: val_loss did not improve from 0.46197

Epoch 00022: val_loss did not improve from 0.46197

Epoch 00023: val_loss did not improve from 0.46197

Epoch 00024: val_loss did not improve from 0.46197

Epoch 00025: val_loss did not improve from 0.46197

Epoch 00026: val_loss did not improve from 0.46197

Epoch 00027: val_loss did not improve from 0.46197

Epoch 00028: val_loss did not improve from 0.46197

Epoch 00029: val_loss did not improve from 0.46197

Epoch 00030: val_loss did not improve from 0.46197

Epoch 00031: val_loss did not improve from 0.46197

Epoch 00032: val_loss did not improve from 0.46197
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_binary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQBhQJm\nBBkAUwCpAk7pAgAAAKkAqQHaAXhyAwAAAHIDAAAA+hsvaG9tZS9zYW1odWFuZy9NTC9tb2RlbHMu\ncHnaCDxsYW1iZGE+1AAAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 0, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
45063/45063 [==============================] - 121s 3ms/step - loss: 0.5705 - accuracy: 0.7694
Testing Loss = 0.570549, Testing Accuracy = 0.769390
The data set contains images
[[0.661747395992279, 0.33825257420539856], [0.013488818891346455, 0.9865111112594604], [0.37953728437423706, 0.6204627752304077], [0.9592958688735962, 0.04070412367582321], [0.0021867193281650543, 0.9978132247924805], [0.9534160494804382, 0.046583984047174454], [0.0843101367354393, 0.9156898260116577], [0.5689941048622131, 0.43100592494010925], [0.47531619668006897, 0.5246838331222534], [0.9127362370491028, 0.08726374804973602]]
[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0]]
2
$W^+$ (auc = 0.85)
$Z$ (auc = 0.85)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-12 19:44:06.713411
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
322/322 [==============================] - 31s 77ms/step - loss: 1.3641 - accuracy: 0.7469 - val_loss: 0.5105 - val_accuracy: 0.7738

Epoch 00001: val_loss improved from inf to 0.51046, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 2/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4758 - accuracy: 0.7921 - val_loss: 0.4622 - val_accuracy: 0.7975

Epoch 00002: val_loss improved from 0.51046 to 0.46225, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 3/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4654 - accuracy: 0.7957 - val_loss: 0.4445 - val_accuracy: 0.8064

Epoch 00003: val_loss improved from 0.46225 to 0.44452, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 4/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4591 - accuracy: 0.8001 - val_loss: 0.4442 - val_accuracy: 0.8067

Epoch 00004: val_loss improved from 0.44452 to 0.44417, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 5/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4563 - accuracy: 0.8020 - val_loss: 0.4449 - val_accuracy: 0.8088

Epoch 00005: val_loss did not improve from 0.44417
Epoch 6/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4512 - accuracy: 0.8043 - val_loss: 0.4428 - val_accuracy: 0.8087

Epoch 00006: val_loss improved from 0.44417 to 0.44284, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 7/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4495 - accuracy: 0.8052 - val_loss: 0.4439 - val_accuracy: 0.8083

Epoch 00007: val_loss did not improve from 0.44284
Epoch 8/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4446 - accuracy: 0.8102 - val_loss: 0.4523 - val_accuracy: 0.8065

Epoch 00008: val_loss did not improve from 0.44284
Epoch 9/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4409 - accuracy: 0.8136 - val_loss: 0.4579 - val_accuracy: 0.8058

Epoch 00009: val_loss did not improve from 0.44284
Epoch 10/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4369 - accuracy: 0.8177 - val_loss: 0.4614 - val_accuracy: 0.8049

Epoch 00010: val_loss did not improve from 0.44284
Epoch 11/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4319 - accuracy: 0.8221 - val_loss: 0.4816 - val_accuracy: 0.8028

Epoch 00011: val_loss did not improve from 0.44284
Epoch 12/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4255 - accuracy: 0.8286 - val_loss: 0.4939 - val_accuracy: 0.7967

Epoch 00012: val_loss did not improve from 0.44284
Epoch 13/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4194 - accuracy: 0.8345 - val_loss: 0.4911 - val_accuracy: 0.7987

Epoch 00013: val_loss did not improve from 0.44284
Epoch 14/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4112 - accuracy: 0.8423 - val_loss: 0.5139 - val_accuracy: 0.7923

Epoch 00014: val_loss did not improve from 0.44284
Epoch 15/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4088 - accuracy: 0.8451 - val_loss: 0.5363 - val_accuracy: 0.7850

Epoch 00015: val_loss did not improve from 0.44284
Epoch 16/500
322/322 [==============================] - 21s 66ms/step - loss: 0.4053 - accuracy: 0.8476 - val_loss: 0.5544 - val_accuracy: 0.7843

Epoch 00016: val_loss did not improve from 0.44284
Epoch 17/500
322/322 [==============================] - 21s 65ms/step - loss: 0.4020 - accuracy: 0.8520 - val_loss: 0.6337 - val_accuracy: 0.7462

Epoch 00017: val_loss did not improve from 0.44284
Epoch 18/500
322/322 [==============================] - 21s 65ms/step - loss: 0.3929 - accuracy: 0.8564 - val_loss: 0.5982 - val_accuracy: 0.7546

Epoch 00018: val_loss did not improve from 0.44284
Epoch 19/500
322/322 [==============================] - 21s 66ms/step - loss: 0.3795 - accuracy: 0.8661 - val_loss: 0.5910 - val_accuracy: 0.7576

Epoch 00019: val_loss did not improve from 0.44284
Epoch 20/500
322/322 [==============================] - 22s 67ms/step - loss: 0.3737 - accuracy: 0.8710 - val_loss: 0.5955 - val_accuracy: 0.7749

Epoch 00020: val_loss did not improve from 0.44284
Epoch 21/500
322/322 [==============================] - 21s 65ms/step - loss: 0.3532 - accuracy: 0.8818 - val_loss: 0.6323 - val_accuracy: 0.7747

Epoch 00021: val_loss did not improve from 0.44284
Epoch 22/500
322/322 [==============================] - 21s 65ms/step - loss: 0.3427 - accuracy: 0.8884 - val_loss: 0.6622 - val_accuracy: 0.7681

Epoch 00022: val_loss did not improve from 0.44284
Epoch 23/500
322/322 [==============================] - 21s 65ms/step - loss: 0.3386 - accuracy: 0.8906 - val_loss: 0.6709 - val_accuracy: 0.7661

Epoch 00023: val_loss did not improve from 0.44284
Epoch 24/500
322/322 [==============================] - 21s 65ms/step - loss: 0.3528 - accuracy: 0.8838 - val_loss: 0.6917 - val_accuracy: 0.7719

Epoch 00024: val_loss did not improve from 0.44284
Epoch 25/500
322/322 [==============================] - 21s 66ms/step - loss: 0.3464 - accuracy: 0.8871 - val_loss: 0.7314 - val_accuracy: 0.7682

Epoch 00025: val_loss did not improve from 0.44284
Epoch 26/500
322/322 [==============================] - 21s 66ms/step - loss: 0.3336 - accuracy: 0.8940 - val_loss: 0.8026 - val_accuracy: 0.7552

Epoch 00026: val_loss did not improve from 0.44284
Epoch 00026: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_binary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQBhQJm\nBBkAUwApAk7pAgAAAKkAqQHaAXhyAgAAAHICAAAA+h8vaG9tZS9zYW1odWFuZy9NTC9DTk4vbW9k\nZWxzLnB52gg8bGFtYmRhPjMAAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
51661/51661 [==============================] - 211s 4ms/step - loss: 0.4458 - accuracy: 0.8058
Testing Loss = 0.445771, Testing Accuracy = 0.805772
The data set contains images
[[0.338067889213562, 0.6619321703910828], [0.3476470708847046, 0.6523529291152954], [0.19024114310741425, 0.8097589015960693], [0.5928939580917358, 0.40710604190826416], [0.8921435475349426, 0.10785649716854095], [0.08759261667728424, 0.912407398223877], [0.3847154676914215, 0.6152845621109009], [0.25842928886413574, 0.7415707111358643], [0.9823697805404663, 0.0176301971077919], [0.27479714155197144, 0.7252028584480286]]
[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]]
2
$W^+$ (auc = 0.88)
$Z$ (auc = 0.88)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-12 20:52:15.762527
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
322/322 [==============================] - 30s 67ms/step - loss: 1.3501 - accuracy: 0.7540 - val_loss: 0.5262 - val_accuracy: 0.7608

Epoch 00001: val_loss improved from inf to 0.52621, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 2/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4755 - accuracy: 0.7921 - val_loss: 0.4568 - val_accuracy: 0.8009

Epoch 00002: val_loss improved from 0.52621 to 0.45684, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 3/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4635 - accuracy: 0.7980 - val_loss: 0.4462 - val_accuracy: 0.8045

Epoch 00003: val_loss improved from 0.45684 to 0.44621, saving model to /home/samhuang/ML/best_model/best_model_binary-WpZ_CNN_kappa0.15/
Epoch 4/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4603 - accuracy: 0.7994 - val_loss: 0.4533 - val_accuracy: 0.8034

Epoch 00004: val_loss did not improve from 0.44621
Epoch 5/500
322/322 [==============================] - 36s 111ms/step - loss: 0.4563 - accuracy: 0.8006 - val_loss: 0.4503 - val_accuracy: 0.8035

Epoch 00005: val_loss did not improve from 0.44621
Epoch 6/500
322/322 [==============================] - 66s 204ms/step - loss: 0.4535 - accuracy: 0.8029 - val_loss: 0.4571 - val_accuracy: 0.8003

Epoch 00006: val_loss did not improve from 0.44621
Epoch 7/500
322/322 [==============================] - 25s 77ms/step - loss: 0.4489 - accuracy: 0.8059 - val_loss: 0.4521 - val_accuracy: 0.8063

Epoch 00007: val_loss did not improve from 0.44621
Epoch 8/500
322/322 [==============================] - 22s 69ms/step - loss: 0.4459 - accuracy: 0.8083 - val_loss: 0.4547 - val_accuracy: 0.8053

Epoch 00008: val_loss did not improve from 0.44621
Epoch 9/500
322/322 [==============================] - 22s 67ms/step - loss: 0.4417 - accuracy: 0.8121 - val_loss: 0.4500 - val_accuracy: 0.8073

Epoch 00009: val_loss did not improve from 0.44621
Epoch 10/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4361 - accuracy: 0.8169 - val_loss: 0.4605 - val_accuracy: 0.8045

Epoch 00010: val_loss did not improve from 0.44621
Epoch 11/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4328 - accuracy: 0.8199 - val_loss: 0.4665 - val_accuracy: 0.8027

Epoch 00011: val_loss did not improve from 0.44621
Epoch 12/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4257 - accuracy: 0.8259 - val_loss: 0.4810 - val_accuracy: 0.7994

Epoch 00012: val_loss did not improve from 0.44621
Epoch 13/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4204 - accuracy: 0.8306 - val_loss: 0.4811 - val_accuracy: 0.8015

Epoch 00013: val_loss did not improve from 0.44621
Epoch 14/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4138 - accuracy: 0.8363 - val_loss: 0.4897 - val_accuracy: 0.7999

Epoch 00014: val_loss did not improve from 0.44621
Epoch 15/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4138 - accuracy: 0.8376 - val_loss: 0.5488 - val_accuracy: 0.7628

Epoch 00015: val_loss did not improve from 0.44621
Epoch 16/500
322/322 [==============================] - 22s 68ms/step - loss: 0.4056 - accuracy: 0.8426 - val_loss: 0.5181 - val_accuracy: 0.7851

Epoch 00016: val_loss did not improve from 0.44621
Epoch 17/500
322/322 [==============================] - 22s 67ms/step - loss: 0.3944 - accuracy: 0.8512 - val_loss: 0.5624 - val_accuracy: 0.7673

Epoch 00017: val_loss did not improve from 0.44621
Epoch 18/500
322/322 [==============================] - 22s 69ms/step - loss: 0.3950 - accuracy: 0.8522 - val_loss: 0.6104 - val_accuracy: 0.7415

Epoch 00018: val_loss did not improve from 0.44621
Epoch 19/500
322/322 [==============================] - 22s 67ms/step - loss: 0.3866 - accuracy: 0.8573 - val_loss: 0.5514 - val_accuracy: 0.7568

Epoch 00019: val_loss did not improve from 0.44621
Epoch 20/500
322/322 [==============================] - 22s 68ms/step - loss: 0.3806 - accuracy: 0.8616 - val_loss: 0.5518 - val_accuracy: 0.7823

Epoch 00020: val_loss did not improve from 0.44621
Epoch 21/500
322/322 [==============================] - 22s 68ms/step - loss: 0.3562 - accuracy: 0.8757 - val_loss: 0.6103 - val_accuracy: 0.7572

Epoch 00021: val_loss did not improve from 0.44621
Epoch 22/500
322/322 [==============================] - 22s 68ms/step - loss: 0.3554 - accuracy: 0.8770 - val_loss: 0.5871 - val_accuracy: 0.7796

Epoch 00022: val_loss did not improve from 0.44621
Epoch 23/500
322/322 [==============================] - 51s 160ms/step - loss: 0.3415 - accuracy: 0.8850 - val_loss: 0.6219 - val_accuracy: 0.7754

Epoch 00023: val_loss did not improve from 0.44621
Epoch 00023: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_binary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQBhQJm\nBBkAUwApAk7pAgAAAKkAqQHaAXhyAgAAAHICAAAA+h8vaG9tZS9zYW1odWFuZy9NTC9DTk4vbW9k\nZWxzLnB52gg8bGFtYmRhPjMAAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
51661/51661 [==============================] - 168s 3ms/step - loss: 0.4481 - accuracy: 0.8035
Testing Loss = 0.448067, Testing Accuracy = 0.803508
The data set contains images
[[0.15522247552871704, 0.844777524471283], [0.20152141153812408, 0.7984785437583923], [0.2477262169122696, 0.7522737979888916], [0.5610716938972473, 0.4389283061027527], [0.8452274203300476, 0.15477265417575836], [0.07536698132753372, 0.9246329665184021], [0.3891885280609131, 0.6108115315437317], [0.25056183338165283, 0.7494381666183472], [0.9642308950424194, 0.03576917573809624], [0.3774693012237549, 0.6225307583808899]]
[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]]
2
$W^+$ (auc = 0.88)
$Z$ (auc = 0.88)
