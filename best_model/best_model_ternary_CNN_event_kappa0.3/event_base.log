

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-23 13:46:47.175870
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 9s 70ms/step - loss: 12.4963 - accuracy: 0.2005 - val_loss: 8.7713 - val_accuracy: 0.2088

Epoch 00001: val_loss improved from inf to 8.77129, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 2/100
83/83 [==============================] - 6s 66ms/step - loss: 6.8354 - accuracy: 0.2090 - val_loss: 5.3910 - val_accuracy: 0.2132

Epoch 00002: val_loss improved from 8.77129 to 5.39097, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 3/100
83/83 [==============================] - 6s 66ms/step - loss: 4.6054 - accuracy: 0.2200 - val_loss: 3.9919 - val_accuracy: 0.2220

Epoch 00003: val_loss improved from 5.39097 to 3.99187, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 4/100
83/83 [==============================] - 6s 66ms/step - loss: 3.5005 - accuracy: 0.2787 - val_loss: 3.2201 - val_accuracy: 0.2503

Epoch 00004: val_loss improved from 3.99187 to 3.22012, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 5/100
83/83 [==============================] - 6s 67ms/step - loss: 2.8959 - accuracy: 0.2974 - val_loss: 2.7317 - val_accuracy: 0.2751

Epoch 00005: val_loss improved from 3.22012 to 2.73172, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 6/100
83/83 [==============================] - 6s 67ms/step - loss: 2.5080 - accuracy: 0.3065 - val_loss: 2.3886 - val_accuracy: 0.3073

Epoch 00006: val_loss improved from 2.73172 to 2.38859, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 7/100
83/83 [==============================] - 6s 67ms/step - loss: 2.2402 - accuracy: 0.3151 - val_loss: 2.1494 - val_accuracy: 0.3217

Epoch 00007: val_loss improved from 2.38859 to 2.14938, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 8/100
83/83 [==============================] - 6s 66ms/step - loss: 2.0513 - accuracy: 0.3228 - val_loss: 1.9738 - val_accuracy: 0.3308

Epoch 00008: val_loss improved from 2.14938 to 1.97384, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 9/100
83/83 [==============================] - 6s 67ms/step - loss: 1.9182 - accuracy: 0.3291 - val_loss: 1.8639 - val_accuracy: 0.3334

Epoch 00009: val_loss improved from 1.97384 to 1.86394, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 10/100
83/83 [==============================] - 6s 67ms/step - loss: 1.8232 - accuracy: 0.3334 - val_loss: 1.7769 - val_accuracy: 0.3433

Epoch 00010: val_loss improved from 1.86394 to 1.77694, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 11/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7527 - accuracy: 0.3474 - val_loss: 1.7183 - val_accuracy: 0.3548

Epoch 00011: val_loss improved from 1.77694 to 1.71833, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 12/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7026 - accuracy: 0.3562 - val_loss: 1.6781 - val_accuracy: 0.3626

Epoch 00012: val_loss improved from 1.71833 to 1.67807, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 13/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6634 - accuracy: 0.3618 - val_loss: 1.6504 - val_accuracy: 0.3631

Epoch 00013: val_loss improved from 1.67807 to 1.65036, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 14/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6334 - accuracy: 0.3720 - val_loss: 1.6277 - val_accuracy: 0.3695

Epoch 00014: val_loss improved from 1.65036 to 1.62768, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 15/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6096 - accuracy: 0.3796 - val_loss: 1.6079 - val_accuracy: 0.3798

Epoch 00015: val_loss improved from 1.62768 to 1.60790, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 16/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5940 - accuracy: 0.3855 - val_loss: 1.6075 - val_accuracy: 0.3720

Epoch 00016: val_loss improved from 1.60790 to 1.60751, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 17/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5799 - accuracy: 0.3890 - val_loss: 1.5920 - val_accuracy: 0.3793

Epoch 00017: val_loss improved from 1.60751 to 1.59202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5676 - accuracy: 0.3942 - val_loss: 1.5869 - val_accuracy: 0.3808

Epoch 00018: val_loss improved from 1.59202 to 1.58690, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 19/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5576 - accuracy: 0.3981 - val_loss: 1.5762 - val_accuracy: 0.3861

Epoch 00019: val_loss improved from 1.58690 to 1.57615, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 20/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5515 - accuracy: 0.4000 - val_loss: 1.5792 - val_accuracy: 0.3844

Epoch 00020: val_loss did not improve from 1.57615
Epoch 21/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5457 - accuracy: 0.4045 - val_loss: 1.5735 - val_accuracy: 0.3847

Epoch 00021: val_loss improved from 1.57615 to 1.57348, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 22/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5373 - accuracy: 0.4088 - val_loss: 1.5707 - val_accuracy: 0.3898

Epoch 00022: val_loss improved from 1.57348 to 1.57066, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5315 - accuracy: 0.4127 - val_loss: 1.5711 - val_accuracy: 0.3893

Epoch 00023: val_loss did not improve from 1.57066
Epoch 24/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5233 - accuracy: 0.4191 - val_loss: 1.5751 - val_accuracy: 0.3871

Epoch 00024: val_loss did not improve from 1.57066
Epoch 25/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5189 - accuracy: 0.4185 - val_loss: 1.5693 - val_accuracy: 0.3916

Epoch 00025: val_loss improved from 1.57066 to 1.56925, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/0
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5134 - accuracy: 0.4244 - val_loss: 1.5743 - val_accuracy: 0.3927

Epoch 00026: val_loss did not improve from 1.56925
Epoch 27/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5074 - accuracy: 0.4294 - val_loss: 1.5748 - val_accuracy: 0.3937

Epoch 00027: val_loss did not improve from 1.56925
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5012 - accuracy: 0.4335 - val_loss: 1.5781 - val_accuracy: 0.3893

Epoch 00028: val_loss did not improve from 1.56925
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4960 - accuracy: 0.4393 - val_loss: 1.5801 - val_accuracy: 0.3919

Epoch 00029: val_loss did not improve from 1.56925
Epoch 30/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4940 - accuracy: 0.4407 - val_loss: 1.5766 - val_accuracy: 0.3960

Epoch 00030: val_loss did not improve from 1.56925
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4900 - accuracy: 0.4430 - val_loss: 1.5819 - val_accuracy: 0.3941

Epoch 00031: val_loss did not improve from 1.56925
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4816 - accuracy: 0.4499 - val_loss: 1.5866 - val_accuracy: 0.3938

Epoch 00032: val_loss did not improve from 1.56925
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4708 - accuracy: 0.4545 - val_loss: 1.5889 - val_accuracy: 0.3959

Epoch 00033: val_loss did not improve from 1.56925
Epoch 34/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4663 - accuracy: 0.4600 - val_loss: 1.5919 - val_accuracy: 0.3953

Epoch 00034: val_loss did not improve from 1.56925
Epoch 35/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4580 - accuracy: 0.4649 - val_loss: 1.5970 - val_accuracy: 0.4007

Epoch 00035: val_loss did not improve from 1.56925
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.5734 - accuracy: 0.3888
Testing Loss = 1.573406, Testing Accuracy = 0.388806
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.3144 - accuracy: 0.1959 - val_loss: 8.5591 - val_accuracy: 0.2104

Epoch 00001: val_loss improved from inf to 8.55908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6638 - accuracy: 0.2085 - val_loss: 5.2641 - val_accuracy: 0.2126

Epoch 00002: val_loss improved from 8.55908 to 5.26407, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.5053 - accuracy: 0.2219 - val_loss: 3.9203 - val_accuracy: 0.2285

Epoch 00003: val_loss improved from 5.26407 to 3.92032, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.4441 - accuracy: 0.2852 - val_loss: 3.1792 - val_accuracy: 0.2468

Epoch 00004: val_loss improved from 3.92032 to 3.17919, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 5/100
83/83 [==============================] - 6s 67ms/step - loss: 2.8699 - accuracy: 0.2966 - val_loss: 2.7095 - val_accuracy: 0.2773

Epoch 00005: val_loss improved from 3.17919 to 2.70951, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.4910 - accuracy: 0.3048 - val_loss: 2.3795 - val_accuracy: 0.2948

Epoch 00006: val_loss improved from 2.70951 to 2.37945, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2296 - accuracy: 0.3146 - val_loss: 2.1371 - val_accuracy: 0.3133

Epoch 00007: val_loss improved from 2.37945 to 2.13709, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 8/100
83/83 [==============================] - 6s 67ms/step - loss: 2.0460 - accuracy: 0.3195 - val_loss: 1.9688 - val_accuracy: 0.3315

Epoch 00008: val_loss improved from 2.13709 to 1.96878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9155 - accuracy: 0.3265 - val_loss: 1.8609 - val_accuracy: 0.3326

Epoch 00009: val_loss improved from 1.96878 to 1.86085, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 10/100
83/83 [==============================] - 6s 67ms/step - loss: 1.8223 - accuracy: 0.3315 - val_loss: 1.7791 - val_accuracy: 0.3406

Epoch 00010: val_loss improved from 1.86085 to 1.77913, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7531 - accuracy: 0.3387 - val_loss: 1.7201 - val_accuracy: 0.3494

Epoch 00011: val_loss improved from 1.77913 to 1.72007, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7026 - accuracy: 0.3506 - val_loss: 1.6756 - val_accuracy: 0.3567

Epoch 00012: val_loss improved from 1.72007 to 1.67564, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6658 - accuracy: 0.3577 - val_loss: 1.6446 - val_accuracy: 0.3685

Epoch 00013: val_loss improved from 1.67564 to 1.64461, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 14/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6335 - accuracy: 0.3696 - val_loss: 1.6245 - val_accuracy: 0.3710

Epoch 00014: val_loss improved from 1.64461 to 1.62452, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6126 - accuracy: 0.3745 - val_loss: 1.6163 - val_accuracy: 0.3690

Epoch 00015: val_loss improved from 1.62452 to 1.61627, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5948 - accuracy: 0.3829 - val_loss: 1.6006 - val_accuracy: 0.3744

Epoch 00016: val_loss improved from 1.61627 to 1.60061, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 17/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5806 - accuracy: 0.3875 - val_loss: 1.5951 - val_accuracy: 0.3778

Epoch 00017: val_loss improved from 1.60061 to 1.59505, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 18/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5681 - accuracy: 0.3929 - val_loss: 1.5949 - val_accuracy: 0.3729

Epoch 00018: val_loss improved from 1.59505 to 1.59493, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 19/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5585 - accuracy: 0.3966 - val_loss: 1.5848 - val_accuracy: 0.3791

Epoch 00019: val_loss improved from 1.59493 to 1.58477, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 20/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5514 - accuracy: 0.4004 - val_loss: 1.5788 - val_accuracy: 0.3835

Epoch 00020: val_loss improved from 1.58477 to 1.57877, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 21/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5439 - accuracy: 0.4064 - val_loss: 1.5681 - val_accuracy: 0.3898

Epoch 00021: val_loss improved from 1.57877 to 1.56811, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/1
Epoch 22/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5375 - accuracy: 0.4075 - val_loss: 1.5684 - val_accuracy: 0.3926

Epoch 00022: val_loss did not improve from 1.56811
Epoch 23/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5284 - accuracy: 0.4154 - val_loss: 1.5749 - val_accuracy: 0.3868

Epoch 00023: val_loss did not improve from 1.56811
Epoch 24/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5219 - accuracy: 0.4185 - val_loss: 1.5721 - val_accuracy: 0.3892

Epoch 00024: val_loss did not improve from 1.56811
Epoch 25/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5168 - accuracy: 0.4217 - val_loss: 1.5762 - val_accuracy: 0.3828

Epoch 00025: val_loss did not improve from 1.56811
Epoch 26/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5141 - accuracy: 0.4264 - val_loss: 1.5768 - val_accuracy: 0.3855

Epoch 00026: val_loss did not improve from 1.56811
Epoch 27/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5060 - accuracy: 0.4315 - val_loss: 1.5737 - val_accuracy: 0.3930

Epoch 00027: val_loss did not improve from 1.56811
Epoch 28/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5002 - accuracy: 0.4323 - val_loss: 1.5839 - val_accuracy: 0.3869

Epoch 00028: val_loss did not improve from 1.56811
Epoch 29/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4954 - accuracy: 0.4380 - val_loss: 1.5847 - val_accuracy: 0.3886

Epoch 00029: val_loss did not improve from 1.56811
Epoch 30/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4865 - accuracy: 0.4457 - val_loss: 1.5823 - val_accuracy: 0.3921

Epoch 00030: val_loss did not improve from 1.56811
Epoch 31/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4803 - accuracy: 0.4483 - val_loss: 1.5941 - val_accuracy: 0.3838

Epoch 00031: val_loss did not improve from 1.56811
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5742 - accuracy: 0.3898
Testing Loss = 1.574225, Testing Accuracy = 0.389774
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 68ms/step - loss: 12.4101 - accuracy: 0.1995 - val_loss: 8.6711 - val_accuracy: 0.2097

Epoch 00001: val_loss improved from inf to 8.67113, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 2/100
83/83 [==============================] - 6s 66ms/step - loss: 6.7489 - accuracy: 0.2064 - val_loss: 5.3217 - val_accuracy: 0.2115

Epoch 00002: val_loss improved from 8.67113 to 5.32171, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 3/100
83/83 [==============================] - 6s 66ms/step - loss: 4.5414 - accuracy: 0.2230 - val_loss: 3.9372 - val_accuracy: 0.2327

Epoch 00003: val_loss improved from 5.32171 to 3.93724, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 4/100
83/83 [==============================] - 6s 66ms/step - loss: 3.4601 - accuracy: 0.2798 - val_loss: 3.1936 - val_accuracy: 0.2518

Epoch 00004: val_loss improved from 3.93724 to 3.19356, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 5/100
83/83 [==============================] - 6s 66ms/step - loss: 2.8784 - accuracy: 0.2982 - val_loss: 2.7167 - val_accuracy: 0.2731

Epoch 00005: val_loss improved from 3.19356 to 2.71672, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 6/100
83/83 [==============================] - 6s 66ms/step - loss: 2.4991 - accuracy: 0.3063 - val_loss: 2.3828 - val_accuracy: 0.3018

Epoch 00006: val_loss improved from 2.71672 to 2.38275, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 7/100
83/83 [==============================] - 6s 66ms/step - loss: 2.2335 - accuracy: 0.3152 - val_loss: 2.1395 - val_accuracy: 0.3222

Epoch 00007: val_loss improved from 2.38275 to 2.13950, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 8/100
83/83 [==============================] - 6s 66ms/step - loss: 2.0490 - accuracy: 0.3242 - val_loss: 1.9753 - val_accuracy: 0.3286

Epoch 00008: val_loss improved from 2.13950 to 1.97529, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 9/100
83/83 [==============================] - 6s 66ms/step - loss: 1.9160 - accuracy: 0.3304 - val_loss: 1.8511 - val_accuracy: 0.3413

Epoch 00009: val_loss improved from 1.97529 to 1.85114, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 10/100
83/83 [==============================] - 6s 66ms/step - loss: 1.8194 - accuracy: 0.3397 - val_loss: 1.7706 - val_accuracy: 0.3488

Epoch 00010: val_loss improved from 1.85114 to 1.77063, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 11/100
83/83 [==============================] - 6s 66ms/step - loss: 1.7489 - accuracy: 0.3512 - val_loss: 1.7134 - val_accuracy: 0.3578

Epoch 00011: val_loss improved from 1.77063 to 1.71338, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 12/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6971 - accuracy: 0.3606 - val_loss: 1.6706 - val_accuracy: 0.3645

Epoch 00012: val_loss improved from 1.71338 to 1.67060, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 13/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6577 - accuracy: 0.3700 - val_loss: 1.6441 - val_accuracy: 0.3702

Epoch 00013: val_loss improved from 1.67060 to 1.64412, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 14/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6274 - accuracy: 0.3765 - val_loss: 1.6150 - val_accuracy: 0.3838

Epoch 00014: val_loss improved from 1.64412 to 1.61504, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 15/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6025 - accuracy: 0.3839 - val_loss: 1.6005 - val_accuracy: 0.3828

Epoch 00015: val_loss improved from 1.61504 to 1.60047, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 16/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5889 - accuracy: 0.3877 - val_loss: 1.6004 - val_accuracy: 0.3794

Epoch 00016: val_loss improved from 1.60047 to 1.60038, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 17/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5749 - accuracy: 0.3934 - val_loss: 1.5886 - val_accuracy: 0.3834

Epoch 00017: val_loss improved from 1.60038 to 1.58857, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 18/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5640 - accuracy: 0.3965 - val_loss: 1.5794 - val_accuracy: 0.3866

Epoch 00018: val_loss improved from 1.58857 to 1.57940, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 19/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5562 - accuracy: 0.3979 - val_loss: 1.5703 - val_accuracy: 0.3898

Epoch 00019: val_loss improved from 1.57940 to 1.57030, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 20/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5445 - accuracy: 0.4073 - val_loss: 1.5720 - val_accuracy: 0.3879

Epoch 00020: val_loss did not improve from 1.57030
Epoch 21/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5365 - accuracy: 0.4106 - val_loss: 1.5741 - val_accuracy: 0.3871

Epoch 00021: val_loss did not improve from 1.57030
Epoch 22/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5340 - accuracy: 0.4118 - val_loss: 1.5639 - val_accuracy: 0.3964

Epoch 00022: val_loss improved from 1.57030 to 1.56387, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/2
Epoch 23/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5268 - accuracy: 0.4144 - val_loss: 1.5726 - val_accuracy: 0.3890

Epoch 00023: val_loss did not improve from 1.56387
Epoch 24/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5205 - accuracy: 0.4204 - val_loss: 1.5686 - val_accuracy: 0.3914

Epoch 00024: val_loss did not improve from 1.56387
Epoch 25/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5137 - accuracy: 0.4231 - val_loss: 1.5669 - val_accuracy: 0.3919

Epoch 00025: val_loss did not improve from 1.56387
Epoch 26/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5080 - accuracy: 0.4270 - val_loss: 1.5764 - val_accuracy: 0.3900

Epoch 00026: val_loss did not improve from 1.56387
Epoch 27/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4970 - accuracy: 0.4370 - val_loss: 1.5680 - val_accuracy: 0.3944

Epoch 00027: val_loss did not improve from 1.56387
Epoch 28/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4944 - accuracy: 0.4389 - val_loss: 1.5665 - val_accuracy: 0.3984

Epoch 00028: val_loss did not improve from 1.56387
Epoch 29/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4885 - accuracy: 0.4400 - val_loss: 1.5709 - val_accuracy: 0.3962

Epoch 00029: val_loss did not improve from 1.56387
Epoch 30/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4814 - accuracy: 0.4471 - val_loss: 1.5749 - val_accuracy: 0.3982

Epoch 00030: val_loss did not improve from 1.56387
Epoch 31/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4769 - accuracy: 0.4495 - val_loss: 1.5759 - val_accuracy: 0.4005

Epoch 00031: val_loss did not improve from 1.56387
Epoch 32/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4675 - accuracy: 0.4563 - val_loss: 1.5796 - val_accuracy: 0.3994

Epoch 00032: val_loss did not improve from 1.56387
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5702 - accuracy: 0.3954
Testing Loss = 1.570233, Testing Accuracy = 0.395356
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 66ms/step - loss: 12.3731 - accuracy: 0.1983 - val_loss: 8.6290 - val_accuracy: 0.2108

Epoch 00001: val_loss improved from inf to 8.62897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 2/100
83/83 [==============================] - 5s 65ms/step - loss: 6.7208 - accuracy: 0.2072 - val_loss: 5.3054 - val_accuracy: 0.2119

Epoch 00002: val_loss improved from 8.62897 to 5.30544, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 3/100
83/83 [==============================] - 5s 65ms/step - loss: 4.5296 - accuracy: 0.2262 - val_loss: 3.9355 - val_accuracy: 0.2297

Epoch 00003: val_loss improved from 5.30544 to 3.93546, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 4/100
83/83 [==============================] - 5s 65ms/step - loss: 3.4589 - accuracy: 0.2826 - val_loss: 3.1931 - val_accuracy: 0.2582

Epoch 00004: val_loss improved from 3.93546 to 3.19307, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 5/100
83/83 [==============================] - 5s 65ms/step - loss: 2.8786 - accuracy: 0.2947 - val_loss: 2.7165 - val_accuracy: 0.2837

Epoch 00005: val_loss improved from 3.19307 to 2.71650, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 6/100
83/83 [==============================] - 5s 65ms/step - loss: 2.4988 - accuracy: 0.3086 - val_loss: 2.3839 - val_accuracy: 0.3095

Epoch 00006: val_loss improved from 2.71650 to 2.38393, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 7/100
83/83 [==============================] - 6s 66ms/step - loss: 2.2367 - accuracy: 0.3146 - val_loss: 2.1442 - val_accuracy: 0.3200

Epoch 00007: val_loss improved from 2.38393 to 2.14415, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 8/100
83/83 [==============================] - 5s 65ms/step - loss: 2.0513 - accuracy: 0.3209 - val_loss: 1.9726 - val_accuracy: 0.3351

Epoch 00008: val_loss improved from 2.14415 to 1.97262, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 9/100
83/83 [==============================] - 5s 65ms/step - loss: 1.9210 - accuracy: 0.3269 - val_loss: 1.8633 - val_accuracy: 0.3336

Epoch 00009: val_loss improved from 1.97262 to 1.86330, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 10/100
83/83 [==============================] - 5s 65ms/step - loss: 1.8240 - accuracy: 0.3353 - val_loss: 1.7761 - val_accuracy: 0.3453

Epoch 00010: val_loss improved from 1.86330 to 1.77611, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 11/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7561 - accuracy: 0.3458 - val_loss: 1.7188 - val_accuracy: 0.3555

Epoch 00011: val_loss improved from 1.77611 to 1.71883, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 12/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7025 - accuracy: 0.3571 - val_loss: 1.6743 - val_accuracy: 0.3679

Epoch 00012: val_loss improved from 1.71883 to 1.67425, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 13/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6656 - accuracy: 0.3638 - val_loss: 1.6495 - val_accuracy: 0.3644

Epoch 00013: val_loss improved from 1.67425 to 1.64952, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 14/100
83/83 [==============================] - 5s 66ms/step - loss: 1.6351 - accuracy: 0.3738 - val_loss: 1.6281 - val_accuracy: 0.3715

Epoch 00014: val_loss improved from 1.64952 to 1.62808, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 15/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6146 - accuracy: 0.3767 - val_loss: 1.6049 - val_accuracy: 0.3835

Epoch 00015: val_loss improved from 1.62808 to 1.60489, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 16/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5937 - accuracy: 0.3838 - val_loss: 1.6004 - val_accuracy: 0.3786

Epoch 00016: val_loss improved from 1.60489 to 1.60037, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 17/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5811 - accuracy: 0.3894 - val_loss: 1.5936 - val_accuracy: 0.3798

Epoch 00017: val_loss improved from 1.60037 to 1.59364, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 18/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5714 - accuracy: 0.3930 - val_loss: 1.5909 - val_accuracy: 0.3798

Epoch 00018: val_loss improved from 1.59364 to 1.59089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 19/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5594 - accuracy: 0.3994 - val_loss: 1.5775 - val_accuracy: 0.3882

Epoch 00019: val_loss improved from 1.59089 to 1.57752, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 20/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5484 - accuracy: 0.4048 - val_loss: 1.5667 - val_accuracy: 0.3934

Epoch 00020: val_loss improved from 1.57752 to 1.56671, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 21/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5392 - accuracy: 0.4076 - val_loss: 1.5677 - val_accuracy: 0.3946

Epoch 00021: val_loss did not improve from 1.56671
Epoch 22/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5387 - accuracy: 0.4076 - val_loss: 1.5678 - val_accuracy: 0.3955

Epoch 00022: val_loss did not improve from 1.56671
Epoch 23/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5336 - accuracy: 0.4114 - val_loss: 1.5641 - val_accuracy: 0.3972

Epoch 00023: val_loss improved from 1.56671 to 1.56413, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 24/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5224 - accuracy: 0.4212 - val_loss: 1.5700 - val_accuracy: 0.3935

Epoch 00024: val_loss did not improve from 1.56413
Epoch 25/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5151 - accuracy: 0.4234 - val_loss: 1.5728 - val_accuracy: 0.3946

Epoch 00025: val_loss did not improve from 1.56413
Epoch 26/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5142 - accuracy: 0.4245 - val_loss: 1.5643 - val_accuracy: 0.3964

Epoch 00026: val_loss did not improve from 1.56413
Epoch 27/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5063 - accuracy: 0.4309 - val_loss: 1.5629 - val_accuracy: 0.3974

Epoch 00027: val_loss improved from 1.56413 to 1.56287, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/3
Epoch 28/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4979 - accuracy: 0.4349 - val_loss: 1.5764 - val_accuracy: 0.3950

Epoch 00028: val_loss did not improve from 1.56287
Epoch 29/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4889 - accuracy: 0.4408 - val_loss: 1.5687 - val_accuracy: 0.3985

Epoch 00029: val_loss did not improve from 1.56287
Epoch 30/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4840 - accuracy: 0.4468 - val_loss: 1.5708 - val_accuracy: 0.4031

Epoch 00030: val_loss did not improve from 1.56287
Epoch 31/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4771 - accuracy: 0.4496 - val_loss: 1.5761 - val_accuracy: 0.4010

Epoch 00031: val_loss did not improve from 1.56287
Epoch 32/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4735 - accuracy: 0.4556 - val_loss: 1.5814 - val_accuracy: 0.4004

Epoch 00032: val_loss did not improve from 1.56287
Epoch 33/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4638 - accuracy: 0.4613 - val_loss: 1.5827 - val_accuracy: 0.4038

Epoch 00033: val_loss did not improve from 1.56287
Epoch 34/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4585 - accuracy: 0.4661 - val_loss: 1.5979 - val_accuracy: 0.3959

Epoch 00034: val_loss did not improve from 1.56287
Epoch 35/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4489 - accuracy: 0.4725 - val_loss: 1.6028 - val_accuracy: 0.3979

Epoch 00035: val_loss did not improve from 1.56287
Epoch 36/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4411 - accuracy: 0.4780 - val_loss: 1.6060 - val_accuracy: 0.3993

Epoch 00036: val_loss did not improve from 1.56287
Epoch 37/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4343 - accuracy: 0.4822 - val_loss: 1.6178 - val_accuracy: 0.3993

Epoch 00037: val_loss did not improve from 1.56287
Epoch 00037: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5735 - accuracy: 0.3965
Testing Loss = 1.573525, Testing Accuracy = 0.396472
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 66ms/step - loss: 12.4267 - accuracy: 0.1983 - val_loss: 8.6915 - val_accuracy: 0.2128

Epoch 00001: val_loss improved from inf to 8.69145, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 2/100
83/83 [==============================] - 5s 65ms/step - loss: 6.7738 - accuracy: 0.2095 - val_loss: 5.3491 - val_accuracy: 0.2112

Epoch 00002: val_loss improved from 8.69145 to 5.34908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 3/100
83/83 [==============================] - 5s 65ms/step - loss: 4.5586 - accuracy: 0.2297 - val_loss: 3.9637 - val_accuracy: 0.2295

Epoch 00003: val_loss improved from 5.34908 to 3.96369, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 4/100
83/83 [==============================] - 5s 65ms/step - loss: 3.4801 - accuracy: 0.2816 - val_loss: 3.2103 - val_accuracy: 0.2516

Epoch 00004: val_loss improved from 3.96369 to 3.21030, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 5/100
83/83 [==============================] - 5s 65ms/step - loss: 2.8909 - accuracy: 0.2963 - val_loss: 2.7275 - val_accuracy: 0.2817

Epoch 00005: val_loss improved from 3.21030 to 2.72748, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 6/100
83/83 [==============================] - 5s 65ms/step - loss: 2.5075 - accuracy: 0.3018 - val_loss: 2.3874 - val_accuracy: 0.3096

Epoch 00006: val_loss improved from 2.72748 to 2.38739, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 7/100
83/83 [==============================] - 5s 65ms/step - loss: 2.2413 - accuracy: 0.3123 - val_loss: 2.1473 - val_accuracy: 0.3197

Epoch 00007: val_loss improved from 2.38739 to 2.14728, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 8/100
83/83 [==============================] - 6s 66ms/step - loss: 2.0535 - accuracy: 0.3199 - val_loss: 1.9768 - val_accuracy: 0.3302

Epoch 00008: val_loss improved from 2.14728 to 1.97683, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 9/100
83/83 [==============================] - 5s 65ms/step - loss: 1.9200 - accuracy: 0.3303 - val_loss: 1.8595 - val_accuracy: 0.3362

Epoch 00009: val_loss improved from 1.97683 to 1.85952, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 10/100
83/83 [==============================] - 5s 65ms/step - loss: 1.8249 - accuracy: 0.3359 - val_loss: 1.7830 - val_accuracy: 0.3383

Epoch 00010: val_loss improved from 1.85952 to 1.78303, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 11/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7546 - accuracy: 0.3465 - val_loss: 1.7240 - val_accuracy: 0.3487

Epoch 00011: val_loss improved from 1.78303 to 1.72402, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 12/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7040 - accuracy: 0.3518 - val_loss: 1.6798 - val_accuracy: 0.3583

Epoch 00012: val_loss improved from 1.72402 to 1.67979, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 13/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6646 - accuracy: 0.3622 - val_loss: 1.6485 - val_accuracy: 0.3652

Epoch 00013: val_loss improved from 1.67979 to 1.64845, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 14/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6348 - accuracy: 0.3718 - val_loss: 1.6271 - val_accuracy: 0.3704

Epoch 00014: val_loss improved from 1.64845 to 1.62715, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 15/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6127 - accuracy: 0.3777 - val_loss: 1.6152 - val_accuracy: 0.3699

Epoch 00015: val_loss improved from 1.62715 to 1.61525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 16/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5940 - accuracy: 0.3844 - val_loss: 1.6080 - val_accuracy: 0.3707

Epoch 00016: val_loss improved from 1.61525 to 1.60803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 17/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5806 - accuracy: 0.3874 - val_loss: 1.5952 - val_accuracy: 0.3751

Epoch 00017: val_loss improved from 1.60803 to 1.59517, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 18/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5675 - accuracy: 0.3949 - val_loss: 1.5950 - val_accuracy: 0.3763

Epoch 00018: val_loss improved from 1.59517 to 1.59501, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 19/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5612 - accuracy: 0.3946 - val_loss: 1.5865 - val_accuracy: 0.3828

Epoch 00019: val_loss improved from 1.59501 to 1.58649, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 20/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5507 - accuracy: 0.4023 - val_loss: 1.5824 - val_accuracy: 0.3856

Epoch 00020: val_loss improved from 1.58649 to 1.58243, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 21/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5421 - accuracy: 0.4086 - val_loss: 1.5827 - val_accuracy: 0.3828

Epoch 00021: val_loss did not improve from 1.58243
Epoch 22/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5362 - accuracy: 0.4104 - val_loss: 1.5749 - val_accuracy: 0.3867

Epoch 00022: val_loss improved from 1.58243 to 1.57490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 23/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5290 - accuracy: 0.4134 - val_loss: 1.5802 - val_accuracy: 0.3862

Epoch 00023: val_loss did not improve from 1.57490
Epoch 24/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5191 - accuracy: 0.4218 - val_loss: 1.5720 - val_accuracy: 0.3922

Epoch 00024: val_loss improved from 1.57490 to 1.57201, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/4
Epoch 25/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5135 - accuracy: 0.4231 - val_loss: 1.5728 - val_accuracy: 0.3931

Epoch 00025: val_loss did not improve from 1.57201
Epoch 26/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5094 - accuracy: 0.4275 - val_loss: 1.5766 - val_accuracy: 0.3907

Epoch 00026: val_loss did not improve from 1.57201
Epoch 27/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5039 - accuracy: 0.4305 - val_loss: 1.5761 - val_accuracy: 0.3916

Epoch 00027: val_loss did not improve from 1.57201
Epoch 28/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4962 - accuracy: 0.4351 - val_loss: 1.5786 - val_accuracy: 0.3923

Epoch 00028: val_loss did not improve from 1.57201
Epoch 29/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4888 - accuracy: 0.4423 - val_loss: 1.5804 - val_accuracy: 0.3924

Epoch 00029: val_loss did not improve from 1.57201
Epoch 30/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4840 - accuracy: 0.4447 - val_loss: 1.5840 - val_accuracy: 0.3893

Epoch 00030: val_loss did not improve from 1.57201
Epoch 31/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4759 - accuracy: 0.4512 - val_loss: 1.5892 - val_accuracy: 0.3909

Epoch 00031: val_loss did not improve from 1.57201
Epoch 32/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4679 - accuracy: 0.4568 - val_loss: 1.5995 - val_accuracy: 0.3874

Epoch 00032: val_loss did not improve from 1.57201
Epoch 33/100
83/83 [==============================] - 5s 65ms/step - loss: 1.4617 - accuracy: 0.4643 - val_loss: 1.5998 - val_accuracy: 0.3911

Epoch 00033: val_loss did not improve from 1.57201
Epoch 34/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4529 - accuracy: 0.4668 - val_loss: 1.6093 - val_accuracy: 0.3900

Epoch 00034: val_loss did not improve from 1.57201
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5780 - accuracy: 0.3886
Testing Loss = 1.578043, Testing Accuracy = 0.388583
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 66ms/step - loss: 12.5134 - accuracy: 0.1980 - val_loss: 8.8104 - val_accuracy: 0.2089

Epoch 00001: val_loss improved from inf to 8.81039, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 2/100
83/83 [==============================] - 5s 65ms/step - loss: 6.8689 - accuracy: 0.2078 - val_loss: 5.4173 - val_accuracy: 0.2130

Epoch 00002: val_loss improved from 8.81039 to 5.41729, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 3/100
83/83 [==============================] - 5s 65ms/step - loss: 4.5988 - accuracy: 0.2371 - val_loss: 3.9930 - val_accuracy: 0.2313

Epoch 00003: val_loss improved from 5.41729 to 3.99301, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 4/100
83/83 [==============================] - 5s 65ms/step - loss: 3.5037 - accuracy: 0.2855 - val_loss: 3.2335 - val_accuracy: 0.2538

Epoch 00004: val_loss improved from 3.99301 to 3.23346, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 5/100
83/83 [==============================] - 5s 65ms/step - loss: 2.9118 - accuracy: 0.2975 - val_loss: 2.7488 - val_accuracy: 0.2779

Epoch 00005: val_loss improved from 3.23346 to 2.74880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 6/100
83/83 [==============================] - 5s 65ms/step - loss: 2.5218 - accuracy: 0.3093 - val_loss: 2.4016 - val_accuracy: 0.3028

Epoch 00006: val_loss improved from 2.74880 to 2.40157, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 7/100
83/83 [==============================] - 6s 66ms/step - loss: 2.2537 - accuracy: 0.3148 - val_loss: 2.1588 - val_accuracy: 0.3175

Epoch 00007: val_loss improved from 2.40157 to 2.15877, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 8/100
83/83 [==============================] - 5s 66ms/step - loss: 2.0641 - accuracy: 0.3194 - val_loss: 1.9860 - val_accuracy: 0.3289

Epoch 00008: val_loss improved from 2.15877 to 1.98597, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 9/100
83/83 [==============================] - 5s 65ms/step - loss: 1.9294 - accuracy: 0.3255 - val_loss: 1.8644 - val_accuracy: 0.3373

Epoch 00009: val_loss improved from 1.98597 to 1.86436, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 10/100
83/83 [==============================] - 5s 66ms/step - loss: 1.8314 - accuracy: 0.3359 - val_loss: 1.7872 - val_accuracy: 0.3398

Epoch 00010: val_loss improved from 1.86436 to 1.78720, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 11/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7623 - accuracy: 0.3426 - val_loss: 1.7280 - val_accuracy: 0.3462

Epoch 00011: val_loss improved from 1.78720 to 1.72803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 12/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7113 - accuracy: 0.3516 - val_loss: 1.6849 - val_accuracy: 0.3587

Epoch 00012: val_loss improved from 1.72803 to 1.68494, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 13/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6720 - accuracy: 0.3593 - val_loss: 1.6582 - val_accuracy: 0.3652

Epoch 00013: val_loss improved from 1.68494 to 1.65823, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 14/100
83/83 [==============================] - 5s 66ms/step - loss: 1.6395 - accuracy: 0.3694 - val_loss: 1.6281 - val_accuracy: 0.3693

Epoch 00014: val_loss improved from 1.65823 to 1.62808, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 15/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6189 - accuracy: 0.3735 - val_loss: 1.6144 - val_accuracy: 0.3728

Epoch 00015: val_loss improved from 1.62808 to 1.61437, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 16/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5993 - accuracy: 0.3812 - val_loss: 1.6002 - val_accuracy: 0.3779

Epoch 00016: val_loss improved from 1.61437 to 1.60017, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 17/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5850 - accuracy: 0.3860 - val_loss: 1.5934 - val_accuracy: 0.3783

Epoch 00017: val_loss improved from 1.60017 to 1.59340, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 18/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5735 - accuracy: 0.3900 - val_loss: 1.5852 - val_accuracy: 0.3841

Epoch 00018: val_loss improved from 1.59340 to 1.58523, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 19/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5627 - accuracy: 0.3972 - val_loss: 1.5791 - val_accuracy: 0.3848

Epoch 00019: val_loss improved from 1.58523 to 1.57910, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 20/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5506 - accuracy: 0.4032 - val_loss: 1.5783 - val_accuracy: 0.3841

Epoch 00020: val_loss improved from 1.57910 to 1.57827, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 21/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5460 - accuracy: 0.4040 - val_loss: 1.5759 - val_accuracy: 0.3825

Epoch 00021: val_loss improved from 1.57827 to 1.57595, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 22/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5415 - accuracy: 0.4072 - val_loss: 1.5723 - val_accuracy: 0.3891

Epoch 00022: val_loss improved from 1.57595 to 1.57231, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 23/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5303 - accuracy: 0.4146 - val_loss: 1.5696 - val_accuracy: 0.3895

Epoch 00023: val_loss improved from 1.57231 to 1.56957, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/5
Epoch 24/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5254 - accuracy: 0.4152 - val_loss: 1.5791 - val_accuracy: 0.3849

Epoch 00024: val_loss did not improve from 1.56957
Epoch 25/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5229 - accuracy: 0.4189 - val_loss: 1.5708 - val_accuracy: 0.3905

Epoch 00025: val_loss did not improve from 1.56957
Epoch 26/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5170 - accuracy: 0.4235 - val_loss: 1.5733 - val_accuracy: 0.3868

Epoch 00026: val_loss did not improve from 1.56957
Epoch 27/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5102 - accuracy: 0.4275 - val_loss: 1.5743 - val_accuracy: 0.3916

Epoch 00027: val_loss did not improve from 1.56957
Epoch 28/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5008 - accuracy: 0.4321 - val_loss: 1.5750 - val_accuracy: 0.3911

Epoch 00028: val_loss did not improve from 1.56957
Epoch 29/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4946 - accuracy: 0.4377 - val_loss: 1.5732 - val_accuracy: 0.3969

Epoch 00029: val_loss did not improve from 1.56957
Epoch 30/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4881 - accuracy: 0.4430 - val_loss: 1.5705 - val_accuracy: 0.4025

Epoch 00030: val_loss did not improve from 1.56957
Epoch 31/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4811 - accuracy: 0.4481 - val_loss: 1.5742 - val_accuracy: 0.4065

Epoch 00031: val_loss did not improve from 1.56957
Epoch 32/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4735 - accuracy: 0.4513 - val_loss: 1.5806 - val_accuracy: 0.4025

Epoch 00032: val_loss did not improve from 1.56957
Epoch 33/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4693 - accuracy: 0.4597 - val_loss: 1.5854 - val_accuracy: 0.3995

Epoch 00033: val_loss did not improve from 1.56957
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 4ms/step - loss: 1.5753 - accuracy: 0.3917
Testing Loss = 1.575258, Testing Accuracy = 0.391709
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 66ms/step - loss: 12.4372 - accuracy: 0.2001 - val_loss: 8.6962 - val_accuracy: 0.2118

Epoch 00001: val_loss improved from inf to 8.69622, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 2/100
83/83 [==============================] - 5s 65ms/step - loss: 6.7661 - accuracy: 0.2116 - val_loss: 5.3337 - val_accuracy: 0.2108

Epoch 00002: val_loss improved from 8.69622 to 5.33373, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 3/100
83/83 [==============================] - 5s 65ms/step - loss: 4.5561 - accuracy: 0.2217 - val_loss: 3.9439 - val_accuracy: 0.2260

Epoch 00003: val_loss improved from 5.33373 to 3.94387, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 4/100
83/83 [==============================] - 5s 65ms/step - loss: 3.4738 - accuracy: 0.2757 - val_loss: 3.2013 - val_accuracy: 0.2558

Epoch 00004: val_loss improved from 3.94387 to 3.20129, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 5/100
83/83 [==============================] - 5s 65ms/step - loss: 2.8809 - accuracy: 0.2946 - val_loss: 2.7185 - val_accuracy: 0.2807

Epoch 00005: val_loss improved from 3.20129 to 2.71852, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 6/100
83/83 [==============================] - 5s 65ms/step - loss: 2.5006 - accuracy: 0.3027 - val_loss: 2.3806 - val_accuracy: 0.3088

Epoch 00006: val_loss improved from 2.71852 to 2.38058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 7/100
83/83 [==============================] - 5s 65ms/step - loss: 2.2357 - accuracy: 0.3122 - val_loss: 2.1425 - val_accuracy: 0.3165

Epoch 00007: val_loss improved from 2.38058 to 2.14252, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 8/100
83/83 [==============================] - 5s 65ms/step - loss: 2.0499 - accuracy: 0.3193 - val_loss: 1.9720 - val_accuracy: 0.3350

Epoch 00008: val_loss improved from 2.14252 to 1.97195, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 9/100
83/83 [==============================] - 5s 65ms/step - loss: 1.9169 - accuracy: 0.3266 - val_loss: 1.8627 - val_accuracy: 0.3335

Epoch 00009: val_loss improved from 1.97195 to 1.86267, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 10/100
83/83 [==============================] - 5s 65ms/step - loss: 1.8233 - accuracy: 0.3318 - val_loss: 1.7768 - val_accuracy: 0.3434

Epoch 00010: val_loss improved from 1.86267 to 1.77682, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 11/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7536 - accuracy: 0.3416 - val_loss: 1.7188 - val_accuracy: 0.3522

Epoch 00011: val_loss improved from 1.77682 to 1.71876, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 12/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7025 - accuracy: 0.3518 - val_loss: 1.6774 - val_accuracy: 0.3608

Epoch 00012: val_loss improved from 1.71876 to 1.67735, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 13/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6652 - accuracy: 0.3611 - val_loss: 1.6519 - val_accuracy: 0.3667

Epoch 00013: val_loss improved from 1.67735 to 1.65185, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 14/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6347 - accuracy: 0.3691 - val_loss: 1.6280 - val_accuracy: 0.3688

Epoch 00014: val_loss improved from 1.65185 to 1.62801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 15/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6117 - accuracy: 0.3789 - val_loss: 1.6077 - val_accuracy: 0.3784

Epoch 00015: val_loss improved from 1.62801 to 1.60774, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 16/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5968 - accuracy: 0.3826 - val_loss: 1.6098 - val_accuracy: 0.3687

Epoch 00016: val_loss did not improve from 1.60774
Epoch 17/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5808 - accuracy: 0.3887 - val_loss: 1.5883 - val_accuracy: 0.3812

Epoch 00017: val_loss improved from 1.60774 to 1.58825, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 18/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5682 - accuracy: 0.3958 - val_loss: 1.5799 - val_accuracy: 0.3853

Epoch 00018: val_loss improved from 1.58825 to 1.57986, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 19/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5592 - accuracy: 0.3970 - val_loss: 1.5896 - val_accuracy: 0.3775

Epoch 00019: val_loss did not improve from 1.57986
Epoch 20/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5520 - accuracy: 0.4047 - val_loss: 1.5725 - val_accuracy: 0.3878

Epoch 00020: val_loss improved from 1.57986 to 1.57253, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/6
Epoch 21/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5427 - accuracy: 0.4079 - val_loss: 1.5820 - val_accuracy: 0.3815

Epoch 00021: val_loss did not improve from 1.57253
Epoch 22/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5358 - accuracy: 0.4095 - val_loss: 1.5827 - val_accuracy: 0.3825

Epoch 00022: val_loss did not improve from 1.57253
Epoch 23/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5290 - accuracy: 0.4138 - val_loss: 1.5746 - val_accuracy: 0.3884

Epoch 00023: val_loss did not improve from 1.57253
Epoch 24/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5205 - accuracy: 0.4182 - val_loss: 1.5766 - val_accuracy: 0.3860

Epoch 00024: val_loss did not improve from 1.57253
Epoch 25/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5155 - accuracy: 0.4246 - val_loss: 1.5782 - val_accuracy: 0.3889

Epoch 00025: val_loss did not improve from 1.57253
Epoch 26/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5081 - accuracy: 0.4300 - val_loss: 1.5776 - val_accuracy: 0.3891

Epoch 00026: val_loss did not improve from 1.57253
Epoch 27/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5030 - accuracy: 0.4323 - val_loss: 1.5743 - val_accuracy: 0.3914

Epoch 00027: val_loss did not improve from 1.57253
Epoch 28/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4961 - accuracy: 0.4367 - val_loss: 1.5791 - val_accuracy: 0.3900

Epoch 00028: val_loss did not improve from 1.57253
Epoch 29/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4892 - accuracy: 0.4415 - val_loss: 1.5780 - val_accuracy: 0.3938

Epoch 00029: val_loss did not improve from 1.57253
Epoch 30/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4828 - accuracy: 0.4488 - val_loss: 1.5805 - val_accuracy: 0.3977

Epoch 00030: val_loss did not improve from 1.57253
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5788 - accuracy: 0.3915
Testing Loss = 1.578817, Testing Accuracy = 0.391486
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 66ms/step - loss: 12.3385 - accuracy: 0.1983 - val_loss: 8.5924 - val_accuracy: 0.2111

Epoch 00001: val_loss improved from inf to 8.59243, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 2/100
83/83 [==============================] - 5s 65ms/step - loss: 6.6870 - accuracy: 0.2072 - val_loss: 5.2794 - val_accuracy: 0.2139

Epoch 00002: val_loss improved from 8.59243 to 5.27937, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 3/100
83/83 [==============================] - 5s 65ms/step - loss: 4.4732 - accuracy: 0.2496 - val_loss: 3.9226 - val_accuracy: 0.2340

Epoch 00003: val_loss improved from 5.27937 to 3.92261, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 4/100
83/83 [==============================] - 5s 65ms/step - loss: 3.4484 - accuracy: 0.2915 - val_loss: 3.1985 - val_accuracy: 0.2562

Epoch 00004: val_loss improved from 3.92261 to 3.19851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 5/100
83/83 [==============================] - 5s 66ms/step - loss: 2.8821 - accuracy: 0.2993 - val_loss: 2.7255 - val_accuracy: 0.2829

Epoch 00005: val_loss improved from 3.19851 to 2.72550, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 6/100
83/83 [==============================] - 5s 65ms/step - loss: 2.5064 - accuracy: 0.3059 - val_loss: 2.3889 - val_accuracy: 0.3016

Epoch 00006: val_loss improved from 2.72550 to 2.38886, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 7/100
83/83 [==============================] - 5s 66ms/step - loss: 2.2422 - accuracy: 0.3161 - val_loss: 2.1478 - val_accuracy: 0.3213

Epoch 00007: val_loss improved from 2.38886 to 2.14776, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 8/100
83/83 [==============================] - 5s 65ms/step - loss: 2.0567 - accuracy: 0.3236 - val_loss: 1.9786 - val_accuracy: 0.3302

Epoch 00008: val_loss improved from 2.14776 to 1.97863, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 9/100
83/83 [==============================] - 5s 65ms/step - loss: 1.9247 - accuracy: 0.3280 - val_loss: 1.8624 - val_accuracy: 0.3336

Epoch 00009: val_loss improved from 1.97863 to 1.86240, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 10/100
83/83 [==============================] - 5s 65ms/step - loss: 1.8275 - accuracy: 0.3339 - val_loss: 1.7823 - val_accuracy: 0.3393

Epoch 00010: val_loss improved from 1.86240 to 1.78235, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 11/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7605 - accuracy: 0.3445 - val_loss: 1.7289 - val_accuracy: 0.3475

Epoch 00011: val_loss improved from 1.78235 to 1.72886, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 12/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7083 - accuracy: 0.3512 - val_loss: 1.6863 - val_accuracy: 0.3543

Epoch 00012: val_loss improved from 1.72886 to 1.68631, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 13/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6705 - accuracy: 0.3559 - val_loss: 1.6595 - val_accuracy: 0.3581

Epoch 00013: val_loss improved from 1.68631 to 1.65952, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 14/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6405 - accuracy: 0.3674 - val_loss: 1.6302 - val_accuracy: 0.3687

Epoch 00014: val_loss improved from 1.65952 to 1.63016, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 15/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6186 - accuracy: 0.3711 - val_loss: 1.6146 - val_accuracy: 0.3742

Epoch 00015: val_loss improved from 1.63016 to 1.61455, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 16/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5979 - accuracy: 0.3785 - val_loss: 1.6026 - val_accuracy: 0.3728

Epoch 00016: val_loss improved from 1.61455 to 1.60263, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 17/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5847 - accuracy: 0.3888 - val_loss: 1.5959 - val_accuracy: 0.3775

Epoch 00017: val_loss improved from 1.60263 to 1.59589, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 18/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5721 - accuracy: 0.3915 - val_loss: 1.5882 - val_accuracy: 0.3789

Epoch 00018: val_loss improved from 1.59589 to 1.58818, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 19/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5625 - accuracy: 0.3951 - val_loss: 1.5887 - val_accuracy: 0.3786

Epoch 00019: val_loss did not improve from 1.58818
Epoch 20/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5584 - accuracy: 0.3962 - val_loss: 1.5825 - val_accuracy: 0.3840

Epoch 00020: val_loss improved from 1.58818 to 1.58249, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 21/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5465 - accuracy: 0.4028 - val_loss: 1.5705 - val_accuracy: 0.3907

Epoch 00021: val_loss improved from 1.58249 to 1.57046, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 22/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5342 - accuracy: 0.4120 - val_loss: 1.5689 - val_accuracy: 0.3905

Epoch 00022: val_loss improved from 1.57046 to 1.56891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/7
Epoch 23/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5279 - accuracy: 0.4155 - val_loss: 1.5752 - val_accuracy: 0.3912

Epoch 00023: val_loss did not improve from 1.56891
Epoch 24/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5278 - accuracy: 0.4170 - val_loss: 1.5698 - val_accuracy: 0.3927

Epoch 00024: val_loss did not improve from 1.56891
Epoch 25/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5179 - accuracy: 0.4229 - val_loss: 1.5803 - val_accuracy: 0.3872

Epoch 00025: val_loss did not improve from 1.56891
Epoch 26/100
83/83 [==============================] - 6s 66ms/step - loss: 1.5144 - accuracy: 0.4263 - val_loss: 1.5778 - val_accuracy: 0.3906

Epoch 00026: val_loss did not improve from 1.56891
Epoch 27/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5102 - accuracy: 0.4282 - val_loss: 1.5732 - val_accuracy: 0.3909

Epoch 00027: val_loss did not improve from 1.56891
Epoch 28/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5026 - accuracy: 0.4323 - val_loss: 1.5764 - val_accuracy: 0.3919

Epoch 00028: val_loss did not improve from 1.56891
Epoch 29/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4922 - accuracy: 0.4389 - val_loss: 1.5815 - val_accuracy: 0.3890

Epoch 00029: val_loss did not improve from 1.56891
Epoch 30/100
83/83 [==============================] - 5s 65ms/step - loss: 1.4866 - accuracy: 0.4454 - val_loss: 1.5839 - val_accuracy: 0.3953

Epoch 00030: val_loss did not improve from 1.56891
Epoch 31/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4793 - accuracy: 0.4505 - val_loss: 1.5882 - val_accuracy: 0.3964

Epoch 00031: val_loss did not improve from 1.56891
Epoch 32/100
83/83 [==============================] - 5s 65ms/step - loss: 1.4759 - accuracy: 0.4532 - val_loss: 1.5908 - val_accuracy: 0.3972

Epoch 00032: val_loss did not improve from 1.56891
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5746 - accuracy: 0.3936
Testing Loss = 1.574618, Testing Accuracy = 0.393570
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 66ms/step - loss: 12.4519 - accuracy: 0.1974 - val_loss: 8.7307 - val_accuracy: 0.2114

Epoch 00001: val_loss improved from inf to 8.73069, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 2/100
83/83 [==============================] - 5s 65ms/step - loss: 6.8006 - accuracy: 0.2085 - val_loss: 5.3637 - val_accuracy: 0.2117

Epoch 00002: val_loss improved from 8.73069 to 5.36369, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 3/100
83/83 [==============================] - 5s 65ms/step - loss: 4.5750 - accuracy: 0.2234 - val_loss: 3.9614 - val_accuracy: 0.2283

Epoch 00003: val_loss improved from 5.36369 to 3.96137, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 4/100
83/83 [==============================] - 5s 65ms/step - loss: 3.4849 - accuracy: 0.2800 - val_loss: 3.2106 - val_accuracy: 0.2569

Epoch 00004: val_loss improved from 3.96137 to 3.21062, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 5/100
83/83 [==============================] - 5s 65ms/step - loss: 2.8915 - accuracy: 0.2968 - val_loss: 2.7313 - val_accuracy: 0.2816

Epoch 00005: val_loss improved from 3.21062 to 2.73129, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 6/100
83/83 [==============================] - 5s 65ms/step - loss: 2.5083 - accuracy: 0.3071 - val_loss: 2.3908 - val_accuracy: 0.3061

Epoch 00006: val_loss improved from 2.73129 to 2.39085, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 7/100
83/83 [==============================] - 5s 65ms/step - loss: 2.2420 - accuracy: 0.3136 - val_loss: 2.1511 - val_accuracy: 0.3218

Epoch 00007: val_loss improved from 2.39085 to 2.15111, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 8/100
83/83 [==============================] - 5s 65ms/step - loss: 2.0550 - accuracy: 0.3259 - val_loss: 1.9771 - val_accuracy: 0.3322

Epoch 00008: val_loss improved from 2.15111 to 1.97715, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 9/100
83/83 [==============================] - 5s 65ms/step - loss: 1.9218 - accuracy: 0.3296 - val_loss: 1.8590 - val_accuracy: 0.3405

Epoch 00009: val_loss improved from 1.97715 to 1.85897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 10/100
83/83 [==============================] - 5s 65ms/step - loss: 1.8257 - accuracy: 0.3348 - val_loss: 1.7778 - val_accuracy: 0.3458

Epoch 00010: val_loss improved from 1.85897 to 1.77783, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 11/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7553 - accuracy: 0.3462 - val_loss: 1.7185 - val_accuracy: 0.3595

Epoch 00011: val_loss improved from 1.77783 to 1.71853, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 12/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7036 - accuracy: 0.3554 - val_loss: 1.6800 - val_accuracy: 0.3608

Epoch 00012: val_loss improved from 1.71853 to 1.67996, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 13/100
83/83 [==============================] - 6s 66ms/step - loss: 1.6650 - accuracy: 0.3632 - val_loss: 1.6461 - val_accuracy: 0.3703

Epoch 00013: val_loss improved from 1.67996 to 1.64613, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 14/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6339 - accuracy: 0.3705 - val_loss: 1.6247 - val_accuracy: 0.3750

Epoch 00014: val_loss improved from 1.64613 to 1.62469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 15/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6123 - accuracy: 0.3765 - val_loss: 1.6109 - val_accuracy: 0.3762

Epoch 00015: val_loss improved from 1.62469 to 1.61089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 16/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5950 - accuracy: 0.3814 - val_loss: 1.5988 - val_accuracy: 0.3792

Epoch 00016: val_loss improved from 1.61089 to 1.59879, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 17/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5812 - accuracy: 0.3883 - val_loss: 1.5917 - val_accuracy: 0.3802

Epoch 00017: val_loss improved from 1.59879 to 1.59172, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 18/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5687 - accuracy: 0.3924 - val_loss: 1.5929 - val_accuracy: 0.3757

Epoch 00018: val_loss did not improve from 1.59172
Epoch 19/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5589 - accuracy: 0.3984 - val_loss: 1.5825 - val_accuracy: 0.3824

Epoch 00019: val_loss improved from 1.59172 to 1.58250, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 20/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5495 - accuracy: 0.4015 - val_loss: 1.5769 - val_accuracy: 0.3835

Epoch 00020: val_loss improved from 1.58250 to 1.57689, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 21/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5408 - accuracy: 0.4056 - val_loss: 1.5680 - val_accuracy: 0.3928

Epoch 00021: val_loss improved from 1.57689 to 1.56803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 22/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5344 - accuracy: 0.4108 - val_loss: 1.5836 - val_accuracy: 0.3815

Epoch 00022: val_loss did not improve from 1.56803
Epoch 23/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5294 - accuracy: 0.4131 - val_loss: 1.5722 - val_accuracy: 0.3889

Epoch 00023: val_loss did not improve from 1.56803
Epoch 24/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5207 - accuracy: 0.4198 - val_loss: 1.5733 - val_accuracy: 0.3878

Epoch 00024: val_loss did not improve from 1.56803
Epoch 25/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5152 - accuracy: 0.4242 - val_loss: 1.5662 - val_accuracy: 0.3970

Epoch 00025: val_loss improved from 1.56803 to 1.56620, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 26/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5106 - accuracy: 0.4254 - val_loss: 1.5651 - val_accuracy: 0.3968

Epoch 00026: val_loss improved from 1.56620 to 1.56511, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/8
Epoch 27/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5034 - accuracy: 0.4317 - val_loss: 1.5676 - val_accuracy: 0.3970

Epoch 00027: val_loss did not improve from 1.56511
Epoch 28/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4987 - accuracy: 0.4316 - val_loss: 1.5679 - val_accuracy: 0.3996

Epoch 00028: val_loss did not improve from 1.56511
Epoch 29/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4904 - accuracy: 0.4415 - val_loss: 1.5720 - val_accuracy: 0.3999

Epoch 00029: val_loss did not improve from 1.56511
Epoch 30/100
83/83 [==============================] - 5s 65ms/step - loss: 1.4866 - accuracy: 0.4431 - val_loss: 1.5754 - val_accuracy: 0.4007

Epoch 00030: val_loss did not improve from 1.56511
Epoch 31/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4789 - accuracy: 0.4496 - val_loss: 1.5765 - val_accuracy: 0.3977

Epoch 00031: val_loss did not improve from 1.56511
Epoch 32/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4739 - accuracy: 0.4537 - val_loss: 1.5820 - val_accuracy: 0.4003

Epoch 00032: val_loss did not improve from 1.56511
Epoch 33/100
83/83 [==============================] - 6s 66ms/step - loss: 1.4691 - accuracy: 0.4575 - val_loss: 1.5945 - val_accuracy: 0.3975

Epoch 00033: val_loss did not improve from 1.56511
Epoch 34/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4616 - accuracy: 0.4612 - val_loss: 1.5953 - val_accuracy: 0.3979

Epoch 00034: val_loss did not improve from 1.56511
Epoch 35/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4563 - accuracy: 0.4674 - val_loss: 1.5976 - val_accuracy: 0.3964

Epoch 00035: val_loss did not improve from 1.56511
Epoch 36/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4451 - accuracy: 0.4724 - val_loss: 1.6084 - val_accuracy: 0.3950

Epoch 00036: val_loss did not improve from 1.56511
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.5729 - accuracy: 0.3928
Testing Loss = 1.572890, Testing Accuracy = 0.392751
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 66ms/step - loss: 12.4237 - accuracy: 0.1982 - val_loss: 8.6872 - val_accuracy: 0.2101

Epoch 00001: val_loss improved from inf to 8.68722, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 2/100
83/83 [==============================] - 5s 65ms/step - loss: 6.7592 - accuracy: 0.2101 - val_loss: 5.3307 - val_accuracy: 0.2147

Epoch 00002: val_loss improved from 8.68722 to 5.33075, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 3/100
83/83 [==============================] - 5s 65ms/step - loss: 4.5002 - accuracy: 0.2567 - val_loss: 3.9486 - val_accuracy: 0.2309

Epoch 00003: val_loss improved from 5.33075 to 3.94862, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 4/100
83/83 [==============================] - 5s 65ms/step - loss: 3.4664 - accuracy: 0.2925 - val_loss: 3.2069 - val_accuracy: 0.2545

Epoch 00004: val_loss improved from 3.94862 to 3.20687, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 5/100
83/83 [==============================] - 5s 65ms/step - loss: 2.8901 - accuracy: 0.3033 - val_loss: 2.7291 - val_accuracy: 0.2778

Epoch 00005: val_loss improved from 3.20687 to 2.72908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 6/100
83/83 [==============================] - 5s 65ms/step - loss: 2.5095 - accuracy: 0.3084 - val_loss: 2.3931 - val_accuracy: 0.3117

Epoch 00006: val_loss improved from 2.72908 to 2.39306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 7/100
83/83 [==============================] - 5s 65ms/step - loss: 2.2454 - accuracy: 0.3159 - val_loss: 2.1535 - val_accuracy: 0.3233

Epoch 00007: val_loss improved from 2.39306 to 2.15347, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 8/100
83/83 [==============================] - 5s 65ms/step - loss: 2.0573 - accuracy: 0.3219 - val_loss: 1.9828 - val_accuracy: 0.3329

Epoch 00008: val_loss improved from 2.15347 to 1.98281, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 9/100
83/83 [==============================] - 5s 65ms/step - loss: 1.9269 - accuracy: 0.3263 - val_loss: 1.8659 - val_accuracy: 0.3363

Epoch 00009: val_loss improved from 1.98281 to 1.86591, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 10/100
83/83 [==============================] - 5s 65ms/step - loss: 1.8285 - accuracy: 0.3369 - val_loss: 1.7820 - val_accuracy: 0.3469

Epoch 00010: val_loss improved from 1.86591 to 1.78205, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 11/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7594 - accuracy: 0.3453 - val_loss: 1.7248 - val_accuracy: 0.3525

Epoch 00011: val_loss improved from 1.78205 to 1.72479, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 12/100
83/83 [==============================] - 5s 65ms/step - loss: 1.7057 - accuracy: 0.3526 - val_loss: 1.6816 - val_accuracy: 0.3667

Epoch 00012: val_loss improved from 1.72479 to 1.68164, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 13/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6681 - accuracy: 0.3631 - val_loss: 1.6478 - val_accuracy: 0.3734

Epoch 00013: val_loss improved from 1.68164 to 1.64783, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 14/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6366 - accuracy: 0.3689 - val_loss: 1.6232 - val_accuracy: 0.3776

Epoch 00014: val_loss improved from 1.64783 to 1.62316, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 15/100
83/83 [==============================] - 5s 65ms/step - loss: 1.6125 - accuracy: 0.3778 - val_loss: 1.6164 - val_accuracy: 0.3712

Epoch 00015: val_loss improved from 1.62316 to 1.61641, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 16/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5946 - accuracy: 0.3832 - val_loss: 1.5997 - val_accuracy: 0.3749

Epoch 00016: val_loss improved from 1.61641 to 1.59973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 17/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5813 - accuracy: 0.3872 - val_loss: 1.5945 - val_accuracy: 0.3783

Epoch 00017: val_loss improved from 1.59973 to 1.59450, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 18/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5686 - accuracy: 0.3942 - val_loss: 1.5787 - val_accuracy: 0.3891

Epoch 00018: val_loss improved from 1.59450 to 1.57872, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 19/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5568 - accuracy: 0.4007 - val_loss: 1.5704 - val_accuracy: 0.3931

Epoch 00019: val_loss improved from 1.57872 to 1.57042, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 20/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5488 - accuracy: 0.4024 - val_loss: 1.5748 - val_accuracy: 0.3872

Epoch 00020: val_loss did not improve from 1.57042
Epoch 21/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5472 - accuracy: 0.4032 - val_loss: 1.5702 - val_accuracy: 0.3928

Epoch 00021: val_loss improved from 1.57042 to 1.57022, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 22/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5364 - accuracy: 0.4101 - val_loss: 1.5693 - val_accuracy: 0.3924

Epoch 00022: val_loss improved from 1.57022 to 1.56931, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.3/Try/9
Epoch 23/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5291 - accuracy: 0.4160 - val_loss: 1.5702 - val_accuracy: 0.3892

Epoch 00023: val_loss did not improve from 1.56931
Epoch 24/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5240 - accuracy: 0.4199 - val_loss: 1.5803 - val_accuracy: 0.3854

Epoch 00024: val_loss did not improve from 1.56931
Epoch 25/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5208 - accuracy: 0.4218 - val_loss: 1.5777 - val_accuracy: 0.3871

Epoch 00025: val_loss did not improve from 1.56931
Epoch 26/100
83/83 [==============================] - 5s 66ms/step - loss: 1.5150 - accuracy: 0.4274 - val_loss: 1.5792 - val_accuracy: 0.3843

Epoch 00026: val_loss did not improve from 1.56931
Epoch 27/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5055 - accuracy: 0.4306 - val_loss: 1.5745 - val_accuracy: 0.3932

Epoch 00027: val_loss did not improve from 1.56931
Epoch 28/100
83/83 [==============================] - 5s 65ms/step - loss: 1.5015 - accuracy: 0.4336 - val_loss: 1.5772 - val_accuracy: 0.3920

Epoch 00028: val_loss did not improve from 1.56931
Epoch 29/100
83/83 [==============================] - 5s 65ms/step - loss: 1.4946 - accuracy: 0.4395 - val_loss: 1.5785 - val_accuracy: 0.3921

Epoch 00029: val_loss did not improve from 1.56931
Epoch 30/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4821 - accuracy: 0.4467 - val_loss: 1.5776 - val_accuracy: 0.3945

Epoch 00030: val_loss did not improve from 1.56931
Epoch 31/100
83/83 [==============================] - 5s 65ms/step - loss: 1.4805 - accuracy: 0.4479 - val_loss: 1.5833 - val_accuracy: 0.3950

Epoch 00031: val_loss did not improve from 1.56931
Epoch 32/100
83/83 [==============================] - 5s 66ms/step - loss: 1.4752 - accuracy: 0.4547 - val_loss: 1.5890 - val_accuracy: 0.3927

Epoch 00032: val_loss did not improve from 1.56931
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5724 - accuracy: 0.3883
Testing Loss = 1.572396, Testing Accuracy = 0.388285
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 83.92 +- 0.0951 %)
$W^-/W^-$ (auc = 83.53 +- 0.1556 %)
$Z/Z$ (auc = 76.48 +- 0.3892 %)
$W^+/W^-$ (auc = 70.42 +- 0.1868 %)
$W^+/Z$$ (auc = 67.34 +- 0.1347 %)
$W^-/Z$ (auc = 68.96 +- 0.1769 %)
The summarized testing accuracy = 39.17 +- 0.2725 %, with the loss = 1.5743 +- 0.002429
