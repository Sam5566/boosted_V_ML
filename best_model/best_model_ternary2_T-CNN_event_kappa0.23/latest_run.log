

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2023-01-31 15:16:05.415940
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 48000.
Epoch 1/100
93/93 [==============================] - 10s 71ms/step - loss: 11.2288 - accuracy: 0.3419 - val_loss: 7.3205 - val_accuracy: 0.3564

Epoch 00001: val_loss improved from inf to 7.32047, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 2/100
93/93 [==============================] - 6s 69ms/step - loss: 5.4779 - accuracy: 0.3622 - val_loss: 4.1621 - val_accuracy: 0.3640

Epoch 00002: val_loss improved from 7.32047 to 4.16213, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 3/100
93/93 [==============================] - 6s 67ms/step - loss: 3.4433 - accuracy: 0.4431 - val_loss: 2.9234 - val_accuracy: 0.4306

Epoch 00003: val_loss improved from 4.16213 to 2.92337, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 4/100
93/93 [==============================] - 6s 68ms/step - loss: 2.5261 - accuracy: 0.4834 - val_loss: 2.2514 - val_accuracy: 0.4691

Epoch 00004: val_loss improved from 2.92337 to 2.25140, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 5/100
93/93 [==============================] - 6s 68ms/step - loss: 2.0012 - accuracy: 0.4947 - val_loss: 1.8210 - val_accuracy: 0.4959

Epoch 00005: val_loss improved from 2.25140 to 1.82099, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 6/100
93/93 [==============================] - 6s 68ms/step - loss: 1.6597 - accuracy: 0.5024 - val_loss: 1.5378 - val_accuracy: 0.5032

Epoch 00006: val_loss improved from 1.82099 to 1.53776, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 7/100
93/93 [==============================] - 6s 69ms/step - loss: 1.4344 - accuracy: 0.5096 - val_loss: 1.3514 - val_accuracy: 0.5133

Epoch 00007: val_loss improved from 1.53776 to 1.35137, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 8/100
93/93 [==============================] - 6s 69ms/step - loss: 1.2836 - accuracy: 0.5143 - val_loss: 1.2293 - val_accuracy: 0.5165

Epoch 00008: val_loss improved from 1.35137 to 1.22926, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 9/100
93/93 [==============================] - 7s 70ms/step - loss: 1.1859 - accuracy: 0.5155 - val_loss: 1.1528 - val_accuracy: 0.5184

Epoch 00009: val_loss improved from 1.22926 to 1.15277, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 10/100
93/93 [==============================] - 6s 67ms/step - loss: 1.1210 - accuracy: 0.5210 - val_loss: 1.1049 - val_accuracy: 0.5160

Epoch 00010: val_loss improved from 1.15277 to 1.10493, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 11/100
93/93 [==============================] - 6s 68ms/step - loss: 1.0799 - accuracy: 0.5218 - val_loss: 1.0731 - val_accuracy: 0.5186

Epoch 00011: val_loss improved from 1.10493 to 1.07307, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 12/100
93/93 [==============================] - 6s 67ms/step - loss: 1.0529 - accuracy: 0.5258 - val_loss: 1.0527 - val_accuracy: 0.5203

Epoch 00012: val_loss improved from 1.07307 to 1.05274, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 13/100
93/93 [==============================] - 6s 69ms/step - loss: 1.0354 - accuracy: 0.5294 - val_loss: 1.0409 - val_accuracy: 0.5222

Epoch 00013: val_loss improved from 1.05274 to 1.04092, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 14/100
93/93 [==============================] - 7s 69ms/step - loss: 1.0244 - accuracy: 0.5329 - val_loss: 1.0340 - val_accuracy: 0.5244

Epoch 00014: val_loss improved from 1.04092 to 1.03396, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 15/100
93/93 [==============================] - 6s 67ms/step - loss: 1.0156 - accuracy: 0.5376 - val_loss: 1.0321 - val_accuracy: 0.5234

Epoch 00015: val_loss improved from 1.03396 to 1.03210, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 16/100
93/93 [==============================] - 6s 66ms/step - loss: 1.0101 - accuracy: 0.5417 - val_loss: 1.0289 - val_accuracy: 0.5243

Epoch 00016: val_loss improved from 1.03210 to 1.02894, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 17/100
93/93 [==============================] - 6s 67ms/step - loss: 1.0032 - accuracy: 0.5478 - val_loss: 1.0313 - val_accuracy: 0.5239

Epoch 00017: val_loss did not improve from 1.02894
Epoch 18/100
93/93 [==============================] - 6s 67ms/step - loss: 0.9993 - accuracy: 0.5531 - val_loss: 1.0278 - val_accuracy: 0.5254

Epoch 00018: val_loss improved from 1.02894 to 1.02780, saving model to /home/samhuang/ML/best_model/best_model_ternary2_T-CNN_event_kappa0.23/Try/0
Epoch 19/100
93/93 [==============================] - 6s 68ms/step - loss: 0.9945 - accuracy: 0.5570 - val_loss: 1.0320 - val_accuracy: 0.5286

Epoch 00019: val_loss did not improve from 1.02780
Epoch 20/100
93/93 [==============================] - 6s 66ms/step - loss: 0.9897 - accuracy: 0.5665 - val_loss: 1.0295 - val_accuracy: 0.5334

Epoch 00020: val_loss did not improve from 1.02780
Epoch 21/100
93/93 [==============================] - 6s 66ms/step - loss: 0.9851 - accuracy: 0.5709 - val_loss: 1.0408 - val_accuracy: 0.5270

Epoch 00021: val_loss did not improve from 1.02780
Epoch 22/100
93/93 [==============================] - 6s 66ms/step - loss: 0.9780 - accuracy: 0.5791 - val_loss: 1.0331 - val_accuracy: 0.5358

Epoch 00022: val_loss did not improve from 1.02780
Epoch 23/100
93/93 [==============================] - 6s 67ms/step - loss: 0.9741 - accuracy: 0.5843 - val_loss: 1.0483 - val_accuracy: 0.5291

Epoch 00023: val_loss did not improve from 1.02780
Epoch 24/100
93/93 [==============================] - 6s 68ms/step - loss: 0.9660 - accuracy: 0.5946 - val_loss: 1.0427 - val_accuracy: 0.5340

Epoch 00024: val_loss did not improve from 1.02780
Epoch 25/100
93/93 [==============================] - 6s 67ms/step - loss: 0.9583 - accuracy: 0.6043 - val_loss: 1.0501 - val_accuracy: 0.5321

Epoch 00025: val_loss did not improve from 1.02780
Epoch 26/100
93/93 [==============================] - 6s 67ms/step - loss: 0.9516 - accuracy: 0.6121 - val_loss: 1.0568 - val_accuracy: 0.5322

Epoch 00026: val_loss did not improve from 1.02780
Epoch 27/100
93/93 [==============================] - 6s 67ms/step - loss: 0.9422 - accuracy: 0.6208 - val_loss: 1.0752 - val_accuracy: 0.5323

Epoch 00027: val_loss did not improve from 1.02780
Epoch 28/100
93/93 [==============================] - 6s 67ms/step - loss: 0.9329 - accuracy: 0.6334 - val_loss: 1.0908 - val_accuracy: 0.5256

Epoch 00028: val_loss did not improve from 1.02780
Epoch 00028: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
15000/15000 [==============================] - 74s 5ms/step - loss: 1.0231 - accuracy: 0.5331
Testing Loss = 1.023092, Testing Accuracy = 0.533067
The data set contains images
[[0.47783002257347107, 0.3675660490989685, 0.15460391342639923], [0.4408130645751953, 0.20519062876701355, 0.3539963364601135], [0.1709146350622177, 0.18483473360538483, 0.6442506313323975], [0.1637888252735138, 0.7195973992347717, 0.11661374568939209], [0.279072642326355, 0.17270515859127045, 0.5482222437858582], [0.35116034746170044, 0.47125840187072754, 0.17758119106292725], [0.35002273321151733, 0.09573237597942352, 0.554244875907898], [0.43758830428123474, 0.16079041361808777, 0.40162134170532227], [0.21843068301677704, 0.6954480409622192, 0.08612123876810074], [0.5395469665527344, 0.23541727662086487, 0.22503580152988434]]
N of classes 3
$W^+/W^-$ (auc = 67.22 +- 0.0000 %)
$W^+/Z$ (auc = 74.05 +- 0.0000 %)
$W^-/Z$ (auc = 74.03 +- 0.0000 %)
N of classes 3
$W^+/W^-$ (acc = 48.88 +- 0.0000 %
$W^+/Z$ (acc = 56.10 +- 0.0000 %
$W^-/Z$ (acc = 55.19 +- 0.0000 %
The summarized testing accuracy = 53.31 +- 0.0000 %, with the loss = 1.0231 +- 0.000000
