

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-24 11:22:45.398225
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 60s 72ms/step - loss: 3.5509 - accuracy: 0.6054 - val_loss: 1.1405 - val_accuracy: 0.6515

Epoch 00001: val_loss improved from inf to 1.14048, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 2/100
748/748 [==============================] - 53s 70ms/step - loss: 0.9477 - accuracy: 0.6481 - val_loss: 0.8493 - val_accuracy: 0.6576

Epoch 00002: val_loss improved from 1.14048 to 0.84931, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 3/100
748/748 [==============================] - 50s 66ms/step - loss: 0.8493 - accuracy: 0.6525 - val_loss: 0.8248 - val_accuracy: 0.6615

Epoch 00003: val_loss improved from 0.84931 to 0.82482, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 4/100
748/748 [==============================] - 50s 66ms/step - loss: 0.8336 - accuracy: 0.6557 - val_loss: 0.8186 - val_accuracy: 0.6618

Epoch 00004: val_loss improved from 0.82482 to 0.81860, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 5/100
748/748 [==============================] - 49s 66ms/step - loss: 0.8244 - accuracy: 0.6591 - val_loss: 0.8102 - val_accuracy: 0.6644

Epoch 00005: val_loss improved from 0.81860 to 0.81016, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 6/100
748/748 [==============================] - 50s 67ms/step - loss: 0.8177 - accuracy: 0.6619 - val_loss: 0.8074 - val_accuracy: 0.6656

Epoch 00006: val_loss improved from 0.81016 to 0.80742, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 7/100
748/748 [==============================] - 49s 66ms/step - loss: 0.8109 - accuracy: 0.6658 - val_loss: 0.8010 - val_accuracy: 0.6697

Epoch 00007: val_loss improved from 0.80742 to 0.80100, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 8/100
748/748 [==============================] - 50s 67ms/step - loss: 0.8041 - accuracy: 0.6692 - val_loss: 0.8017 - val_accuracy: 0.6689

Epoch 00008: val_loss did not improve from 0.80100
Epoch 9/100
748/748 [==============================] - 50s 66ms/step - loss: 0.7990 - accuracy: 0.6723 - val_loss: 0.7896 - val_accuracy: 0.6759

Epoch 00009: val_loss improved from 0.80100 to 0.78961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 10/100
748/748 [==============================] - 49s 66ms/step - loss: 0.7949 - accuracy: 0.6746 - val_loss: 0.7950 - val_accuracy: 0.6716

Epoch 00010: val_loss did not improve from 0.78961
Epoch 11/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7913 - accuracy: 0.6759 - val_loss: 0.7946 - val_accuracy: 0.6705

Epoch 00011: val_loss did not improve from 0.78961
Epoch 12/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7886 - accuracy: 0.6777 - val_loss: 0.7902 - val_accuracy: 0.6731

Epoch 00012: val_loss did not improve from 0.78961
Epoch 13/100
748/748 [==============================] - 50s 66ms/step - loss: 0.7860 - accuracy: 0.6786 - val_loss: 0.7854 - val_accuracy: 0.6766

Epoch 00013: val_loss improved from 0.78961 to 0.78535, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 14/100
748/748 [==============================] - 49s 66ms/step - loss: 0.7836 - accuracy: 0.6799 - val_loss: 0.7849 - val_accuracy: 0.6765

Epoch 00014: val_loss improved from 0.78535 to 0.78487, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 15/100
748/748 [==============================] - 49s 66ms/step - loss: 0.7813 - accuracy: 0.6815 - val_loss: 0.7863 - val_accuracy: 0.6755

Epoch 00015: val_loss did not improve from 0.78487
Epoch 16/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7793 - accuracy: 0.6825 - val_loss: 0.7956 - val_accuracy: 0.6665

Epoch 00016: val_loss did not improve from 0.78487
Epoch 17/100
748/748 [==============================] - 49s 66ms/step - loss: 0.7777 - accuracy: 0.6832 - val_loss: 0.7818 - val_accuracy: 0.6778

Epoch 00017: val_loss improved from 0.78487 to 0.78183, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 18/100
748/748 [==============================] - 49s 66ms/step - loss: 0.7758 - accuracy: 0.6846 - val_loss: 0.7855 - val_accuracy: 0.6746

Epoch 00018: val_loss did not improve from 0.78183
Epoch 19/100
748/748 [==============================] - 49s 66ms/step - loss: 0.7746 - accuracy: 0.6850 - val_loss: 0.7836 - val_accuracy: 0.6758

Epoch 00019: val_loss did not improve from 0.78183
Epoch 20/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7729 - accuracy: 0.6862 - val_loss: 0.7818 - val_accuracy: 0.6766

Epoch 00020: val_loss improved from 0.78183 to 0.78175, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 21/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7718 - accuracy: 0.6873 - val_loss: 0.7869 - val_accuracy: 0.6733

Epoch 00021: val_loss did not improve from 0.78175
Epoch 22/100
748/748 [==============================] - 53s 71ms/step - loss: 0.7695 - accuracy: 0.6884 - val_loss: 0.7757 - val_accuracy: 0.6817

Epoch 00022: val_loss improved from 0.78175 to 0.77569, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 23/100
748/748 [==============================] - 49s 66ms/step - loss: 0.7678 - accuracy: 0.6895 - val_loss: 0.7824 - val_accuracy: 0.6764

Epoch 00023: val_loss did not improve from 0.77569
Epoch 24/100
748/748 [==============================] - 50s 66ms/step - loss: 0.7667 - accuracy: 0.6906 - val_loss: 0.7811 - val_accuracy: 0.6785

Epoch 00024: val_loss did not improve from 0.77569
Epoch 25/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7651 - accuracy: 0.6911 - val_loss: 0.7848 - val_accuracy: 0.6757

Epoch 00025: val_loss did not improve from 0.77569
Epoch 26/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7635 - accuracy: 0.6930 - val_loss: 0.7891 - val_accuracy: 0.6726

Epoch 00026: val_loss did not improve from 0.77569
Epoch 27/100
748/748 [==============================] - 50s 66ms/step - loss: 0.7621 - accuracy: 0.6934 - val_loss: 0.7890 - val_accuracy: 0.6726

Epoch 00027: val_loss did not improve from 0.77569
Epoch 28/100
748/748 [==============================] - 49s 66ms/step - loss: 0.7608 - accuracy: 0.6947 - val_loss: 0.7831 - val_accuracy: 0.6766

Epoch 00028: val_loss did not improve from 0.77569
Epoch 29/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7593 - accuracy: 0.6956 - val_loss: 0.7853 - val_accuracy: 0.6750

Epoch 00029: val_loss did not improve from 0.77569
Epoch 30/100
748/748 [==============================] - 49s 66ms/step - loss: 0.7570 - accuracy: 0.6976 - val_loss: 0.7842 - val_accuracy: 0.6780

Epoch 00030: val_loss did not improve from 0.77569
Epoch 31/100
748/748 [==============================] - 49s 66ms/step - loss: 0.7552 - accuracy: 0.6986 - val_loss: 0.7937 - val_accuracy: 0.6714

Epoch 00031: val_loss did not improve from 0.77569
Epoch 32/100
748/748 [==============================] - 49s 66ms/step - loss: 0.7534 - accuracy: 0.7000 - val_loss: 0.7865 - val_accuracy: 0.6766

Epoch 00032: val_loss did not improve from 0.77569
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 489s 4ms/step - loss: 0.7792 - accuracy: 0.6797
Testing Loss = 0.779172, Testing Accuracy = 0.679722
The data set contains images
N of classes 3
$W^+$ (auc = 85.48 +- 0.0000 %)
$W^-$ (auc = 85.44 +- 0.0000 %)
$Z$ (auc = 83.65 +- 0.0000 %)
The summarized testing accuracy = 67.97 +- 0.0000 (percent), with the loss = 0.7792 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-24 14:59:28.242715
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 64s 70ms/step - loss: 3.5215 - accuracy: 0.6022 - val_loss: 1.1368 - val_accuracy: 0.6468

Epoch 00001: val_loss improved from inf to 1.13683, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 2/100
748/748 [==============================] - 51s 69ms/step - loss: 0.9407 - accuracy: 0.6486 - val_loss: 0.8485 - val_accuracy: 0.6565

Epoch 00002: val_loss improved from 1.13683 to 0.84847, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 3/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8450 - accuracy: 0.6540 - val_loss: 0.8195 - val_accuracy: 0.6634

Epoch 00003: val_loss improved from 0.84847 to 0.81954, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 4/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8287 - accuracy: 0.6587 - val_loss: 0.8079 - val_accuracy: 0.6678

Epoch 00004: val_loss improved from 0.81954 to 0.80794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 5/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8189 - accuracy: 0.6634 - val_loss: 0.8023 - val_accuracy: 0.6706

Epoch 00005: val_loss improved from 0.80794 to 0.80229, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 6/100
748/748 [==============================] - 52s 70ms/step - loss: 0.8101 - accuracy: 0.6683 - val_loss: 0.7944 - val_accuracy: 0.6742

Epoch 00006: val_loss improved from 0.80229 to 0.79442, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 7/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8033 - accuracy: 0.6721 - val_loss: 0.7902 - val_accuracy: 0.6770

Epoch 00007: val_loss improved from 0.79442 to 0.79020, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 8/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7976 - accuracy: 0.6746 - val_loss: 0.7869 - val_accuracy: 0.6790

Epoch 00008: val_loss improved from 0.79020 to 0.78690, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 9/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7942 - accuracy: 0.6760 - val_loss: 0.7869 - val_accuracy: 0.6782

Epoch 00009: val_loss did not improve from 0.78690
Epoch 10/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7903 - accuracy: 0.6788 - val_loss: 0.7789 - val_accuracy: 0.6831

Epoch 00010: val_loss improved from 0.78690 to 0.77893, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 11/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7879 - accuracy: 0.6796 - val_loss: 0.7793 - val_accuracy: 0.6820

Epoch 00011: val_loss did not improve from 0.77893
Epoch 12/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7848 - accuracy: 0.6813 - val_loss: 0.7758 - val_accuracy: 0.6845

Epoch 00012: val_loss improved from 0.77893 to 0.77575, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 13/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7823 - accuracy: 0.6823 - val_loss: 0.7773 - val_accuracy: 0.6827

Epoch 00013: val_loss did not improve from 0.77575
Epoch 14/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7801 - accuracy: 0.6836 - val_loss: 0.7766 - val_accuracy: 0.6820

Epoch 00014: val_loss did not improve from 0.77575
Epoch 15/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7781 - accuracy: 0.6848 - val_loss: 0.7749 - val_accuracy: 0.6835

Epoch 00015: val_loss improved from 0.77575 to 0.77487, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 16/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7761 - accuracy: 0.6860 - val_loss: 0.7723 - val_accuracy: 0.6848

Epoch 00016: val_loss improved from 0.77487 to 0.77227, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 17/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7741 - accuracy: 0.6873 - val_loss: 0.7723 - val_accuracy: 0.6849

Epoch 00017: val_loss improved from 0.77227 to 0.77226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 18/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7724 - accuracy: 0.6879 - val_loss: 0.7773 - val_accuracy: 0.6803

Epoch 00018: val_loss did not improve from 0.77226
Epoch 19/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7702 - accuracy: 0.6892 - val_loss: 0.7719 - val_accuracy: 0.6841

Epoch 00019: val_loss improved from 0.77226 to 0.77194, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 20/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7687 - accuracy: 0.6900 - val_loss: 0.7693 - val_accuracy: 0.6858

Epoch 00020: val_loss improved from 0.77194 to 0.76931, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 21/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7671 - accuracy: 0.6912 - val_loss: 0.7687 - val_accuracy: 0.6856

Epoch 00021: val_loss improved from 0.76931 to 0.76871, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 22/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7652 - accuracy: 0.6925 - val_loss: 0.7717 - val_accuracy: 0.6840

Epoch 00022: val_loss did not improve from 0.76871
Epoch 23/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7635 - accuracy: 0.6936 - val_loss: 0.7683 - val_accuracy: 0.6876

Epoch 00023: val_loss improved from 0.76871 to 0.76828, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-fishbone/Try/0
Epoch 24/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7609 - accuracy: 0.6954 - val_loss: 0.7703 - val_accuracy: 0.6845

Epoch 00024: val_loss did not improve from 0.76828
Epoch 25/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7598 - accuracy: 0.6957 - val_loss: 0.7698 - val_accuracy: 0.6856

Epoch 00025: val_loss did not improve from 0.76828
Epoch 26/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7577 - accuracy: 0.6978 - val_loss: 0.7712 - val_accuracy: 0.6852

Epoch 00026: val_loss did not improve from 0.76828
Epoch 27/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7557 - accuracy: 0.6986 - val_loss: 0.7707 - val_accuracy: 0.6859

Epoch 00027: val_loss did not improve from 0.76828
Epoch 28/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7535 - accuracy: 0.7000 - val_loss: 0.7702 - val_accuracy: 0.6868

Epoch 00028: val_loss did not improve from 0.76828
Epoch 29/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7514 - accuracy: 0.7029 - val_loss: 0.7761 - val_accuracy: 0.6830

Epoch 00029: val_loss did not improve from 0.76828
Epoch 30/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7488 - accuracy: 0.7044 - val_loss: 0.7744 - val_accuracy: 0.6851

Epoch 00030: val_loss did not improve from 0.76828
Epoch 31/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7470 - accuracy: 0.7056 - val_loss: 0.7795 - val_accuracy: 0.6817

Epoch 00031: val_loss did not improve from 0.76828
Epoch 32/100
748/748 [==============================] - 230s 308ms/step - loss: 0.7456 - accuracy: 0.7076 - val_loss: 0.7755 - val_accuracy: 0.6845

Epoch 00032: val_loss did not improve from 0.76828
Epoch 33/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7432 - accuracy: 0.7092 - val_loss: 0.7784 - val_accuracy: 0.6832

Epoch 00033: val_loss did not improve from 0.76828
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 488s 4ms/step - loss: 0.7713 - accuracy: 0.6846
Testing Loss = 0.771282, Testing Accuracy = 0.684557
The data set contains images
N of classes 3
$W^+$ (auc = 85.53 +- 0.0000 %)
$W^-$ (auc = 85.55 +- 0.0000 %)
$Z$ (auc = 83.95 +- 0.0000 %)
The summarized testing accuracy = 68.46 +- 0.0000 (percent), with the loss = 0.7713 +- 0.000000
