

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-26 18:26:24.769051
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 15s 71ms/step - loss: 12.3556 - accuracy: 0.2077 - val_loss: 8.6204 - val_accuracy: 0.2218

Epoch 00001: val_loss improved from inf to 8.62044, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6810 - accuracy: 0.2685 - val_loss: 5.3448 - val_accuracy: 0.2734

Epoch 00002: val_loss improved from 8.62044 to 5.34476, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.5446 - accuracy: 0.2876 - val_loss: 3.9706 - val_accuracy: 0.2924

Epoch 00003: val_loss improved from 5.34476 to 3.97061, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5521 - accuracy: 0.2967 - val_loss: 3.2187 - val_accuracy: 0.3046

Epoch 00004: val_loss improved from 3.97061 to 3.21873, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9668 - accuracy: 0.3067 - val_loss: 2.7389 - val_accuracy: 0.3165

Epoch 00005: val_loss improved from 3.21873 to 2.73892, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.5757 - accuracy: 0.3122 - val_loss: 2.4110 - val_accuracy: 0.3229

Epoch 00006: val_loss improved from 2.73892 to 2.41098, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3010 - accuracy: 0.3184 - val_loss: 2.1823 - val_accuracy: 0.3239

Epoch 00007: val_loss improved from 2.41098 to 2.18226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.1035 - accuracy: 0.3232 - val_loss: 2.0186 - val_accuracy: 0.3260

Epoch 00008: val_loss improved from 2.18226 to 2.01860, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9639 - accuracy: 0.3280 - val_loss: 1.9084 - val_accuracy: 0.3260

Epoch 00009: val_loss improved from 2.01860 to 1.90844, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8655 - accuracy: 0.3316 - val_loss: 1.8263 - val_accuracy: 0.3284

Epoch 00010: val_loss improved from 1.90844 to 1.82629, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7928 - accuracy: 0.3362 - val_loss: 1.7670 - val_accuracy: 0.3361

Epoch 00011: val_loss improved from 1.82629 to 1.76704, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7425 - accuracy: 0.3386 - val_loss: 1.7269 - val_accuracy: 0.3366

Epoch 00012: val_loss improved from 1.76704 to 1.72687, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7077 - accuracy: 0.3435 - val_loss: 1.6966 - val_accuracy: 0.3408

Epoch 00013: val_loss improved from 1.72687 to 1.69657, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6800 - accuracy: 0.3458 - val_loss: 1.6808 - val_accuracy: 0.3386

Epoch 00014: val_loss improved from 1.69657 to 1.68083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6605 - accuracy: 0.3495 - val_loss: 1.6693 - val_accuracy: 0.3403

Epoch 00015: val_loss improved from 1.68083 to 1.66932, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6470 - accuracy: 0.3492 - val_loss: 1.6540 - val_accuracy: 0.3420

Epoch 00016: val_loss improved from 1.66932 to 1.65396, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6336 - accuracy: 0.3554 - val_loss: 1.6499 - val_accuracy: 0.3413

Epoch 00017: val_loss improved from 1.65396 to 1.64990, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6243 - accuracy: 0.3589 - val_loss: 1.6420 - val_accuracy: 0.3448

Epoch 00018: val_loss improved from 1.64990 to 1.64195, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6162 - accuracy: 0.3630 - val_loss: 1.6396 - val_accuracy: 0.3452

Epoch 00019: val_loss improved from 1.64195 to 1.63963, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6105 - accuracy: 0.3626 - val_loss: 1.6375 - val_accuracy: 0.3460

Epoch 00020: val_loss improved from 1.63963 to 1.63752, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/0
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6041 - accuracy: 0.3670 - val_loss: 1.6384 - val_accuracy: 0.3482

Epoch 00021: val_loss did not improve from 1.63752
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6005 - accuracy: 0.3704 - val_loss: 1.6386 - val_accuracy: 0.3475

Epoch 00022: val_loss did not improve from 1.63752
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5937 - accuracy: 0.3755 - val_loss: 1.6432 - val_accuracy: 0.3457

Epoch 00023: val_loss did not improve from 1.63752
Epoch 24/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5911 - accuracy: 0.3756 - val_loss: 1.6397 - val_accuracy: 0.3478

Epoch 00024: val_loss did not improve from 1.63752
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5851 - accuracy: 0.3834 - val_loss: 1.6455 - val_accuracy: 0.3482

Epoch 00025: val_loss did not improve from 1.63752
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5846 - accuracy: 0.3848 - val_loss: 1.6523 - val_accuracy: 0.3457

Epoch 00026: val_loss did not improve from 1.63752
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5779 - accuracy: 0.3896 - val_loss: 1.6549 - val_accuracy: 0.3487

Epoch 00027: val_loss did not improve from 1.63752
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5743 - accuracy: 0.3913 - val_loss: 1.6631 - val_accuracy: 0.3437

Epoch 00028: val_loss did not improve from 1.63752
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5688 - accuracy: 0.3979 - val_loss: 1.6761 - val_accuracy: 0.3421

Epoch 00029: val_loss did not improve from 1.63752
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5667 - accuracy: 0.4022 - val_loss: 1.6826 - val_accuracy: 0.3441

Epoch 00030: val_loss did not improve from 1.63752
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 58s 4ms/step - loss: 1.6499 - accuracy: 0.3360
Testing Loss = 1.649896, Testing Accuracy = 0.335963
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 70ms/step - loss: 12.3472 - accuracy: 0.2040 - val_loss: 8.5901 - val_accuracy: 0.2142

Epoch 00001: val_loss improved from inf to 8.59014, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6556 - accuracy: 0.2671 - val_loss: 5.3224 - val_accuracy: 0.2781

Epoch 00002: val_loss improved from 8.59014 to 5.32243, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 3/100
83/83 [==============================] - 6s 70ms/step - loss: 4.5376 - accuracy: 0.2944 - val_loss: 3.9679 - val_accuracy: 0.2949

Epoch 00003: val_loss improved from 5.32243 to 3.96794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.5537 - accuracy: 0.3025 - val_loss: 3.2278 - val_accuracy: 0.3053

Epoch 00004: val_loss improved from 3.96794 to 3.22781, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 2.9727 - accuracy: 0.3085 - val_loss: 2.7462 - val_accuracy: 0.3152

Epoch 00005: val_loss improved from 3.22781 to 2.74619, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5787 - accuracy: 0.3131 - val_loss: 2.4127 - val_accuracy: 0.3230

Epoch 00006: val_loss improved from 2.74619 to 2.41267, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 7/100
83/83 [==============================] - 6s 71ms/step - loss: 2.3026 - accuracy: 0.3181 - val_loss: 2.1821 - val_accuracy: 0.3252

Epoch 00007: val_loss improved from 2.41267 to 2.18211, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 8/100
83/83 [==============================] - 7s 81ms/step - loss: 2.1065 - accuracy: 0.3237 - val_loss: 2.0233 - val_accuracy: 0.3270

Epoch 00008: val_loss improved from 2.18211 to 2.02331, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9668 - accuracy: 0.3265 - val_loss: 1.9068 - val_accuracy: 0.3292

Epoch 00009: val_loss improved from 2.02331 to 1.90678, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 10/100
83/83 [==============================] - 6s 70ms/step - loss: 1.8662 - accuracy: 0.3298 - val_loss: 1.8251 - val_accuracy: 0.3297

Epoch 00010: val_loss improved from 1.90678 to 1.82513, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7949 - accuracy: 0.3334 - val_loss: 1.7658 - val_accuracy: 0.3323

Epoch 00011: val_loss improved from 1.82513 to 1.76584, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7441 - accuracy: 0.3372 - val_loss: 1.7274 - val_accuracy: 0.3371

Epoch 00012: val_loss improved from 1.76584 to 1.72745, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 13/100
83/83 [==============================] - 6s 70ms/step - loss: 1.7067 - accuracy: 0.3420 - val_loss: 1.6967 - val_accuracy: 0.3409

Epoch 00013: val_loss improved from 1.72745 to 1.69671, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6778 - accuracy: 0.3461 - val_loss: 1.6739 - val_accuracy: 0.3465

Epoch 00014: val_loss improved from 1.69671 to 1.67385, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 15/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6589 - accuracy: 0.3489 - val_loss: 1.6623 - val_accuracy: 0.3429

Epoch 00015: val_loss improved from 1.67385 to 1.66233, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6453 - accuracy: 0.3497 - val_loss: 1.6533 - val_accuracy: 0.3410

Epoch 00016: val_loss improved from 1.66233 to 1.65325, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 17/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6321 - accuracy: 0.3563 - val_loss: 1.6471 - val_accuracy: 0.3430

Epoch 00017: val_loss improved from 1.65325 to 1.64715, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6237 - accuracy: 0.3578 - val_loss: 1.6379 - val_accuracy: 0.3487

Epoch 00018: val_loss improved from 1.64715 to 1.63786, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6144 - accuracy: 0.3633 - val_loss: 1.6368 - val_accuracy: 0.3449

Epoch 00019: val_loss improved from 1.63786 to 1.63683, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 20/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6059 - accuracy: 0.3658 - val_loss: 1.6357 - val_accuracy: 0.3473

Epoch 00020: val_loss improved from 1.63683 to 1.63570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/1
Epoch 21/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6034 - accuracy: 0.3693 - val_loss: 1.6390 - val_accuracy: 0.3451

Epoch 00021: val_loss did not improve from 1.63570
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5976 - accuracy: 0.3720 - val_loss: 1.6406 - val_accuracy: 0.3437

Epoch 00022: val_loss did not improve from 1.63570
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5926 - accuracy: 0.3754 - val_loss: 1.6402 - val_accuracy: 0.3479

Epoch 00023: val_loss did not improve from 1.63570
Epoch 24/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5884 - accuracy: 0.3772 - val_loss: 1.6421 - val_accuracy: 0.3462

Epoch 00024: val_loss did not improve from 1.63570
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5847 - accuracy: 0.3845 - val_loss: 1.6450 - val_accuracy: 0.3473

Epoch 00025: val_loss did not improve from 1.63570
Epoch 26/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5795 - accuracy: 0.3856 - val_loss: 1.6504 - val_accuracy: 0.3516

Epoch 00026: val_loss did not improve from 1.63570
Epoch 27/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5766 - accuracy: 0.3909 - val_loss: 1.6551 - val_accuracy: 0.3482

Epoch 00027: val_loss did not improve from 1.63570
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5741 - accuracy: 0.3937 - val_loss: 1.6664 - val_accuracy: 0.3434

Epoch 00028: val_loss did not improve from 1.63570
Epoch 29/100
83/83 [==============================] - 6s 71ms/step - loss: 1.5700 - accuracy: 0.3992 - val_loss: 1.6794 - val_accuracy: 0.3405

Epoch 00029: val_loss did not improve from 1.63570
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5620 - accuracy: 0.4081 - val_loss: 1.6826 - val_accuracy: 0.3430

Epoch 00030: val_loss did not improve from 1.63570
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 58s 4ms/step - loss: 1.6474 - accuracy: 0.3418
Testing Loss = 1.647384, Testing Accuracy = 0.341843
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 70ms/step - loss: 12.3547 - accuracy: 0.2024 - val_loss: 8.6241 - val_accuracy: 0.2097

Epoch 00001: val_loss improved from inf to 8.62409, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6755 - accuracy: 0.2620 - val_loss: 5.3354 - val_accuracy: 0.2648

Epoch 00002: val_loss improved from 8.62409 to 5.33537, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5337 - accuracy: 0.2904 - val_loss: 3.9657 - val_accuracy: 0.2934

Epoch 00003: val_loss improved from 5.33537 to 3.96566, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 4/100
83/83 [==============================] - 6s 71ms/step - loss: 3.5472 - accuracy: 0.2961 - val_loss: 3.2209 - val_accuracy: 0.3059

Epoch 00004: val_loss improved from 3.96566 to 3.22089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9644 - accuracy: 0.3070 - val_loss: 2.7387 - val_accuracy: 0.3148

Epoch 00005: val_loss improved from 3.22089 to 2.73871, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.5745 - accuracy: 0.3140 - val_loss: 2.4126 - val_accuracy: 0.3177

Epoch 00006: val_loss improved from 2.73871 to 2.41264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3005 - accuracy: 0.3185 - val_loss: 2.1830 - val_accuracy: 0.3225

Epoch 00007: val_loss improved from 2.41264 to 2.18302, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.1061 - accuracy: 0.3228 - val_loss: 2.0237 - val_accuracy: 0.3241

Epoch 00008: val_loss improved from 2.18302 to 2.02371, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9672 - accuracy: 0.3271 - val_loss: 1.9108 - val_accuracy: 0.3242

Epoch 00009: val_loss improved from 2.02371 to 1.91081, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8666 - accuracy: 0.3312 - val_loss: 1.8352 - val_accuracy: 0.3240

Epoch 00010: val_loss improved from 1.91081 to 1.83521, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7961 - accuracy: 0.3364 - val_loss: 1.7738 - val_accuracy: 0.3256

Epoch 00011: val_loss improved from 1.83521 to 1.77379, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 12/100
83/83 [==============================] - 6s 72ms/step - loss: 1.7455 - accuracy: 0.3397 - val_loss: 1.7278 - val_accuracy: 0.3332

Epoch 00012: val_loss improved from 1.77379 to 1.72777, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7082 - accuracy: 0.3434 - val_loss: 1.6999 - val_accuracy: 0.3378

Epoch 00013: val_loss improved from 1.72777 to 1.69993, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 14/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6806 - accuracy: 0.3467 - val_loss: 1.6781 - val_accuracy: 0.3401

Epoch 00014: val_loss improved from 1.69993 to 1.67807, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6607 - accuracy: 0.3484 - val_loss: 1.6650 - val_accuracy: 0.3370

Epoch 00015: val_loss improved from 1.67807 to 1.66501, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6467 - accuracy: 0.3522 - val_loss: 1.6547 - val_accuracy: 0.3409

Epoch 00016: val_loss improved from 1.66501 to 1.65474, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6334 - accuracy: 0.3546 - val_loss: 1.6536 - val_accuracy: 0.3374

Epoch 00017: val_loss improved from 1.65474 to 1.65362, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 18/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6236 - accuracy: 0.3567 - val_loss: 1.6429 - val_accuracy: 0.3424

Epoch 00018: val_loss improved from 1.65362 to 1.64294, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6154 - accuracy: 0.3613 - val_loss: 1.6427 - val_accuracy: 0.3396

Epoch 00019: val_loss improved from 1.64294 to 1.64267, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6085 - accuracy: 0.3656 - val_loss: 1.6396 - val_accuracy: 0.3451

Epoch 00020: val_loss improved from 1.64267 to 1.63957, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6049 - accuracy: 0.3690 - val_loss: 1.6359 - val_accuracy: 0.3479

Epoch 00021: val_loss improved from 1.63957 to 1.63590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/2
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5979 - accuracy: 0.3741 - val_loss: 1.6376 - val_accuracy: 0.3472

Epoch 00022: val_loss did not improve from 1.63590
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5931 - accuracy: 0.3772 - val_loss: 1.6443 - val_accuracy: 0.3482

Epoch 00023: val_loss did not improve from 1.63590
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5903 - accuracy: 0.3798 - val_loss: 1.6471 - val_accuracy: 0.3469

Epoch 00024: val_loss did not improve from 1.63590
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5882 - accuracy: 0.3807 - val_loss: 1.6484 - val_accuracy: 0.3472

Epoch 00025: val_loss did not improve from 1.63590
Epoch 26/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5806 - accuracy: 0.3886 - val_loss: 1.6526 - val_accuracy: 0.3462

Epoch 00026: val_loss did not improve from 1.63590
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5774 - accuracy: 0.3898 - val_loss: 1.6572 - val_accuracy: 0.3450

Epoch 00027: val_loss did not improve from 1.63590
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5732 - accuracy: 0.3973 - val_loss: 1.6651 - val_accuracy: 0.3442

Epoch 00028: val_loss did not improve from 1.63590
Epoch 29/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5665 - accuracy: 0.4044 - val_loss: 1.6701 - val_accuracy: 0.3418

Epoch 00029: val_loss did not improve from 1.63590
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5624 - accuracy: 0.4076 - val_loss: 1.6821 - val_accuracy: 0.3443

Epoch 00030: val_loss did not improve from 1.63590
Epoch 31/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5574 - accuracy: 0.4157 - val_loss: 1.6872 - val_accuracy: 0.3439

Epoch 00031: val_loss did not improve from 1.63590
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 57s 4ms/step - loss: 1.6482 - accuracy: 0.3389
Testing Loss = 1.648155, Testing Accuracy = 0.338940
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.2999 - accuracy: 0.2058 - val_loss: 8.5565 - val_accuracy: 0.2122

Epoch 00001: val_loss improved from inf to 8.55647, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6231 - accuracy: 0.2626 - val_loss: 5.3001 - val_accuracy: 0.2627

Epoch 00002: val_loss improved from 8.55647 to 5.30010, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5061 - accuracy: 0.2899 - val_loss: 3.9429 - val_accuracy: 0.2940

Epoch 00003: val_loss improved from 5.30010 to 3.94289, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.5318 - accuracy: 0.3023 - val_loss: 3.2091 - val_accuracy: 0.3030

Epoch 00004: val_loss improved from 3.94289 to 3.20911, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9568 - accuracy: 0.3074 - val_loss: 2.7310 - val_accuracy: 0.3159

Epoch 00005: val_loss improved from 3.20911 to 2.73096, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.5682 - accuracy: 0.3120 - val_loss: 2.4043 - val_accuracy: 0.3219

Epoch 00006: val_loss improved from 2.73096 to 2.40435, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2936 - accuracy: 0.3175 - val_loss: 2.1752 - val_accuracy: 0.3227

Epoch 00007: val_loss improved from 2.40435 to 2.17519, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1000 - accuracy: 0.3233 - val_loss: 2.0154 - val_accuracy: 0.3298

Epoch 00008: val_loss improved from 2.17519 to 2.01536, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9622 - accuracy: 0.3270 - val_loss: 1.9049 - val_accuracy: 0.3284

Epoch 00009: val_loss improved from 2.01536 to 1.90494, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8625 - accuracy: 0.3310 - val_loss: 1.8236 - val_accuracy: 0.3278

Epoch 00010: val_loss improved from 1.90494 to 1.82356, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7925 - accuracy: 0.3337 - val_loss: 1.7671 - val_accuracy: 0.3296

Epoch 00011: val_loss improved from 1.82356 to 1.76710, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7430 - accuracy: 0.3365 - val_loss: 1.7296 - val_accuracy: 0.3295

Epoch 00012: val_loss improved from 1.76710 to 1.72964, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7064 - accuracy: 0.3417 - val_loss: 1.6965 - val_accuracy: 0.3350

Epoch 00013: val_loss improved from 1.72964 to 1.69652, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6788 - accuracy: 0.3443 - val_loss: 1.6766 - val_accuracy: 0.3371

Epoch 00014: val_loss improved from 1.69652 to 1.67657, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6579 - accuracy: 0.3458 - val_loss: 1.6650 - val_accuracy: 0.3418

Epoch 00015: val_loss improved from 1.67657 to 1.66499, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6435 - accuracy: 0.3494 - val_loss: 1.6509 - val_accuracy: 0.3439

Epoch 00016: val_loss improved from 1.66499 to 1.65092, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6317 - accuracy: 0.3544 - val_loss: 1.6479 - val_accuracy: 0.3440

Epoch 00017: val_loss improved from 1.65092 to 1.64795, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6217 - accuracy: 0.3569 - val_loss: 1.6366 - val_accuracy: 0.3490

Epoch 00018: val_loss improved from 1.64795 to 1.63659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6153 - accuracy: 0.3604 - val_loss: 1.6374 - val_accuracy: 0.3509

Epoch 00019: val_loss did not improve from 1.63659
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6097 - accuracy: 0.3616 - val_loss: 1.6336 - val_accuracy: 0.3517

Epoch 00020: val_loss improved from 1.63659 to 1.63355, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6032 - accuracy: 0.3646 - val_loss: 1.6313 - val_accuracy: 0.3510

Epoch 00021: val_loss improved from 1.63355 to 1.63133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/3
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5986 - accuracy: 0.3686 - val_loss: 1.6333 - val_accuracy: 0.3499

Epoch 00022: val_loss did not improve from 1.63133
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5940 - accuracy: 0.3734 - val_loss: 1.6388 - val_accuracy: 0.3479

Epoch 00023: val_loss did not improve from 1.63133
Epoch 24/100
83/83 [==============================] - 6s 71ms/step - loss: 1.5896 - accuracy: 0.3747 - val_loss: 1.6431 - val_accuracy: 0.3479

Epoch 00024: val_loss did not improve from 1.63133
Epoch 25/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5860 - accuracy: 0.3802 - val_loss: 1.6432 - val_accuracy: 0.3484

Epoch 00025: val_loss did not improve from 1.63133
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5813 - accuracy: 0.3854 - val_loss: 1.6534 - val_accuracy: 0.3475

Epoch 00026: val_loss did not improve from 1.63133
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5772 - accuracy: 0.3910 - val_loss: 1.6529 - val_accuracy: 0.3487

Epoch 00027: val_loss did not improve from 1.63133
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5724 - accuracy: 0.3922 - val_loss: 1.6569 - val_accuracy: 0.3453

Epoch 00028: val_loss did not improve from 1.63133
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5687 - accuracy: 0.3993 - val_loss: 1.6686 - val_accuracy: 0.3469

Epoch 00029: val_loss did not improve from 1.63133
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5628 - accuracy: 0.4021 - val_loss: 1.6720 - val_accuracy: 0.3479

Epoch 00030: val_loss did not improve from 1.63133
Epoch 31/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5586 - accuracy: 0.4072 - val_loss: 1.6867 - val_accuracy: 0.3430

Epoch 00031: val_loss did not improve from 1.63133
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.6413 - accuracy: 0.3405
Testing Loss = 1.641271, Testing Accuracy = 0.340503
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 70ms/step - loss: 12.4586 - accuracy: 0.2030 - val_loss: 8.7309 - val_accuracy: 0.2118

Epoch 00001: val_loss improved from inf to 8.73088, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 2/100
83/83 [==============================] - 6s 69ms/step - loss: 6.7599 - accuracy: 0.2695 - val_loss: 5.3969 - val_accuracy: 0.2700

Epoch 00002: val_loss improved from 8.73088 to 5.39689, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5859 - accuracy: 0.2865 - val_loss: 3.9996 - val_accuracy: 0.2939

Epoch 00003: val_loss improved from 5.39689 to 3.99960, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 4/100
83/83 [==============================] - 6s 70ms/step - loss: 3.5780 - accuracy: 0.2965 - val_loss: 3.2408 - val_accuracy: 0.3031

Epoch 00004: val_loss improved from 3.99960 to 3.24080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9832 - accuracy: 0.3042 - val_loss: 2.7546 - val_accuracy: 0.3113

Epoch 00005: val_loss improved from 3.24080 to 2.75465, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5870 - accuracy: 0.3126 - val_loss: 2.4226 - val_accuracy: 0.3183

Epoch 00006: val_loss improved from 2.75465 to 2.42263, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3084 - accuracy: 0.3183 - val_loss: 2.1887 - val_accuracy: 0.3226

Epoch 00007: val_loss improved from 2.42263 to 2.18872, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1097 - accuracy: 0.3195 - val_loss: 2.0251 - val_accuracy: 0.3254

Epoch 00008: val_loss improved from 2.18872 to 2.02515, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9695 - accuracy: 0.3264 - val_loss: 1.9101 - val_accuracy: 0.3250

Epoch 00009: val_loss improved from 2.02515 to 1.91006, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8697 - accuracy: 0.3287 - val_loss: 1.8289 - val_accuracy: 0.3237

Epoch 00010: val_loss improved from 1.91006 to 1.82886, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7970 - accuracy: 0.3334 - val_loss: 1.7723 - val_accuracy: 0.3248

Epoch 00011: val_loss improved from 1.82886 to 1.77235, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 12/100
83/83 [==============================] - 6s 70ms/step - loss: 1.7465 - accuracy: 0.3357 - val_loss: 1.7317 - val_accuracy: 0.3279

Epoch 00012: val_loss improved from 1.77235 to 1.73165, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7089 - accuracy: 0.3403 - val_loss: 1.6998 - val_accuracy: 0.3325

Epoch 00013: val_loss improved from 1.73165 to 1.69983, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6819 - accuracy: 0.3410 - val_loss: 1.6774 - val_accuracy: 0.3380

Epoch 00014: val_loss improved from 1.69983 to 1.67739, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6601 - accuracy: 0.3455 - val_loss: 1.6632 - val_accuracy: 0.3402

Epoch 00015: val_loss improved from 1.67739 to 1.66315, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6441 - accuracy: 0.3532 - val_loss: 1.6535 - val_accuracy: 0.3398

Epoch 00016: val_loss improved from 1.66315 to 1.65354, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6358 - accuracy: 0.3502 - val_loss: 1.6438 - val_accuracy: 0.3432

Epoch 00017: val_loss improved from 1.65354 to 1.64377, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6253 - accuracy: 0.3540 - val_loss: 1.6420 - val_accuracy: 0.3418

Epoch 00018: val_loss improved from 1.64377 to 1.64200, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6175 - accuracy: 0.3580 - val_loss: 1.6365 - val_accuracy: 0.3425

Epoch 00019: val_loss improved from 1.64200 to 1.63648, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6115 - accuracy: 0.3615 - val_loss: 1.6333 - val_accuracy: 0.3466

Epoch 00020: val_loss improved from 1.63648 to 1.63327, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6046 - accuracy: 0.3638 - val_loss: 1.6317 - val_accuracy: 0.3446

Epoch 00021: val_loss improved from 1.63327 to 1.63173, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/4
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5992 - accuracy: 0.3692 - val_loss: 1.6380 - val_accuracy: 0.3438

Epoch 00022: val_loss did not improve from 1.63173
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5971 - accuracy: 0.3716 - val_loss: 1.6341 - val_accuracy: 0.3488

Epoch 00023: val_loss did not improve from 1.63173
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5897 - accuracy: 0.3763 - val_loss: 1.6377 - val_accuracy: 0.3447

Epoch 00024: val_loss did not improve from 1.63173
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5887 - accuracy: 0.3792 - val_loss: 1.6399 - val_accuracy: 0.3468

Epoch 00025: val_loss did not improve from 1.63173
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5825 - accuracy: 0.3834 - val_loss: 1.6456 - val_accuracy: 0.3457

Epoch 00026: val_loss did not improve from 1.63173
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5842 - accuracy: 0.3832 - val_loss: 1.6466 - val_accuracy: 0.3476

Epoch 00027: val_loss did not improve from 1.63173
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5766 - accuracy: 0.3898 - val_loss: 1.6520 - val_accuracy: 0.3418

Epoch 00028: val_loss did not improve from 1.63173
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5728 - accuracy: 0.3921 - val_loss: 1.6585 - val_accuracy: 0.3460

Epoch 00029: val_loss did not improve from 1.63173
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5674 - accuracy: 0.3979 - val_loss: 1.6661 - val_accuracy: 0.3442

Epoch 00030: val_loss did not improve from 1.63173
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5670 - accuracy: 0.4031 - val_loss: 1.6762 - val_accuracy: 0.3433

Epoch 00031: val_loss did not improve from 1.63173
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6430 - accuracy: 0.3387
Testing Loss = 1.643019, Testing Accuracy = 0.338717
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 70ms/step - loss: 12.4043 - accuracy: 0.2030 - val_loss: 8.6816 - val_accuracy: 0.2123

Epoch 00001: val_loss improved from inf to 8.68156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 2/100
83/83 [==============================] - 6s 70ms/step - loss: 6.7248 - accuracy: 0.2654 - val_loss: 5.3657 - val_accuracy: 0.2808

Epoch 00002: val_loss improved from 8.68156 to 5.36566, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.5703 - accuracy: 0.2885 - val_loss: 3.9888 - val_accuracy: 0.2914

Epoch 00003: val_loss improved from 5.36566 to 3.98880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.5674 - accuracy: 0.2981 - val_loss: 3.2335 - val_accuracy: 0.3070

Epoch 00004: val_loss improved from 3.98880 to 3.23352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 2.9782 - accuracy: 0.3043 - val_loss: 2.7510 - val_accuracy: 0.3157

Epoch 00005: val_loss improved from 3.23352 to 2.75102, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 6/100
83/83 [==============================] - 6s 70ms/step - loss: 2.5821 - accuracy: 0.3145 - val_loss: 2.4167 - val_accuracy: 0.3237

Epoch 00006: val_loss improved from 2.75102 to 2.41669, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.3061 - accuracy: 0.3148 - val_loss: 2.1856 - val_accuracy: 0.3269

Epoch 00007: val_loss improved from 2.41669 to 2.18563, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.1073 - accuracy: 0.3201 - val_loss: 2.0226 - val_accuracy: 0.3265

Epoch 00008: val_loss improved from 2.18563 to 2.02259, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9668 - accuracy: 0.3223 - val_loss: 1.9097 - val_accuracy: 0.3229

Epoch 00009: val_loss improved from 2.02259 to 1.90968, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8672 - accuracy: 0.3288 - val_loss: 1.8273 - val_accuracy: 0.3260

Epoch 00010: val_loss improved from 1.90968 to 1.82732, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7936 - accuracy: 0.3327 - val_loss: 1.7708 - val_accuracy: 0.3271

Epoch 00011: val_loss improved from 1.82732 to 1.77076, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7443 - accuracy: 0.3343 - val_loss: 1.7272 - val_accuracy: 0.3314

Epoch 00012: val_loss improved from 1.77076 to 1.72721, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7080 - accuracy: 0.3383 - val_loss: 1.6947 - val_accuracy: 0.3363

Epoch 00013: val_loss improved from 1.72721 to 1.69470, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6792 - accuracy: 0.3438 - val_loss: 1.6753 - val_accuracy: 0.3385

Epoch 00014: val_loss improved from 1.69470 to 1.67525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6594 - accuracy: 0.3475 - val_loss: 1.6618 - val_accuracy: 0.3394

Epoch 00015: val_loss improved from 1.67525 to 1.66181, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6449 - accuracy: 0.3516 - val_loss: 1.6541 - val_accuracy: 0.3413

Epoch 00016: val_loss improved from 1.66181 to 1.65407, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6341 - accuracy: 0.3551 - val_loss: 1.6441 - val_accuracy: 0.3394

Epoch 00017: val_loss improved from 1.65407 to 1.64412, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6220 - accuracy: 0.3595 - val_loss: 1.6387 - val_accuracy: 0.3472

Epoch 00018: val_loss improved from 1.64412 to 1.63868, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6149 - accuracy: 0.3600 - val_loss: 1.6396 - val_accuracy: 0.3447

Epoch 00019: val_loss did not improve from 1.63868
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6103 - accuracy: 0.3630 - val_loss: 1.6336 - val_accuracy: 0.3487

Epoch 00020: val_loss improved from 1.63868 to 1.63363, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6041 - accuracy: 0.3656 - val_loss: 1.6321 - val_accuracy: 0.3471

Epoch 00021: val_loss improved from 1.63363 to 1.63207, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/5
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5993 - accuracy: 0.3681 - val_loss: 1.6345 - val_accuracy: 0.3466

Epoch 00022: val_loss did not improve from 1.63207
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5920 - accuracy: 0.3737 - val_loss: 1.6365 - val_accuracy: 0.3504

Epoch 00023: val_loss did not improve from 1.63207
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5906 - accuracy: 0.3750 - val_loss: 1.6378 - val_accuracy: 0.3486

Epoch 00024: val_loss did not improve from 1.63207
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5860 - accuracy: 0.3810 - val_loss: 1.6431 - val_accuracy: 0.3466

Epoch 00025: val_loss did not improve from 1.63207
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5829 - accuracy: 0.3849 - val_loss: 1.6454 - val_accuracy: 0.3469

Epoch 00026: val_loss did not improve from 1.63207
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5790 - accuracy: 0.3880 - val_loss: 1.6535 - val_accuracy: 0.3483

Epoch 00027: val_loss did not improve from 1.63207
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5738 - accuracy: 0.3948 - val_loss: 1.6579 - val_accuracy: 0.3438

Epoch 00028: val_loss did not improve from 1.63207
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5683 - accuracy: 0.3967 - val_loss: 1.6664 - val_accuracy: 0.3433

Epoch 00029: val_loss did not improve from 1.63207
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5637 - accuracy: 0.4042 - val_loss: 1.6712 - val_accuracy: 0.3484

Epoch 00030: val_loss did not improve from 1.63207
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5607 - accuracy: 0.4100 - val_loss: 1.6821 - val_accuracy: 0.3482

Epoch 00031: val_loss did not improve from 1.63207
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 56s 4ms/step - loss: 1.6438 - accuracy: 0.3391
Testing Loss = 1.643838, Testing Accuracy = 0.339089
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 70ms/step - loss: 12.3688 - accuracy: 0.2107 - val_loss: 8.6589 - val_accuracy: 0.2222

Epoch 00001: val_loss improved from inf to 8.65888, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7328 - accuracy: 0.2735 - val_loss: 5.3958 - val_accuracy: 0.2706

Epoch 00002: val_loss improved from 8.65888 to 5.39576, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.5903 - accuracy: 0.2902 - val_loss: 4.0080 - val_accuracy: 0.2947

Epoch 00003: val_loss improved from 5.39576 to 4.00803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5859 - accuracy: 0.2985 - val_loss: 3.2491 - val_accuracy: 0.3069

Epoch 00004: val_loss improved from 4.00803 to 3.24906, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9915 - accuracy: 0.3048 - val_loss: 2.7603 - val_accuracy: 0.3156

Epoch 00005: val_loss improved from 3.24906 to 2.76026, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.5922 - accuracy: 0.3148 - val_loss: 2.4289 - val_accuracy: 0.3209

Epoch 00006: val_loss improved from 2.76026 to 2.42895, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.3170 - accuracy: 0.3166 - val_loss: 2.1951 - val_accuracy: 0.3248

Epoch 00007: val_loss improved from 2.42895 to 2.19512, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1159 - accuracy: 0.3228 - val_loss: 2.0288 - val_accuracy: 0.3278

Epoch 00008: val_loss improved from 2.19512 to 2.02880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9719 - accuracy: 0.3268 - val_loss: 1.9145 - val_accuracy: 0.3262

Epoch 00009: val_loss improved from 2.02880 to 1.91451, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8717 - accuracy: 0.3330 - val_loss: 1.8298 - val_accuracy: 0.3311

Epoch 00010: val_loss improved from 1.91451 to 1.82984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7974 - accuracy: 0.3373 - val_loss: 1.7716 - val_accuracy: 0.3310

Epoch 00011: val_loss improved from 1.82984 to 1.77161, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7463 - accuracy: 0.3375 - val_loss: 1.7293 - val_accuracy: 0.3363

Epoch 00012: val_loss improved from 1.77161 to 1.72934, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7084 - accuracy: 0.3430 - val_loss: 1.6969 - val_accuracy: 0.3395

Epoch 00013: val_loss improved from 1.72934 to 1.69694, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6805 - accuracy: 0.3484 - val_loss: 1.6781 - val_accuracy: 0.3421

Epoch 00014: val_loss improved from 1.69694 to 1.67814, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6588 - accuracy: 0.3521 - val_loss: 1.6642 - val_accuracy: 0.3435

Epoch 00015: val_loss improved from 1.67814 to 1.66415, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6440 - accuracy: 0.3548 - val_loss: 1.6562 - val_accuracy: 0.3394

Epoch 00016: val_loss improved from 1.66415 to 1.65616, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6331 - accuracy: 0.3571 - val_loss: 1.6479 - val_accuracy: 0.3437

Epoch 00017: val_loss improved from 1.65616 to 1.64795, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 18/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6229 - accuracy: 0.3596 - val_loss: 1.6440 - val_accuracy: 0.3413

Epoch 00018: val_loss improved from 1.64795 to 1.64397, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6163 - accuracy: 0.3604 - val_loss: 1.6371 - val_accuracy: 0.3453

Epoch 00019: val_loss improved from 1.64397 to 1.63713, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/6
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6074 - accuracy: 0.3666 - val_loss: 1.6388 - val_accuracy: 0.3438

Epoch 00020: val_loss did not improve from 1.63713
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6049 - accuracy: 0.3666 - val_loss: 1.6408 - val_accuracy: 0.3415

Epoch 00021: val_loss did not improve from 1.63713
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5988 - accuracy: 0.3713 - val_loss: 1.6398 - val_accuracy: 0.3458

Epoch 00022: val_loss did not improve from 1.63713
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5940 - accuracy: 0.3752 - val_loss: 1.6450 - val_accuracy: 0.3451

Epoch 00023: val_loss did not improve from 1.63713
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5908 - accuracy: 0.3776 - val_loss: 1.6456 - val_accuracy: 0.3453

Epoch 00024: val_loss did not improve from 1.63713
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5846 - accuracy: 0.3832 - val_loss: 1.6456 - val_accuracy: 0.3453

Epoch 00025: val_loss did not improve from 1.63713
Epoch 26/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5830 - accuracy: 0.3845 - val_loss: 1.6568 - val_accuracy: 0.3421

Epoch 00026: val_loss did not improve from 1.63713
Epoch 27/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5783 - accuracy: 0.3913 - val_loss: 1.6616 - val_accuracy: 0.3434

Epoch 00027: val_loss did not improve from 1.63713
Epoch 28/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5752 - accuracy: 0.3938 - val_loss: 1.6645 - val_accuracy: 0.3431

Epoch 00028: val_loss did not improve from 1.63713
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5688 - accuracy: 0.3986 - val_loss: 1.6720 - val_accuracy: 0.3440

Epoch 00029: val_loss did not improve from 1.63713
Epoch 00029: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.6472 - accuracy: 0.3413
Testing Loss = 1.647217, Testing Accuracy = 0.341322
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.3486 - accuracy: 0.2023 - val_loss: 8.6185 - val_accuracy: 0.2079

Epoch 00001: val_loss improved from inf to 8.61852, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6714 - accuracy: 0.2567 - val_loss: 5.3134 - val_accuracy: 0.2731

Epoch 00002: val_loss improved from 8.61852 to 5.31340, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5252 - accuracy: 0.2851 - val_loss: 3.9554 - val_accuracy: 0.2944

Epoch 00003: val_loss improved from 5.31340 to 3.95541, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5416 - accuracy: 0.2935 - val_loss: 3.2164 - val_accuracy: 0.3028

Epoch 00004: val_loss improved from 3.95541 to 3.21636, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9610 - accuracy: 0.3060 - val_loss: 2.7350 - val_accuracy: 0.3146

Epoch 00005: val_loss improved from 3.21636 to 2.73500, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5692 - accuracy: 0.3106 - val_loss: 2.4055 - val_accuracy: 0.3227

Epoch 00006: val_loss improved from 2.73500 to 2.40552, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2984 - accuracy: 0.3167 - val_loss: 2.1807 - val_accuracy: 0.3245

Epoch 00007: val_loss improved from 2.40552 to 2.18066, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1054 - accuracy: 0.3203 - val_loss: 2.0191 - val_accuracy: 0.3238

Epoch 00008: val_loss improved from 2.18066 to 2.01905, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9654 - accuracy: 0.3223 - val_loss: 1.9078 - val_accuracy: 0.3237

Epoch 00009: val_loss improved from 2.01905 to 1.90781, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8663 - accuracy: 0.3300 - val_loss: 1.8288 - val_accuracy: 0.3230

Epoch 00010: val_loss improved from 1.90781 to 1.82881, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7964 - accuracy: 0.3331 - val_loss: 1.7668 - val_accuracy: 0.3316

Epoch 00011: val_loss improved from 1.82881 to 1.76684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7449 - accuracy: 0.3364 - val_loss: 1.7329 - val_accuracy: 0.3290

Epoch 00012: val_loss improved from 1.76684 to 1.73293, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7089 - accuracy: 0.3378 - val_loss: 1.7009 - val_accuracy: 0.3310

Epoch 00013: val_loss improved from 1.73293 to 1.70090, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6802 - accuracy: 0.3431 - val_loss: 1.6740 - val_accuracy: 0.3384

Epoch 00014: val_loss improved from 1.70090 to 1.67405, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6611 - accuracy: 0.3470 - val_loss: 1.6656 - val_accuracy: 0.3364

Epoch 00015: val_loss improved from 1.67405 to 1.66558, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6456 - accuracy: 0.3503 - val_loss: 1.6528 - val_accuracy: 0.3373

Epoch 00016: val_loss improved from 1.66558 to 1.65281, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6347 - accuracy: 0.3542 - val_loss: 1.6427 - val_accuracy: 0.3412

Epoch 00017: val_loss improved from 1.65281 to 1.64269, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6244 - accuracy: 0.3596 - val_loss: 1.6370 - val_accuracy: 0.3443

Epoch 00018: val_loss improved from 1.64269 to 1.63700, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6164 - accuracy: 0.3598 - val_loss: 1.6374 - val_accuracy: 0.3412

Epoch 00019: val_loss did not improve from 1.63700
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6102 - accuracy: 0.3620 - val_loss: 1.6328 - val_accuracy: 0.3427

Epoch 00020: val_loss improved from 1.63700 to 1.63279, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/7
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6044 - accuracy: 0.3656 - val_loss: 1.6339 - val_accuracy: 0.3468

Epoch 00021: val_loss did not improve from 1.63279
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6001 - accuracy: 0.3714 - val_loss: 1.6332 - val_accuracy: 0.3444

Epoch 00022: val_loss did not improve from 1.63279
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5937 - accuracy: 0.3735 - val_loss: 1.6371 - val_accuracy: 0.3427

Epoch 00023: val_loss did not improve from 1.63279
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5906 - accuracy: 0.3791 - val_loss: 1.6382 - val_accuracy: 0.3445

Epoch 00024: val_loss did not improve from 1.63279
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5868 - accuracy: 0.3809 - val_loss: 1.6409 - val_accuracy: 0.3470

Epoch 00025: val_loss did not improve from 1.63279
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5840 - accuracy: 0.3831 - val_loss: 1.6431 - val_accuracy: 0.3496

Epoch 00026: val_loss did not improve from 1.63279
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5793 - accuracy: 0.3896 - val_loss: 1.6485 - val_accuracy: 0.3473

Epoch 00027: val_loss did not improve from 1.63279
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5735 - accuracy: 0.3942 - val_loss: 1.6553 - val_accuracy: 0.3473

Epoch 00028: val_loss did not improve from 1.63279
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5679 - accuracy: 0.4008 - val_loss: 1.6662 - val_accuracy: 0.3413

Epoch 00029: val_loss did not improve from 1.63279
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5670 - accuracy: 0.4034 - val_loss: 1.6686 - val_accuracy: 0.3479

Epoch 00030: val_loss did not improve from 1.63279
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 58s 4ms/step - loss: 1.6445 - accuracy: 0.3421
Testing Loss = 1.644483, Testing Accuracy = 0.342141
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.3256 - accuracy: 0.2016 - val_loss: 8.5881 - val_accuracy: 0.2071

Epoch 00001: val_loss improved from inf to 8.58806, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6464 - accuracy: 0.2604 - val_loss: 5.2995 - val_accuracy: 0.2779

Epoch 00002: val_loss improved from 8.58806 to 5.29948, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5144 - accuracy: 0.2876 - val_loss: 3.9462 - val_accuracy: 0.2907

Epoch 00003: val_loss improved from 5.29948 to 3.94617, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5351 - accuracy: 0.2973 - val_loss: 3.2074 - val_accuracy: 0.3057

Epoch 00004: val_loss improved from 3.94617 to 3.20744, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9548 - accuracy: 0.3101 - val_loss: 2.7323 - val_accuracy: 0.3140

Epoch 00005: val_loss improved from 3.20744 to 2.73226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5667 - accuracy: 0.3133 - val_loss: 2.4047 - val_accuracy: 0.3204

Epoch 00006: val_loss improved from 2.73226 to 2.40472, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2951 - accuracy: 0.3183 - val_loss: 2.1771 - val_accuracy: 0.3241

Epoch 00007: val_loss improved from 2.40472 to 2.17711, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0981 - accuracy: 0.3240 - val_loss: 2.0168 - val_accuracy: 0.3276

Epoch 00008: val_loss improved from 2.17711 to 2.01683, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9627 - accuracy: 0.3272 - val_loss: 1.9055 - val_accuracy: 0.3225

Epoch 00009: val_loss improved from 2.01683 to 1.90552, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8643 - accuracy: 0.3323 - val_loss: 1.8235 - val_accuracy: 0.3315

Epoch 00010: val_loss improved from 1.90552 to 1.82348, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7916 - accuracy: 0.3353 - val_loss: 1.7622 - val_accuracy: 0.3348

Epoch 00011: val_loss improved from 1.82348 to 1.76220, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7420 - accuracy: 0.3385 - val_loss: 1.7247 - val_accuracy: 0.3324

Epoch 00012: val_loss improved from 1.76220 to 1.72470, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7042 - accuracy: 0.3429 - val_loss: 1.6927 - val_accuracy: 0.3396

Epoch 00013: val_loss improved from 1.72470 to 1.69272, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6783 - accuracy: 0.3458 - val_loss: 1.6766 - val_accuracy: 0.3395

Epoch 00014: val_loss improved from 1.69272 to 1.67659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6584 - accuracy: 0.3475 - val_loss: 1.6627 - val_accuracy: 0.3419

Epoch 00015: val_loss improved from 1.67659 to 1.66269, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 16/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6429 - accuracy: 0.3519 - val_loss: 1.6496 - val_accuracy: 0.3471

Epoch 00016: val_loss improved from 1.66269 to 1.64964, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6307 - accuracy: 0.3550 - val_loss: 1.6443 - val_accuracy: 0.3448

Epoch 00017: val_loss improved from 1.64964 to 1.64431, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6223 - accuracy: 0.3595 - val_loss: 1.6359 - val_accuracy: 0.3479

Epoch 00018: val_loss improved from 1.64431 to 1.63588, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6152 - accuracy: 0.3615 - val_loss: 1.6371 - val_accuracy: 0.3459

Epoch 00019: val_loss did not improve from 1.63588
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6078 - accuracy: 0.3654 - val_loss: 1.6336 - val_accuracy: 0.3480

Epoch 00020: val_loss improved from 1.63588 to 1.63358, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/8
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6028 - accuracy: 0.3682 - val_loss: 1.6349 - val_accuracy: 0.3507

Epoch 00021: val_loss did not improve from 1.63358
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5980 - accuracy: 0.3691 - val_loss: 1.6357 - val_accuracy: 0.3492

Epoch 00022: val_loss did not improve from 1.63358
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5941 - accuracy: 0.3725 - val_loss: 1.6337 - val_accuracy: 0.3497

Epoch 00023: val_loss did not improve from 1.63358
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5907 - accuracy: 0.3765 - val_loss: 1.6385 - val_accuracy: 0.3499

Epoch 00024: val_loss did not improve from 1.63358
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5841 - accuracy: 0.3806 - val_loss: 1.6411 - val_accuracy: 0.3496

Epoch 00025: val_loss did not improve from 1.63358
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5806 - accuracy: 0.3856 - val_loss: 1.6449 - val_accuracy: 0.3533

Epoch 00026: val_loss did not improve from 1.63358
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5739 - accuracy: 0.3905 - val_loss: 1.6485 - val_accuracy: 0.3522

Epoch 00027: val_loss did not improve from 1.63358
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5740 - accuracy: 0.3914 - val_loss: 1.6551 - val_accuracy: 0.3521

Epoch 00028: val_loss did not improve from 1.63358
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5679 - accuracy: 0.3970 - val_loss: 1.6611 - val_accuracy: 0.3529

Epoch 00029: val_loss did not improve from 1.63358
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5672 - accuracy: 0.3999 - val_loss: 1.6763 - val_accuracy: 0.3455

Epoch 00030: val_loss did not improve from 1.63358
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 58s 4ms/step - loss: 1.6455 - accuracy: 0.3387
Testing Loss = 1.645544, Testing Accuracy = 0.338717
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 70ms/step - loss: 12.4063 - accuracy: 0.2078 - val_loss: 8.6824 - val_accuracy: 0.2142

Epoch 00001: val_loss improved from inf to 8.68237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7284 - accuracy: 0.2659 - val_loss: 5.3762 - val_accuracy: 0.2800

Epoch 00002: val_loss improved from 8.68237 to 5.37617, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5775 - accuracy: 0.2869 - val_loss: 3.9954 - val_accuracy: 0.2953

Epoch 00003: val_loss improved from 5.37617 to 3.99539, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5721 - accuracy: 0.2988 - val_loss: 3.2376 - val_accuracy: 0.3087

Epoch 00004: val_loss improved from 3.99539 to 3.23755, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 2.9805 - accuracy: 0.3053 - val_loss: 2.7523 - val_accuracy: 0.3155

Epoch 00005: val_loss improved from 3.23755 to 2.75230, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.5828 - accuracy: 0.3116 - val_loss: 2.4192 - val_accuracy: 0.3221

Epoch 00006: val_loss improved from 2.75230 to 2.41915, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3056 - accuracy: 0.3169 - val_loss: 2.1855 - val_accuracy: 0.3211

Epoch 00007: val_loss improved from 2.41915 to 2.18555, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1093 - accuracy: 0.3242 - val_loss: 2.0247 - val_accuracy: 0.3251

Epoch 00008: val_loss improved from 2.18555 to 2.02474, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9685 - accuracy: 0.3279 - val_loss: 1.9099 - val_accuracy: 0.3271

Epoch 00009: val_loss improved from 2.02474 to 1.90995, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8690 - accuracy: 0.3302 - val_loss: 1.8316 - val_accuracy: 0.3247

Epoch 00010: val_loss improved from 1.90995 to 1.83165, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7965 - accuracy: 0.3322 - val_loss: 1.7708 - val_accuracy: 0.3297

Epoch 00011: val_loss improved from 1.83165 to 1.77083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7454 - accuracy: 0.3365 - val_loss: 1.7310 - val_accuracy: 0.3325

Epoch 00012: val_loss improved from 1.77083 to 1.73099, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7073 - accuracy: 0.3407 - val_loss: 1.6979 - val_accuracy: 0.3398

Epoch 00013: val_loss improved from 1.73099 to 1.69795, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6795 - accuracy: 0.3440 - val_loss: 1.6809 - val_accuracy: 0.3380

Epoch 00014: val_loss improved from 1.69795 to 1.68090, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6609 - accuracy: 0.3474 - val_loss: 1.6630 - val_accuracy: 0.3427

Epoch 00015: val_loss improved from 1.68090 to 1.66297, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6450 - accuracy: 0.3515 - val_loss: 1.6531 - val_accuracy: 0.3436

Epoch 00016: val_loss improved from 1.66297 to 1.65311, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6324 - accuracy: 0.3530 - val_loss: 1.6472 - val_accuracy: 0.3470

Epoch 00017: val_loss improved from 1.65311 to 1.64723, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6241 - accuracy: 0.3568 - val_loss: 1.6428 - val_accuracy: 0.3477

Epoch 00018: val_loss improved from 1.64723 to 1.64283, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6168 - accuracy: 0.3584 - val_loss: 1.6362 - val_accuracy: 0.3507

Epoch 00019: val_loss improved from 1.64283 to 1.63616, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6078 - accuracy: 0.3642 - val_loss: 1.6369 - val_accuracy: 0.3501

Epoch 00020: val_loss did not improve from 1.63616
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6033 - accuracy: 0.3704 - val_loss: 1.6343 - val_accuracy: 0.3508

Epoch 00021: val_loss improved from 1.63616 to 1.63427, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r11/Try/9
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6000 - accuracy: 0.3689 - val_loss: 1.6381 - val_accuracy: 0.3491

Epoch 00022: val_loss did not improve from 1.63427
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5953 - accuracy: 0.3725 - val_loss: 1.6380 - val_accuracy: 0.3520

Epoch 00023: val_loss did not improve from 1.63427
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5906 - accuracy: 0.3761 - val_loss: 1.6468 - val_accuracy: 0.3454

Epoch 00024: val_loss did not improve from 1.63427
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5859 - accuracy: 0.3797 - val_loss: 1.6454 - val_accuracy: 0.3475

Epoch 00025: val_loss did not improve from 1.63427
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5805 - accuracy: 0.3868 - val_loss: 1.6461 - val_accuracy: 0.3495

Epoch 00026: val_loss did not improve from 1.63427
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5757 - accuracy: 0.3895 - val_loss: 1.6513 - val_accuracy: 0.3497

Epoch 00027: val_loss did not improve from 1.63427
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5740 - accuracy: 0.3964 - val_loss: 1.6584 - val_accuracy: 0.3487

Epoch 00028: val_loss did not improve from 1.63427
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5668 - accuracy: 0.4008 - val_loss: 1.6625 - val_accuracy: 0.3482

Epoch 00029: val_loss did not improve from 1.63427
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5608 - accuracy: 0.4061 - val_loss: 1.6704 - val_accuracy: 0.3478

Epoch 00030: val_loss did not improve from 1.63427
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5577 - accuracy: 0.4094 - val_loss: 1.6798 - val_accuracy: 0.3443

Epoch 00031: val_loss did not improve from 1.63427
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6437 - accuracy: 0.3409
Testing Loss = 1.643714, Testing Accuracy = 0.340875
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 81.58 +- 0.0452 %)
$W^-/W^-$ (auc = 80.95 +- 0.0772 %)
$Z/Z$ (auc = 66.90 +- 0.1425 %)
$W^+/W^-$ (auc = 66.04 +- 0.1585 %)
$W^+/Z$$ (auc = 65.82 +- 0.1012 %)
$W^-/Z$ (auc = 67.20 +- 0.0839 %)
The summarized testing accuracy = 33.98 +- 0.1787 %, with the loss = 1.6455 +- 0.002527
