

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-27 11:46:53.502437
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 4s 16ms/step - loss: 9.1938 - accuracy: 0.1965 - val_loss: 8.0971 - val_accuracy: 0.2178

Epoch 00001: val_loss improved from inf to 8.09709, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 2/100
83/83 [==============================] - 1s 14ms/step - loss: 7.1940 - accuracy: 0.2206 - val_loss: 6.3484 - val_accuracy: 0.2479

Epoch 00002: val_loss improved from 8.09709 to 6.34839, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 3/100
83/83 [==============================] - 1s 13ms/step - loss: 5.6546 - accuracy: 0.2624 - val_loss: 5.0469 - val_accuracy: 0.2863

Epoch 00003: val_loss improved from 6.34839 to 5.04685, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 4/100
83/83 [==============================] - 1s 13ms/step - loss: 4.5531 - accuracy: 0.2810 - val_loss: 4.0978 - val_accuracy: 0.2957

Epoch 00004: val_loss improved from 5.04685 to 4.09777, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 5/100
83/83 [==============================] - 1s 13ms/step - loss: 3.7449 - accuracy: 0.2852 - val_loss: 3.4016 - val_accuracy: 0.3045

Epoch 00005: val_loss improved from 4.09777 to 3.40156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 6/100
83/83 [==============================] - 1s 14ms/step - loss: 3.1489 - accuracy: 0.2903 - val_loss: 2.8925 - val_accuracy: 0.3035

Epoch 00006: val_loss improved from 3.40156 to 2.89245, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 7/100
83/83 [==============================] - 1s 13ms/step - loss: 2.7139 - accuracy: 0.2930 - val_loss: 2.5235 - val_accuracy: 0.3023

Epoch 00007: val_loss improved from 2.89245 to 2.52349, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 8/100
83/83 [==============================] - 1s 14ms/step - loss: 2.3984 - accuracy: 0.2948 - val_loss: 2.2576 - val_accuracy: 0.3032

Epoch 00008: val_loss improved from 2.52349 to 2.25757, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 9/100
83/83 [==============================] - 1s 13ms/step - loss: 2.1706 - accuracy: 0.2966 - val_loss: 2.0681 - val_accuracy: 0.3014

Epoch 00009: val_loss improved from 2.25757 to 2.06812, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 10/100
83/83 [==============================] - 1s 13ms/step - loss: 2.0082 - accuracy: 0.2991 - val_loss: 1.9331 - val_accuracy: 0.3049

Epoch 00010: val_loss improved from 2.06812 to 1.93306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 11/100
83/83 [==============================] - 1s 13ms/step - loss: 1.8928 - accuracy: 0.3013 - val_loss: 1.8390 - val_accuracy: 0.3021

Epoch 00011: val_loss improved from 1.93306 to 1.83903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 12/100
83/83 [==============================] - 1s 13ms/step - loss: 1.8123 - accuracy: 0.3016 - val_loss: 1.7733 - val_accuracy: 0.3050

Epoch 00012: val_loss improved from 1.83903 to 1.77329, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 13/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7539 - accuracy: 0.3053 - val_loss: 1.7279 - val_accuracy: 0.3061

Epoch 00013: val_loss improved from 1.77329 to 1.72793, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 14/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7158 - accuracy: 0.3078 - val_loss: 1.6968 - val_accuracy: 0.3053

Epoch 00014: val_loss improved from 1.72793 to 1.69680, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 15/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6876 - accuracy: 0.3060 - val_loss: 1.6767 - val_accuracy: 0.3046

Epoch 00015: val_loss improved from 1.69680 to 1.67673, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 16/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6676 - accuracy: 0.3098 - val_loss: 1.6615 - val_accuracy: 0.3054

Epoch 00016: val_loss improved from 1.67673 to 1.66152, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 17/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6544 - accuracy: 0.3081 - val_loss: 1.6513 - val_accuracy: 0.3043

Epoch 00017: val_loss improved from 1.66152 to 1.65131, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 18/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6436 - accuracy: 0.3097 - val_loss: 1.6440 - val_accuracy: 0.3053

Epoch 00018: val_loss improved from 1.65131 to 1.64397, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 19/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6352 - accuracy: 0.3107 - val_loss: 1.6385 - val_accuracy: 0.3054

Epoch 00019: val_loss improved from 1.64397 to 1.63851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 20/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6291 - accuracy: 0.3140 - val_loss: 1.6353 - val_accuracy: 0.3044

Epoch 00020: val_loss improved from 1.63851 to 1.63529, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 21/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6235 - accuracy: 0.3143 - val_loss: 1.6326 - val_accuracy: 0.3070

Epoch 00021: val_loss improved from 1.63529 to 1.63263, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 22/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6200 - accuracy: 0.3173 - val_loss: 1.6314 - val_accuracy: 0.3049

Epoch 00022: val_loss improved from 1.63263 to 1.63144, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 23/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6161 - accuracy: 0.3141 - val_loss: 1.6306 - val_accuracy: 0.3053

Epoch 00023: val_loss improved from 1.63144 to 1.63063, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 24/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6116 - accuracy: 0.3197 - val_loss: 1.6298 - val_accuracy: 0.3068

Epoch 00024: val_loss improved from 1.63063 to 1.62975, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/0
Epoch 25/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6076 - accuracy: 0.3165 - val_loss: 1.6302 - val_accuracy: 0.3052

Epoch 00025: val_loss did not improve from 1.62975
Epoch 26/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6040 - accuracy: 0.3220 - val_loss: 1.6323 - val_accuracy: 0.3061

Epoch 00026: val_loss did not improve from 1.62975
Epoch 27/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5982 - accuracy: 0.3252 - val_loss: 1.6350 - val_accuracy: 0.3021

Epoch 00027: val_loss did not improve from 1.62975
Epoch 28/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5931 - accuracy: 0.3258 - val_loss: 1.6398 - val_accuracy: 0.2987

Epoch 00028: val_loss did not improve from 1.62975
Epoch 29/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5891 - accuracy: 0.3288 - val_loss: 1.6415 - val_accuracy: 0.2977

Epoch 00029: val_loss did not improve from 1.62975
Epoch 30/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5828 - accuracy: 0.3302 - val_loss: 1.6417 - val_accuracy: 0.2999

Epoch 00030: val_loss did not improve from 1.62975
Epoch 31/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5774 - accuracy: 0.3373 - val_loss: 1.6455 - val_accuracy: 0.2979

Epoch 00031: val_loss did not improve from 1.62975
Epoch 32/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5709 - accuracy: 0.3397 - val_loss: 1.6525 - val_accuracy: 0.2994

Epoch 00032: val_loss did not improve from 1.62975
Epoch 33/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5645 - accuracy: 0.3439 - val_loss: 1.6598 - val_accuracy: 0.2957

Epoch 00033: val_loss did not improve from 1.62975
Epoch 34/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5572 - accuracy: 0.3485 - val_loss: 1.6709 - val_accuracy: 0.2937

Epoch 00034: val_loss did not improve from 1.62975
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               1642152   [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 1,645,230[0m
[92mTrainable params: 1,645,226[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 15, 15, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 15, 15, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 15, 15, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 7, 7, 32)          0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 7, 7, 128)         65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 3, 3, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 3, 3, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 256)               0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               131584    [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 1,642,152[0m
[94mTrainable params: 1,642,148[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 15, 15, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 52s 4ms/step - loss: 1.6340 - accuracy: 0.3065
Testing Loss = 1.634040, Testing Accuracy = 0.306490
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 15ms/step - loss: 9.2030 - accuracy: 0.2007 - val_loss: 8.1106 - val_accuracy: 0.2178

Epoch 00001: val_loss improved from inf to 8.11056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 2/100
83/83 [==============================] - 1s 12ms/step - loss: 7.1897 - accuracy: 0.2406 - val_loss: 6.3553 - val_accuracy: 0.2671

Epoch 00002: val_loss improved from 8.11056 to 6.35525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 3/100
83/83 [==============================] - 1s 12ms/step - loss: 5.6794 - accuracy: 0.2713 - val_loss: 5.0758 - val_accuracy: 0.2852

Epoch 00003: val_loss improved from 6.35525 to 5.07575, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 4/100
83/83 [==============================] - 1s 12ms/step - loss: 4.5825 - accuracy: 0.2810 - val_loss: 4.1266 - val_accuracy: 0.2976

Epoch 00004: val_loss improved from 5.07575 to 4.12664, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 5/100
83/83 [==============================] - 1s 13ms/step - loss: 3.7717 - accuracy: 0.2881 - val_loss: 3.4269 - val_accuracy: 0.3007

Epoch 00005: val_loss improved from 4.12664 to 3.42688, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 6/100
83/83 [==============================] - 1s 12ms/step - loss: 3.1727 - accuracy: 0.2892 - val_loss: 2.9128 - val_accuracy: 0.3013

Epoch 00006: val_loss improved from 3.42688 to 2.91283, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 7/100
83/83 [==============================] - 1s 12ms/step - loss: 2.7337 - accuracy: 0.2922 - val_loss: 2.5394 - val_accuracy: 0.3047

Epoch 00007: val_loss improved from 2.91283 to 2.53941, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 8/100
83/83 [==============================] - 1s 13ms/step - loss: 2.4128 - accuracy: 0.2930 - val_loss: 2.2698 - val_accuracy: 0.3055

Epoch 00008: val_loss improved from 2.53941 to 2.26984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 9/100
83/83 [==============================] - 1s 13ms/step - loss: 2.1825 - accuracy: 0.2972 - val_loss: 2.0767 - val_accuracy: 0.3072

Epoch 00009: val_loss improved from 2.26984 to 2.07670, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 10/100
83/83 [==============================] - 1s 13ms/step - loss: 2.0168 - accuracy: 0.3002 - val_loss: 1.9393 - val_accuracy: 0.3086

Epoch 00010: val_loss improved from 2.07670 to 1.93930, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 11/100
83/83 [==============================] - 1s 13ms/step - loss: 1.8988 - accuracy: 0.3022 - val_loss: 1.8439 - val_accuracy: 0.3075

Epoch 00011: val_loss improved from 1.93930 to 1.84386, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 12/100
83/83 [==============================] - 1s 13ms/step - loss: 1.8163 - accuracy: 0.3013 - val_loss: 1.7759 - val_accuracy: 0.3076

Epoch 00012: val_loss improved from 1.84386 to 1.77593, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 13/100
83/83 [==============================] - 1s 12ms/step - loss: 1.7589 - accuracy: 0.3031 - val_loss: 1.7305 - val_accuracy: 0.3078

Epoch 00013: val_loss improved from 1.77593 to 1.73046, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 14/100
83/83 [==============================] - 1s 12ms/step - loss: 1.7192 - accuracy: 0.3060 - val_loss: 1.6979 - val_accuracy: 0.3071

Epoch 00014: val_loss improved from 1.73046 to 1.69788, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 15/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6924 - accuracy: 0.3063 - val_loss: 1.6761 - val_accuracy: 0.3080

Epoch 00015: val_loss improved from 1.69788 to 1.67606, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 16/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6701 - accuracy: 0.3074 - val_loss: 1.6605 - val_accuracy: 0.3075

Epoch 00016: val_loss improved from 1.67606 to 1.66050, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 17/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6559 - accuracy: 0.3086 - val_loss: 1.6496 - val_accuracy: 0.3089

Epoch 00017: val_loss improved from 1.66050 to 1.64956, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 18/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6454 - accuracy: 0.3078 - val_loss: 1.6427 - val_accuracy: 0.3063

Epoch 00018: val_loss improved from 1.64956 to 1.64266, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 19/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6370 - accuracy: 0.3132 - val_loss: 1.6367 - val_accuracy: 0.3101

Epoch 00019: val_loss improved from 1.64266 to 1.63666, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 20/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6316 - accuracy: 0.3117 - val_loss: 1.6325 - val_accuracy: 0.3108

Epoch 00020: val_loss improved from 1.63666 to 1.63245, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 21/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6254 - accuracy: 0.3177 - val_loss: 1.6296 - val_accuracy: 0.3119

Epoch 00021: val_loss improved from 1.63245 to 1.62955, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 22/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6201 - accuracy: 0.3200 - val_loss: 1.6249 - val_accuracy: 0.3131

Epoch 00022: val_loss improved from 1.62955 to 1.62486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 23/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6158 - accuracy: 0.3228 - val_loss: 1.6213 - val_accuracy: 0.3196

Epoch 00023: val_loss improved from 1.62486 to 1.62125, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 24/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6099 - accuracy: 0.3280 - val_loss: 1.6190 - val_accuracy: 0.3202

Epoch 00024: val_loss improved from 1.62125 to 1.61897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 25/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6053 - accuracy: 0.3312 - val_loss: 1.6169 - val_accuracy: 0.3229

Epoch 00025: val_loss improved from 1.61897 to 1.61691, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 26/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6010 - accuracy: 0.3365 - val_loss: 1.6163 - val_accuracy: 0.3227

Epoch 00026: val_loss improved from 1.61691 to 1.61628, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/1
Epoch 27/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5976 - accuracy: 0.3357 - val_loss: 1.6164 - val_accuracy: 0.3262

Epoch 00027: val_loss did not improve from 1.61628
Epoch 28/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5908 - accuracy: 0.3400 - val_loss: 1.6178 - val_accuracy: 0.3252

Epoch 00028: val_loss did not improve from 1.61628
Epoch 29/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5860 - accuracy: 0.3420 - val_loss: 1.6217 - val_accuracy: 0.3237

Epoch 00029: val_loss did not improve from 1.61628
Epoch 30/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5827 - accuracy: 0.3436 - val_loss: 1.6243 - val_accuracy: 0.3230

Epoch 00030: val_loss did not improve from 1.61628
Epoch 31/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5775 - accuracy: 0.3474 - val_loss: 1.6275 - val_accuracy: 0.3194

Epoch 00031: val_loss did not improve from 1.61628
Epoch 32/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5716 - accuracy: 0.3492 - val_loss: 1.6239 - val_accuracy: 0.3269

Epoch 00032: val_loss did not improve from 1.61628
Epoch 33/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5659 - accuracy: 0.3571 - val_loss: 1.6257 - val_accuracy: 0.3265

Epoch 00033: val_loss did not improve from 1.61628
Epoch 34/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5593 - accuracy: 0.3584 - val_loss: 1.6315 - val_accuracy: 0.3225

Epoch 00034: val_loss did not improve from 1.61628
Epoch 35/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5536 - accuracy: 0.3634 - val_loss: 1.6369 - val_accuracy: 0.3206

Epoch 00035: val_loss did not improve from 1.61628
Epoch 36/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5476 - accuracy: 0.3660 - val_loss: 1.6418 - val_accuracy: 0.3215

Epoch 00036: val_loss did not improve from 1.61628
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               1642152   [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 1,645,230[0m
[92mTrainable params: 1,645,226[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 15, 15, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 15, 15, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 15, 15, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 7, 7, 32)          0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 7, 7, 128)         65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 3, 3, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 3, 3, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 256)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               131584    [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 1,642,152[0m
[94mTrainable params: 1,642,148[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 15, 15, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 52s 4ms/step - loss: 1.6231 - accuracy: 0.3218
Testing Loss = 1.623130, Testing Accuracy = 0.321822
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 14ms/step - loss: 9.1937 - accuracy: 0.2001 - val_loss: 8.0998 - val_accuracy: 0.2178

Epoch 00001: val_loss improved from inf to 8.09980, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 2/100
83/83 [==============================] - 1s 13ms/step - loss: 7.1787 - accuracy: 0.2368 - val_loss: 6.3479 - val_accuracy: 0.2513

Epoch 00002: val_loss improved from 8.09980 to 6.34789, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 3/100
83/83 [==============================] - 1s 12ms/step - loss: 5.6651 - accuracy: 0.2693 - val_loss: 5.0628 - val_accuracy: 0.2863

Epoch 00003: val_loss improved from 6.34789 to 5.06277, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 4/100
83/83 [==============================] - 1s 13ms/step - loss: 4.5698 - accuracy: 0.2806 - val_loss: 4.1149 - val_accuracy: 0.2974

Epoch 00004: val_loss improved from 5.06277 to 4.11493, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 5/100
83/83 [==============================] - 1s 12ms/step - loss: 3.7598 - accuracy: 0.2862 - val_loss: 3.4154 - val_accuracy: 0.2990

Epoch 00005: val_loss improved from 4.11493 to 3.41543, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 6/100
83/83 [==============================] - 1s 12ms/step - loss: 3.1626 - accuracy: 0.2887 - val_loss: 2.9031 - val_accuracy: 0.3006

Epoch 00006: val_loss improved from 3.41543 to 2.90313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 7/100
83/83 [==============================] - 1s 12ms/step - loss: 2.7231 - accuracy: 0.2938 - val_loss: 2.5319 - val_accuracy: 0.3033

Epoch 00007: val_loss improved from 2.90313 to 2.53188, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 8/100
83/83 [==============================] - 1s 13ms/step - loss: 2.4045 - accuracy: 0.2977 - val_loss: 2.2634 - val_accuracy: 0.3045

Epoch 00008: val_loss improved from 2.53188 to 2.26344, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 9/100
83/83 [==============================] - 1s 13ms/step - loss: 2.1749 - accuracy: 0.2971 - val_loss: 2.0724 - val_accuracy: 0.3057

Epoch 00009: val_loss improved from 2.26344 to 2.07237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 10/100
83/83 [==============================] - 1s 13ms/step - loss: 2.0111 - accuracy: 0.2995 - val_loss: 1.9365 - val_accuracy: 0.3060

Epoch 00010: val_loss improved from 2.07237 to 1.93654, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 11/100
83/83 [==============================] - 1s 13ms/step - loss: 1.8943 - accuracy: 0.3014 - val_loss: 1.8411 - val_accuracy: 0.3059

Epoch 00011: val_loss improved from 1.93654 to 1.84109, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 12/100
83/83 [==============================] - 1s 13ms/step - loss: 1.8126 - accuracy: 0.3028 - val_loss: 1.7749 - val_accuracy: 0.3055

Epoch 00012: val_loss improved from 1.84109 to 1.77488, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 13/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7560 - accuracy: 0.3037 - val_loss: 1.7297 - val_accuracy: 0.3052

Epoch 00013: val_loss improved from 1.77488 to 1.72971, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 14/100
83/83 [==============================] - 1s 14ms/step - loss: 1.7163 - accuracy: 0.3078 - val_loss: 1.6982 - val_accuracy: 0.3048

Epoch 00014: val_loss improved from 1.72971 to 1.69816, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 15/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6893 - accuracy: 0.3072 - val_loss: 1.6760 - val_accuracy: 0.3068

Epoch 00015: val_loss improved from 1.69816 to 1.67603, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 16/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6685 - accuracy: 0.3070 - val_loss: 1.6613 - val_accuracy: 0.3068

Epoch 00016: val_loss improved from 1.67603 to 1.66126, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 17/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6545 - accuracy: 0.3104 - val_loss: 1.6511 - val_accuracy: 0.3067

Epoch 00017: val_loss improved from 1.66126 to 1.65109, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 18/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6445 - accuracy: 0.3091 - val_loss: 1.6436 - val_accuracy: 0.3065

Epoch 00018: val_loss improved from 1.65109 to 1.64359, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 19/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6361 - accuracy: 0.3126 - val_loss: 1.6383 - val_accuracy: 0.3063

Epoch 00019: val_loss improved from 1.64359 to 1.63829, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 20/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6302 - accuracy: 0.3140 - val_loss: 1.6348 - val_accuracy: 0.3048

Epoch 00020: val_loss improved from 1.63829 to 1.63482, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 21/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6258 - accuracy: 0.3145 - val_loss: 1.6324 - val_accuracy: 0.3060

Epoch 00021: val_loss improved from 1.63482 to 1.63237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 22/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6220 - accuracy: 0.3129 - val_loss: 1.6314 - val_accuracy: 0.3054

Epoch 00022: val_loss improved from 1.63237 to 1.63140, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 23/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6169 - accuracy: 0.3145 - val_loss: 1.6292 - val_accuracy: 0.3050

Epoch 00023: val_loss improved from 1.63140 to 1.62916, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 24/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6129 - accuracy: 0.3181 - val_loss: 1.6285 - val_accuracy: 0.3042

Epoch 00024: val_loss improved from 1.62916 to 1.62853, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 25/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6107 - accuracy: 0.3176 - val_loss: 1.6283 - val_accuracy: 0.3058

Epoch 00025: val_loss improved from 1.62853 to 1.62828, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/2
Epoch 26/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6063 - accuracy: 0.3206 - val_loss: 1.6283 - val_accuracy: 0.3092

Epoch 00026: val_loss did not improve from 1.62828
Epoch 27/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6028 - accuracy: 0.3218 - val_loss: 1.6298 - val_accuracy: 0.3046

Epoch 00027: val_loss did not improve from 1.62828
Epoch 28/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5968 - accuracy: 0.3240 - val_loss: 1.6331 - val_accuracy: 0.3054

Epoch 00028: val_loss did not improve from 1.62828
Epoch 29/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5951 - accuracy: 0.3265 - val_loss: 1.6383 - val_accuracy: 0.3021

Epoch 00029: val_loss did not improve from 1.62828
Epoch 30/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5888 - accuracy: 0.3275 - val_loss: 1.6407 - val_accuracy: 0.3038

Epoch 00030: val_loss did not improve from 1.62828
Epoch 31/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5836 - accuracy: 0.3328 - val_loss: 1.6374 - val_accuracy: 0.3018

Epoch 00031: val_loss did not improve from 1.62828
Epoch 32/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5782 - accuracy: 0.3349 - val_loss: 1.6411 - val_accuracy: 0.3015

Epoch 00032: val_loss did not improve from 1.62828
Epoch 33/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5719 - accuracy: 0.3370 - val_loss: 1.6464 - val_accuracy: 0.2992

Epoch 00033: val_loss did not improve from 1.62828
Epoch 34/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5661 - accuracy: 0.3427 - val_loss: 1.6580 - val_accuracy: 0.2971

Epoch 00034: val_loss did not improve from 1.62828
Epoch 35/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5590 - accuracy: 0.3463 - val_loss: 1.6636 - val_accuracy: 0.2955

Epoch 00035: val_loss did not improve from 1.62828
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               1642152   [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 1,645,230[0m
[92mTrainable params: 1,645,226[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 15, 15, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 15, 15, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 15, 15, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 7, 7, 32)          0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 7, 7, 128)         65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 3, 3, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 3, 3, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 256)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               131584    [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 1,642,152[0m
[94mTrainable params: 1,642,148[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 15, 15, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 51s 4ms/step - loss: 1.6349 - accuracy: 0.3031
Testing Loss = 1.634876, Testing Accuracy = 0.303141
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 9.1996 - accuracy: 0.1971 - val_loss: 8.1055 - val_accuracy: 0.2178

Epoch 00001: val_loss improved from inf to 8.10549, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 2/100
83/83 [==============================] - 1s 13ms/step - loss: 7.1900 - accuracy: 0.2325 - val_loss: 6.3492 - val_accuracy: 0.2611

Epoch 00002: val_loss improved from 8.10549 to 6.34925, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 3/100
83/83 [==============================] - 1s 14ms/step - loss: 5.6635 - accuracy: 0.2723 - val_loss: 5.0612 - val_accuracy: 0.2931

Epoch 00003: val_loss improved from 6.34925 to 5.06121, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 4/100
83/83 [==============================] - 1s 13ms/step - loss: 4.5705 - accuracy: 0.2795 - val_loss: 4.1157 - val_accuracy: 0.3022

Epoch 00004: val_loss improved from 5.06121 to 4.11574, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 5/100
83/83 [==============================] - 1s 12ms/step - loss: 3.7618 - accuracy: 0.2885 - val_loss: 3.4176 - val_accuracy: 0.3019

Epoch 00005: val_loss improved from 4.11574 to 3.41764, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 6/100
83/83 [==============================] - 1s 13ms/step - loss: 3.1645 - accuracy: 0.2880 - val_loss: 2.9059 - val_accuracy: 0.3029

Epoch 00006: val_loss improved from 3.41764 to 2.90591, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 7/100
83/83 [==============================] - 1s 14ms/step - loss: 2.7247 - accuracy: 0.2936 - val_loss: 2.5338 - val_accuracy: 0.3045

Epoch 00007: val_loss improved from 2.90591 to 2.53381, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 8/100
83/83 [==============================] - 1s 13ms/step - loss: 2.4054 - accuracy: 0.2933 - val_loss: 2.2652 - val_accuracy: 0.3062

Epoch 00008: val_loss improved from 2.53381 to 2.26517, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 9/100
83/83 [==============================] - 1s 12ms/step - loss: 2.1770 - accuracy: 0.2969 - val_loss: 2.0732 - val_accuracy: 0.3066

Epoch 00009: val_loss improved from 2.26517 to 2.07318, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 10/100
83/83 [==============================] - 1s 14ms/step - loss: 2.0137 - accuracy: 0.2995 - val_loss: 1.9376 - val_accuracy: 0.3065

Epoch 00010: val_loss improved from 2.07318 to 1.93759, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 11/100
83/83 [==============================] - 1s 14ms/step - loss: 1.8962 - accuracy: 0.3013 - val_loss: 1.8418 - val_accuracy: 0.3067

Epoch 00011: val_loss improved from 1.93759 to 1.84183, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 12/100
83/83 [==============================] - 1s 14ms/step - loss: 1.8149 - accuracy: 0.3026 - val_loss: 1.7757 - val_accuracy: 0.3073

Epoch 00012: val_loss improved from 1.84183 to 1.77567, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 13/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7560 - accuracy: 0.3040 - val_loss: 1.7295 - val_accuracy: 0.3077

Epoch 00013: val_loss improved from 1.77567 to 1.72952, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 14/100
83/83 [==============================] - 1s 14ms/step - loss: 1.7171 - accuracy: 0.3052 - val_loss: 1.6984 - val_accuracy: 0.3073

Epoch 00014: val_loss improved from 1.72952 to 1.69843, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 15/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6885 - accuracy: 0.3069 - val_loss: 1.6759 - val_accuracy: 0.3098

Epoch 00015: val_loss improved from 1.69843 to 1.67590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 16/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6696 - accuracy: 0.3070 - val_loss: 1.6608 - val_accuracy: 0.3092

Epoch 00016: val_loss improved from 1.67590 to 1.66078, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 17/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6557 - accuracy: 0.3091 - val_loss: 1.6506 - val_accuracy: 0.3082

Epoch 00017: val_loss improved from 1.66078 to 1.65057, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 18/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6433 - accuracy: 0.3129 - val_loss: 1.6435 - val_accuracy: 0.3089

Epoch 00018: val_loss improved from 1.65057 to 1.64352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 19/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6368 - accuracy: 0.3107 - val_loss: 1.6382 - val_accuracy: 0.3068

Epoch 00019: val_loss improved from 1.64352 to 1.63825, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 20/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6295 - accuracy: 0.3137 - val_loss: 1.6341 - val_accuracy: 0.3063

Epoch 00020: val_loss improved from 1.63825 to 1.63415, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 21/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6256 - accuracy: 0.3129 - val_loss: 1.6313 - val_accuracy: 0.3082

Epoch 00021: val_loss improved from 1.63415 to 1.63129, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 22/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6208 - accuracy: 0.3183 - val_loss: 1.6300 - val_accuracy: 0.3076

Epoch 00022: val_loss improved from 1.63129 to 1.63003, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 23/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6156 - accuracy: 0.3185 - val_loss: 1.6273 - val_accuracy: 0.3103

Epoch 00023: val_loss improved from 1.63003 to 1.62726, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 24/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6117 - accuracy: 0.3218 - val_loss: 1.6252 - val_accuracy: 0.3139

Epoch 00024: val_loss improved from 1.62726 to 1.62518, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 25/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6075 - accuracy: 0.3250 - val_loss: 1.6243 - val_accuracy: 0.3133

Epoch 00025: val_loss improved from 1.62518 to 1.62434, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 26/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6027 - accuracy: 0.3293 - val_loss: 1.6232 - val_accuracy: 0.3181

Epoch 00026: val_loss improved from 1.62434 to 1.62321, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/3
Epoch 27/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5980 - accuracy: 0.3330 - val_loss: 1.6237 - val_accuracy: 0.3154

Epoch 00027: val_loss did not improve from 1.62321
Epoch 28/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5925 - accuracy: 0.3369 - val_loss: 1.6258 - val_accuracy: 0.3166

Epoch 00028: val_loss did not improve from 1.62321
Epoch 29/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5873 - accuracy: 0.3393 - val_loss: 1.6294 - val_accuracy: 0.3147

Epoch 00029: val_loss did not improve from 1.62321
Epoch 30/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5807 - accuracy: 0.3417 - val_loss: 1.6305 - val_accuracy: 0.3175

Epoch 00030: val_loss did not improve from 1.62321
Epoch 31/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5769 - accuracy: 0.3441 - val_loss: 1.6291 - val_accuracy: 0.3195

Epoch 00031: val_loss did not improve from 1.62321
Epoch 32/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5696 - accuracy: 0.3502 - val_loss: 1.6340 - val_accuracy: 0.3201

Epoch 00032: val_loss did not improve from 1.62321
Epoch 33/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5629 - accuracy: 0.3556 - val_loss: 1.6404 - val_accuracy: 0.3187

Epoch 00033: val_loss did not improve from 1.62321
Epoch 34/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5555 - accuracy: 0.3588 - val_loss: 1.6488 - val_accuracy: 0.3149

Epoch 00034: val_loss did not improve from 1.62321
Epoch 35/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5489 - accuracy: 0.3643 - val_loss: 1.6576 - val_accuracy: 0.3107

Epoch 00035: val_loss did not improve from 1.62321
Epoch 36/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5415 - accuracy: 0.3663 - val_loss: 1.6656 - val_accuracy: 0.3095

Epoch 00036: val_loss did not improve from 1.62321
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               1642152   [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 1,645,230[0m
[92mTrainable params: 1,645,226[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 15, 15, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 15, 15, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 15, 15, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 7, 7, 32)          0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 7, 7, 128)         65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 3, 3, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 3, 3, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 256)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               131584    [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 1,642,152[0m
[94mTrainable params: 1,642,148[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 15, 15, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 51s 4ms/step - loss: 1.6313 - accuracy: 0.3133
Testing Loss = 1.631285, Testing Accuracy = 0.313263
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 13ms/step - loss: 9.2127 - accuracy: 0.2009 - val_loss: 8.1176 - val_accuracy: 0.2177

Epoch 00001: val_loss improved from inf to 8.11762, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 2/100
83/83 [==============================] - 1s 13ms/step - loss: 7.1934 - accuracy: 0.2372 - val_loss: 6.3610 - val_accuracy: 0.2656

Epoch 00002: val_loss improved from 8.11762 to 6.36099, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 3/100
83/83 [==============================] - 1s 13ms/step - loss: 5.6816 - accuracy: 0.2707 - val_loss: 5.0789 - val_accuracy: 0.2863

Epoch 00003: val_loss improved from 6.36099 to 5.07888, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 4/100
83/83 [==============================] - 1s 13ms/step - loss: 4.5838 - accuracy: 0.2798 - val_loss: 4.1268 - val_accuracy: 0.2972

Epoch 00004: val_loss improved from 5.07888 to 4.12684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 5/100
83/83 [==============================] - 1s 12ms/step - loss: 3.7740 - accuracy: 0.2852 - val_loss: 3.4278 - val_accuracy: 0.3028

Epoch 00005: val_loss improved from 4.12684 to 3.42785, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 6/100
83/83 [==============================] - 1s 12ms/step - loss: 3.1720 - accuracy: 0.2902 - val_loss: 2.9133 - val_accuracy: 0.3036

Epoch 00006: val_loss improved from 3.42785 to 2.91325, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 7/100
83/83 [==============================] - 1s 12ms/step - loss: 2.7327 - accuracy: 0.2944 - val_loss: 2.5398 - val_accuracy: 0.3021

Epoch 00007: val_loss improved from 2.91325 to 2.53982, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 8/100
83/83 [==============================] - 1s 12ms/step - loss: 2.4116 - accuracy: 0.2965 - val_loss: 2.2701 - val_accuracy: 0.3047

Epoch 00008: val_loss improved from 2.53982 to 2.27013, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 9/100
83/83 [==============================] - 1s 13ms/step - loss: 2.1811 - accuracy: 0.2992 - val_loss: 2.0778 - val_accuracy: 0.3057

Epoch 00009: val_loss improved from 2.27013 to 2.07777, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 10/100
83/83 [==============================] - 1s 12ms/step - loss: 2.0164 - accuracy: 0.3000 - val_loss: 1.9410 - val_accuracy: 0.3053

Epoch 00010: val_loss improved from 2.07777 to 1.94098, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 11/100
83/83 [==============================] - 1s 13ms/step - loss: 1.8981 - accuracy: 0.3005 - val_loss: 1.8444 - val_accuracy: 0.3072

Epoch 00011: val_loss improved from 1.94098 to 1.84443, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 12/100
83/83 [==============================] - 1s 12ms/step - loss: 1.8162 - accuracy: 0.3025 - val_loss: 1.7786 - val_accuracy: 0.3077

Epoch 00012: val_loss improved from 1.84443 to 1.77856, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 13/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7591 - accuracy: 0.3041 - val_loss: 1.7321 - val_accuracy: 0.3090

Epoch 00013: val_loss improved from 1.77856 to 1.73212, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 14/100
83/83 [==============================] - 1s 12ms/step - loss: 1.7200 - accuracy: 0.3036 - val_loss: 1.7001 - val_accuracy: 0.3109

Epoch 00014: val_loss improved from 1.73212 to 1.70008, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 15/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6903 - accuracy: 0.3071 - val_loss: 1.6779 - val_accuracy: 0.3104

Epoch 00015: val_loss improved from 1.70008 to 1.67794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 16/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6705 - accuracy: 0.3054 - val_loss: 1.6630 - val_accuracy: 0.3106

Epoch 00016: val_loss improved from 1.67794 to 1.66297, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 17/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6567 - accuracy: 0.3074 - val_loss: 1.6520 - val_accuracy: 0.3109

Epoch 00017: val_loss improved from 1.66297 to 1.65200, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 18/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6457 - accuracy: 0.3093 - val_loss: 1.6457 - val_accuracy: 0.3107

Epoch 00018: val_loss improved from 1.65200 to 1.64565, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 19/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6374 - accuracy: 0.3100 - val_loss: 1.6400 - val_accuracy: 0.3093

Epoch 00019: val_loss improved from 1.64565 to 1.64001, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 20/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6321 - accuracy: 0.3123 - val_loss: 1.6361 - val_accuracy: 0.3099

Epoch 00020: val_loss improved from 1.64001 to 1.63606, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 21/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6263 - accuracy: 0.3109 - val_loss: 1.6338 - val_accuracy: 0.3105

Epoch 00021: val_loss improved from 1.63606 to 1.63380, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 22/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6214 - accuracy: 0.3129 - val_loss: 1.6320 - val_accuracy: 0.3084

Epoch 00022: val_loss improved from 1.63380 to 1.63202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 23/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6190 - accuracy: 0.3138 - val_loss: 1.6312 - val_accuracy: 0.3080

Epoch 00023: val_loss improved from 1.63202 to 1.63115, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 24/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6154 - accuracy: 0.3134 - val_loss: 1.6303 - val_accuracy: 0.3100

Epoch 00024: val_loss improved from 1.63115 to 1.63025, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 25/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6111 - accuracy: 0.3178 - val_loss: 1.6301 - val_accuracy: 0.3068

Epoch 00025: val_loss improved from 1.63025 to 1.63009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/4
Epoch 26/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6075 - accuracy: 0.3198 - val_loss: 1.6320 - val_accuracy: 0.3027

Epoch 00026: val_loss did not improve from 1.63009
Epoch 27/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6028 - accuracy: 0.3208 - val_loss: 1.6338 - val_accuracy: 0.2999

Epoch 00027: val_loss did not improve from 1.63009
Epoch 28/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5986 - accuracy: 0.3234 - val_loss: 1.6356 - val_accuracy: 0.3004

Epoch 00028: val_loss did not improve from 1.63009
Epoch 29/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5943 - accuracy: 0.3256 - val_loss: 1.6385 - val_accuracy: 0.2971

Epoch 00029: val_loss did not improve from 1.63009
Epoch 30/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5894 - accuracy: 0.3293 - val_loss: 1.6404 - val_accuracy: 0.2975

Epoch 00030: val_loss did not improve from 1.63009
Epoch 31/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5844 - accuracy: 0.3308 - val_loss: 1.6397 - val_accuracy: 0.3025

Epoch 00031: val_loss did not improve from 1.63009
Epoch 32/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5792 - accuracy: 0.3355 - val_loss: 1.6433 - val_accuracy: 0.3021

Epoch 00032: val_loss did not improve from 1.63009
Epoch 33/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5739 - accuracy: 0.3393 - val_loss: 1.6485 - val_accuracy: 0.2976

Epoch 00033: val_loss did not improve from 1.63009
Epoch 34/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5671 - accuracy: 0.3427 - val_loss: 1.6557 - val_accuracy: 0.2966

Epoch 00034: val_loss did not improve from 1.63009
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               1642152   [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 1,645,230[0m
[92mTrainable params: 1,645,226[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 15, 15, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 15, 15, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 15, 15, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 7, 7, 32)          0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 7, 7, 128)         65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 3, 3, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 3, 3, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 256)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               131584    [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 1,642,152[0m
[94mTrainable params: 1,642,148[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 15, 15, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 52s 4ms/step - loss: 1.6341 - accuracy: 0.3040
Testing Loss = 1.634142, Testing Accuracy = 0.303960
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 14ms/step - loss: 9.2073 - accuracy: 0.2004 - val_loss: 8.1149 - val_accuracy: 0.2178

Epoch 00001: val_loss improved from inf to 8.11494, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 2/100
83/83 [==============================] - 1s 12ms/step - loss: 7.2017 - accuracy: 0.2328 - val_loss: 6.3633 - val_accuracy: 0.2567

Epoch 00002: val_loss improved from 8.11494 to 6.36332, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 3/100
83/83 [==============================] - 1s 11ms/step - loss: 5.6801 - accuracy: 0.2686 - val_loss: 5.0764 - val_accuracy: 0.2887

Epoch 00003: val_loss improved from 6.36332 to 5.07643, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 4/100
83/83 [==============================] - 1s 13ms/step - loss: 4.5837 - accuracy: 0.2806 - val_loss: 4.1297 - val_accuracy: 0.3002

Epoch 00004: val_loss improved from 5.07643 to 4.12973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 5/100
83/83 [==============================] - 1s 12ms/step - loss: 3.7764 - accuracy: 0.2835 - val_loss: 3.4315 - val_accuracy: 0.3021

Epoch 00005: val_loss improved from 4.12973 to 3.43154, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 6/100
83/83 [==============================] - 1s 13ms/step - loss: 3.1757 - accuracy: 0.2864 - val_loss: 2.9186 - val_accuracy: 0.3051

Epoch 00006: val_loss improved from 3.43154 to 2.91855, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 7/100
83/83 [==============================] - 1s 13ms/step - loss: 2.7373 - accuracy: 0.2943 - val_loss: 2.5449 - val_accuracy: 0.3058

Epoch 00007: val_loss improved from 2.91855 to 2.54492, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 8/100
83/83 [==============================] - 1s 12ms/step - loss: 2.4163 - accuracy: 0.2961 - val_loss: 2.2749 - val_accuracy: 0.3060

Epoch 00008: val_loss improved from 2.54492 to 2.27494, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 9/100
83/83 [==============================] - 1s 12ms/step - loss: 2.1860 - accuracy: 0.2966 - val_loss: 2.0819 - val_accuracy: 0.3064

Epoch 00009: val_loss improved from 2.27494 to 2.08189, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 10/100
83/83 [==============================] - 1s 12ms/step - loss: 2.0197 - accuracy: 0.3020 - val_loss: 1.9444 - val_accuracy: 0.3059

Epoch 00010: val_loss improved from 2.08189 to 1.94443, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 11/100
83/83 [==============================] - 1s 12ms/step - loss: 1.9022 - accuracy: 0.3012 - val_loss: 1.8477 - val_accuracy: 0.3069

Epoch 00011: val_loss improved from 1.94443 to 1.84769, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 12/100
83/83 [==============================] - 1s 12ms/step - loss: 1.8196 - accuracy: 0.3013 - val_loss: 1.7806 - val_accuracy: 0.3065

Epoch 00012: val_loss improved from 1.84769 to 1.78058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 13/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7596 - accuracy: 0.3012 - val_loss: 1.7334 - val_accuracy: 0.3065

Epoch 00013: val_loss improved from 1.78058 to 1.73339, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 14/100
83/83 [==============================] - 1s 12ms/step - loss: 1.7186 - accuracy: 0.3059 - val_loss: 1.7013 - val_accuracy: 0.3069

Epoch 00014: val_loss improved from 1.73339 to 1.70133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 15/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6917 - accuracy: 0.3061 - val_loss: 1.6798 - val_accuracy: 0.3056

Epoch 00015: val_loss improved from 1.70133 to 1.67976, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 16/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6714 - accuracy: 0.3085 - val_loss: 1.6633 - val_accuracy: 0.3072

Epoch 00016: val_loss improved from 1.67976 to 1.66326, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 17/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6565 - accuracy: 0.3088 - val_loss: 1.6531 - val_accuracy: 0.3061

Epoch 00017: val_loss improved from 1.66326 to 1.65306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 18/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6458 - accuracy: 0.3062 - val_loss: 1.6458 - val_accuracy: 0.3050

Epoch 00018: val_loss improved from 1.65306 to 1.64583, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 19/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6372 - accuracy: 0.3126 - val_loss: 1.6406 - val_accuracy: 0.3064

Epoch 00019: val_loss improved from 1.64583 to 1.64060, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 20/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6322 - accuracy: 0.3100 - val_loss: 1.6368 - val_accuracy: 0.3064

Epoch 00020: val_loss improved from 1.64060 to 1.63677, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 21/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6269 - accuracy: 0.3121 - val_loss: 1.6340 - val_accuracy: 0.3052

Epoch 00021: val_loss improved from 1.63677 to 1.63405, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 22/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6221 - accuracy: 0.3135 - val_loss: 1.6329 - val_accuracy: 0.3018

Epoch 00022: val_loss improved from 1.63405 to 1.63290, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 23/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6181 - accuracy: 0.3144 - val_loss: 1.6311 - val_accuracy: 0.3022

Epoch 00023: val_loss improved from 1.63290 to 1.63115, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 24/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6140 - accuracy: 0.3135 - val_loss: 1.6304 - val_accuracy: 0.3024

Epoch 00024: val_loss improved from 1.63115 to 1.63038, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 25/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6108 - accuracy: 0.3177 - val_loss: 1.6298 - val_accuracy: 0.3038

Epoch 00025: val_loss improved from 1.63038 to 1.62979, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/5
Epoch 26/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6073 - accuracy: 0.3178 - val_loss: 1.6300 - val_accuracy: 0.3022

Epoch 00026: val_loss did not improve from 1.62979
Epoch 27/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6029 - accuracy: 0.3196 - val_loss: 1.6323 - val_accuracy: 0.3027

Epoch 00027: val_loss did not improve from 1.62979
Epoch 28/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5983 - accuracy: 0.3221 - val_loss: 1.6347 - val_accuracy: 0.3011

Epoch 00028: val_loss did not improve from 1.62979
Epoch 29/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5934 - accuracy: 0.3271 - val_loss: 1.6385 - val_accuracy: 0.2984

Epoch 00029: val_loss did not improve from 1.62979
Epoch 30/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5898 - accuracy: 0.3288 - val_loss: 1.6396 - val_accuracy: 0.2985

Epoch 00030: val_loss did not improve from 1.62979
Epoch 31/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5847 - accuracy: 0.3295 - val_loss: 1.6389 - val_accuracy: 0.3015

Epoch 00031: val_loss did not improve from 1.62979
Epoch 32/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5788 - accuracy: 0.3335 - val_loss: 1.6410 - val_accuracy: 0.3027

Epoch 00032: val_loss did not improve from 1.62979
Epoch 33/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5739 - accuracy: 0.3380 - val_loss: 1.6461 - val_accuracy: 0.3032

Epoch 00033: val_loss did not improve from 1.62979
Epoch 34/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5680 - accuracy: 0.3435 - val_loss: 1.6514 - val_accuracy: 0.3048

Epoch 00034: val_loss did not improve from 1.62979
Epoch 35/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5615 - accuracy: 0.3475 - val_loss: 1.6575 - val_accuracy: 0.3041

Epoch 00035: val_loss did not improve from 1.62979
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               1642152   [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 1,645,230[0m
[92mTrainable params: 1,645,226[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 15, 15, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 15, 15, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 15, 15, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 7, 7, 32)          0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 7, 7, 128)         65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 3, 3, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 3, 3, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 256)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               131584    [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 1,642,152[0m
[94mTrainable params: 1,642,148[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 15, 15, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 51s 4ms/step - loss: 1.6341 - accuracy: 0.3045
Testing Loss = 1.634150, Testing Accuracy = 0.304480
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 13ms/step - loss: 9.1932 - accuracy: 0.1984 - val_loss: 8.1007 - val_accuracy: 0.2178

Epoch 00001: val_loss improved from inf to 8.10071, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 2/100
83/83 [==============================] - 1s 12ms/step - loss: 7.1933 - accuracy: 0.2277 - val_loss: 6.3536 - val_accuracy: 0.2551

Epoch 00002: val_loss improved from 8.10071 to 6.35363, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 3/100
83/83 [==============================] - 1s 13ms/step - loss: 5.6645 - accuracy: 0.2651 - val_loss: 5.0602 - val_accuracy: 0.2913

Epoch 00003: val_loss improved from 6.35363 to 5.06017, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 4/100
83/83 [==============================] - 1s 11ms/step - loss: 4.5663 - accuracy: 0.2778 - val_loss: 4.1118 - val_accuracy: 0.3001

Epoch 00004: val_loss improved from 5.06017 to 4.11178, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 5/100
83/83 [==============================] - 1s 12ms/step - loss: 3.7560 - accuracy: 0.2854 - val_loss: 3.4127 - val_accuracy: 0.3025

Epoch 00005: val_loss improved from 4.11178 to 3.41271, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 6/100
83/83 [==============================] - 1s 12ms/step - loss: 3.1599 - accuracy: 0.2914 - val_loss: 2.9021 - val_accuracy: 0.3019

Epoch 00006: val_loss improved from 3.41271 to 2.90211, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 7/100
83/83 [==============================] - 1s 12ms/step - loss: 2.7220 - accuracy: 0.2905 - val_loss: 2.5308 - val_accuracy: 0.3049

Epoch 00007: val_loss improved from 2.90211 to 2.53080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 8/100
83/83 [==============================] - 1s 11ms/step - loss: 2.4046 - accuracy: 0.2933 - val_loss: 2.2633 - val_accuracy: 0.3067

Epoch 00008: val_loss improved from 2.53080 to 2.26332, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 9/100
83/83 [==============================] - 1s 12ms/step - loss: 2.1746 - accuracy: 0.2987 - val_loss: 2.0718 - val_accuracy: 0.3064

Epoch 00009: val_loss improved from 2.26332 to 2.07180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 10/100
83/83 [==============================] - 1s 13ms/step - loss: 2.0112 - accuracy: 0.2969 - val_loss: 1.9363 - val_accuracy: 0.3079

Epoch 00010: val_loss improved from 2.07180 to 1.93628, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 11/100
83/83 [==============================] - 1s 12ms/step - loss: 1.8961 - accuracy: 0.3000 - val_loss: 1.8412 - val_accuracy: 0.3047

Epoch 00011: val_loss improved from 1.93628 to 1.84120, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 12/100
83/83 [==============================] - 1s 12ms/step - loss: 1.8144 - accuracy: 0.3010 - val_loss: 1.7752 - val_accuracy: 0.3067

Epoch 00012: val_loss improved from 1.84120 to 1.77518, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 13/100
83/83 [==============================] - 1s 12ms/step - loss: 1.7563 - accuracy: 0.3033 - val_loss: 1.7291 - val_accuracy: 0.3084

Epoch 00013: val_loss improved from 1.77518 to 1.72912, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 14/100
83/83 [==============================] - 1s 12ms/step - loss: 1.7157 - accuracy: 0.3050 - val_loss: 1.6974 - val_accuracy: 0.3083

Epoch 00014: val_loss improved from 1.72912 to 1.69737, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 15/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6879 - accuracy: 0.3068 - val_loss: 1.6756 - val_accuracy: 0.3079

Epoch 00015: val_loss improved from 1.69737 to 1.67563, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 16/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6688 - accuracy: 0.3064 - val_loss: 1.6612 - val_accuracy: 0.3072

Epoch 00016: val_loss improved from 1.67563 to 1.66117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 17/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6557 - accuracy: 0.3063 - val_loss: 1.6506 - val_accuracy: 0.3092

Epoch 00017: val_loss improved from 1.66117 to 1.65058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 18/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6459 - accuracy: 0.3076 - val_loss: 1.6432 - val_accuracy: 0.3096

Epoch 00018: val_loss improved from 1.65058 to 1.64325, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 19/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6376 - accuracy: 0.3082 - val_loss: 1.6377 - val_accuracy: 0.3079

Epoch 00019: val_loss improved from 1.64325 to 1.63768, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 20/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6300 - accuracy: 0.3114 - val_loss: 1.6344 - val_accuracy: 0.3067

Epoch 00020: val_loss improved from 1.63768 to 1.63441, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 21/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6251 - accuracy: 0.3149 - val_loss: 1.6314 - val_accuracy: 0.3077

Epoch 00021: val_loss improved from 1.63441 to 1.63139, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 22/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6219 - accuracy: 0.3127 - val_loss: 1.6307 - val_accuracy: 0.3063

Epoch 00022: val_loss improved from 1.63139 to 1.63074, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 23/100
83/83 [==============================] - 1s 11ms/step - loss: 1.6180 - accuracy: 0.3140 - val_loss: 1.6285 - val_accuracy: 0.3071

Epoch 00023: val_loss improved from 1.63074 to 1.62846, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 24/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6132 - accuracy: 0.3165 - val_loss: 1.6273 - val_accuracy: 0.3084

Epoch 00024: val_loss improved from 1.62846 to 1.62728, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 25/100
83/83 [==============================] - 1s 11ms/step - loss: 1.6104 - accuracy: 0.3189 - val_loss: 1.6268 - val_accuracy: 0.3089

Epoch 00025: val_loss improved from 1.62728 to 1.62678, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 26/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6075 - accuracy: 0.3194 - val_loss: 1.6262 - val_accuracy: 0.3087

Epoch 00026: val_loss improved from 1.62678 to 1.62618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 27/100
83/83 [==============================] - 1s 11ms/step - loss: 1.6032 - accuracy: 0.3235 - val_loss: 1.6259 - val_accuracy: 0.3112

Epoch 00027: val_loss improved from 1.62618 to 1.62590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/6
Epoch 28/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5990 - accuracy: 0.3277 - val_loss: 1.6262 - val_accuracy: 0.3090

Epoch 00028: val_loss did not improve from 1.62590
Epoch 29/100
83/83 [==============================] - 1s 11ms/step - loss: 1.5939 - accuracy: 0.3313 - val_loss: 1.6287 - val_accuracy: 0.3070

Epoch 00029: val_loss did not improve from 1.62590
Epoch 30/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5897 - accuracy: 0.3356 - val_loss: 1.6320 - val_accuracy: 0.3071

Epoch 00030: val_loss did not improve from 1.62590
Epoch 31/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5838 - accuracy: 0.3389 - val_loss: 1.6342 - val_accuracy: 0.3072

Epoch 00031: val_loss did not improve from 1.62590
Epoch 32/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5792 - accuracy: 0.3405 - val_loss: 1.6338 - val_accuracy: 0.3077

Epoch 00032: val_loss did not improve from 1.62590
Epoch 33/100
83/83 [==============================] - 1s 11ms/step - loss: 1.5726 - accuracy: 0.3446 - val_loss: 1.6345 - val_accuracy: 0.3120

Epoch 00033: val_loss did not improve from 1.62590
Epoch 34/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5671 - accuracy: 0.3497 - val_loss: 1.6398 - val_accuracy: 0.3098

Epoch 00034: val_loss did not improve from 1.62590
Epoch 35/100
83/83 [==============================] - 1s 11ms/step - loss: 1.5607 - accuracy: 0.3511 - val_loss: 1.6491 - val_accuracy: 0.3063

Epoch 00035: val_loss did not improve from 1.62590
Epoch 36/100
83/83 [==============================] - 1s 11ms/step - loss: 1.5551 - accuracy: 0.3563 - val_loss: 1.6570 - val_accuracy: 0.3031

Epoch 00036: val_loss did not improve from 1.62590
Epoch 37/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5493 - accuracy: 0.3606 - val_loss: 1.6664 - val_accuracy: 0.2996

Epoch 00037: val_loss did not improve from 1.62590
Epoch 00037: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               1642152   [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 1,645,230[0m
[92mTrainable params: 1,645,226[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 15, 15, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 15, 15, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 15, 15, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 7, 7, 32)          0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 7, 7, 128)         65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 3, 3, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 3, 3, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 256)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               131584    [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 1,642,152[0m
[94mTrainable params: 1,642,148[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 15, 15, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 50s 4ms/step - loss: 1.6308 - accuracy: 0.3019
Testing Loss = 1.630839, Testing Accuracy = 0.301950
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 14ms/step - loss: 9.1926 - accuracy: 0.1988 - val_loss: 8.1026 - val_accuracy: 0.2178

Epoch 00001: val_loss improved from inf to 8.10262, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 2/100
83/83 [==============================] - 1s 12ms/step - loss: 7.1873 - accuracy: 0.2365 - val_loss: 6.3484 - val_accuracy: 0.2539

Epoch 00002: val_loss improved from 8.10262 to 6.34844, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 3/100
83/83 [==============================] - 1s 13ms/step - loss: 5.6716 - accuracy: 0.2685 - val_loss: 5.0716 - val_accuracy: 0.2873

Epoch 00003: val_loss improved from 6.34844 to 5.07165, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 4/100
83/83 [==============================] - 1s 13ms/step - loss: 4.5770 - accuracy: 0.2793 - val_loss: 4.1219 - val_accuracy: 0.2986

Epoch 00004: val_loss improved from 5.07165 to 4.12193, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 5/100
83/83 [==============================] - 1s 13ms/step - loss: 3.7664 - accuracy: 0.2857 - val_loss: 3.4236 - val_accuracy: 0.3025

Epoch 00005: val_loss improved from 4.12193 to 3.42359, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 6/100
83/83 [==============================] - 1s 12ms/step - loss: 3.1698 - accuracy: 0.2901 - val_loss: 2.9114 - val_accuracy: 0.3012

Epoch 00006: val_loss improved from 3.42359 to 2.91138, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 7/100
83/83 [==============================] - 1s 12ms/step - loss: 2.7306 - accuracy: 0.2931 - val_loss: 2.5391 - val_accuracy: 0.3019

Epoch 00007: val_loss improved from 2.91138 to 2.53909, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 8/100
83/83 [==============================] - 1s 12ms/step - loss: 2.4127 - accuracy: 0.2948 - val_loss: 2.2704 - val_accuracy: 0.3029

Epoch 00008: val_loss improved from 2.53909 to 2.27041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 9/100
83/83 [==============================] - 1s 12ms/step - loss: 2.1805 - accuracy: 0.2974 - val_loss: 2.0781 - val_accuracy: 0.3065

Epoch 00009: val_loss improved from 2.27041 to 2.07807, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 10/100
83/83 [==============================] - 1s 13ms/step - loss: 2.0164 - accuracy: 0.2983 - val_loss: 1.9410 - val_accuracy: 0.3059

Epoch 00010: val_loss improved from 2.07807 to 1.94104, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 11/100
83/83 [==============================] - 1s 12ms/step - loss: 1.8991 - accuracy: 0.3018 - val_loss: 1.8453 - val_accuracy: 0.3068

Epoch 00011: val_loss improved from 1.94104 to 1.84527, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 12/100
83/83 [==============================] - 1s 13ms/step - loss: 1.8163 - accuracy: 0.3016 - val_loss: 1.7789 - val_accuracy: 0.3035

Epoch 00012: val_loss improved from 1.84527 to 1.77893, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 13/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7587 - accuracy: 0.3044 - val_loss: 1.7324 - val_accuracy: 0.3029

Epoch 00013: val_loss improved from 1.77893 to 1.73238, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 14/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7192 - accuracy: 0.3039 - val_loss: 1.7000 - val_accuracy: 0.3030

Epoch 00014: val_loss improved from 1.73238 to 1.70004, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 15/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6910 - accuracy: 0.3063 - val_loss: 1.6781 - val_accuracy: 0.3052

Epoch 00015: val_loss improved from 1.70004 to 1.67813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 16/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6706 - accuracy: 0.3058 - val_loss: 1.6634 - val_accuracy: 0.3053

Epoch 00016: val_loss improved from 1.67813 to 1.66338, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 17/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6572 - accuracy: 0.3065 - val_loss: 1.6523 - val_accuracy: 0.3043

Epoch 00017: val_loss improved from 1.66338 to 1.65231, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 18/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6470 - accuracy: 0.3080 - val_loss: 1.6450 - val_accuracy: 0.3059

Epoch 00018: val_loss improved from 1.65231 to 1.64501, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 19/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6390 - accuracy: 0.3099 - val_loss: 1.6400 - val_accuracy: 0.3070

Epoch 00019: val_loss improved from 1.64501 to 1.64002, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 20/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6319 - accuracy: 0.3098 - val_loss: 1.6366 - val_accuracy: 0.3052

Epoch 00020: val_loss improved from 1.64002 to 1.63664, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 21/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6269 - accuracy: 0.3126 - val_loss: 1.6331 - val_accuracy: 0.3062

Epoch 00021: val_loss improved from 1.63664 to 1.63312, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 22/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6237 - accuracy: 0.3132 - val_loss: 1.6312 - val_accuracy: 0.3061

Epoch 00022: val_loss improved from 1.63312 to 1.63117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 23/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6201 - accuracy: 0.3131 - val_loss: 1.6305 - val_accuracy: 0.3044

Epoch 00023: val_loss improved from 1.63117 to 1.63054, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 24/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6167 - accuracy: 0.3170 - val_loss: 1.6294 - val_accuracy: 0.3048

Epoch 00024: val_loss improved from 1.63054 to 1.62937, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 25/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6145 - accuracy: 0.3165 - val_loss: 1.6290 - val_accuracy: 0.3029

Epoch 00025: val_loss improved from 1.62937 to 1.62902, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 26/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6114 - accuracy: 0.3163 - val_loss: 1.6285 - val_accuracy: 0.3028

Epoch 00026: val_loss improved from 1.62902 to 1.62847, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/7
Epoch 27/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6075 - accuracy: 0.3184 - val_loss: 1.6290 - val_accuracy: 0.3021

Epoch 00027: val_loss did not improve from 1.62847
Epoch 28/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6051 - accuracy: 0.3205 - val_loss: 1.6304 - val_accuracy: 0.3010

Epoch 00028: val_loss did not improve from 1.62847
Epoch 29/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6001 - accuracy: 0.3245 - val_loss: 1.6329 - val_accuracy: 0.3010

Epoch 00029: val_loss did not improve from 1.62847
Epoch 30/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5959 - accuracy: 0.3263 - val_loss: 1.6364 - val_accuracy: 0.2990

Epoch 00030: val_loss did not improve from 1.62847
Epoch 31/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5919 - accuracy: 0.3301 - val_loss: 1.6408 - val_accuracy: 0.2963

Epoch 00031: val_loss did not improve from 1.62847
Epoch 32/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5868 - accuracy: 0.3303 - val_loss: 1.6407 - val_accuracy: 0.3004

Epoch 00032: val_loss did not improve from 1.62847
Epoch 33/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5824 - accuracy: 0.3337 - val_loss: 1.6400 - val_accuracy: 0.2990

Epoch 00033: val_loss did not improve from 1.62847
Epoch 34/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5774 - accuracy: 0.3397 - val_loss: 1.6442 - val_accuracy: 0.2974

Epoch 00034: val_loss did not improve from 1.62847
Epoch 35/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5706 - accuracy: 0.3408 - val_loss: 1.6513 - val_accuracy: 0.2938

Epoch 00035: val_loss did not improve from 1.62847
Epoch 36/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5647 - accuracy: 0.3460 - val_loss: 1.6597 - val_accuracy: 0.2909

Epoch 00036: val_loss did not improve from 1.62847
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               1642152   [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 1,645,230[0m
[92mTrainable params: 1,645,226[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 15, 15, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 15, 15, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 15, 15, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 7, 7, 32)          0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 7, 7, 128)         65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 3, 3, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 3, 3, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 256)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               131584    [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 1,642,152[0m
[94mTrainable params: 1,642,148[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 15, 15, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 49s 4ms/step - loss: 1.6320 - accuracy: 0.3082
Testing Loss = 1.632050, Testing Accuracy = 0.308202
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 14ms/step - loss: 9.2061 - accuracy: 0.1957 - val_loss: 8.1112 - val_accuracy: 0.2178

Epoch 00001: val_loss improved from inf to 8.11117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 2/100
83/83 [==============================] - 1s 12ms/step - loss: 7.1957 - accuracy: 0.2326 - val_loss: 6.3607 - val_accuracy: 0.2515

Epoch 00002: val_loss improved from 8.11117 to 6.36073, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 3/100
83/83 [==============================] - 1s 12ms/step - loss: 5.6774 - accuracy: 0.2674 - val_loss: 5.0771 - val_accuracy: 0.2875

Epoch 00003: val_loss improved from 6.36073 to 5.07707, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 4/100
83/83 [==============================] - 1s 13ms/step - loss: 4.5795 - accuracy: 0.2822 - val_loss: 4.1257 - val_accuracy: 0.3006

Epoch 00004: val_loss improved from 5.07707 to 4.12566, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 5/100
83/83 [==============================] - 1s 12ms/step - loss: 3.7710 - accuracy: 0.2853 - val_loss: 3.4273 - val_accuracy: 0.3014

Epoch 00005: val_loss improved from 4.12566 to 3.42735, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 6/100
83/83 [==============================] - 1s 13ms/step - loss: 3.1710 - accuracy: 0.2936 - val_loss: 2.9135 - val_accuracy: 0.3019

Epoch 00006: val_loss improved from 3.42735 to 2.91346, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 7/100
83/83 [==============================] - 1s 13ms/step - loss: 2.7315 - accuracy: 0.2948 - val_loss: 2.5413 - val_accuracy: 0.3044

Epoch 00007: val_loss improved from 2.91346 to 2.54127, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 8/100
83/83 [==============================] - 1s 12ms/step - loss: 2.4137 - accuracy: 0.2974 - val_loss: 2.2725 - val_accuracy: 0.3075

Epoch 00008: val_loss improved from 2.54127 to 2.27255, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 9/100
83/83 [==============================] - 1s 13ms/step - loss: 2.1828 - accuracy: 0.2995 - val_loss: 2.0804 - val_accuracy: 0.3085

Epoch 00009: val_loss improved from 2.27255 to 2.08035, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 10/100
83/83 [==============================] - 1s 13ms/step - loss: 2.0165 - accuracy: 0.3014 - val_loss: 1.9428 - val_accuracy: 0.3095

Epoch 00010: val_loss improved from 2.08035 to 1.94283, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 11/100
83/83 [==============================] - 1s 13ms/step - loss: 1.9002 - accuracy: 0.3014 - val_loss: 1.8466 - val_accuracy: 0.3088

Epoch 00011: val_loss improved from 1.94283 to 1.84662, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 12/100
83/83 [==============================] - 1s 13ms/step - loss: 1.8175 - accuracy: 0.3027 - val_loss: 1.7801 - val_accuracy: 0.3094

Epoch 00012: val_loss improved from 1.84662 to 1.78008, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 13/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7581 - accuracy: 0.3051 - val_loss: 1.7329 - val_accuracy: 0.3080

Epoch 00013: val_loss improved from 1.78008 to 1.73289, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 14/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7185 - accuracy: 0.3062 - val_loss: 1.7008 - val_accuracy: 0.3077

Epoch 00014: val_loss improved from 1.73289 to 1.70083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 15/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6896 - accuracy: 0.3059 - val_loss: 1.6784 - val_accuracy: 0.3089

Epoch 00015: val_loss improved from 1.70083 to 1.67837, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 16/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6697 - accuracy: 0.3069 - val_loss: 1.6636 - val_accuracy: 0.3086

Epoch 00016: val_loss improved from 1.67837 to 1.66357, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 17/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6556 - accuracy: 0.3096 - val_loss: 1.6522 - val_accuracy: 0.3096

Epoch 00017: val_loss improved from 1.66357 to 1.65220, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 18/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6446 - accuracy: 0.3094 - val_loss: 1.6459 - val_accuracy: 0.3075

Epoch 00018: val_loss improved from 1.65220 to 1.64591, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 19/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6361 - accuracy: 0.3108 - val_loss: 1.6396 - val_accuracy: 0.3072

Epoch 00019: val_loss improved from 1.64591 to 1.63956, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 20/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6300 - accuracy: 0.3125 - val_loss: 1.6364 - val_accuracy: 0.3061

Epoch 00020: val_loss improved from 1.63956 to 1.63637, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 21/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6259 - accuracy: 0.3147 - val_loss: 1.6332 - val_accuracy: 0.3057

Epoch 00021: val_loss improved from 1.63637 to 1.63323, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 22/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6206 - accuracy: 0.3146 - val_loss: 1.6318 - val_accuracy: 0.3020

Epoch 00022: val_loss improved from 1.63323 to 1.63180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 23/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6165 - accuracy: 0.3164 - val_loss: 1.6303 - val_accuracy: 0.3032

Epoch 00023: val_loss improved from 1.63180 to 1.63026, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 24/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6137 - accuracy: 0.3174 - val_loss: 1.6296 - val_accuracy: 0.3019

Epoch 00024: val_loss improved from 1.63026 to 1.62960, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/8
Epoch 25/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6093 - accuracy: 0.3180 - val_loss: 1.6300 - val_accuracy: 0.3021

Epoch 00025: val_loss did not improve from 1.62960
Epoch 26/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6033 - accuracy: 0.3233 - val_loss: 1.6319 - val_accuracy: 0.3004

Epoch 00026: val_loss did not improve from 1.62960
Epoch 27/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6006 - accuracy: 0.3220 - val_loss: 1.6333 - val_accuracy: 0.2998

Epoch 00027: val_loss did not improve from 1.62960
Epoch 28/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5958 - accuracy: 0.3227 - val_loss: 1.6367 - val_accuracy: 0.2990

Epoch 00028: val_loss did not improve from 1.62960
Epoch 29/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5925 - accuracy: 0.3265 - val_loss: 1.6372 - val_accuracy: 0.2989

Epoch 00029: val_loss did not improve from 1.62960
Epoch 30/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5878 - accuracy: 0.3303 - val_loss: 1.6364 - val_accuracy: 0.2987

Epoch 00030: val_loss did not improve from 1.62960
Epoch 31/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5820 - accuracy: 0.3314 - val_loss: 1.6396 - val_accuracy: 0.2994

Epoch 00031: val_loss did not improve from 1.62960
Epoch 32/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5773 - accuracy: 0.3355 - val_loss: 1.6449 - val_accuracy: 0.2973

Epoch 00032: val_loss did not improve from 1.62960
Epoch 33/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5715 - accuracy: 0.3415 - val_loss: 1.6507 - val_accuracy: 0.2958

Epoch 00033: val_loss did not improve from 1.62960
Epoch 34/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5644 - accuracy: 0.3448 - val_loss: 1.6594 - val_accuracy: 0.2922

Epoch 00034: val_loss did not improve from 1.62960
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               1642152   [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 1,645,230[0m
[92mTrainable params: 1,645,226[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 15, 15, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 15, 15, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 15, 15, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 7, 7, 32)          0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 7, 7, 128)         65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 3, 3, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 3, 3, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 256)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               131584    [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 1,642,152[0m
[94mTrainable params: 1,642,148[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 15, 15, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 51s 4ms/step - loss: 1.6344 - accuracy: 0.3033
Testing Loss = 1.634391, Testing Accuracy = 0.303290
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 14ms/step - loss: 9.1760 - accuracy: 0.1981 - val_loss: 8.0828 - val_accuracy: 0.2178

Epoch 00001: val_loss improved from inf to 8.08279, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 2/100
83/83 [==============================] - 1s 12ms/step - loss: 7.1747 - accuracy: 0.2265 - val_loss: 6.3342 - val_accuracy: 0.2485

Epoch 00002: val_loss improved from 8.08279 to 6.33424, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 3/100
83/83 [==============================] - 1s 13ms/step - loss: 5.6454 - accuracy: 0.2655 - val_loss: 5.0441 - val_accuracy: 0.2890

Epoch 00003: val_loss improved from 6.33424 to 5.04406, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 4/100
83/83 [==============================] - 1s 13ms/step - loss: 4.5526 - accuracy: 0.2828 - val_loss: 4.0998 - val_accuracy: 0.3023

Epoch 00004: val_loss improved from 5.04406 to 4.09984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 5/100
83/83 [==============================] - 1s 12ms/step - loss: 3.7457 - accuracy: 0.2878 - val_loss: 3.4045 - val_accuracy: 0.3028

Epoch 00005: val_loss improved from 4.09984 to 3.40449, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 6/100
83/83 [==============================] - 1s 12ms/step - loss: 3.1533 - accuracy: 0.2914 - val_loss: 2.8976 - val_accuracy: 0.3039

Epoch 00006: val_loss improved from 3.40449 to 2.89755, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 7/100
83/83 [==============================] - 1s 14ms/step - loss: 2.7178 - accuracy: 0.2935 - val_loss: 2.5278 - val_accuracy: 0.3058

Epoch 00007: val_loss improved from 2.89755 to 2.52782, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 8/100
83/83 [==============================] - 1s 13ms/step - loss: 2.4020 - accuracy: 0.2962 - val_loss: 2.2619 - val_accuracy: 0.3042

Epoch 00008: val_loss improved from 2.52782 to 2.26193, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 9/100
83/83 [==============================] - 1s 12ms/step - loss: 2.1730 - accuracy: 0.2998 - val_loss: 2.0719 - val_accuracy: 0.3043

Epoch 00009: val_loss improved from 2.26193 to 2.07194, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 10/100
83/83 [==============================] - 1s 13ms/step - loss: 2.0097 - accuracy: 0.3025 - val_loss: 1.9365 - val_accuracy: 0.3052

Epoch 00010: val_loss improved from 2.07194 to 1.93649, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 11/100
83/83 [==============================] - 1s 12ms/step - loss: 1.8962 - accuracy: 0.3023 - val_loss: 1.8420 - val_accuracy: 0.3052

Epoch 00011: val_loss improved from 1.93649 to 1.84204, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 12/100
83/83 [==============================] - 1s 12ms/step - loss: 1.8132 - accuracy: 0.3045 - val_loss: 1.7759 - val_accuracy: 0.3067

Epoch 00012: val_loss improved from 1.84204 to 1.77593, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 13/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7561 - accuracy: 0.3039 - val_loss: 1.7299 - val_accuracy: 0.3080

Epoch 00013: val_loss improved from 1.77593 to 1.72988, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 14/100
83/83 [==============================] - 1s 13ms/step - loss: 1.7178 - accuracy: 0.3053 - val_loss: 1.6989 - val_accuracy: 0.3059

Epoch 00014: val_loss improved from 1.72988 to 1.69894, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 15/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6880 - accuracy: 0.3073 - val_loss: 1.6769 - val_accuracy: 0.3073

Epoch 00015: val_loss improved from 1.69894 to 1.67691, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 16/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6682 - accuracy: 0.3088 - val_loss: 1.6616 - val_accuracy: 0.3087

Epoch 00016: val_loss improved from 1.67691 to 1.66157, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 17/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6549 - accuracy: 0.3113 - val_loss: 1.6515 - val_accuracy: 0.3080

Epoch 00017: val_loss improved from 1.66157 to 1.65149, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 18/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6448 - accuracy: 0.3085 - val_loss: 1.6436 - val_accuracy: 0.3088

Epoch 00018: val_loss improved from 1.65149 to 1.64365, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 19/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6350 - accuracy: 0.3101 - val_loss: 1.6385 - val_accuracy: 0.3086

Epoch 00019: val_loss improved from 1.64365 to 1.63848, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 20/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6289 - accuracy: 0.3133 - val_loss: 1.6346 - val_accuracy: 0.3097

Epoch 00020: val_loss improved from 1.63848 to 1.63456, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 21/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6236 - accuracy: 0.3190 - val_loss: 1.6313 - val_accuracy: 0.3107

Epoch 00021: val_loss improved from 1.63456 to 1.63133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 22/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6191 - accuracy: 0.3203 - val_loss: 1.6279 - val_accuracy: 0.3129

Epoch 00022: val_loss improved from 1.63133 to 1.62790, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 23/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6129 - accuracy: 0.3240 - val_loss: 1.6245 - val_accuracy: 0.3161

Epoch 00023: val_loss improved from 1.62790 to 1.62452, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 24/100
83/83 [==============================] - 1s 13ms/step - loss: 1.6080 - accuracy: 0.3277 - val_loss: 1.6225 - val_accuracy: 0.3155

Epoch 00024: val_loss improved from 1.62452 to 1.62250, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 25/100
83/83 [==============================] - 1s 12ms/step - loss: 1.6025 - accuracy: 0.3329 - val_loss: 1.6222 - val_accuracy: 0.3155

Epoch 00025: val_loss improved from 1.62250 to 1.62220, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 26/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5977 - accuracy: 0.3369 - val_loss: 1.6220 - val_accuracy: 0.3158

Epoch 00026: val_loss improved from 1.62220 to 1.62197, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2-12/Try/9
Epoch 27/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5912 - accuracy: 0.3400 - val_loss: 1.6232 - val_accuracy: 0.3196

Epoch 00027: val_loss did not improve from 1.62197
Epoch 28/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5873 - accuracy: 0.3422 - val_loss: 1.6285 - val_accuracy: 0.3181

Epoch 00028: val_loss did not improve from 1.62197
Epoch 29/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5810 - accuracy: 0.3470 - val_loss: 1.6293 - val_accuracy: 0.3189

Epoch 00029: val_loss did not improve from 1.62197
Epoch 30/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5760 - accuracy: 0.3475 - val_loss: 1.6279 - val_accuracy: 0.3218

Epoch 00030: val_loss did not improve from 1.62197
Epoch 31/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5720 - accuracy: 0.3508 - val_loss: 1.6306 - val_accuracy: 0.3238

Epoch 00031: val_loss did not improve from 1.62197
Epoch 32/100
83/83 [==============================] - 1s 13ms/step - loss: 1.5640 - accuracy: 0.3548 - val_loss: 1.6363 - val_accuracy: 0.3201

Epoch 00032: val_loss did not improve from 1.62197
Epoch 33/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5594 - accuracy: 0.3588 - val_loss: 1.6424 - val_accuracy: 0.3180

Epoch 00033: val_loss did not improve from 1.62197
Epoch 34/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5526 - accuracy: 0.3612 - val_loss: 1.6517 - val_accuracy: 0.3147

Epoch 00034: val_loss did not improve from 1.62197
Epoch 35/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5455 - accuracy: 0.3660 - val_loss: 1.6556 - val_accuracy: 0.3155

Epoch 00035: val_loss did not improve from 1.62197
Epoch 36/100
83/83 [==============================] - 1s 12ms/step - loss: 1.5393 - accuracy: 0.3668 - val_loss: 1.6670 - val_accuracy: 0.3114

Epoch 00036: val_loss did not improve from 1.62197
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               1642152   [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 1,645,230[0m
[92mTrainable params: 1,645,226[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 15, 15, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 15, 15, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 15, 15, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 7, 7, 32)          0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 7, 7, 128)         65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 3, 3, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 3, 3, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 1, 1, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 256)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               131584    [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 1,642,152[0m
[94mTrainable params: 1,642,148[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 15, 15, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 49s 4ms/step - loss: 1.6280 - accuracy: 0.3204
Testing Loss = 1.627985, Testing Accuracy = 0.320408
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 80.35 +- 0.1008 %)
$W^-/W^-$ (auc = 79.89 +- 0.0909 %)
$Z/Z$ (auc = 58.59 +- 1.9797 %)
$W^+/W^-$ (auc = 59.67 +- 2.3035 %)
$W^+/Z$$ (auc = 64.78 +- 0.1195 %)
$W^-/Z$ (auc = 66.37 +- 0.1195 %)
The summarized testing accuracy = 30.87 +- 0.6937 %, with the loss = 1.6317 +- 0.003508
