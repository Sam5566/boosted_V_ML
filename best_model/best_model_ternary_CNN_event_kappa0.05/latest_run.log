

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-23 15:54:35.379737
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 9s 70ms/step - loss: 12.4074 - accuracy: 0.1960 - val_loss: 8.6583 - val_accuracy: 0.2123

Epoch 00001: val_loss improved from inf to 8.65826, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.7468 - accuracy: 0.2054 - val_loss: 5.3286 - val_accuracy: 0.2134

Epoch 00002: val_loss improved from 8.65826 to 5.32864, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.5682 - accuracy: 0.2091 - val_loss: 3.9609 - val_accuracy: 0.2180

Epoch 00003: val_loss improved from 5.32864 to 3.96095, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.5127 - accuracy: 0.2518 - val_loss: 3.1608 - val_accuracy: 0.2821

Epoch 00004: val_loss improved from 3.96095 to 3.16079, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8952 - accuracy: 0.2865 - val_loss: 2.6867 - val_accuracy: 0.2931

Epoch 00005: val_loss improved from 3.16079 to 2.68674, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 6/100
83/83 [==============================] - 6s 67ms/step - loss: 2.5117 - accuracy: 0.2925 - val_loss: 2.3603 - val_accuracy: 0.3016

Epoch 00006: val_loss improved from 2.68674 to 2.36032, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2484 - accuracy: 0.2979 - val_loss: 2.1362 - val_accuracy: 0.3105

Epoch 00007: val_loss improved from 2.36032 to 2.13622, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0600 - accuracy: 0.3051 - val_loss: 1.9790 - val_accuracy: 0.3146

Epoch 00008: val_loss improved from 2.13622 to 1.97897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9295 - accuracy: 0.3099 - val_loss: 1.8725 - val_accuracy: 0.3180

Epoch 00009: val_loss improved from 1.97897 to 1.87247, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8370 - accuracy: 0.3168 - val_loss: 1.7999 - val_accuracy: 0.3187

Epoch 00010: val_loss improved from 1.87247 to 1.79986, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7730 - accuracy: 0.3205 - val_loss: 1.7440 - val_accuracy: 0.3271

Epoch 00011: val_loss improved from 1.79986 to 1.74396, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7273 - accuracy: 0.3245 - val_loss: 1.7055 - val_accuracy: 0.3316

Epoch 00012: val_loss improved from 1.74396 to 1.70549, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6932 - accuracy: 0.3324 - val_loss: 1.6818 - val_accuracy: 0.3335

Epoch 00013: val_loss improved from 1.70549 to 1.68179, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 14/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6673 - accuracy: 0.3396 - val_loss: 1.6583 - val_accuracy: 0.3443

Epoch 00014: val_loss improved from 1.68179 to 1.65831, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6495 - accuracy: 0.3434 - val_loss: 1.6410 - val_accuracy: 0.3520

Epoch 00015: val_loss improved from 1.65831 to 1.64104, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6306 - accuracy: 0.3543 - val_loss: 1.6280 - val_accuracy: 0.3582

Epoch 00016: val_loss improved from 1.64104 to 1.62801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6166 - accuracy: 0.3627 - val_loss: 1.6165 - val_accuracy: 0.3633

Epoch 00017: val_loss improved from 1.62801 to 1.61653, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6019 - accuracy: 0.3680 - val_loss: 1.6205 - val_accuracy: 0.3596

Epoch 00018: val_loss did not improve from 1.61653
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5929 - accuracy: 0.3746 - val_loss: 1.5998 - val_accuracy: 0.3718

Epoch 00019: val_loss improved from 1.61653 to 1.59979, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5806 - accuracy: 0.3823 - val_loss: 1.6058 - val_accuracy: 0.3700

Epoch 00020: val_loss did not improve from 1.59979
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5719 - accuracy: 0.3867 - val_loss: 1.5953 - val_accuracy: 0.3774

Epoch 00021: val_loss improved from 1.59979 to 1.59526, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5630 - accuracy: 0.3912 - val_loss: 1.5886 - val_accuracy: 0.3778

Epoch 00022: val_loss improved from 1.59526 to 1.58863, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5535 - accuracy: 0.3993 - val_loss: 1.5883 - val_accuracy: 0.3784

Epoch 00023: val_loss improved from 1.58863 to 1.58832, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/0
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5468 - accuracy: 0.4046 - val_loss: 1.5904 - val_accuracy: 0.3816

Epoch 00024: val_loss did not improve from 1.58832
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5403 - accuracy: 0.4073 - val_loss: 1.5927 - val_accuracy: 0.3808

Epoch 00025: val_loss did not improve from 1.58832
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5306 - accuracy: 0.4177 - val_loss: 1.5962 - val_accuracy: 0.3826

Epoch 00026: val_loss did not improve from 1.58832
Epoch 27/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5216 - accuracy: 0.4231 - val_loss: 1.5995 - val_accuracy: 0.3829

Epoch 00027: val_loss did not improve from 1.58832
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5158 - accuracy: 0.4306 - val_loss: 1.6105 - val_accuracy: 0.3770

Epoch 00028: val_loss did not improve from 1.58832
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5093 - accuracy: 0.4328 - val_loss: 1.6149 - val_accuracy: 0.3782

Epoch 00029: val_loss did not improve from 1.58832
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4963 - accuracy: 0.4413 - val_loss: 1.6228 - val_accuracy: 0.3803

Epoch 00030: val_loss did not improve from 1.58832
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4875 - accuracy: 0.4475 - val_loss: 1.6288 - val_accuracy: 0.3812

Epoch 00031: val_loss did not improve from 1.58832
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4778 - accuracy: 0.4593 - val_loss: 1.6397 - val_accuracy: 0.3812

Epoch 00032: val_loss did not improve from 1.58832
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4697 - accuracy: 0.4631 - val_loss: 1.6676 - val_accuracy: 0.3782

Epoch 00033: val_loss did not improve from 1.58832
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5946 - accuracy: 0.3814
Testing Loss = 1.594613, Testing Accuracy = 0.381364
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.5726 - accuracy: 0.1979 - val_loss: 8.8758 - val_accuracy: 0.2112

Epoch 00001: val_loss improved from inf to 8.87577, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.9246 - accuracy: 0.2045 - val_loss: 5.4582 - val_accuracy: 0.2142

Epoch 00002: val_loss improved from 8.87577 to 5.45819, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6615 - accuracy: 0.2075 - val_loss: 4.0226 - val_accuracy: 0.2154

Epoch 00003: val_loss improved from 5.45819 to 4.02261, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.6092 - accuracy: 0.2188 - val_loss: 3.2381 - val_accuracy: 0.2476

Epoch 00004: val_loss improved from 4.02261 to 3.23809, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9230 - accuracy: 0.2777 - val_loss: 2.6944 - val_accuracy: 0.2928

Epoch 00005: val_loss improved from 3.23809 to 2.69442, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5155 - accuracy: 0.2924 - val_loss: 2.3591 - val_accuracy: 0.2979

Epoch 00006: val_loss improved from 2.69442 to 2.35908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2462 - accuracy: 0.2972 - val_loss: 2.1305 - val_accuracy: 0.3062

Epoch 00007: val_loss improved from 2.35908 to 2.13053, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.0570 - accuracy: 0.3039 - val_loss: 1.9742 - val_accuracy: 0.3122

Epoch 00008: val_loss improved from 2.13053 to 1.97416, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9265 - accuracy: 0.3077 - val_loss: 1.8658 - val_accuracy: 0.3170

Epoch 00009: val_loss improved from 1.97416 to 1.86576, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8333 - accuracy: 0.3179 - val_loss: 1.7906 - val_accuracy: 0.3231

Epoch 00010: val_loss improved from 1.86576 to 1.79063, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 11/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7700 - accuracy: 0.3236 - val_loss: 1.7385 - val_accuracy: 0.3272

Epoch 00011: val_loss improved from 1.79063 to 1.73847, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 12/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7223 - accuracy: 0.3310 - val_loss: 1.7029 - val_accuracy: 0.3295

Epoch 00012: val_loss improved from 1.73847 to 1.70289, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6883 - accuracy: 0.3364 - val_loss: 1.6745 - val_accuracy: 0.3371

Epoch 00013: val_loss improved from 1.70289 to 1.67454, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6645 - accuracy: 0.3401 - val_loss: 1.6530 - val_accuracy: 0.3428

Epoch 00014: val_loss improved from 1.67454 to 1.65296, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6442 - accuracy: 0.3472 - val_loss: 1.6379 - val_accuracy: 0.3518

Epoch 00015: val_loss improved from 1.65296 to 1.63793, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6258 - accuracy: 0.3595 - val_loss: 1.6207 - val_accuracy: 0.3587

Epoch 00016: val_loss improved from 1.63793 to 1.62072, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6090 - accuracy: 0.3663 - val_loss: 1.6170 - val_accuracy: 0.3624

Epoch 00017: val_loss improved from 1.62072 to 1.61703, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5989 - accuracy: 0.3711 - val_loss: 1.6123 - val_accuracy: 0.3666

Epoch 00018: val_loss improved from 1.61703 to 1.61232, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5879 - accuracy: 0.3798 - val_loss: 1.6018 - val_accuracy: 0.3699

Epoch 00019: val_loss improved from 1.61232 to 1.60176, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5776 - accuracy: 0.3824 - val_loss: 1.5915 - val_accuracy: 0.3723

Epoch 00020: val_loss improved from 1.60176 to 1.59154, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5663 - accuracy: 0.3876 - val_loss: 1.5928 - val_accuracy: 0.3745

Epoch 00021: val_loss did not improve from 1.59154
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5635 - accuracy: 0.3944 - val_loss: 1.5862 - val_accuracy: 0.3753

Epoch 00022: val_loss improved from 1.59154 to 1.58620, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5517 - accuracy: 0.4000 - val_loss: 1.5904 - val_accuracy: 0.3802

Epoch 00023: val_loss did not improve from 1.58620
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5424 - accuracy: 0.4064 - val_loss: 1.5905 - val_accuracy: 0.3800

Epoch 00024: val_loss did not improve from 1.58620
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5386 - accuracy: 0.4072 - val_loss: 1.5909 - val_accuracy: 0.3792

Epoch 00025: val_loss did not improve from 1.58620
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5309 - accuracy: 0.4156 - val_loss: 1.5882 - val_accuracy: 0.3810

Epoch 00026: val_loss did not improve from 1.58620
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5253 - accuracy: 0.4188 - val_loss: 1.5855 - val_accuracy: 0.3865

Epoch 00027: val_loss improved from 1.58620 to 1.58553, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/1
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5199 - accuracy: 0.4213 - val_loss: 1.5882 - val_accuracy: 0.3866

Epoch 00028: val_loss did not improve from 1.58553
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5102 - accuracy: 0.4279 - val_loss: 1.5959 - val_accuracy: 0.3823

Epoch 00029: val_loss did not improve from 1.58553
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5025 - accuracy: 0.4343 - val_loss: 1.6103 - val_accuracy: 0.3842

Epoch 00030: val_loss did not improve from 1.58553
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4943 - accuracy: 0.4421 - val_loss: 1.6097 - val_accuracy: 0.3828

Epoch 00031: val_loss did not improve from 1.58553
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4878 - accuracy: 0.4448 - val_loss: 1.6135 - val_accuracy: 0.3849

Epoch 00032: val_loss did not improve from 1.58553
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4779 - accuracy: 0.4537 - val_loss: 1.6203 - val_accuracy: 0.3850

Epoch 00033: val_loss did not improve from 1.58553
Epoch 34/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4675 - accuracy: 0.4644 - val_loss: 1.6247 - val_accuracy: 0.3838

Epoch 00034: val_loss did not improve from 1.58553
Epoch 35/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4608 - accuracy: 0.4641 - val_loss: 1.6356 - val_accuracy: 0.3834

Epoch 00035: val_loss did not improve from 1.58553
Epoch 36/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4481 - accuracy: 0.4725 - val_loss: 1.6475 - val_accuracy: 0.3840

Epoch 00036: val_loss did not improve from 1.58553
Epoch 37/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4392 - accuracy: 0.4819 - val_loss: 1.6523 - val_accuracy: 0.3812

Epoch 00037: val_loss did not improve from 1.58553
Epoch 00037: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.5931 - accuracy: 0.3864
Testing Loss = 1.593147, Testing Accuracy = 0.386350
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4302 - accuracy: 0.2006 - val_loss: 8.7010 - val_accuracy: 0.2134

Epoch 00001: val_loss improved from inf to 8.70105, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7824 - accuracy: 0.2039 - val_loss: 5.3540 - val_accuracy: 0.2126

Epoch 00002: val_loss improved from 8.70105 to 5.35398, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5871 - accuracy: 0.2094 - val_loss: 3.9716 - val_accuracy: 0.2146

Epoch 00003: val_loss improved from 5.35398 to 3.97160, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.5513 - accuracy: 0.2337 - val_loss: 3.1739 - val_accuracy: 0.2729

Epoch 00004: val_loss improved from 3.97160 to 3.17389, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8960 - accuracy: 0.2845 - val_loss: 2.6821 - val_accuracy: 0.2936

Epoch 00005: val_loss improved from 3.17389 to 2.68208, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 6/100
83/83 [==============================] - 6s 67ms/step - loss: 2.5094 - accuracy: 0.2927 - val_loss: 2.3556 - val_accuracy: 0.3029

Epoch 00006: val_loss improved from 2.68208 to 2.35556, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2430 - accuracy: 0.2982 - val_loss: 2.1290 - val_accuracy: 0.3068

Epoch 00007: val_loss improved from 2.35556 to 2.12898, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0590 - accuracy: 0.3026 - val_loss: 1.9747 - val_accuracy: 0.3128

Epoch 00008: val_loss improved from 2.12898 to 1.97469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9260 - accuracy: 0.3136 - val_loss: 1.8696 - val_accuracy: 0.3175

Epoch 00009: val_loss improved from 1.97469 to 1.86956, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8326 - accuracy: 0.3185 - val_loss: 1.7920 - val_accuracy: 0.3261

Epoch 00010: val_loss improved from 1.86956 to 1.79198, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7682 - accuracy: 0.3271 - val_loss: 1.7422 - val_accuracy: 0.3271

Epoch 00011: val_loss improved from 1.79198 to 1.74223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7205 - accuracy: 0.3327 - val_loss: 1.7031 - val_accuracy: 0.3332

Epoch 00012: val_loss improved from 1.74223 to 1.70306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6861 - accuracy: 0.3399 - val_loss: 1.6738 - val_accuracy: 0.3446

Epoch 00013: val_loss improved from 1.70306 to 1.67378, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6609 - accuracy: 0.3473 - val_loss: 1.6520 - val_accuracy: 0.3497

Epoch 00014: val_loss improved from 1.67378 to 1.65195, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6391 - accuracy: 0.3548 - val_loss: 1.6343 - val_accuracy: 0.3602

Epoch 00015: val_loss improved from 1.65195 to 1.63433, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 16/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6198 - accuracy: 0.3647 - val_loss: 1.6217 - val_accuracy: 0.3613

Epoch 00016: val_loss improved from 1.63433 to 1.62171, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6067 - accuracy: 0.3708 - val_loss: 1.6154 - val_accuracy: 0.3669

Epoch 00017: val_loss improved from 1.62171 to 1.61542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5981 - accuracy: 0.3748 - val_loss: 1.6036 - val_accuracy: 0.3698

Epoch 00018: val_loss improved from 1.61542 to 1.60358, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5838 - accuracy: 0.3821 - val_loss: 1.5961 - val_accuracy: 0.3726

Epoch 00019: val_loss improved from 1.60358 to 1.59611, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5711 - accuracy: 0.3913 - val_loss: 1.5928 - val_accuracy: 0.3768

Epoch 00020: val_loss improved from 1.59611 to 1.59281, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5646 - accuracy: 0.3964 - val_loss: 1.5916 - val_accuracy: 0.3780

Epoch 00021: val_loss improved from 1.59281 to 1.59155, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/2
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5536 - accuracy: 0.4005 - val_loss: 1.5916 - val_accuracy: 0.3792

Epoch 00022: val_loss did not improve from 1.59155
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5447 - accuracy: 0.4095 - val_loss: 1.5929 - val_accuracy: 0.3784

Epoch 00023: val_loss did not improve from 1.59155
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5400 - accuracy: 0.4109 - val_loss: 1.5959 - val_accuracy: 0.3769

Epoch 00024: val_loss did not improve from 1.59155
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5331 - accuracy: 0.4186 - val_loss: 1.5945 - val_accuracy: 0.3802

Epoch 00025: val_loss did not improve from 1.59155
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5213 - accuracy: 0.4247 - val_loss: 1.6020 - val_accuracy: 0.3836

Epoch 00026: val_loss did not improve from 1.59155
Epoch 27/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5117 - accuracy: 0.4331 - val_loss: 1.6044 - val_accuracy: 0.3851

Epoch 00027: val_loss did not improve from 1.59155
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5027 - accuracy: 0.4402 - val_loss: 1.6154 - val_accuracy: 0.3806

Epoch 00028: val_loss did not improve from 1.59155
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4921 - accuracy: 0.4472 - val_loss: 1.6284 - val_accuracy: 0.3831

Epoch 00029: val_loss did not improve from 1.59155
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4811 - accuracy: 0.4546 - val_loss: 1.6314 - val_accuracy: 0.3788

Epoch 00030: val_loss did not improve from 1.59155
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4703 - accuracy: 0.4624 - val_loss: 1.6369 - val_accuracy: 0.3825

Epoch 00031: val_loss did not improve from 1.59155
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5960 - accuracy: 0.3761
Testing Loss = 1.596027, Testing Accuracy = 0.376079
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4666 - accuracy: 0.1976 - val_loss: 8.7449 - val_accuracy: 0.2126

Epoch 00001: val_loss improved from inf to 8.74490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.8133 - accuracy: 0.2067 - val_loss: 5.3747 - val_accuracy: 0.2143

Epoch 00002: val_loss improved from 8.74490 to 5.37469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.6011 - accuracy: 0.2098 - val_loss: 3.9822 - val_accuracy: 0.2164

Epoch 00003: val_loss improved from 5.37469 to 3.98217, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5656 - accuracy: 0.2264 - val_loss: 3.1839 - val_accuracy: 0.2670

Epoch 00004: val_loss improved from 3.98217 to 3.18393, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 5/100
83/83 [==============================] - 6s 67ms/step - loss: 2.9001 - accuracy: 0.2847 - val_loss: 2.6806 - val_accuracy: 0.2943

Epoch 00005: val_loss improved from 3.18393 to 2.68059, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 6/100
83/83 [==============================] - 6s 67ms/step - loss: 2.5089 - accuracy: 0.2947 - val_loss: 2.3577 - val_accuracy: 0.3023

Epoch 00006: val_loss improved from 2.68059 to 2.35769, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2425 - accuracy: 0.2986 - val_loss: 2.1333 - val_accuracy: 0.3050

Epoch 00007: val_loss improved from 2.35769 to 2.13335, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 8/100
83/83 [==============================] - 6s 67ms/step - loss: 2.0562 - accuracy: 0.3053 - val_loss: 1.9738 - val_accuracy: 0.3125

Epoch 00008: val_loss improved from 2.13335 to 1.97383, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 9/100
83/83 [==============================] - 6s 67ms/step - loss: 1.9245 - accuracy: 0.3149 - val_loss: 1.8711 - val_accuracy: 0.3187

Epoch 00009: val_loss improved from 1.97383 to 1.87107, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8320 - accuracy: 0.3202 - val_loss: 1.7895 - val_accuracy: 0.3268

Epoch 00010: val_loss improved from 1.87107 to 1.78954, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7686 - accuracy: 0.3281 - val_loss: 1.7399 - val_accuracy: 0.3240

Epoch 00011: val_loss improved from 1.78954 to 1.73992, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7209 - accuracy: 0.3321 - val_loss: 1.7052 - val_accuracy: 0.3257

Epoch 00012: val_loss improved from 1.73992 to 1.70520, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6877 - accuracy: 0.3388 - val_loss: 1.6750 - val_accuracy: 0.3398

Epoch 00013: val_loss improved from 1.70520 to 1.67496, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6640 - accuracy: 0.3440 - val_loss: 1.6528 - val_accuracy: 0.3463

Epoch 00014: val_loss improved from 1.67496 to 1.65277, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6426 - accuracy: 0.3511 - val_loss: 1.6387 - val_accuracy: 0.3483

Epoch 00015: val_loss improved from 1.65277 to 1.63869, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6254 - accuracy: 0.3603 - val_loss: 1.6269 - val_accuracy: 0.3541

Epoch 00016: val_loss improved from 1.63869 to 1.62695, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6102 - accuracy: 0.3646 - val_loss: 1.6112 - val_accuracy: 0.3650

Epoch 00017: val_loss improved from 1.62695 to 1.61119, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5941 - accuracy: 0.3751 - val_loss: 1.6144 - val_accuracy: 0.3641

Epoch 00018: val_loss did not improve from 1.61119
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5849 - accuracy: 0.3771 - val_loss: 1.6056 - val_accuracy: 0.3711

Epoch 00019: val_loss improved from 1.61119 to 1.60560, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5757 - accuracy: 0.3870 - val_loss: 1.6075 - val_accuracy: 0.3703

Epoch 00020: val_loss did not improve from 1.60560
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5636 - accuracy: 0.3934 - val_loss: 1.6101 - val_accuracy: 0.3715

Epoch 00021: val_loss did not improve from 1.60560
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5570 - accuracy: 0.3977 - val_loss: 1.6046 - val_accuracy: 0.3758

Epoch 00022: val_loss improved from 1.60560 to 1.60459, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5504 - accuracy: 0.4046 - val_loss: 1.6068 - val_accuracy: 0.3757

Epoch 00023: val_loss did not improve from 1.60459
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5463 - accuracy: 0.4050 - val_loss: 1.5965 - val_accuracy: 0.3752

Epoch 00024: val_loss improved from 1.60459 to 1.59650, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5366 - accuracy: 0.4119 - val_loss: 1.5933 - val_accuracy: 0.3804

Epoch 00025: val_loss improved from 1.59650 to 1.59331, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5304 - accuracy: 0.4170 - val_loss: 1.5902 - val_accuracy: 0.3811

Epoch 00026: val_loss improved from 1.59331 to 1.59023, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/3
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5220 - accuracy: 0.4219 - val_loss: 1.5990 - val_accuracy: 0.3815

Epoch 00027: val_loss did not improve from 1.59023
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5157 - accuracy: 0.4259 - val_loss: 1.5988 - val_accuracy: 0.3836

Epoch 00028: val_loss did not improve from 1.59023
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5088 - accuracy: 0.4328 - val_loss: 1.6031 - val_accuracy: 0.3818

Epoch 00029: val_loss did not improve from 1.59023
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4924 - accuracy: 0.4463 - val_loss: 1.6210 - val_accuracy: 0.3831

Epoch 00030: val_loss did not improve from 1.59023
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4841 - accuracy: 0.4510 - val_loss: 1.6245 - val_accuracy: 0.3837

Epoch 00031: val_loss did not improve from 1.59023
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4714 - accuracy: 0.4598 - val_loss: 1.6308 - val_accuracy: 0.3854

Epoch 00032: val_loss did not improve from 1.59023
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4633 - accuracy: 0.4677 - val_loss: 1.6396 - val_accuracy: 0.3810

Epoch 00033: val_loss did not improve from 1.59023
Epoch 34/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4499 - accuracy: 0.4755 - val_loss: 1.6580 - val_accuracy: 0.3821

Epoch 00034: val_loss did not improve from 1.59023
Epoch 35/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4415 - accuracy: 0.4837 - val_loss: 1.6677 - val_accuracy: 0.3791

Epoch 00035: val_loss did not improve from 1.59023
Epoch 36/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4299 - accuracy: 0.4921 - val_loss: 1.6875 - val_accuracy: 0.3781

Epoch 00036: val_loss did not improve from 1.59023
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.5957 - accuracy: 0.3831
Testing Loss = 1.595713, Testing Accuracy = 0.383150
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 68ms/step - loss: 12.4951 - accuracy: 0.1986 - val_loss: 8.7945 - val_accuracy: 0.2121

Epoch 00001: val_loss improved from inf to 8.79452, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.8614 - accuracy: 0.2064 - val_loss: 5.4139 - val_accuracy: 0.2146

Epoch 00002: val_loss improved from 8.79452 to 5.41390, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.6297 - accuracy: 0.2113 - val_loss: 4.0011 - val_accuracy: 0.2144

Epoch 00003: val_loss improved from 5.41390 to 4.00111, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.5821 - accuracy: 0.2284 - val_loss: 3.1942 - val_accuracy: 0.2773

Epoch 00004: val_loss improved from 4.00111 to 3.19420, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9068 - accuracy: 0.2817 - val_loss: 2.6833 - val_accuracy: 0.2953

Epoch 00005: val_loss improved from 3.19420 to 2.68325, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 6/100
83/83 [==============================] - 6s 67ms/step - loss: 2.5110 - accuracy: 0.2927 - val_loss: 2.3554 - val_accuracy: 0.2996

Epoch 00006: val_loss improved from 2.68325 to 2.35538, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2434 - accuracy: 0.2974 - val_loss: 2.1293 - val_accuracy: 0.3100

Epoch 00007: val_loss improved from 2.35538 to 2.12930, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 8/100
83/83 [==============================] - 6s 67ms/step - loss: 2.0570 - accuracy: 0.3049 - val_loss: 1.9735 - val_accuracy: 0.3159

Epoch 00008: val_loss improved from 2.12930 to 1.97351, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9241 - accuracy: 0.3158 - val_loss: 1.8697 - val_accuracy: 0.3184

Epoch 00009: val_loss improved from 1.97351 to 1.86966, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8329 - accuracy: 0.3204 - val_loss: 1.7914 - val_accuracy: 0.3262

Epoch 00010: val_loss improved from 1.86966 to 1.79136, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7684 - accuracy: 0.3253 - val_loss: 1.7406 - val_accuracy: 0.3249

Epoch 00011: val_loss improved from 1.79136 to 1.74064, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7203 - accuracy: 0.3307 - val_loss: 1.7027 - val_accuracy: 0.3310

Epoch 00012: val_loss improved from 1.74064 to 1.70269, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6888 - accuracy: 0.3368 - val_loss: 1.6756 - val_accuracy: 0.3367

Epoch 00013: val_loss improved from 1.70269 to 1.67559, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6642 - accuracy: 0.3429 - val_loss: 1.6536 - val_accuracy: 0.3447

Epoch 00014: val_loss improved from 1.67559 to 1.65363, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6427 - accuracy: 0.3504 - val_loss: 1.6374 - val_accuracy: 0.3531

Epoch 00015: val_loss improved from 1.65363 to 1.63740, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6271 - accuracy: 0.3582 - val_loss: 1.6238 - val_accuracy: 0.3616

Epoch 00016: val_loss improved from 1.63740 to 1.62375, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6113 - accuracy: 0.3663 - val_loss: 1.6201 - val_accuracy: 0.3638

Epoch 00017: val_loss improved from 1.62375 to 1.62009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5993 - accuracy: 0.3721 - val_loss: 1.6050 - val_accuracy: 0.3694

Epoch 00018: val_loss improved from 1.62009 to 1.60497, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5897 - accuracy: 0.3765 - val_loss: 1.5983 - val_accuracy: 0.3688

Epoch 00019: val_loss improved from 1.60497 to 1.59835, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 20/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5809 - accuracy: 0.3810 - val_loss: 1.5968 - val_accuracy: 0.3719

Epoch 00020: val_loss improved from 1.59835 to 1.59681, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 21/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5698 - accuracy: 0.3885 - val_loss: 1.5926 - val_accuracy: 0.3726

Epoch 00021: val_loss improved from 1.59681 to 1.59258, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5628 - accuracy: 0.3951 - val_loss: 1.5883 - val_accuracy: 0.3775

Epoch 00022: val_loss improved from 1.59258 to 1.58826, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/4
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5539 - accuracy: 0.3988 - val_loss: 1.5883 - val_accuracy: 0.3764

Epoch 00023: val_loss did not improve from 1.58826
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5473 - accuracy: 0.4045 - val_loss: 1.5903 - val_accuracy: 0.3756

Epoch 00024: val_loss did not improve from 1.58826
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5376 - accuracy: 0.4127 - val_loss: 1.5935 - val_accuracy: 0.3794

Epoch 00025: val_loss did not improve from 1.58826
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5295 - accuracy: 0.4175 - val_loss: 1.6014 - val_accuracy: 0.3753

Epoch 00026: val_loss did not improve from 1.58826
Epoch 27/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5221 - accuracy: 0.4247 - val_loss: 1.5972 - val_accuracy: 0.3802

Epoch 00027: val_loss did not improve from 1.58826
Epoch 28/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5158 - accuracy: 0.4291 - val_loss: 1.6140 - val_accuracy: 0.3741

Epoch 00028: val_loss did not improve from 1.58826
Epoch 29/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5055 - accuracy: 0.4363 - val_loss: 1.6231 - val_accuracy: 0.3788

Epoch 00029: val_loss did not improve from 1.58826
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4999 - accuracy: 0.4406 - val_loss: 1.6547 - val_accuracy: 0.3705

Epoch 00030: val_loss did not improve from 1.58826
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4901 - accuracy: 0.4476 - val_loss: 1.6340 - val_accuracy: 0.3757

Epoch 00031: val_loss did not improve from 1.58826
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4814 - accuracy: 0.4521 - val_loss: 1.6247 - val_accuracy: 0.3822

Epoch 00032: val_loss did not improve from 1.58826
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5912 - accuracy: 0.3826
Testing Loss = 1.591157, Testing Accuracy = 0.382554
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 75ms/step - loss: 12.5341 - accuracy: 0.1953 - val_loss: 8.8346 - val_accuracy: 0.2127

Epoch 00001: val_loss improved from inf to 8.83459, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 2/100
83/83 [==============================] - 6s 70ms/step - loss: 6.8904 - accuracy: 0.2064 - val_loss: 5.4347 - val_accuracy: 0.2127

Epoch 00002: val_loss improved from 8.83459 to 5.43470, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6463 - accuracy: 0.2101 - val_loss: 4.0128 - val_accuracy: 0.2150

Epoch 00003: val_loss improved from 5.43470 to 4.01276, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.6083 - accuracy: 0.2133 - val_loss: 3.2575 - val_accuracy: 0.2199

Epoch 00004: val_loss improved from 4.01276 to 3.25751, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9408 - accuracy: 0.2629 - val_loss: 2.6917 - val_accuracy: 0.2872

Epoch 00005: val_loss improved from 3.25751 to 2.69168, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5126 - accuracy: 0.2887 - val_loss: 2.3579 - val_accuracy: 0.2985

Epoch 00006: val_loss improved from 2.69168 to 2.35790, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 7/100
83/83 [==============================] - 6s 67ms/step - loss: 2.2423 - accuracy: 0.2980 - val_loss: 2.1301 - val_accuracy: 0.3057

Epoch 00007: val_loss improved from 2.35790 to 2.13010, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.0560 - accuracy: 0.3039 - val_loss: 1.9729 - val_accuracy: 0.3123

Epoch 00008: val_loss improved from 2.13010 to 1.97289, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9248 - accuracy: 0.3093 - val_loss: 1.8648 - val_accuracy: 0.3185

Epoch 00009: val_loss improved from 1.97289 to 1.86479, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8329 - accuracy: 0.3149 - val_loss: 1.7932 - val_accuracy: 0.3234

Epoch 00010: val_loss improved from 1.86479 to 1.79317, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7668 - accuracy: 0.3228 - val_loss: 1.7380 - val_accuracy: 0.3281

Epoch 00011: val_loss improved from 1.79317 to 1.73800, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7216 - accuracy: 0.3286 - val_loss: 1.7010 - val_accuracy: 0.3268

Epoch 00012: val_loss improved from 1.73800 to 1.70102, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6877 - accuracy: 0.3326 - val_loss: 1.6781 - val_accuracy: 0.3301

Epoch 00013: val_loss improved from 1.70102 to 1.67810, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6638 - accuracy: 0.3400 - val_loss: 1.6564 - val_accuracy: 0.3360

Epoch 00014: val_loss improved from 1.67810 to 1.65644, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6459 - accuracy: 0.3439 - val_loss: 1.6387 - val_accuracy: 0.3469

Epoch 00015: val_loss improved from 1.65644 to 1.63872, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 16/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6283 - accuracy: 0.3520 - val_loss: 1.6259 - val_accuracy: 0.3548

Epoch 00016: val_loss improved from 1.63872 to 1.62590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6131 - accuracy: 0.3634 - val_loss: 1.6120 - val_accuracy: 0.3646

Epoch 00017: val_loss improved from 1.62590 to 1.61204, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 18/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6027 - accuracy: 0.3682 - val_loss: 1.6046 - val_accuracy: 0.3673

Epoch 00018: val_loss improved from 1.61204 to 1.60464, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 19/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5909 - accuracy: 0.3763 - val_loss: 1.5971 - val_accuracy: 0.3728

Epoch 00019: val_loss improved from 1.60464 to 1.59706, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 20/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5806 - accuracy: 0.3801 - val_loss: 1.5929 - val_accuracy: 0.3754

Epoch 00020: val_loss improved from 1.59706 to 1.59286, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 21/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5680 - accuracy: 0.3895 - val_loss: 1.5881 - val_accuracy: 0.3806

Epoch 00021: val_loss improved from 1.59286 to 1.58814, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5631 - accuracy: 0.3917 - val_loss: 1.5846 - val_accuracy: 0.3804

Epoch 00022: val_loss improved from 1.58814 to 1.58463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/5
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5529 - accuracy: 0.3985 - val_loss: 1.5855 - val_accuracy: 0.3809

Epoch 00023: val_loss did not improve from 1.58463
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5439 - accuracy: 0.4050 - val_loss: 1.5866 - val_accuracy: 0.3815

Epoch 00024: val_loss did not improve from 1.58463
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5407 - accuracy: 0.4088 - val_loss: 1.5861 - val_accuracy: 0.3827

Epoch 00025: val_loss did not improve from 1.58463
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5316 - accuracy: 0.4156 - val_loss: 1.5908 - val_accuracy: 0.3819

Epoch 00026: val_loss did not improve from 1.58463
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5300 - accuracy: 0.4183 - val_loss: 1.5918 - val_accuracy: 0.3797

Epoch 00027: val_loss did not improve from 1.58463
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5187 - accuracy: 0.4235 - val_loss: 1.5943 - val_accuracy: 0.3810

Epoch 00028: val_loss did not improve from 1.58463
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5073 - accuracy: 0.4312 - val_loss: 1.6091 - val_accuracy: 0.3790

Epoch 00029: val_loss did not improve from 1.58463
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4994 - accuracy: 0.4392 - val_loss: 1.6076 - val_accuracy: 0.3819

Epoch 00030: val_loss did not improve from 1.58463
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4913 - accuracy: 0.4453 - val_loss: 1.6223 - val_accuracy: 0.3803

Epoch 00031: val_loss did not improve from 1.58463
Epoch 32/100
83/83 [==============================] - 6s 67ms/step - loss: 1.4837 - accuracy: 0.4548 - val_loss: 1.6227 - val_accuracy: 0.3825

Epoch 00032: val_loss did not improve from 1.58463
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.5895 - accuracy: 0.3799
Testing Loss = 1.589494, Testing Accuracy = 0.379949
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4962 - accuracy: 0.1927 - val_loss: 8.7929 - val_accuracy: 0.2132

Epoch 00001: val_loss improved from inf to 8.79290, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8595 - accuracy: 0.2047 - val_loss: 5.4131 - val_accuracy: 0.2116

Epoch 00002: val_loss improved from 8.79290 to 5.41308, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.6311 - accuracy: 0.2065 - val_loss: 4.0025 - val_accuracy: 0.2146

Epoch 00003: val_loss improved from 5.41308 to 4.00247, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5821 - accuracy: 0.2267 - val_loss: 3.1882 - val_accuracy: 0.2662

Epoch 00004: val_loss improved from 4.00247 to 3.18818, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 5/100
83/83 [==============================] - 6s 67ms/step - loss: 2.9093 - accuracy: 0.2810 - val_loss: 2.6869 - val_accuracy: 0.2905

Epoch 00005: val_loss improved from 3.18818 to 2.68687, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5142 - accuracy: 0.2904 - val_loss: 2.3620 - val_accuracy: 0.2943

Epoch 00006: val_loss improved from 2.68687 to 2.36197, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2461 - accuracy: 0.2971 - val_loss: 2.1323 - val_accuracy: 0.3021

Epoch 00007: val_loss improved from 2.36197 to 2.13226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0603 - accuracy: 0.3050 - val_loss: 1.9766 - val_accuracy: 0.3108

Epoch 00008: val_loss improved from 2.13226 to 1.97659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9284 - accuracy: 0.3116 - val_loss: 1.8680 - val_accuracy: 0.3171

Epoch 00009: val_loss improved from 1.97659 to 1.86803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8359 - accuracy: 0.3132 - val_loss: 1.7972 - val_accuracy: 0.3190

Epoch 00010: val_loss improved from 1.86803 to 1.79717, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7674 - accuracy: 0.3221 - val_loss: 1.7392 - val_accuracy: 0.3276

Epoch 00011: val_loss improved from 1.79717 to 1.73922, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7236 - accuracy: 0.3287 - val_loss: 1.7033 - val_accuracy: 0.3299

Epoch 00012: val_loss improved from 1.73922 to 1.70327, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6884 - accuracy: 0.3379 - val_loss: 1.6758 - val_accuracy: 0.3339

Epoch 00013: val_loss improved from 1.70327 to 1.67577, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6639 - accuracy: 0.3411 - val_loss: 1.6519 - val_accuracy: 0.3457

Epoch 00014: val_loss improved from 1.67577 to 1.65194, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6441 - accuracy: 0.3462 - val_loss: 1.6370 - val_accuracy: 0.3482

Epoch 00015: val_loss improved from 1.65194 to 1.63697, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6265 - accuracy: 0.3565 - val_loss: 1.6220 - val_accuracy: 0.3602

Epoch 00016: val_loss improved from 1.63697 to 1.62202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6114 - accuracy: 0.3634 - val_loss: 1.6109 - val_accuracy: 0.3661

Epoch 00017: val_loss improved from 1.62202 to 1.61089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5992 - accuracy: 0.3707 - val_loss: 1.6008 - val_accuracy: 0.3679

Epoch 00018: val_loss improved from 1.61089 to 1.60076, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5874 - accuracy: 0.3771 - val_loss: 1.5928 - val_accuracy: 0.3716

Epoch 00019: val_loss improved from 1.60076 to 1.59278, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5764 - accuracy: 0.3845 - val_loss: 1.5916 - val_accuracy: 0.3755

Epoch 00020: val_loss improved from 1.59278 to 1.59158, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5703 - accuracy: 0.3864 - val_loss: 1.5866 - val_accuracy: 0.3786

Epoch 00021: val_loss improved from 1.59158 to 1.58663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5581 - accuracy: 0.3947 - val_loss: 1.5841 - val_accuracy: 0.3799

Epoch 00022: val_loss improved from 1.58663 to 1.58413, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5546 - accuracy: 0.3986 - val_loss: 1.5822 - val_accuracy: 0.3824

Epoch 00023: val_loss improved from 1.58413 to 1.58216, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/6
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5434 - accuracy: 0.4030 - val_loss: 1.5823 - val_accuracy: 0.3819

Epoch 00024: val_loss did not improve from 1.58216
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5383 - accuracy: 0.4068 - val_loss: 1.5864 - val_accuracy: 0.3808

Epoch 00025: val_loss did not improve from 1.58216
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5301 - accuracy: 0.4155 - val_loss: 1.5859 - val_accuracy: 0.3872

Epoch 00026: val_loss did not improve from 1.58216
Epoch 27/100
83/83 [==============================] - 6s 67ms/step - loss: 1.5292 - accuracy: 0.4163 - val_loss: 1.5853 - val_accuracy: 0.3850

Epoch 00027: val_loss did not improve from 1.58216
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5196 - accuracy: 0.4218 - val_loss: 1.5870 - val_accuracy: 0.3884

Epoch 00028: val_loss did not improve from 1.58216
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5147 - accuracy: 0.4267 - val_loss: 1.5898 - val_accuracy: 0.3842

Epoch 00029: val_loss did not improve from 1.58216
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5029 - accuracy: 0.4351 - val_loss: 1.5986 - val_accuracy: 0.3854

Epoch 00030: val_loss did not improve from 1.58216
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4942 - accuracy: 0.4415 - val_loss: 1.6040 - val_accuracy: 0.3880

Epoch 00031: val_loss did not improve from 1.58216
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4841 - accuracy: 0.4481 - val_loss: 1.6164 - val_accuracy: 0.3869

Epoch 00032: val_loss did not improve from 1.58216
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4795 - accuracy: 0.4504 - val_loss: 1.6190 - val_accuracy: 0.3856

Epoch 00033: val_loss did not improve from 1.58216
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5882 - accuracy: 0.3834
Testing Loss = 1.588189, Testing Accuracy = 0.383447
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.5015 - accuracy: 0.1952 - val_loss: 8.7787 - val_accuracy: 0.2114

Epoch 00001: val_loss improved from inf to 8.77868, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.8432 - accuracy: 0.2062 - val_loss: 5.3975 - val_accuracy: 0.2125

Epoch 00002: val_loss improved from 8.77868 to 5.39751, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.6166 - accuracy: 0.2100 - val_loss: 3.9939 - val_accuracy: 0.2181

Epoch 00003: val_loss improved from 5.39751 to 3.99393, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5582 - accuracy: 0.2400 - val_loss: 3.1848 - val_accuracy: 0.2793

Epoch 00004: val_loss improved from 3.99393 to 3.18480, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9072 - accuracy: 0.2833 - val_loss: 2.6914 - val_accuracy: 0.2920

Epoch 00005: val_loss improved from 3.18480 to 2.69141, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5153 - accuracy: 0.2963 - val_loss: 2.3612 - val_accuracy: 0.3023

Epoch 00006: val_loss improved from 2.69141 to 2.36119, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2473 - accuracy: 0.3034 - val_loss: 2.1342 - val_accuracy: 0.3096

Epoch 00007: val_loss improved from 2.36119 to 2.13419, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0603 - accuracy: 0.3063 - val_loss: 1.9798 - val_accuracy: 0.3109

Epoch 00008: val_loss improved from 2.13419 to 1.97984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9295 - accuracy: 0.3129 - val_loss: 1.8707 - val_accuracy: 0.3170

Epoch 00009: val_loss improved from 1.97984 to 1.87073, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8352 - accuracy: 0.3190 - val_loss: 1.7950 - val_accuracy: 0.3258

Epoch 00010: val_loss improved from 1.87073 to 1.79500, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7725 - accuracy: 0.3232 - val_loss: 1.7409 - val_accuracy: 0.3295

Epoch 00011: val_loss improved from 1.79500 to 1.74094, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7245 - accuracy: 0.3301 - val_loss: 1.7056 - val_accuracy: 0.3293

Epoch 00012: val_loss improved from 1.74094 to 1.70563, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6909 - accuracy: 0.3364 - val_loss: 1.6788 - val_accuracy: 0.3350

Epoch 00013: val_loss improved from 1.70563 to 1.67884, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6665 - accuracy: 0.3430 - val_loss: 1.6587 - val_accuracy: 0.3425

Epoch 00014: val_loss improved from 1.67884 to 1.65869, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6437 - accuracy: 0.3510 - val_loss: 1.6395 - val_accuracy: 0.3534

Epoch 00015: val_loss improved from 1.65869 to 1.63952, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6264 - accuracy: 0.3600 - val_loss: 1.6244 - val_accuracy: 0.3608

Epoch 00016: val_loss improved from 1.63952 to 1.62442, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6145 - accuracy: 0.3644 - val_loss: 1.6143 - val_accuracy: 0.3665

Epoch 00017: val_loss improved from 1.62442 to 1.61427, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6002 - accuracy: 0.3710 - val_loss: 1.6177 - val_accuracy: 0.3646

Epoch 00018: val_loss did not improve from 1.61427
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5907 - accuracy: 0.3760 - val_loss: 1.5994 - val_accuracy: 0.3721

Epoch 00019: val_loss improved from 1.61427 to 1.59936, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5798 - accuracy: 0.3836 - val_loss: 1.6015 - val_accuracy: 0.3709

Epoch 00020: val_loss did not improve from 1.59936
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5711 - accuracy: 0.3908 - val_loss: 1.5910 - val_accuracy: 0.3775

Epoch 00021: val_loss improved from 1.59936 to 1.59099, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/7
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5654 - accuracy: 0.3925 - val_loss: 1.5924 - val_accuracy: 0.3787

Epoch 00022: val_loss did not improve from 1.59099
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5545 - accuracy: 0.4016 - val_loss: 1.5918 - val_accuracy: 0.3804

Epoch 00023: val_loss did not improve from 1.59099
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5470 - accuracy: 0.4049 - val_loss: 1.5937 - val_accuracy: 0.3815

Epoch 00024: val_loss did not improve from 1.59099
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5369 - accuracy: 0.4120 - val_loss: 1.5986 - val_accuracy: 0.3800

Epoch 00025: val_loss did not improve from 1.59099
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5282 - accuracy: 0.4231 - val_loss: 1.6085 - val_accuracy: 0.3776

Epoch 00026: val_loss did not improve from 1.59099
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5206 - accuracy: 0.4275 - val_loss: 1.6091 - val_accuracy: 0.3812

Epoch 00027: val_loss did not improve from 1.59099
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5132 - accuracy: 0.4330 - val_loss: 1.6167 - val_accuracy: 0.3786

Epoch 00028: val_loss did not improve from 1.59099
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5040 - accuracy: 0.4415 - val_loss: 1.6315 - val_accuracy: 0.3756

Epoch 00029: val_loss did not improve from 1.59099
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4932 - accuracy: 0.4505 - val_loss: 1.6357 - val_accuracy: 0.3789

Epoch 00030: val_loss did not improve from 1.59099
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4854 - accuracy: 0.4543 - val_loss: 1.6430 - val_accuracy: 0.3752

Epoch 00031: val_loss did not improve from 1.59099
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5986 - accuracy: 0.3789
Testing Loss = 1.598621, Testing Accuracy = 0.378907
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.4268 - accuracy: 0.1971 - val_loss: 8.7068 - val_accuracy: 0.2122

Epoch 00001: val_loss improved from inf to 8.70680, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.7894 - accuracy: 0.2045 - val_loss: 5.3602 - val_accuracy: 0.2138

Epoch 00002: val_loss improved from 8.70680 to 5.36019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.5904 - accuracy: 0.2081 - val_loss: 3.9744 - val_accuracy: 0.2157

Epoch 00003: val_loss improved from 5.36019 to 3.97442, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5435 - accuracy: 0.2395 - val_loss: 3.1783 - val_accuracy: 0.2798

Epoch 00004: val_loss improved from 3.97442 to 3.17825, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9034 - accuracy: 0.2807 - val_loss: 2.6916 - val_accuracy: 0.2940

Epoch 00005: val_loss improved from 3.17825 to 2.69155, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5151 - accuracy: 0.2906 - val_loss: 2.3633 - val_accuracy: 0.2983

Epoch 00006: val_loss improved from 2.69155 to 2.36331, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2489 - accuracy: 0.2957 - val_loss: 2.1375 - val_accuracy: 0.3041

Epoch 00007: val_loss improved from 2.36331 to 2.13753, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0620 - accuracy: 0.3019 - val_loss: 1.9777 - val_accuracy: 0.3130

Epoch 00008: val_loss improved from 2.13753 to 1.97772, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9310 - accuracy: 0.3097 - val_loss: 1.8701 - val_accuracy: 0.3188

Epoch 00009: val_loss improved from 1.97772 to 1.87006, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8385 - accuracy: 0.3140 - val_loss: 1.7987 - val_accuracy: 0.3206

Epoch 00010: val_loss improved from 1.87006 to 1.79871, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7725 - accuracy: 0.3229 - val_loss: 1.7460 - val_accuracy: 0.3252

Epoch 00011: val_loss improved from 1.79871 to 1.74598, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7255 - accuracy: 0.3269 - val_loss: 1.7056 - val_accuracy: 0.3322

Epoch 00012: val_loss improved from 1.74598 to 1.70556, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6939 - accuracy: 0.3333 - val_loss: 1.6823 - val_accuracy: 0.3298

Epoch 00013: val_loss improved from 1.70556 to 1.68225, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6682 - accuracy: 0.3407 - val_loss: 1.6602 - val_accuracy: 0.3401

Epoch 00014: val_loss improved from 1.68225 to 1.66021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6501 - accuracy: 0.3423 - val_loss: 1.6432 - val_accuracy: 0.3494

Epoch 00015: val_loss improved from 1.66021 to 1.64315, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6329 - accuracy: 0.3501 - val_loss: 1.6291 - val_accuracy: 0.3558

Epoch 00016: val_loss improved from 1.64315 to 1.62908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6160 - accuracy: 0.3605 - val_loss: 1.6271 - val_accuracy: 0.3596

Epoch 00017: val_loss improved from 1.62908 to 1.62712, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6086 - accuracy: 0.3646 - val_loss: 1.6097 - val_accuracy: 0.3667

Epoch 00018: val_loss improved from 1.62712 to 1.60973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5915 - accuracy: 0.3740 - val_loss: 1.6083 - val_accuracy: 0.3667

Epoch 00019: val_loss improved from 1.60973 to 1.60828, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5828 - accuracy: 0.3826 - val_loss: 1.6031 - val_accuracy: 0.3697

Epoch 00020: val_loss improved from 1.60828 to 1.60307, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5724 - accuracy: 0.3891 - val_loss: 1.6158 - val_accuracy: 0.3668

Epoch 00021: val_loss did not improve from 1.60307
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5690 - accuracy: 0.3879 - val_loss: 1.5928 - val_accuracy: 0.3747

Epoch 00022: val_loss improved from 1.60307 to 1.59279, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5571 - accuracy: 0.3976 - val_loss: 1.5880 - val_accuracy: 0.3777

Epoch 00023: val_loss improved from 1.59279 to 1.58799, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/8
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5461 - accuracy: 0.4055 - val_loss: 1.5961 - val_accuracy: 0.3790

Epoch 00024: val_loss did not improve from 1.58799
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5389 - accuracy: 0.4101 - val_loss: 1.5898 - val_accuracy: 0.3812

Epoch 00025: val_loss did not improve from 1.58799
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5376 - accuracy: 0.4119 - val_loss: 1.5907 - val_accuracy: 0.3791

Epoch 00026: val_loss did not improve from 1.58799
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5276 - accuracy: 0.4194 - val_loss: 1.5914 - val_accuracy: 0.3811

Epoch 00027: val_loss did not improve from 1.58799
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5208 - accuracy: 0.4259 - val_loss: 1.5954 - val_accuracy: 0.3825

Epoch 00028: val_loss did not improve from 1.58799
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5119 - accuracy: 0.4295 - val_loss: 1.6063 - val_accuracy: 0.3837

Epoch 00029: val_loss did not improve from 1.58799
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5007 - accuracy: 0.4414 - val_loss: 1.6092 - val_accuracy: 0.3863

Epoch 00030: val_loss did not improve from 1.58799
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4901 - accuracy: 0.4483 - val_loss: 1.6205 - val_accuracy: 0.3858

Epoch 00031: val_loss did not improve from 1.58799
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4805 - accuracy: 0.4548 - val_loss: 1.6245 - val_accuracy: 0.3823

Epoch 00032: val_loss did not improve from 1.58799
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4730 - accuracy: 0.4605 - val_loss: 1.6504 - val_accuracy: 0.3813

Epoch 00033: val_loss did not improve from 1.58799
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5921 - accuracy: 0.3819
Testing Loss = 1.592051, Testing Accuracy = 0.381884
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.5372 - accuracy: 0.1969 - val_loss: 8.8356 - val_accuracy: 0.2099

Epoch 00001: val_loss improved from inf to 8.83565, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 2/100
83/83 [==============================] - 6s 67ms/step - loss: 6.8871 - accuracy: 0.2052 - val_loss: 5.4274 - val_accuracy: 0.2124

Epoch 00002: val_loss improved from 8.83565 to 5.42741, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.6342 - accuracy: 0.2121 - val_loss: 4.0032 - val_accuracy: 0.2203

Epoch 00003: val_loss improved from 5.42741 to 4.00319, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5363 - accuracy: 0.2605 - val_loss: 3.1850 - val_accuracy: 0.2792

Epoch 00004: val_loss improved from 4.00319 to 3.18504, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9092 - accuracy: 0.2874 - val_loss: 2.7019 - val_accuracy: 0.2900

Epoch 00005: val_loss improved from 3.18504 to 2.70186, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5225 - accuracy: 0.2928 - val_loss: 2.3679 - val_accuracy: 0.3018

Epoch 00006: val_loss improved from 2.70186 to 2.36786, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2527 - accuracy: 0.3013 - val_loss: 2.1416 - val_accuracy: 0.3077

Epoch 00007: val_loss improved from 2.36786 to 2.14164, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0649 - accuracy: 0.3078 - val_loss: 1.9830 - val_accuracy: 0.3157

Epoch 00008: val_loss improved from 2.14164 to 1.98299, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 9/100
83/83 [==============================] - 6s 67ms/step - loss: 1.9340 - accuracy: 0.3150 - val_loss: 1.8748 - val_accuracy: 0.3181

Epoch 00009: val_loss improved from 1.98299 to 1.87475, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8413 - accuracy: 0.3167 - val_loss: 1.7990 - val_accuracy: 0.3228

Epoch 00010: val_loss improved from 1.87475 to 1.79903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7753 - accuracy: 0.3230 - val_loss: 1.7494 - val_accuracy: 0.3233

Epoch 00011: val_loss improved from 1.79903 to 1.74940, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7293 - accuracy: 0.3254 - val_loss: 1.7095 - val_accuracy: 0.3291

Epoch 00012: val_loss improved from 1.74940 to 1.70949, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6962 - accuracy: 0.3291 - val_loss: 1.6836 - val_accuracy: 0.3313

Epoch 00013: val_loss improved from 1.70949 to 1.68360, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6715 - accuracy: 0.3361 - val_loss: 1.6648 - val_accuracy: 0.3313

Epoch 00014: val_loss improved from 1.68360 to 1.66481, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6529 - accuracy: 0.3438 - val_loss: 1.6512 - val_accuracy: 0.3374

Epoch 00015: val_loss improved from 1.66481 to 1.65122, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6390 - accuracy: 0.3469 - val_loss: 1.6363 - val_accuracy: 0.3467

Epoch 00016: val_loss improved from 1.65122 to 1.63634, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 17/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6247 - accuracy: 0.3556 - val_loss: 1.6292 - val_accuracy: 0.3505

Epoch 00017: val_loss improved from 1.63634 to 1.62920, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6117 - accuracy: 0.3620 - val_loss: 1.6178 - val_accuracy: 0.3599

Epoch 00018: val_loss improved from 1.62920 to 1.61781, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 19/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6012 - accuracy: 0.3687 - val_loss: 1.6086 - val_accuracy: 0.3663

Epoch 00019: val_loss improved from 1.61781 to 1.60859, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5903 - accuracy: 0.3758 - val_loss: 1.6039 - val_accuracy: 0.3685

Epoch 00020: val_loss improved from 1.60859 to 1.60387, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5822 - accuracy: 0.3809 - val_loss: 1.6017 - val_accuracy: 0.3706

Epoch 00021: val_loss improved from 1.60387 to 1.60174, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5691 - accuracy: 0.3894 - val_loss: 1.6010 - val_accuracy: 0.3780

Epoch 00022: val_loss improved from 1.60174 to 1.60096, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5650 - accuracy: 0.3913 - val_loss: 1.5956 - val_accuracy: 0.3753

Epoch 00023: val_loss improved from 1.60096 to 1.59556, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5564 - accuracy: 0.3983 - val_loss: 1.5937 - val_accuracy: 0.3805

Epoch 00024: val_loss improved from 1.59556 to 1.59374, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.05/Try/9
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5461 - accuracy: 0.4076 - val_loss: 1.5981 - val_accuracy: 0.3813

Epoch 00025: val_loss did not improve from 1.59374
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5359 - accuracy: 0.4150 - val_loss: 1.6014 - val_accuracy: 0.3782

Epoch 00026: val_loss did not improve from 1.59374
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5263 - accuracy: 0.4206 - val_loss: 1.6070 - val_accuracy: 0.3782

Epoch 00027: val_loss did not improve from 1.59374
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5169 - accuracy: 0.4285 - val_loss: 1.6092 - val_accuracy: 0.3820

Epoch 00028: val_loss did not improve from 1.59374
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5068 - accuracy: 0.4351 - val_loss: 1.6156 - val_accuracy: 0.3831

Epoch 00029: val_loss did not improve from 1.59374
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5014 - accuracy: 0.4421 - val_loss: 1.6211 - val_accuracy: 0.3801

Epoch 00030: val_loss did not improve from 1.59374
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4904 - accuracy: 0.4507 - val_loss: 1.6386 - val_accuracy: 0.3786

Epoch 00031: val_loss did not improve from 1.59374
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4786 - accuracy: 0.4571 - val_loss: 1.6407 - val_accuracy: 0.3784

Epoch 00032: val_loss did not improve from 1.59374
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4687 - accuracy: 0.4652 - val_loss: 1.6554 - val_accuracy: 0.3772

Epoch 00033: val_loss did not improve from 1.59374
Epoch 34/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4565 - accuracy: 0.4749 - val_loss: 1.6714 - val_accuracy: 0.3777

Epoch 00034: val_loss did not improve from 1.59374
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.5996 - accuracy: 0.3777
Testing Loss = 1.599647, Testing Accuracy = 0.377717
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 83.13 +- 0.1511 %)
$W^-/W^-$ (auc = 82.05 +- 0.1524 %)
$Z/Z$ (auc = 75.23 +- 0.4430 %)
$W^+/W^-$ (auc = 69.52 +- 0.1869 %)
$W^+/Z$$ (auc = 66.44 +- 0.1878 %)
$W^-/Z$ (auc = 68.05 +- 0.1221 %)
The summarized testing accuracy = 38.11 +- 0.2878 %, with the loss = 1.5939 +- 0.003566
