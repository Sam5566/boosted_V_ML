

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-23 01:04:40.757796
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 13s 21ms/step - loss: 12.8758 - accuracy: 0.1939 - val_loss: 10.6154 - val_accuracy: 0.2092

Epoch 00001: val_loss improved from inf to 10.61541, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9106 - accuracy: 0.2194 - val_loss: 7.3992 - val_accuracy: 0.2316

Epoch 00002: val_loss improved from 10.61541 to 7.39921, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2543 - accuracy: 0.2670 - val_loss: 5.3121 - val_accuracy: 0.2725

Epoch 00003: val_loss improved from 7.39921 to 5.31212, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 4/100
83/83 [==============================] - 1s 14ms/step - loss: 4.5903 - accuracy: 0.2760 - val_loss: 3.9903 - val_accuracy: 0.2883

Epoch 00004: val_loss improved from 5.31212 to 3.99025, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5322 - accuracy: 0.2851 - val_loss: 3.1463 - val_accuracy: 0.2945

Epoch 00005: val_loss improved from 3.99025 to 3.14630, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 6/100
83/83 [==============================] - 1s 14ms/step - loss: 2.8643 - accuracy: 0.2874 - val_loss: 2.6117 - val_accuracy: 0.2992

Epoch 00006: val_loss improved from 3.14630 to 2.61167, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 7/100
83/83 [==============================] - 1s 14ms/step - loss: 2.4320 - accuracy: 0.2944 - val_loss: 2.2731 - val_accuracy: 0.3021

Epoch 00007: val_loss improved from 2.61167 to 2.27309, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1587 - accuracy: 0.2973 - val_loss: 2.0525 - val_accuracy: 0.3049

Epoch 00008: val_loss improved from 2.27309 to 2.05247, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9801 - accuracy: 0.2994 - val_loss: 1.9111 - val_accuracy: 0.3078

Epoch 00009: val_loss improved from 2.05247 to 1.91113, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 10/100
83/83 [==============================] - 1s 14ms/step - loss: 1.8608 - accuracy: 0.3094 - val_loss: 1.8165 - val_accuracy: 0.3109

Epoch 00010: val_loss improved from 1.91113 to 1.81648, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7829 - accuracy: 0.3117 - val_loss: 1.7583 - val_accuracy: 0.3120

Epoch 00011: val_loss improved from 1.81648 to 1.75828, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 12/100
83/83 [==============================] - 1s 14ms/step - loss: 1.7270 - accuracy: 0.3149 - val_loss: 1.7148 - val_accuracy: 0.3207

Epoch 00012: val_loss improved from 1.75828 to 1.71481, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6898 - accuracy: 0.3228 - val_loss: 1.6826 - val_accuracy: 0.3285

Epoch 00013: val_loss improved from 1.71481 to 1.68264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6640 - accuracy: 0.3255 - val_loss: 1.6655 - val_accuracy: 0.3297

Epoch 00014: val_loss improved from 1.68264 to 1.66551, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6424 - accuracy: 0.3298 - val_loss: 1.6488 - val_accuracy: 0.3323

Epoch 00015: val_loss improved from 1.66551 to 1.64882, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6294 - accuracy: 0.3316 - val_loss: 1.6384 - val_accuracy: 0.3344

Epoch 00016: val_loss improved from 1.64882 to 1.63839, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6192 - accuracy: 0.3349 - val_loss: 1.6311 - val_accuracy: 0.3372

Epoch 00017: val_loss improved from 1.63839 to 1.63109, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 18/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6092 - accuracy: 0.3393 - val_loss: 1.6263 - val_accuracy: 0.3345

Epoch 00018: val_loss improved from 1.63109 to 1.62632, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 19/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6011 - accuracy: 0.3445 - val_loss: 1.6220 - val_accuracy: 0.3377

Epoch 00019: val_loss improved from 1.62632 to 1.62201, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5929 - accuracy: 0.3492 - val_loss: 1.6206 - val_accuracy: 0.3394

Epoch 00020: val_loss improved from 1.62201 to 1.62065, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/0
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5842 - accuracy: 0.3515 - val_loss: 1.6220 - val_accuracy: 0.3363

Epoch 00021: val_loss did not improve from 1.62065
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5756 - accuracy: 0.3595 - val_loss: 1.6248 - val_accuracy: 0.3352

Epoch 00022: val_loss did not improve from 1.62065
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5681 - accuracy: 0.3647 - val_loss: 1.6243 - val_accuracy: 0.3352

Epoch 00023: val_loss did not improve from 1.62065
Epoch 24/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5576 - accuracy: 0.3715 - val_loss: 1.6243 - val_accuracy: 0.3372

Epoch 00024: val_loss did not improve from 1.62065
Epoch 25/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5483 - accuracy: 0.3770 - val_loss: 1.6259 - val_accuracy: 0.3370

Epoch 00025: val_loss did not improve from 1.62065
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5377 - accuracy: 0.3839 - val_loss: 1.6307 - val_accuracy: 0.3380

Epoch 00026: val_loss did not improve from 1.62065
Epoch 27/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5264 - accuracy: 0.3911 - val_loss: 1.6389 - val_accuracy: 0.3389

Epoch 00027: val_loss did not improve from 1.62065
Epoch 28/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5158 - accuracy: 0.3997 - val_loss: 1.6448 - val_accuracy: 0.3385

Epoch 00028: val_loss did not improve from 1.62065
Epoch 29/100
83/83 [==============================] - 1s 14ms/step - loss: 1.4993 - accuracy: 0.4103 - val_loss: 1.6570 - val_accuracy: 0.3359

Epoch 00029: val_loss did not improve from 1.62065
Epoch 30/100
83/83 [==============================] - 1s 14ms/step - loss: 1.4851 - accuracy: 0.4175 - val_loss: 1.6727 - val_accuracy: 0.3338

Epoch 00030: val_loss did not improve from 1.62065
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 55s 4ms/step - loss: 1.6274 - accuracy: 0.3308
Testing Loss = 1.627430, Testing Accuracy = 0.330753
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.9135 - accuracy: 0.1976 - val_loss: 10.6617 - val_accuracy: 0.2096

Epoch 00001: val_loss improved from inf to 10.66165, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 2/100
83/83 [==============================] - 1s 14ms/step - loss: 8.9493 - accuracy: 0.2195 - val_loss: 7.4362 - val_accuracy: 0.2461

Epoch 00002: val_loss improved from 10.66165 to 7.43619, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 3/100
83/83 [==============================] - 1s 14ms/step - loss: 6.2898 - accuracy: 0.2663 - val_loss: 5.3504 - val_accuracy: 0.2683

Epoch 00003: val_loss improved from 7.43619 to 5.35042, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 4/100
83/83 [==============================] - 1s 14ms/step - loss: 4.6191 - accuracy: 0.2797 - val_loss: 4.0178 - val_accuracy: 0.2844

Epoch 00004: val_loss improved from 5.35042 to 4.01776, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5532 - accuracy: 0.2822 - val_loss: 3.1635 - val_accuracy: 0.2915

Epoch 00005: val_loss improved from 4.01776 to 3.16346, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 6/100
83/83 [==============================] - 1s 14ms/step - loss: 2.8748 - accuracy: 0.2908 - val_loss: 2.6208 - val_accuracy: 0.2986

Epoch 00006: val_loss improved from 3.16346 to 2.62080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4430 - accuracy: 0.2941 - val_loss: 2.2784 - val_accuracy: 0.3037

Epoch 00007: val_loss improved from 2.62080 to 2.27840, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1628 - accuracy: 0.2990 - val_loss: 2.0581 - val_accuracy: 0.3051

Epoch 00008: val_loss improved from 2.27840 to 2.05813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9817 - accuracy: 0.3008 - val_loss: 1.9138 - val_accuracy: 0.3072

Epoch 00009: val_loss improved from 2.05813 to 1.91380, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 10/100
83/83 [==============================] - 1s 16ms/step - loss: 1.8632 - accuracy: 0.3062 - val_loss: 1.8194 - val_accuracy: 0.3080

Epoch 00010: val_loss improved from 1.91380 to 1.81938, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7826 - accuracy: 0.3123 - val_loss: 1.7574 - val_accuracy: 0.3137

Epoch 00011: val_loss improved from 1.81938 to 1.75736, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 12/100
83/83 [==============================] - 1s 17ms/step - loss: 1.7281 - accuracy: 0.3166 - val_loss: 1.7127 - val_accuracy: 0.3247

Epoch 00012: val_loss improved from 1.75736 to 1.71270, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6894 - accuracy: 0.3230 - val_loss: 1.6818 - val_accuracy: 0.3308

Epoch 00013: val_loss improved from 1.71270 to 1.68180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 14/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6616 - accuracy: 0.3303 - val_loss: 1.6627 - val_accuracy: 0.3342

Epoch 00014: val_loss improved from 1.68180 to 1.66265, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 15/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6421 - accuracy: 0.3347 - val_loss: 1.6467 - val_accuracy: 0.3355

Epoch 00015: val_loss improved from 1.66265 to 1.64673, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 16/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6272 - accuracy: 0.3345 - val_loss: 1.6366 - val_accuracy: 0.3385

Epoch 00016: val_loss improved from 1.64673 to 1.63663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6152 - accuracy: 0.3413 - val_loss: 1.6284 - val_accuracy: 0.3392

Epoch 00017: val_loss improved from 1.63663 to 1.62837, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 18/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6036 - accuracy: 0.3475 - val_loss: 1.6254 - val_accuracy: 0.3374

Epoch 00018: val_loss improved from 1.62837 to 1.62544, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 19/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5909 - accuracy: 0.3546 - val_loss: 1.6211 - val_accuracy: 0.3361

Epoch 00019: val_loss improved from 1.62544 to 1.62109, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5813 - accuracy: 0.3594 - val_loss: 1.6185 - val_accuracy: 0.3404

Epoch 00020: val_loss improved from 1.62109 to 1.61845, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/1
Epoch 21/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5708 - accuracy: 0.3675 - val_loss: 1.6198 - val_accuracy: 0.3414

Epoch 00021: val_loss did not improve from 1.61845
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5631 - accuracy: 0.3733 - val_loss: 1.6200 - val_accuracy: 0.3427

Epoch 00022: val_loss did not improve from 1.61845
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5546 - accuracy: 0.3757 - val_loss: 1.6239 - val_accuracy: 0.3427

Epoch 00023: val_loss did not improve from 1.61845
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5409 - accuracy: 0.3864 - val_loss: 1.6299 - val_accuracy: 0.3397

Epoch 00024: val_loss did not improve from 1.61845
Epoch 25/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5319 - accuracy: 0.3918 - val_loss: 1.6321 - val_accuracy: 0.3402

Epoch 00025: val_loss did not improve from 1.61845
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5217 - accuracy: 0.3988 - val_loss: 1.6405 - val_accuracy: 0.3398

Epoch 00026: val_loss did not improve from 1.61845
Epoch 27/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5087 - accuracy: 0.4033 - val_loss: 1.6498 - val_accuracy: 0.3371

Epoch 00027: val_loss did not improve from 1.61845
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4971 - accuracy: 0.4156 - val_loss: 1.6574 - val_accuracy: 0.3346

Epoch 00028: val_loss did not improve from 1.61845
Epoch 29/100
83/83 [==============================] - 1s 14ms/step - loss: 1.4819 - accuracy: 0.4230 - val_loss: 1.6702 - val_accuracy: 0.3321

Epoch 00029: val_loss did not improve from 1.61845
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4648 - accuracy: 0.4346 - val_loss: 1.6928 - val_accuracy: 0.3275

Epoch 00030: val_loss did not improve from 1.61845
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 55s 4ms/step - loss: 1.6281 - accuracy: 0.3346
Testing Loss = 1.628104, Testing Accuracy = 0.334623
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 17ms/step - loss: 12.9154 - accuracy: 0.1990 - val_loss: 10.6665 - val_accuracy: 0.2088

Epoch 00001: val_loss improved from inf to 10.66651, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 2/100
83/83 [==============================] - 1s 14ms/step - loss: 8.9670 - accuracy: 0.2128 - val_loss: 7.4569 - val_accuracy: 0.2234

Epoch 00002: val_loss improved from 10.66651 to 7.45689, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 3/100
83/83 [==============================] - 1s 14ms/step - loss: 6.2939 - accuracy: 0.2563 - val_loss: 5.3444 - val_accuracy: 0.2657

Epoch 00003: val_loss improved from 7.45689 to 5.34440, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.6076 - accuracy: 0.2775 - val_loss: 4.0049 - val_accuracy: 0.2837

Epoch 00004: val_loss improved from 5.34440 to 4.00486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5428 - accuracy: 0.2852 - val_loss: 3.1543 - val_accuracy: 0.2902

Epoch 00005: val_loss improved from 4.00486 to 3.15431, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8667 - accuracy: 0.2899 - val_loss: 2.6152 - val_accuracy: 0.2976

Epoch 00006: val_loss improved from 3.15431 to 2.61516, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4356 - accuracy: 0.2951 - val_loss: 2.2717 - val_accuracy: 0.2992

Epoch 00007: val_loss improved from 2.61516 to 2.27168, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1584 - accuracy: 0.2977 - val_loss: 2.0544 - val_accuracy: 0.3031

Epoch 00008: val_loss improved from 2.27168 to 2.05438, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 9/100
83/83 [==============================] - 1s 14ms/step - loss: 1.9774 - accuracy: 0.3031 - val_loss: 1.9112 - val_accuracy: 0.3043

Epoch 00009: val_loss improved from 2.05438 to 1.91123, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8601 - accuracy: 0.3059 - val_loss: 1.8205 - val_accuracy: 0.3071

Epoch 00010: val_loss improved from 1.91123 to 1.82048, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7804 - accuracy: 0.3108 - val_loss: 1.7540 - val_accuracy: 0.3150

Epoch 00011: val_loss improved from 1.82048 to 1.75398, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7257 - accuracy: 0.3166 - val_loss: 1.7129 - val_accuracy: 0.3178

Epoch 00012: val_loss improved from 1.75398 to 1.71293, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6882 - accuracy: 0.3241 - val_loss: 1.6843 - val_accuracy: 0.3236

Epoch 00013: val_loss improved from 1.71293 to 1.68430, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6611 - accuracy: 0.3262 - val_loss: 1.6634 - val_accuracy: 0.3272

Epoch 00014: val_loss improved from 1.68430 to 1.66344, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6418 - accuracy: 0.3310 - val_loss: 1.6532 - val_accuracy: 0.3278

Epoch 00015: val_loss improved from 1.66344 to 1.65318, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6275 - accuracy: 0.3360 - val_loss: 1.6367 - val_accuracy: 0.3337

Epoch 00016: val_loss improved from 1.65318 to 1.63671, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6135 - accuracy: 0.3415 - val_loss: 1.6292 - val_accuracy: 0.3336

Epoch 00017: val_loss improved from 1.63671 to 1.62922, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6040 - accuracy: 0.3430 - val_loss: 1.6245 - val_accuracy: 0.3358

Epoch 00018: val_loss improved from 1.62922 to 1.62445, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5923 - accuracy: 0.3506 - val_loss: 1.6248 - val_accuracy: 0.3347

Epoch 00019: val_loss did not improve from 1.62445
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5842 - accuracy: 0.3556 - val_loss: 1.6277 - val_accuracy: 0.3299

Epoch 00020: val_loss did not improve from 1.62445
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5758 - accuracy: 0.3624 - val_loss: 1.6266 - val_accuracy: 0.3305

Epoch 00021: val_loss did not improve from 1.62445
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5656 - accuracy: 0.3672 - val_loss: 1.6246 - val_accuracy: 0.3349

Epoch 00022: val_loss did not improve from 1.62445
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5548 - accuracy: 0.3738 - val_loss: 1.6235 - val_accuracy: 0.3364

Epoch 00023: val_loss improved from 1.62445 to 1.62351, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/2
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5456 - accuracy: 0.3812 - val_loss: 1.6279 - val_accuracy: 0.3360

Epoch 00024: val_loss did not improve from 1.62351
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5330 - accuracy: 0.3880 - val_loss: 1.6316 - val_accuracy: 0.3375

Epoch 00025: val_loss did not improve from 1.62351
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5200 - accuracy: 0.3977 - val_loss: 1.6441 - val_accuracy: 0.3383

Epoch 00026: val_loss did not improve from 1.62351
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5072 - accuracy: 0.4048 - val_loss: 1.6582 - val_accuracy: 0.3386

Epoch 00027: val_loss did not improve from 1.62351
Epoch 28/100
83/83 [==============================] - 1s 14ms/step - loss: 1.4890 - accuracy: 0.4157 - val_loss: 1.6632 - val_accuracy: 0.3384

Epoch 00028: val_loss did not improve from 1.62351
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4781 - accuracy: 0.4243 - val_loss: 1.6722 - val_accuracy: 0.3359

Epoch 00029: val_loss did not improve from 1.62351
Epoch 30/100
83/83 [==============================] - 1s 14ms/step - loss: 1.4576 - accuracy: 0.4348 - val_loss: 1.6954 - val_accuracy: 0.3301

Epoch 00030: val_loss did not improve from 1.62351
Epoch 31/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4386 - accuracy: 0.4450 - val_loss: 1.7121 - val_accuracy: 0.3276

Epoch 00031: val_loss did not improve from 1.62351
Epoch 32/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4187 - accuracy: 0.4609 - val_loss: 1.7396 - val_accuracy: 0.3294

Epoch 00032: val_loss did not improve from 1.62351
Epoch 33/100
83/83 [==============================] - 1s 14ms/step - loss: 1.3948 - accuracy: 0.4733 - val_loss: 1.7600 - val_accuracy: 0.3210

Epoch 00033: val_loss did not improve from 1.62351
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 55s 4ms/step - loss: 1.6362 - accuracy: 0.3273
Testing Loss = 1.636157, Testing Accuracy = 0.327255
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.9054 - accuracy: 0.2019 - val_loss: 10.6558 - val_accuracy: 0.2140

Epoch 00001: val_loss improved from inf to 10.65580, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 2/100
83/83 [==============================] - 1s 14ms/step - loss: 8.9388 - accuracy: 0.2274 - val_loss: 7.4344 - val_accuracy: 0.2401

Epoch 00002: val_loss improved from 10.65580 to 7.43439, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2925 - accuracy: 0.2693 - val_loss: 5.3594 - val_accuracy: 0.2739

Epoch 00003: val_loss improved from 7.43439 to 5.35944, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 4/100
83/83 [==============================] - 1s 14ms/step - loss: 4.6243 - accuracy: 0.2812 - val_loss: 4.0205 - val_accuracy: 0.2854

Epoch 00004: val_loss improved from 5.35944 to 4.02045, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5601 - accuracy: 0.2878 - val_loss: 3.1691 - val_accuracy: 0.2950

Epoch 00005: val_loss improved from 4.02045 to 3.16907, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8799 - accuracy: 0.2902 - val_loss: 2.6247 - val_accuracy: 0.3004

Epoch 00006: val_loss improved from 3.16907 to 2.62474, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4451 - accuracy: 0.2959 - val_loss: 2.2794 - val_accuracy: 0.3045

Epoch 00007: val_loss improved from 2.62474 to 2.27941, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1651 - accuracy: 0.2978 - val_loss: 2.0600 - val_accuracy: 0.3042

Epoch 00008: val_loss improved from 2.27941 to 2.06003, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9839 - accuracy: 0.3020 - val_loss: 1.9165 - val_accuracy: 0.3075

Epoch 00009: val_loss improved from 2.06003 to 1.91646, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8640 - accuracy: 0.3053 - val_loss: 1.8220 - val_accuracy: 0.3088

Epoch 00010: val_loss improved from 1.91646 to 1.82198, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7843 - accuracy: 0.3119 - val_loss: 1.7579 - val_accuracy: 0.3139

Epoch 00011: val_loss improved from 1.82198 to 1.75786, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7298 - accuracy: 0.3165 - val_loss: 1.7132 - val_accuracy: 0.3208

Epoch 00012: val_loss improved from 1.75786 to 1.71319, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 13/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6906 - accuracy: 0.3245 - val_loss: 1.6844 - val_accuracy: 0.3205

Epoch 00013: val_loss improved from 1.71319 to 1.68437, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6639 - accuracy: 0.3251 - val_loss: 1.6665 - val_accuracy: 0.3233

Epoch 00014: val_loss improved from 1.68437 to 1.66648, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6439 - accuracy: 0.3325 - val_loss: 1.6492 - val_accuracy: 0.3293

Epoch 00015: val_loss improved from 1.66648 to 1.64921, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6292 - accuracy: 0.3333 - val_loss: 1.6383 - val_accuracy: 0.3322

Epoch 00016: val_loss improved from 1.64921 to 1.63826, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6161 - accuracy: 0.3377 - val_loss: 1.6311 - val_accuracy: 0.3381

Epoch 00017: val_loss improved from 1.63826 to 1.63114, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6064 - accuracy: 0.3415 - val_loss: 1.6263 - val_accuracy: 0.3364

Epoch 00018: val_loss improved from 1.63114 to 1.62628, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5961 - accuracy: 0.3508 - val_loss: 1.6265 - val_accuracy: 0.3358

Epoch 00019: val_loss did not improve from 1.62628
Epoch 20/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5875 - accuracy: 0.3517 - val_loss: 1.6248 - val_accuracy: 0.3362

Epoch 00020: val_loss improved from 1.62628 to 1.62484, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/3
Epoch 21/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5780 - accuracy: 0.3590 - val_loss: 1.6252 - val_accuracy: 0.3370

Epoch 00021: val_loss did not improve from 1.62484
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5681 - accuracy: 0.3684 - val_loss: 1.6251 - val_accuracy: 0.3354

Epoch 00022: val_loss did not improve from 1.62484
Epoch 23/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5583 - accuracy: 0.3727 - val_loss: 1.6280 - val_accuracy: 0.3352

Epoch 00023: val_loss did not improve from 1.62484
Epoch 24/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5476 - accuracy: 0.3829 - val_loss: 1.6290 - val_accuracy: 0.3411

Epoch 00024: val_loss did not improve from 1.62484
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5325 - accuracy: 0.3898 - val_loss: 1.6342 - val_accuracy: 0.3393

Epoch 00025: val_loss did not improve from 1.62484
Epoch 26/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5206 - accuracy: 0.3978 - val_loss: 1.6447 - val_accuracy: 0.3369

Epoch 00026: val_loss did not improve from 1.62484
Epoch 27/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5092 - accuracy: 0.4045 - val_loss: 1.6560 - val_accuracy: 0.3373

Epoch 00027: val_loss did not improve from 1.62484
Epoch 28/100
83/83 [==============================] - 1s 14ms/step - loss: 1.4928 - accuracy: 0.4161 - val_loss: 1.6696 - val_accuracy: 0.3317

Epoch 00028: val_loss did not improve from 1.62484
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4728 - accuracy: 0.4297 - val_loss: 1.6803 - val_accuracy: 0.3341

Epoch 00029: val_loss did not improve from 1.62484
Epoch 30/100
83/83 [==============================] - 1s 14ms/step - loss: 1.4567 - accuracy: 0.4372 - val_loss: 1.6954 - val_accuracy: 0.3286

Epoch 00030: val_loss did not improve from 1.62484
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 55s 4ms/step - loss: 1.6346 - accuracy: 0.3286
Testing Loss = 1.634596, Testing Accuracy = 0.328595
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 17ms/step - loss: 12.8656 - accuracy: 0.1971 - val_loss: 10.6006 - val_accuracy: 0.2097

Epoch 00001: val_loss improved from inf to 10.60065, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.8890 - accuracy: 0.2206 - val_loss: 7.3810 - val_accuracy: 0.2407

Epoch 00002: val_loss improved from 10.60065 to 7.38102, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2383 - accuracy: 0.2659 - val_loss: 5.2995 - val_accuracy: 0.2730

Epoch 00003: val_loss improved from 7.38102 to 5.29951, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.5774 - accuracy: 0.2785 - val_loss: 3.9798 - val_accuracy: 0.2859

Epoch 00004: val_loss improved from 5.29951 to 3.97984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5241 - accuracy: 0.2851 - val_loss: 3.1362 - val_accuracy: 0.2949

Epoch 00005: val_loss improved from 3.97984 to 3.13622, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8522 - accuracy: 0.2889 - val_loss: 2.6019 - val_accuracy: 0.2967

Epoch 00006: val_loss improved from 3.13622 to 2.60193, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4234 - accuracy: 0.2924 - val_loss: 2.2647 - val_accuracy: 0.3009

Epoch 00007: val_loss improved from 2.60193 to 2.26465, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 8/100
83/83 [==============================] - 1s 14ms/step - loss: 2.1511 - accuracy: 0.2972 - val_loss: 2.0462 - val_accuracy: 0.3059

Epoch 00008: val_loss improved from 2.26465 to 2.04615, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 9/100
83/83 [==============================] - 1s 16ms/step - loss: 1.9726 - accuracy: 0.3016 - val_loss: 1.9067 - val_accuracy: 0.3072

Epoch 00009: val_loss improved from 2.04615 to 1.90675, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8567 - accuracy: 0.3076 - val_loss: 1.8127 - val_accuracy: 0.3110

Epoch 00010: val_loss improved from 1.90675 to 1.81266, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7786 - accuracy: 0.3128 - val_loss: 1.7556 - val_accuracy: 0.3111

Epoch 00011: val_loss improved from 1.81266 to 1.75561, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 12/100
83/83 [==============================] - 1s 16ms/step - loss: 1.7259 - accuracy: 0.3168 - val_loss: 1.7134 - val_accuracy: 0.3159

Epoch 00012: val_loss improved from 1.75561 to 1.71341, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6874 - accuracy: 0.3219 - val_loss: 1.6793 - val_accuracy: 0.3248

Epoch 00013: val_loss improved from 1.71341 to 1.67934, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 14/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6606 - accuracy: 0.3256 - val_loss: 1.6623 - val_accuracy: 0.3262

Epoch 00014: val_loss improved from 1.67934 to 1.66232, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 15/100
83/83 [==============================] - 1s 16ms/step - loss: 1.6412 - accuracy: 0.3324 - val_loss: 1.6482 - val_accuracy: 0.3306

Epoch 00015: val_loss improved from 1.66232 to 1.64823, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 16/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6274 - accuracy: 0.3345 - val_loss: 1.6352 - val_accuracy: 0.3364

Epoch 00016: val_loss improved from 1.64823 to 1.63525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6160 - accuracy: 0.3372 - val_loss: 1.6303 - val_accuracy: 0.3368

Epoch 00017: val_loss improved from 1.63525 to 1.63032, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 18/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6044 - accuracy: 0.3430 - val_loss: 1.6232 - val_accuracy: 0.3380

Epoch 00018: val_loss improved from 1.63032 to 1.62315, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 19/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5950 - accuracy: 0.3483 - val_loss: 1.6200 - val_accuracy: 0.3381

Epoch 00019: val_loss improved from 1.62315 to 1.61996, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5846 - accuracy: 0.3545 - val_loss: 1.6220 - val_accuracy: 0.3339

Epoch 00020: val_loss did not improve from 1.61996
Epoch 21/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5758 - accuracy: 0.3637 - val_loss: 1.6173 - val_accuracy: 0.3414

Epoch 00021: val_loss improved from 1.61996 to 1.61729, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/4
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5664 - accuracy: 0.3697 - val_loss: 1.6208 - val_accuracy: 0.3386

Epoch 00022: val_loss did not improve from 1.61729
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5572 - accuracy: 0.3731 - val_loss: 1.6208 - val_accuracy: 0.3425

Epoch 00023: val_loss did not improve from 1.61729
Epoch 24/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5463 - accuracy: 0.3795 - val_loss: 1.6283 - val_accuracy: 0.3418

Epoch 00024: val_loss did not improve from 1.61729
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5361 - accuracy: 0.3875 - val_loss: 1.6311 - val_accuracy: 0.3395

Epoch 00025: val_loss did not improve from 1.61729
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5246 - accuracy: 0.3978 - val_loss: 1.6375 - val_accuracy: 0.3392

Epoch 00026: val_loss did not improve from 1.61729
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5108 - accuracy: 0.4025 - val_loss: 1.6441 - val_accuracy: 0.3426

Epoch 00027: val_loss did not improve from 1.61729
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4985 - accuracy: 0.4138 - val_loss: 1.6534 - val_accuracy: 0.3393

Epoch 00028: val_loss did not improve from 1.61729
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4802 - accuracy: 0.4217 - val_loss: 1.6662 - val_accuracy: 0.3418

Epoch 00029: val_loss did not improve from 1.61729
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4682 - accuracy: 0.4316 - val_loss: 1.6855 - val_accuracy: 0.3333

Epoch 00030: val_loss did not improve from 1.61729
Epoch 31/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4470 - accuracy: 0.4441 - val_loss: 1.6994 - val_accuracy: 0.3311

Epoch 00031: val_loss did not improve from 1.61729
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 55s 4ms/step - loss: 1.6265 - accuracy: 0.3299
Testing Loss = 1.626537, Testing Accuracy = 0.329860
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 17ms/step - loss: 12.8953 - accuracy: 0.1963 - val_loss: 10.6360 - val_accuracy: 0.2094

Epoch 00001: val_loss improved from inf to 10.63602, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9330 - accuracy: 0.2130 - val_loss: 7.4244 - val_accuracy: 0.2233

Epoch 00002: val_loss improved from 10.63602 to 7.42444, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2663 - accuracy: 0.2561 - val_loss: 5.3123 - val_accuracy: 0.2709

Epoch 00003: val_loss improved from 7.42444 to 5.31225, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.5830 - accuracy: 0.2824 - val_loss: 3.9840 - val_accuracy: 0.2908

Epoch 00004: val_loss improved from 5.31225 to 3.98402, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5278 - accuracy: 0.2834 - val_loss: 3.1377 - val_accuracy: 0.2979

Epoch 00005: val_loss improved from 3.98402 to 3.13771, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 6/100
83/83 [==============================] - 1s 16ms/step - loss: 2.8536 - accuracy: 0.2908 - val_loss: 2.6006 - val_accuracy: 0.3032

Epoch 00006: val_loss improved from 3.13771 to 2.60058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 7/100
83/83 [==============================] - 1s 17ms/step - loss: 2.4259 - accuracy: 0.2916 - val_loss: 2.2608 - val_accuracy: 0.3049

Epoch 00007: val_loss improved from 2.60058 to 2.26077, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 8/100
83/83 [==============================] - 1s 16ms/step - loss: 2.1512 - accuracy: 0.2987 - val_loss: 2.0468 - val_accuracy: 0.3052

Epoch 00008: val_loss improved from 2.26077 to 2.04679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 9/100
83/83 [==============================] - 1s 16ms/step - loss: 1.9723 - accuracy: 0.3010 - val_loss: 1.9030 - val_accuracy: 0.3100

Epoch 00009: val_loss improved from 2.04679 to 1.90303, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 10/100
83/83 [==============================] - 1s 16ms/step - loss: 1.8543 - accuracy: 0.3096 - val_loss: 1.8116 - val_accuracy: 0.3121

Epoch 00010: val_loss improved from 1.90303 to 1.81161, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7767 - accuracy: 0.3125 - val_loss: 1.7480 - val_accuracy: 0.3199

Epoch 00011: val_loss improved from 1.81161 to 1.74803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 12/100
83/83 [==============================] - 1s 16ms/step - loss: 1.7231 - accuracy: 0.3190 - val_loss: 1.7084 - val_accuracy: 0.3251

Epoch 00012: val_loss improved from 1.74803 to 1.70842, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 13/100
83/83 [==============================] - 1s 16ms/step - loss: 1.6870 - accuracy: 0.3238 - val_loss: 1.6799 - val_accuracy: 0.3281

Epoch 00013: val_loss improved from 1.70842 to 1.67994, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6604 - accuracy: 0.3287 - val_loss: 1.6619 - val_accuracy: 0.3311

Epoch 00014: val_loss improved from 1.67994 to 1.66192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 15/100
83/83 [==============================] - 1s 16ms/step - loss: 1.6419 - accuracy: 0.3329 - val_loss: 1.6478 - val_accuracy: 0.3333

Epoch 00015: val_loss improved from 1.66192 to 1.64782, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6266 - accuracy: 0.3385 - val_loss: 1.6376 - val_accuracy: 0.3335

Epoch 00016: val_loss improved from 1.64782 to 1.63765, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6165 - accuracy: 0.3409 - val_loss: 1.6303 - val_accuracy: 0.3363

Epoch 00017: val_loss improved from 1.63765 to 1.63035, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 18/100
83/83 [==============================] - 1s 16ms/step - loss: 1.6057 - accuracy: 0.3443 - val_loss: 1.6226 - val_accuracy: 0.3391

Epoch 00018: val_loss improved from 1.63035 to 1.62256, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 19/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5985 - accuracy: 0.3471 - val_loss: 1.6193 - val_accuracy: 0.3391

Epoch 00019: val_loss improved from 1.62256 to 1.61928, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 20/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5888 - accuracy: 0.3507 - val_loss: 1.6204 - val_accuracy: 0.3368

Epoch 00020: val_loss did not improve from 1.61928
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5815 - accuracy: 0.3560 - val_loss: 1.6190 - val_accuracy: 0.3386

Epoch 00021: val_loss improved from 1.61928 to 1.61900, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/5
Epoch 22/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5733 - accuracy: 0.3609 - val_loss: 1.6215 - val_accuracy: 0.3367

Epoch 00022: val_loss did not improve from 1.61900
Epoch 23/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5655 - accuracy: 0.3702 - val_loss: 1.6210 - val_accuracy: 0.3375

Epoch 00023: val_loss did not improve from 1.61900
Epoch 24/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5558 - accuracy: 0.3728 - val_loss: 1.6191 - val_accuracy: 0.3393

Epoch 00024: val_loss did not improve from 1.61900
Epoch 25/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5457 - accuracy: 0.3806 - val_loss: 1.6232 - val_accuracy: 0.3394

Epoch 00025: val_loss did not improve from 1.61900
Epoch 26/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5365 - accuracy: 0.3893 - val_loss: 1.6296 - val_accuracy: 0.3398

Epoch 00026: val_loss did not improve from 1.61900
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5246 - accuracy: 0.3950 - val_loss: 1.6360 - val_accuracy: 0.3375

Epoch 00027: val_loss did not improve from 1.61900
Epoch 28/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5115 - accuracy: 0.4016 - val_loss: 1.6451 - val_accuracy: 0.3391

Epoch 00028: val_loss did not improve from 1.61900
Epoch 29/100
83/83 [==============================] - 2s 21ms/step - loss: 1.4983 - accuracy: 0.4107 - val_loss: 1.6536 - val_accuracy: 0.3354

Epoch 00029: val_loss did not improve from 1.61900
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4827 - accuracy: 0.4198 - val_loss: 1.6740 - val_accuracy: 0.3277

Epoch 00030: val_loss did not improve from 1.61900
Epoch 31/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4663 - accuracy: 0.4329 - val_loss: 1.6965 - val_accuracy: 0.3265

Epoch 00031: val_loss did not improve from 1.61900
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 55s 4ms/step - loss: 1.6301 - accuracy: 0.3269
Testing Loss = 1.630141, Testing Accuracy = 0.326883
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.8756 - accuracy: 0.1991 - val_loss: 10.6102 - val_accuracy: 0.2095

Epoch 00001: val_loss improved from inf to 10.61023, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 2/100
83/83 [==============================] - 1s 16ms/step - loss: 8.8997 - accuracy: 0.2192 - val_loss: 7.3858 - val_accuracy: 0.2412

Epoch 00002: val_loss improved from 10.61023 to 7.38582, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2430 - accuracy: 0.2651 - val_loss: 5.3008 - val_accuracy: 0.2794

Epoch 00003: val_loss improved from 7.38582 to 5.30083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.5796 - accuracy: 0.2827 - val_loss: 3.9810 - val_accuracy: 0.2869

Epoch 00004: val_loss improved from 5.30083 to 3.98104, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 5/100
83/83 [==============================] - 1s 14ms/step - loss: 3.5255 - accuracy: 0.2860 - val_loss: 3.1367 - val_accuracy: 0.2947

Epoch 00005: val_loss improved from 3.98104 to 3.13669, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8538 - accuracy: 0.2917 - val_loss: 2.6018 - val_accuracy: 0.2999

Epoch 00006: val_loss improved from 3.13669 to 2.60183, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4248 - accuracy: 0.2960 - val_loss: 2.2649 - val_accuracy: 0.3032

Epoch 00007: val_loss improved from 2.60183 to 2.26488, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 8/100
83/83 [==============================] - 1s 14ms/step - loss: 2.1504 - accuracy: 0.2988 - val_loss: 2.0451 - val_accuracy: 0.3085

Epoch 00008: val_loss improved from 2.26488 to 2.04510, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9713 - accuracy: 0.3038 - val_loss: 1.9061 - val_accuracy: 0.3095

Epoch 00009: val_loss improved from 2.04510 to 1.90610, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8557 - accuracy: 0.3074 - val_loss: 1.8136 - val_accuracy: 0.3119

Epoch 00010: val_loss improved from 1.90610 to 1.81356, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7755 - accuracy: 0.3161 - val_loss: 1.7513 - val_accuracy: 0.3171

Epoch 00011: val_loss improved from 1.81356 to 1.75128, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7220 - accuracy: 0.3239 - val_loss: 1.7105 - val_accuracy: 0.3210

Epoch 00012: val_loss improved from 1.75128 to 1.71047, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6863 - accuracy: 0.3229 - val_loss: 1.6799 - val_accuracy: 0.3277

Epoch 00013: val_loss improved from 1.71047 to 1.67989, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6582 - accuracy: 0.3286 - val_loss: 1.6579 - val_accuracy: 0.3333

Epoch 00014: val_loss improved from 1.67989 to 1.65788, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6404 - accuracy: 0.3332 - val_loss: 1.6472 - val_accuracy: 0.3326

Epoch 00015: val_loss improved from 1.65788 to 1.64716, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6262 - accuracy: 0.3343 - val_loss: 1.6367 - val_accuracy: 0.3338

Epoch 00016: val_loss improved from 1.64716 to 1.63666, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6141 - accuracy: 0.3379 - val_loss: 1.6288 - val_accuracy: 0.3359

Epoch 00017: val_loss improved from 1.63666 to 1.62877, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6044 - accuracy: 0.3436 - val_loss: 1.6241 - val_accuracy: 0.3371

Epoch 00018: val_loss improved from 1.62877 to 1.62412, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5942 - accuracy: 0.3496 - val_loss: 1.6248 - val_accuracy: 0.3305

Epoch 00019: val_loss did not improve from 1.62412
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5845 - accuracy: 0.3550 - val_loss: 1.6235 - val_accuracy: 0.3336

Epoch 00020: val_loss improved from 1.62412 to 1.62349, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5746 - accuracy: 0.3610 - val_loss: 1.6213 - val_accuracy: 0.3385

Epoch 00021: val_loss improved from 1.62349 to 1.62133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5661 - accuracy: 0.3684 - val_loss: 1.6185 - val_accuracy: 0.3381

Epoch 00022: val_loss improved from 1.62133 to 1.61847, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/6
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5570 - accuracy: 0.3744 - val_loss: 1.6214 - val_accuracy: 0.3424

Epoch 00023: val_loss did not improve from 1.61847
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5459 - accuracy: 0.3788 - val_loss: 1.6239 - val_accuracy: 0.3424

Epoch 00024: val_loss did not improve from 1.61847
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5367 - accuracy: 0.3875 - val_loss: 1.6273 - val_accuracy: 0.3406

Epoch 00025: val_loss did not improve from 1.61847
Epoch 26/100
83/83 [==============================] - 1s 16ms/step - loss: 1.5230 - accuracy: 0.3955 - val_loss: 1.6348 - val_accuracy: 0.3433

Epoch 00026: val_loss did not improve from 1.61847
Epoch 27/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5085 - accuracy: 0.4023 - val_loss: 1.6459 - val_accuracy: 0.3397

Epoch 00027: val_loss did not improve from 1.61847
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5024 - accuracy: 0.4090 - val_loss: 1.6532 - val_accuracy: 0.3364

Epoch 00028: val_loss did not improve from 1.61847
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4811 - accuracy: 0.4208 - val_loss: 1.6614 - val_accuracy: 0.3366

Epoch 00029: val_loss did not improve from 1.61847
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4626 - accuracy: 0.4325 - val_loss: 1.6783 - val_accuracy: 0.3364

Epoch 00030: val_loss did not improve from 1.61847
Epoch 31/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4439 - accuracy: 0.4436 - val_loss: 1.7000 - val_accuracy: 0.3338

Epoch 00031: val_loss did not improve from 1.61847
Epoch 32/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4251 - accuracy: 0.4572 - val_loss: 1.7209 - val_accuracy: 0.3305

Epoch 00032: val_loss did not improve from 1.61847
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 55s 4ms/step - loss: 1.6299 - accuracy: 0.3313
Testing Loss = 1.629874, Testing Accuracy = 0.331274
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.8854 - accuracy: 0.1971 - val_loss: 10.6279 - val_accuracy: 0.2105

Epoch 00001: val_loss improved from inf to 10.62794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9167 - accuracy: 0.2222 - val_loss: 7.4080 - val_accuracy: 0.2271

Epoch 00002: val_loss improved from 10.62794 to 7.40801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2611 - accuracy: 0.2632 - val_loss: 5.3216 - val_accuracy: 0.2727

Epoch 00003: val_loss improved from 7.40801 to 5.32160, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 4/100
83/83 [==============================] - 1s 15ms/step - loss: 4.5938 - accuracy: 0.2807 - val_loss: 3.9936 - val_accuracy: 0.2840

Epoch 00004: val_loss improved from 5.32160 to 3.99364, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5361 - accuracy: 0.2861 - val_loss: 3.1450 - val_accuracy: 0.2939

Epoch 00005: val_loss improved from 3.99364 to 3.14504, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8609 - accuracy: 0.2886 - val_loss: 2.6089 - val_accuracy: 0.2999

Epoch 00006: val_loss improved from 3.14504 to 2.60887, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4325 - accuracy: 0.2954 - val_loss: 2.2692 - val_accuracy: 0.3049

Epoch 00007: val_loss improved from 2.60887 to 2.26917, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1559 - accuracy: 0.2976 - val_loss: 2.0492 - val_accuracy: 0.3056

Epoch 00008: val_loss improved from 2.26917 to 2.04924, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9762 - accuracy: 0.3015 - val_loss: 1.9086 - val_accuracy: 0.3078

Epoch 00009: val_loss improved from 2.04924 to 1.90864, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 10/100
83/83 [==============================] - 1s 16ms/step - loss: 1.8591 - accuracy: 0.3072 - val_loss: 1.8184 - val_accuracy: 0.3081

Epoch 00010: val_loss improved from 1.90864 to 1.81837, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7807 - accuracy: 0.3097 - val_loss: 1.7531 - val_accuracy: 0.3164

Epoch 00011: val_loss improved from 1.81837 to 1.75307, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 12/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7264 - accuracy: 0.3169 - val_loss: 1.7104 - val_accuracy: 0.3233

Epoch 00012: val_loss improved from 1.75307 to 1.71041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6908 - accuracy: 0.3224 - val_loss: 1.6845 - val_accuracy: 0.3241

Epoch 00013: val_loss improved from 1.71041 to 1.68454, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6637 - accuracy: 0.3260 - val_loss: 1.6638 - val_accuracy: 0.3294

Epoch 00014: val_loss improved from 1.68454 to 1.66382, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 15/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6428 - accuracy: 0.3321 - val_loss: 1.6492 - val_accuracy: 0.3305

Epoch 00015: val_loss improved from 1.66382 to 1.64918, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6291 - accuracy: 0.3334 - val_loss: 1.6406 - val_accuracy: 0.3320

Epoch 00016: val_loss improved from 1.64918 to 1.64056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6175 - accuracy: 0.3386 - val_loss: 1.6336 - val_accuracy: 0.3356

Epoch 00017: val_loss improved from 1.64056 to 1.63364, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6079 - accuracy: 0.3413 - val_loss: 1.6266 - val_accuracy: 0.3371

Epoch 00018: val_loss improved from 1.63364 to 1.62660, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5980 - accuracy: 0.3459 - val_loss: 1.6225 - val_accuracy: 0.3413

Epoch 00019: val_loss improved from 1.62660 to 1.62253, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5884 - accuracy: 0.3551 - val_loss: 1.6219 - val_accuracy: 0.3396

Epoch 00020: val_loss improved from 1.62253 to 1.62192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 21/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5796 - accuracy: 0.3596 - val_loss: 1.6227 - val_accuracy: 0.3388

Epoch 00021: val_loss did not improve from 1.62192
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5706 - accuracy: 0.3628 - val_loss: 1.6201 - val_accuracy: 0.3421

Epoch 00022: val_loss improved from 1.62192 to 1.62007, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/7
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5609 - accuracy: 0.3714 - val_loss: 1.6226 - val_accuracy: 0.3395

Epoch 00023: val_loss did not improve from 1.62007
Epoch 24/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5517 - accuracy: 0.3791 - val_loss: 1.6257 - val_accuracy: 0.3393

Epoch 00024: val_loss did not improve from 1.62007
Epoch 25/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5434 - accuracy: 0.3817 - val_loss: 1.6307 - val_accuracy: 0.3367

Epoch 00025: val_loss did not improve from 1.62007
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5331 - accuracy: 0.3891 - val_loss: 1.6341 - val_accuracy: 0.3404

Epoch 00026: val_loss did not improve from 1.62007
Epoch 27/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5189 - accuracy: 0.3980 - val_loss: 1.6423 - val_accuracy: 0.3403

Epoch 00027: val_loss did not improve from 1.62007
Epoch 28/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5081 - accuracy: 0.4081 - val_loss: 1.6546 - val_accuracy: 0.3382

Epoch 00028: val_loss did not improve from 1.62007
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4972 - accuracy: 0.4161 - val_loss: 1.6607 - val_accuracy: 0.3366

Epoch 00029: val_loss did not improve from 1.62007
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4780 - accuracy: 0.4256 - val_loss: 1.6732 - val_accuracy: 0.3346

Epoch 00030: val_loss did not improve from 1.62007
Epoch 31/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4591 - accuracy: 0.4383 - val_loss: 1.6958 - val_accuracy: 0.3276

Epoch 00031: val_loss did not improve from 1.62007
Epoch 32/100
83/83 [==============================] - 1s 14ms/step - loss: 1.4423 - accuracy: 0.4496 - val_loss: 1.7073 - val_accuracy: 0.3283

Epoch 00032: val_loss did not improve from 1.62007
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 55s 4ms/step - loss: 1.6300 - accuracy: 0.3297
Testing Loss = 1.630025, Testing Accuracy = 0.329711
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.8981 - accuracy: 0.1987 - val_loss: 10.6443 - val_accuracy: 0.2099

Epoch 00001: val_loss improved from inf to 10.64429, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 2/100
83/83 [==============================] - 1s 14ms/step - loss: 8.9441 - accuracy: 0.2124 - val_loss: 7.4370 - val_accuracy: 0.2247

Epoch 00002: val_loss improved from 10.64429 to 7.43700, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2832 - accuracy: 0.2531 - val_loss: 5.3329 - val_accuracy: 0.2708

Epoch 00003: val_loss improved from 7.43700 to 5.33294, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 4/100
83/83 [==============================] - 1s 14ms/step - loss: 4.6009 - accuracy: 0.2770 - val_loss: 3.9968 - val_accuracy: 0.2851

Epoch 00004: val_loss improved from 5.33294 to 3.99684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 5/100
83/83 [==============================] - 1s 14ms/step - loss: 3.5408 - accuracy: 0.2830 - val_loss: 3.1523 - val_accuracy: 0.2903

Epoch 00005: val_loss improved from 3.99684 to 3.15233, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 6/100
83/83 [==============================] - 1s 15ms/step - loss: 2.8627 - accuracy: 0.2889 - val_loss: 2.6101 - val_accuracy: 0.2958

Epoch 00006: val_loss improved from 3.15233 to 2.61009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 7/100
83/83 [==============================] - 1s 14ms/step - loss: 2.4325 - accuracy: 0.2919 - val_loss: 2.2675 - val_accuracy: 0.3004

Epoch 00007: val_loss improved from 2.61009 to 2.26748, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1572 - accuracy: 0.2952 - val_loss: 2.0506 - val_accuracy: 0.3040

Epoch 00008: val_loss improved from 2.26748 to 2.05056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9776 - accuracy: 0.3001 - val_loss: 1.9109 - val_accuracy: 0.3048

Epoch 00009: val_loss improved from 2.05056 to 1.91093, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8608 - accuracy: 0.3042 - val_loss: 1.8175 - val_accuracy: 0.3082

Epoch 00010: val_loss improved from 1.91093 to 1.81755, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7817 - accuracy: 0.3096 - val_loss: 1.7574 - val_accuracy: 0.3111

Epoch 00011: val_loss improved from 1.81755 to 1.75739, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 12/100
83/83 [==============================] - 1s 14ms/step - loss: 1.7277 - accuracy: 0.3163 - val_loss: 1.7133 - val_accuracy: 0.3173

Epoch 00012: val_loss improved from 1.75739 to 1.71330, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 13/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6888 - accuracy: 0.3211 - val_loss: 1.6833 - val_accuracy: 0.3243

Epoch 00013: val_loss improved from 1.71330 to 1.68332, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 14/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6637 - accuracy: 0.3239 - val_loss: 1.6642 - val_accuracy: 0.3282

Epoch 00014: val_loss improved from 1.68332 to 1.66418, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 15/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6430 - accuracy: 0.3301 - val_loss: 1.6481 - val_accuracy: 0.3343

Epoch 00015: val_loss improved from 1.66418 to 1.64812, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 16/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6307 - accuracy: 0.3327 - val_loss: 1.6428 - val_accuracy: 0.3342

Epoch 00016: val_loss improved from 1.64812 to 1.64280, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6191 - accuracy: 0.3341 - val_loss: 1.6327 - val_accuracy: 0.3377

Epoch 00017: val_loss improved from 1.64280 to 1.63273, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 18/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6075 - accuracy: 0.3406 - val_loss: 1.6280 - val_accuracy: 0.3387

Epoch 00018: val_loss improved from 1.63273 to 1.62797, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 19/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5991 - accuracy: 0.3452 - val_loss: 1.6238 - val_accuracy: 0.3399

Epoch 00019: val_loss improved from 1.62797 to 1.62381, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/8
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5894 - accuracy: 0.3506 - val_loss: 1.6244 - val_accuracy: 0.3324

Epoch 00020: val_loss did not improve from 1.62381
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5796 - accuracy: 0.3584 - val_loss: 1.6250 - val_accuracy: 0.3331

Epoch 00021: val_loss did not improve from 1.62381
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5720 - accuracy: 0.3650 - val_loss: 1.6256 - val_accuracy: 0.3338

Epoch 00022: val_loss did not improve from 1.62381
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5611 - accuracy: 0.3672 - val_loss: 1.6244 - val_accuracy: 0.3383

Epoch 00023: val_loss did not improve from 1.62381
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5502 - accuracy: 0.3786 - val_loss: 1.6265 - val_accuracy: 0.3415

Epoch 00024: val_loss did not improve from 1.62381
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5416 - accuracy: 0.3806 - val_loss: 1.6326 - val_accuracy: 0.3424

Epoch 00025: val_loss did not improve from 1.62381
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5298 - accuracy: 0.3887 - val_loss: 1.6398 - val_accuracy: 0.3418

Epoch 00026: val_loss did not improve from 1.62381
Epoch 27/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5203 - accuracy: 0.3960 - val_loss: 1.6424 - val_accuracy: 0.3384

Epoch 00027: val_loss did not improve from 1.62381
Epoch 28/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5030 - accuracy: 0.4075 - val_loss: 1.6557 - val_accuracy: 0.3396

Epoch 00028: val_loss did not improve from 1.62381
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4894 - accuracy: 0.4143 - val_loss: 1.6746 - val_accuracy: 0.3392

Epoch 00029: val_loss did not improve from 1.62381
Epoch 00029: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 55s 4ms/step - loss: 1.6322 - accuracy: 0.3287
Testing Loss = 1.632164, Testing Accuracy = 0.328669
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 2s 16ms/step - loss: 12.8901 - accuracy: 0.2000 - val_loss: 10.6335 - val_accuracy: 0.2103

Epoch 00001: val_loss improved from inf to 10.63351, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 2/100
83/83 [==============================] - 1s 15ms/step - loss: 8.9213 - accuracy: 0.2228 - val_loss: 7.4110 - val_accuracy: 0.2502

Epoch 00002: val_loss improved from 10.63351 to 7.41098, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 3/100
83/83 [==============================] - 1s 15ms/step - loss: 6.2759 - accuracy: 0.2660 - val_loss: 5.3336 - val_accuracy: 0.2792

Epoch 00003: val_loss improved from 7.41098 to 5.33365, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 4/100
83/83 [==============================] - 1s 14ms/step - loss: 4.6096 - accuracy: 0.2821 - val_loss: 4.0071 - val_accuracy: 0.2893

Epoch 00004: val_loss improved from 5.33365 to 4.00709, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 5/100
83/83 [==============================] - 1s 15ms/step - loss: 3.5518 - accuracy: 0.2857 - val_loss: 3.1618 - val_accuracy: 0.2941

Epoch 00005: val_loss improved from 4.00709 to 3.16181, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 6/100
83/83 [==============================] - 1s 16ms/step - loss: 2.8755 - accuracy: 0.2879 - val_loss: 2.6214 - val_accuracy: 0.2992

Epoch 00006: val_loss improved from 3.16181 to 2.62143, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 7/100
83/83 [==============================] - 1s 15ms/step - loss: 2.4429 - accuracy: 0.2924 - val_loss: 2.2809 - val_accuracy: 0.3009

Epoch 00007: val_loss improved from 2.62143 to 2.28089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 8/100
83/83 [==============================] - 1s 15ms/step - loss: 2.1648 - accuracy: 0.2965 - val_loss: 2.0574 - val_accuracy: 0.3047

Epoch 00008: val_loss improved from 2.28089 to 2.05743, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 9/100
83/83 [==============================] - 1s 15ms/step - loss: 1.9850 - accuracy: 0.3001 - val_loss: 1.9173 - val_accuracy: 0.3077

Epoch 00009: val_loss improved from 2.05743 to 1.91734, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 10/100
83/83 [==============================] - 1s 15ms/step - loss: 1.8652 - accuracy: 0.3066 - val_loss: 1.8202 - val_accuracy: 0.3128

Epoch 00010: val_loss improved from 1.91734 to 1.82020, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 11/100
83/83 [==============================] - 1s 15ms/step - loss: 1.7840 - accuracy: 0.3135 - val_loss: 1.7563 - val_accuracy: 0.3192

Epoch 00011: val_loss improved from 1.82020 to 1.75630, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 12/100
83/83 [==============================] - 1s 14ms/step - loss: 1.7300 - accuracy: 0.3189 - val_loss: 1.7120 - val_accuracy: 0.3257

Epoch 00012: val_loss improved from 1.75630 to 1.71202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 13/100
83/83 [==============================] - 1s 16ms/step - loss: 1.6901 - accuracy: 0.3228 - val_loss: 1.6854 - val_accuracy: 0.3272

Epoch 00013: val_loss improved from 1.71202 to 1.68540, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 14/100
83/83 [==============================] - 1s 16ms/step - loss: 1.6628 - accuracy: 0.3292 - val_loss: 1.6624 - val_accuracy: 0.3313

Epoch 00014: val_loss improved from 1.68540 to 1.66239, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 15/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6449 - accuracy: 0.3296 - val_loss: 1.6507 - val_accuracy: 0.3325

Epoch 00015: val_loss improved from 1.66239 to 1.65074, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 16/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6304 - accuracy: 0.3337 - val_loss: 1.6377 - val_accuracy: 0.3364

Epoch 00016: val_loss improved from 1.65074 to 1.63771, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 17/100
83/83 [==============================] - 1s 15ms/step - loss: 1.6197 - accuracy: 0.3402 - val_loss: 1.6315 - val_accuracy: 0.3373

Epoch 00017: val_loss improved from 1.63771 to 1.63150, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 18/100
83/83 [==============================] - 1s 14ms/step - loss: 1.6073 - accuracy: 0.3436 - val_loss: 1.6246 - val_accuracy: 0.3371

Epoch 00018: val_loss improved from 1.63150 to 1.62461, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 19/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5971 - accuracy: 0.3470 - val_loss: 1.6226 - val_accuracy: 0.3364

Epoch 00019: val_loss improved from 1.62461 to 1.62256, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 20/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5899 - accuracy: 0.3547 - val_loss: 1.6225 - val_accuracy: 0.3362

Epoch 00020: val_loss improved from 1.62256 to 1.62254, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 21/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5809 - accuracy: 0.3594 - val_loss: 1.6194 - val_accuracy: 0.3380

Epoch 00021: val_loss improved from 1.62254 to 1.61941, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 22/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5726 - accuracy: 0.3654 - val_loss: 1.6172 - val_accuracy: 0.3460

Epoch 00022: val_loss improved from 1.61941 to 1.61724, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15-1/Try/9
Epoch 23/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5636 - accuracy: 0.3722 - val_loss: 1.6235 - val_accuracy: 0.3465

Epoch 00023: val_loss did not improve from 1.61724
Epoch 24/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5529 - accuracy: 0.3757 - val_loss: 1.6237 - val_accuracy: 0.3487

Epoch 00024: val_loss did not improve from 1.61724
Epoch 25/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5453 - accuracy: 0.3820 - val_loss: 1.6261 - val_accuracy: 0.3450

Epoch 00025: val_loss did not improve from 1.61724
Epoch 26/100
83/83 [==============================] - 1s 15ms/step - loss: 1.5347 - accuracy: 0.3869 - val_loss: 1.6323 - val_accuracy: 0.3467

Epoch 00026: val_loss did not improve from 1.61724
Epoch 27/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5228 - accuracy: 0.3963 - val_loss: 1.6368 - val_accuracy: 0.3412

Epoch 00027: val_loss did not improve from 1.61724
Epoch 28/100
83/83 [==============================] - 1s 14ms/step - loss: 1.5094 - accuracy: 0.4035 - val_loss: 1.6470 - val_accuracy: 0.3430

Epoch 00028: val_loss did not improve from 1.61724
Epoch 29/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4965 - accuracy: 0.4127 - val_loss: 1.6570 - val_accuracy: 0.3413

Epoch 00029: val_loss did not improve from 1.61724
Epoch 30/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4836 - accuracy: 0.4217 - val_loss: 1.6692 - val_accuracy: 0.3389

Epoch 00030: val_loss did not improve from 1.61724
Epoch 31/100
83/83 [==============================] - 1s 16ms/step - loss: 1.4651 - accuracy: 0.4320 - val_loss: 1.6842 - val_accuracy: 0.3362

Epoch 00031: val_loss did not improve from 1.61724
Epoch 32/100
83/83 [==============================] - 1s 15ms/step - loss: 1.4453 - accuracy: 0.4453 - val_loss: 1.7115 - val_accuracy: 0.3330

Epoch 00032: val_loss did not improve from 1.61724
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               2690728   [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 2,693,806[0m
[92mTrainable params: 2,693,802[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 25, 25, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 25, 25, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 25, 25, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 12, 12, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 12, 12, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 6, 6, 128)         0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 6, 6, 256)         1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 3, 3, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 2304)              0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               1180160   [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 2,690,728[0m
[94mTrainable params: 2,690,724[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 25, 25, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 56s 4ms/step - loss: 1.6285 - accuracy: 0.3303
Testing Loss = 1.628517, Testing Accuracy = 0.330307
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 81.08 +- 0.1342 %)
$W^-/W^-$ (auc = 80.15 +- 0.1500 %)
$Z/Z$ (auc = 65.30 +- 0.5117 %)
$W^+/W^-$ (auc = 64.51 +- 0.3320 %)
$W^+/Z$$ (auc = 64.99 +- 0.1246 %)
$W^-/Z$ (auc = 66.57 +- 0.0776 %)
The summarized testing accuracy = 32.98 +- 0.2105 %, with the loss = 1.6304 +- 0.002948
