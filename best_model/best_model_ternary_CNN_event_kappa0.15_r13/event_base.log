

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-26 22:00:50.348219
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 12s 70ms/step - loss: 12.1558 - accuracy: 0.2258 - val_loss: 8.4154 - val_accuracy: 0.2592

Epoch 00001: val_loss improved from inf to 8.41539, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.5773 - accuracy: 0.2706 - val_loss: 5.2565 - val_accuracy: 0.2960

Epoch 00002: val_loss improved from 8.41539 to 5.25649, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5206 - accuracy: 0.2849 - val_loss: 3.9391 - val_accuracy: 0.3062

Epoch 00003: val_loss improved from 5.25649 to 3.93915, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5548 - accuracy: 0.2965 - val_loss: 3.2091 - val_accuracy: 0.3090

Epoch 00004: val_loss improved from 3.93915 to 3.20915, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9761 - accuracy: 0.3032 - val_loss: 2.7398 - val_accuracy: 0.3159

Epoch 00005: val_loss improved from 3.20915 to 2.73981, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5867 - accuracy: 0.3069 - val_loss: 2.4142 - val_accuracy: 0.3202

Epoch 00006: val_loss improved from 2.73981 to 2.41423, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3107 - accuracy: 0.3109 - val_loss: 2.1858 - val_accuracy: 0.3222

Epoch 00007: val_loss improved from 2.41423 to 2.18581, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1151 - accuracy: 0.3121 - val_loss: 2.0244 - val_accuracy: 0.3224

Epoch 00008: val_loss improved from 2.18581 to 2.02436, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9746 - accuracy: 0.3155 - val_loss: 1.9092 - val_accuracy: 0.3220

Epoch 00009: val_loss improved from 2.02436 to 1.90923, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8752 - accuracy: 0.3190 - val_loss: 1.8262 - val_accuracy: 0.3246

Epoch 00010: val_loss improved from 1.90923 to 1.82616, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8044 - accuracy: 0.3207 - val_loss: 1.7706 - val_accuracy: 0.3205

Epoch 00011: val_loss improved from 1.82616 to 1.77057, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7552 - accuracy: 0.3251 - val_loss: 1.7301 - val_accuracy: 0.3239

Epoch 00012: val_loss improved from 1.77057 to 1.73006, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7193 - accuracy: 0.3255 - val_loss: 1.7026 - val_accuracy: 0.3253

Epoch 00013: val_loss improved from 1.73006 to 1.70256, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6936 - accuracy: 0.3269 - val_loss: 1.6827 - val_accuracy: 0.3255

Epoch 00014: val_loss improved from 1.70256 to 1.68266, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6750 - accuracy: 0.3258 - val_loss: 1.6685 - val_accuracy: 0.3291

Epoch 00015: val_loss improved from 1.68266 to 1.66851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6603 - accuracy: 0.3304 - val_loss: 1.6586 - val_accuracy: 0.3288

Epoch 00016: val_loss improved from 1.66851 to 1.65858, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6507 - accuracy: 0.3316 - val_loss: 1.6523 - val_accuracy: 0.3302

Epoch 00017: val_loss improved from 1.65858 to 1.65228, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6422 - accuracy: 0.3367 - val_loss: 1.6478 - val_accuracy: 0.3306

Epoch 00018: val_loss improved from 1.65228 to 1.64779, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6371 - accuracy: 0.3374 - val_loss: 1.6451 - val_accuracy: 0.3297

Epoch 00019: val_loss improved from 1.64779 to 1.64512, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6328 - accuracy: 0.3400 - val_loss: 1.6421 - val_accuracy: 0.3306

Epoch 00020: val_loss improved from 1.64512 to 1.64207, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6264 - accuracy: 0.3430 - val_loss: 1.6428 - val_accuracy: 0.3294

Epoch 00021: val_loss did not improve from 1.64207
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6234 - accuracy: 0.3425 - val_loss: 1.6425 - val_accuracy: 0.3334

Epoch 00022: val_loss did not improve from 1.64207
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6218 - accuracy: 0.3443 - val_loss: 1.6423 - val_accuracy: 0.3322

Epoch 00023: val_loss did not improve from 1.64207
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6181 - accuracy: 0.3454 - val_loss: 1.6444 - val_accuracy: 0.3316

Epoch 00024: val_loss did not improve from 1.64207
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6143 - accuracy: 0.3515 - val_loss: 1.6466 - val_accuracy: 0.3303

Epoch 00025: val_loss did not improve from 1.64207
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6133 - accuracy: 0.3538 - val_loss: 1.6498 - val_accuracy: 0.3303

Epoch 00026: val_loss did not improve from 1.64207
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6104 - accuracy: 0.3565 - val_loss: 1.6541 - val_accuracy: 0.3283

Epoch 00027: val_loss did not improve from 1.64207
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6096 - accuracy: 0.3578 - val_loss: 1.6573 - val_accuracy: 0.3316

Epoch 00028: val_loss did not improve from 1.64207
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6058 - accuracy: 0.3601 - val_loss: 1.6628 - val_accuracy: 0.3282

Epoch 00029: val_loss did not improve from 1.64207
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6051 - accuracy: 0.3642 - val_loss: 1.6684 - val_accuracy: 0.3294

Epoch 00030: val_loss did not improve from 1.64207
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6483 - accuracy: 0.3327
Testing Loss = 1.648299, Testing Accuracy = 0.332688
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.1350 - accuracy: 0.2192 - val_loss: 8.3667 - val_accuracy: 0.2392

Epoch 00001: val_loss improved from inf to 8.36666, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.5468 - accuracy: 0.2728 - val_loss: 5.2427 - val_accuracy: 0.2913

Epoch 00002: val_loss improved from 8.36666 to 5.24267, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5109 - accuracy: 0.2861 - val_loss: 3.9320 - val_accuracy: 0.3036

Epoch 00003: val_loss improved from 5.24267 to 3.93201, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5542 - accuracy: 0.2946 - val_loss: 3.2115 - val_accuracy: 0.3092

Epoch 00004: val_loss improved from 3.93201 to 3.21149, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9804 - accuracy: 0.2999 - val_loss: 2.7442 - val_accuracy: 0.3152

Epoch 00005: val_loss improved from 3.21149 to 2.74416, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5908 - accuracy: 0.3081 - val_loss: 2.4200 - val_accuracy: 0.3181

Epoch 00006: val_loss improved from 2.74416 to 2.41997, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3154 - accuracy: 0.3114 - val_loss: 2.1920 - val_accuracy: 0.3206

Epoch 00007: val_loss improved from 2.41997 to 2.19203, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1198 - accuracy: 0.3133 - val_loss: 2.0290 - val_accuracy: 0.3202

Epoch 00008: val_loss improved from 2.19203 to 2.02902, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9813 - accuracy: 0.3157 - val_loss: 1.9129 - val_accuracy: 0.3217

Epoch 00009: val_loss improved from 2.02902 to 1.91293, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8809 - accuracy: 0.3181 - val_loss: 1.8319 - val_accuracy: 0.3216

Epoch 00010: val_loss improved from 1.91293 to 1.83194, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8100 - accuracy: 0.3210 - val_loss: 1.7741 - val_accuracy: 0.3246

Epoch 00011: val_loss improved from 1.83194 to 1.77411, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7582 - accuracy: 0.3248 - val_loss: 1.7345 - val_accuracy: 0.3240

Epoch 00012: val_loss improved from 1.77411 to 1.73447, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7221 - accuracy: 0.3238 - val_loss: 1.7055 - val_accuracy: 0.3245

Epoch 00013: val_loss improved from 1.73447 to 1.70555, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6949 - accuracy: 0.3285 - val_loss: 1.6843 - val_accuracy: 0.3252

Epoch 00014: val_loss improved from 1.70555 to 1.68435, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6762 - accuracy: 0.3295 - val_loss: 1.6713 - val_accuracy: 0.3222

Epoch 00015: val_loss improved from 1.68435 to 1.67126, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6625 - accuracy: 0.3296 - val_loss: 1.6605 - val_accuracy: 0.3294

Epoch 00016: val_loss improved from 1.67126 to 1.66049, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 17/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6510 - accuracy: 0.3347 - val_loss: 1.6531 - val_accuracy: 0.3281

Epoch 00017: val_loss improved from 1.66049 to 1.65312, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6444 - accuracy: 0.3347 - val_loss: 1.6474 - val_accuracy: 0.3262

Epoch 00018: val_loss improved from 1.65312 to 1.64741, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6371 - accuracy: 0.3381 - val_loss: 1.6436 - val_accuracy: 0.3308

Epoch 00019: val_loss improved from 1.64741 to 1.64357, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6326 - accuracy: 0.3394 - val_loss: 1.6420 - val_accuracy: 0.3303

Epoch 00020: val_loss improved from 1.64357 to 1.64197, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6283 - accuracy: 0.3416 - val_loss: 1.6429 - val_accuracy: 0.3315

Epoch 00021: val_loss did not improve from 1.64197
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6248 - accuracy: 0.3435 - val_loss: 1.6428 - val_accuracy: 0.3306

Epoch 00022: val_loss did not improve from 1.64197
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6201 - accuracy: 0.3468 - val_loss: 1.6435 - val_accuracy: 0.3326

Epoch 00023: val_loss did not improve from 1.64197
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6201 - accuracy: 0.3463 - val_loss: 1.6443 - val_accuracy: 0.3327

Epoch 00024: val_loss did not improve from 1.64197
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6153 - accuracy: 0.3518 - val_loss: 1.6465 - val_accuracy: 0.3302

Epoch 00025: val_loss did not improve from 1.64197
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6147 - accuracy: 0.3522 - val_loss: 1.6513 - val_accuracy: 0.3311

Epoch 00026: val_loss did not improve from 1.64197
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6108 - accuracy: 0.3539 - val_loss: 1.6520 - val_accuracy: 0.3321

Epoch 00027: val_loss did not improve from 1.64197
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6076 - accuracy: 0.3609 - val_loss: 1.6606 - val_accuracy: 0.3271

Epoch 00028: val_loss did not improve from 1.64197
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6087 - accuracy: 0.3625 - val_loss: 1.6624 - val_accuracy: 0.3286

Epoch 00029: val_loss did not improve from 1.64197
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6049 - accuracy: 0.3652 - val_loss: 1.6684 - val_accuracy: 0.3289

Epoch 00030: val_loss did not improve from 1.64197
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 57s 4ms/step - loss: 1.6497 - accuracy: 0.3328
Testing Loss = 1.649710, Testing Accuracy = 0.332763
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.1221 - accuracy: 0.2155 - val_loss: 8.3406 - val_accuracy: 0.2473

Epoch 00001: val_loss improved from inf to 8.34065, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.5333 - accuracy: 0.2721 - val_loss: 5.2363 - val_accuracy: 0.2871

Epoch 00002: val_loss improved from 8.34065 to 5.23625, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5062 - accuracy: 0.2845 - val_loss: 3.9310 - val_accuracy: 0.3029

Epoch 00003: val_loss improved from 5.23625 to 3.93095, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5501 - accuracy: 0.2964 - val_loss: 3.2098 - val_accuracy: 0.3066

Epoch 00004: val_loss improved from 3.93095 to 3.20975, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9798 - accuracy: 0.3016 - val_loss: 2.7427 - val_accuracy: 0.3134

Epoch 00005: val_loss improved from 3.20975 to 2.74273, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5901 - accuracy: 0.3081 - val_loss: 2.4224 - val_accuracy: 0.3199

Epoch 00006: val_loss improved from 2.74273 to 2.42245, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3177 - accuracy: 0.3104 - val_loss: 2.1926 - val_accuracy: 0.3209

Epoch 00007: val_loss improved from 2.42245 to 2.19264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1221 - accuracy: 0.3154 - val_loss: 2.0299 - val_accuracy: 0.3242

Epoch 00008: val_loss improved from 2.19264 to 2.02987, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9814 - accuracy: 0.3174 - val_loss: 1.9134 - val_accuracy: 0.3240

Epoch 00009: val_loss improved from 2.02987 to 1.91342, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8831 - accuracy: 0.3183 - val_loss: 1.8326 - val_accuracy: 0.3248

Epoch 00010: val_loss improved from 1.91342 to 1.83265, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8097 - accuracy: 0.3215 - val_loss: 1.7732 - val_accuracy: 0.3255

Epoch 00011: val_loss improved from 1.83265 to 1.77323, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7588 - accuracy: 0.3233 - val_loss: 1.7333 - val_accuracy: 0.3247

Epoch 00012: val_loss improved from 1.77323 to 1.73330, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7235 - accuracy: 0.3219 - val_loss: 1.7022 - val_accuracy: 0.3267

Epoch 00013: val_loss improved from 1.73330 to 1.70223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6964 - accuracy: 0.3259 - val_loss: 1.6835 - val_accuracy: 0.3241

Epoch 00014: val_loss improved from 1.70223 to 1.68351, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6779 - accuracy: 0.3294 - val_loss: 1.6701 - val_accuracy: 0.3283

Epoch 00015: val_loss improved from 1.68351 to 1.67010, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6647 - accuracy: 0.3312 - val_loss: 1.6591 - val_accuracy: 0.3288

Epoch 00016: val_loss improved from 1.67010 to 1.65913, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6530 - accuracy: 0.3329 - val_loss: 1.6529 - val_accuracy: 0.3308

Epoch 00017: val_loss improved from 1.65913 to 1.65291, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6460 - accuracy: 0.3319 - val_loss: 1.6471 - val_accuracy: 0.3285

Epoch 00018: val_loss improved from 1.65291 to 1.64713, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6379 - accuracy: 0.3355 - val_loss: 1.6446 - val_accuracy: 0.3299

Epoch 00019: val_loss improved from 1.64713 to 1.64457, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6331 - accuracy: 0.3375 - val_loss: 1.6409 - val_accuracy: 0.3324

Epoch 00020: val_loss improved from 1.64457 to 1.64093, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 21/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6278 - accuracy: 0.3400 - val_loss: 1.6421 - val_accuracy: 0.3323

Epoch 00021: val_loss did not improve from 1.64093
Epoch 22/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6256 - accuracy: 0.3408 - val_loss: 1.6397 - val_accuracy: 0.3334

Epoch 00022: val_loss improved from 1.64093 to 1.63974, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6218 - accuracy: 0.3433 - val_loss: 1.6418 - val_accuracy: 0.3348

Epoch 00023: val_loss did not improve from 1.63974
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6197 - accuracy: 0.3469 - val_loss: 1.6411 - val_accuracy: 0.3353

Epoch 00024: val_loss did not improve from 1.63974
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6191 - accuracy: 0.3480 - val_loss: 1.6440 - val_accuracy: 0.3327

Epoch 00025: val_loss did not improve from 1.63974
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6148 - accuracy: 0.3527 - val_loss: 1.6467 - val_accuracy: 0.3366

Epoch 00026: val_loss did not improve from 1.63974
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6128 - accuracy: 0.3551 - val_loss: 1.6494 - val_accuracy: 0.3327

Epoch 00027: val_loss did not improve from 1.63974
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6113 - accuracy: 0.3549 - val_loss: 1.6552 - val_accuracy: 0.3334

Epoch 00028: val_loss did not improve from 1.63974
Epoch 29/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6088 - accuracy: 0.3591 - val_loss: 1.6603 - val_accuracy: 0.3304

Epoch 00029: val_loss did not improve from 1.63974
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6086 - accuracy: 0.3632 - val_loss: 1.6643 - val_accuracy: 0.3288

Epoch 00030: val_loss did not improve from 1.63974
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6062 - accuracy: 0.3700 - val_loss: 1.6719 - val_accuracy: 0.3271

Epoch 00031: val_loss did not improve from 1.63974
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6054 - accuracy: 0.3710 - val_loss: 1.6785 - val_accuracy: 0.3281

Epoch 00032: val_loss did not improve from 1.63974
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6476 - accuracy: 0.3329
Testing Loss = 1.647595, Testing Accuracy = 0.332912
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.2644 - accuracy: 0.2273 - val_loss: 8.5525 - val_accuracy: 0.2591

Epoch 00001: val_loss improved from inf to 8.55252, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6922 - accuracy: 0.2708 - val_loss: 5.3492 - val_accuracy: 0.2988

Epoch 00002: val_loss improved from 8.55252 to 5.34921, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.5878 - accuracy: 0.2889 - val_loss: 3.9873 - val_accuracy: 0.3023

Epoch 00003: val_loss improved from 5.34921 to 3.98732, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5939 - accuracy: 0.2968 - val_loss: 3.2397 - val_accuracy: 0.3102

Epoch 00004: val_loss improved from 3.98732 to 3.23970, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 3.0004 - accuracy: 0.3059 - val_loss: 2.7618 - val_accuracy: 0.3146

Epoch 00005: val_loss improved from 3.23970 to 2.76178, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.6041 - accuracy: 0.3074 - val_loss: 2.4319 - val_accuracy: 0.3185

Epoch 00006: val_loss improved from 2.76178 to 2.43188, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3256 - accuracy: 0.3109 - val_loss: 2.2026 - val_accuracy: 0.3205

Epoch 00007: val_loss improved from 2.43188 to 2.20263, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 8/100
83/83 [==============================] - 6s 70ms/step - loss: 2.1271 - accuracy: 0.3151 - val_loss: 2.0335 - val_accuracy: 0.3226

Epoch 00008: val_loss improved from 2.20263 to 2.03350, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9834 - accuracy: 0.3183 - val_loss: 1.9169 - val_accuracy: 0.3257

Epoch 00009: val_loss improved from 2.03350 to 1.91694, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8827 - accuracy: 0.3199 - val_loss: 1.8344 - val_accuracy: 0.3241

Epoch 00010: val_loss improved from 1.91694 to 1.83438, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8122 - accuracy: 0.3197 - val_loss: 1.7765 - val_accuracy: 0.3241

Epoch 00011: val_loss improved from 1.83438 to 1.77650, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 12/100
83/83 [==============================] - 6s 70ms/step - loss: 1.7574 - accuracy: 0.3263 - val_loss: 1.7351 - val_accuracy: 0.3266

Epoch 00012: val_loss improved from 1.77650 to 1.73510, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7216 - accuracy: 0.3250 - val_loss: 1.7068 - val_accuracy: 0.3271

Epoch 00013: val_loss improved from 1.73510 to 1.70685, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6951 - accuracy: 0.3293 - val_loss: 1.6856 - val_accuracy: 0.3302

Epoch 00014: val_loss improved from 1.70685 to 1.68561, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6761 - accuracy: 0.3303 - val_loss: 1.6723 - val_accuracy: 0.3280

Epoch 00015: val_loss improved from 1.68561 to 1.67230, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6613 - accuracy: 0.3338 - val_loss: 1.6617 - val_accuracy: 0.3312

Epoch 00016: val_loss improved from 1.67230 to 1.66165, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6519 - accuracy: 0.3348 - val_loss: 1.6552 - val_accuracy: 0.3321

Epoch 00017: val_loss improved from 1.66165 to 1.65519, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6431 - accuracy: 0.3366 - val_loss: 1.6508 - val_accuracy: 0.3319

Epoch 00018: val_loss improved from 1.65519 to 1.65078, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 19/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6362 - accuracy: 0.3425 - val_loss: 1.6488 - val_accuracy: 0.3323

Epoch 00019: val_loss improved from 1.65078 to 1.64881, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6324 - accuracy: 0.3427 - val_loss: 1.6474 - val_accuracy: 0.3300

Epoch 00020: val_loss improved from 1.64881 to 1.64740, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6258 - accuracy: 0.3456 - val_loss: 1.6472 - val_accuracy: 0.3322

Epoch 00021: val_loss improved from 1.64740 to 1.64719, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6254 - accuracy: 0.3445 - val_loss: 1.6476 - val_accuracy: 0.3332

Epoch 00022: val_loss did not improve from 1.64719
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6204 - accuracy: 0.3469 - val_loss: 1.6487 - val_accuracy: 0.3336

Epoch 00023: val_loss did not improve from 1.64719
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6183 - accuracy: 0.3507 - val_loss: 1.6528 - val_accuracy: 0.3309

Epoch 00024: val_loss did not improve from 1.64719
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6153 - accuracy: 0.3553 - val_loss: 1.6561 - val_accuracy: 0.3309

Epoch 00025: val_loss did not improve from 1.64719
Epoch 26/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6133 - accuracy: 0.3571 - val_loss: 1.6592 - val_accuracy: 0.3331

Epoch 00026: val_loss did not improve from 1.64719
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6098 - accuracy: 0.3618 - val_loss: 1.6651 - val_accuracy: 0.3301

Epoch 00027: val_loss did not improve from 1.64719
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6095 - accuracy: 0.3635 - val_loss: 1.6669 - val_accuracy: 0.3319

Epoch 00028: val_loss did not improve from 1.64719
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6059 - accuracy: 0.3674 - val_loss: 1.6750 - val_accuracy: 0.3279

Epoch 00029: val_loss did not improve from 1.64719
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6055 - accuracy: 0.3714 - val_loss: 1.6829 - val_accuracy: 0.3280

Epoch 00030: val_loss did not improve from 1.64719
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6016 - accuracy: 0.3732 - val_loss: 1.6912 - val_accuracy: 0.3315

Epoch 00031: val_loss did not improve from 1.64719
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6537 - accuracy: 0.3352
Testing Loss = 1.653734, Testing Accuracy = 0.335219
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.2411 - accuracy: 0.2214 - val_loss: 8.5010 - val_accuracy: 0.2496

Epoch 00001: val_loss improved from inf to 8.50099, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6526 - accuracy: 0.2753 - val_loss: 5.3215 - val_accuracy: 0.2939

Epoch 00002: val_loss improved from 8.50099 to 5.32146, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5680 - accuracy: 0.2896 - val_loss: 3.9709 - val_accuracy: 0.3032

Epoch 00003: val_loss improved from 5.32146 to 3.97091, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5837 - accuracy: 0.2948 - val_loss: 3.2298 - val_accuracy: 0.3095

Epoch 00004: val_loss improved from 3.97091 to 3.22976, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9948 - accuracy: 0.3023 - val_loss: 2.7556 - val_accuracy: 0.3138

Epoch 00005: val_loss improved from 3.22976 to 2.75560, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5985 - accuracy: 0.3108 - val_loss: 2.4265 - val_accuracy: 0.3206

Epoch 00006: val_loss improved from 2.75560 to 2.42655, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3212 - accuracy: 0.3101 - val_loss: 2.1959 - val_accuracy: 0.3213

Epoch 00007: val_loss improved from 2.42655 to 2.19594, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 8/100
83/83 [==============================] - 6s 67ms/step - loss: 2.1233 - accuracy: 0.3143 - val_loss: 2.0322 - val_accuracy: 0.3217

Epoch 00008: val_loss improved from 2.19594 to 2.03218, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9826 - accuracy: 0.3193 - val_loss: 1.9151 - val_accuracy: 0.3212

Epoch 00009: val_loss improved from 2.03218 to 1.91505, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8804 - accuracy: 0.3204 - val_loss: 1.8327 - val_accuracy: 0.3244

Epoch 00010: val_loss improved from 1.91505 to 1.83265, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8082 - accuracy: 0.3216 - val_loss: 1.7747 - val_accuracy: 0.3213

Epoch 00011: val_loss improved from 1.83265 to 1.77471, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7565 - accuracy: 0.3247 - val_loss: 1.7330 - val_accuracy: 0.3234

Epoch 00012: val_loss improved from 1.77471 to 1.73299, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7208 - accuracy: 0.3252 - val_loss: 1.7057 - val_accuracy: 0.3253

Epoch 00013: val_loss improved from 1.73299 to 1.70574, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6952 - accuracy: 0.3288 - val_loss: 1.6851 - val_accuracy: 0.3279

Epoch 00014: val_loss improved from 1.70574 to 1.68505, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6754 - accuracy: 0.3308 - val_loss: 1.6709 - val_accuracy: 0.3286

Epoch 00015: val_loss improved from 1.68505 to 1.67092, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6606 - accuracy: 0.3350 - val_loss: 1.6611 - val_accuracy: 0.3277

Epoch 00016: val_loss improved from 1.67092 to 1.66107, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6506 - accuracy: 0.3336 - val_loss: 1.6548 - val_accuracy: 0.3301

Epoch 00017: val_loss improved from 1.66107 to 1.65479, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6421 - accuracy: 0.3362 - val_loss: 1.6507 - val_accuracy: 0.3301

Epoch 00018: val_loss improved from 1.65479 to 1.65071, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 19/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6349 - accuracy: 0.3395 - val_loss: 1.6493 - val_accuracy: 0.3294

Epoch 00019: val_loss improved from 1.65071 to 1.64931, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6317 - accuracy: 0.3401 - val_loss: 1.6460 - val_accuracy: 0.3289

Epoch 00020: val_loss improved from 1.64931 to 1.64603, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6257 - accuracy: 0.3458 - val_loss: 1.6483 - val_accuracy: 0.3265

Epoch 00021: val_loss did not improve from 1.64603
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6230 - accuracy: 0.3453 - val_loss: 1.6456 - val_accuracy: 0.3313

Epoch 00022: val_loss improved from 1.64603 to 1.64559, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6201 - accuracy: 0.3487 - val_loss: 1.6489 - val_accuracy: 0.3310

Epoch 00023: val_loss did not improve from 1.64559
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6178 - accuracy: 0.3507 - val_loss: 1.6491 - val_accuracy: 0.3283

Epoch 00024: val_loss did not improve from 1.64559
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6145 - accuracy: 0.3526 - val_loss: 1.6525 - val_accuracy: 0.3320

Epoch 00025: val_loss did not improve from 1.64559
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6141 - accuracy: 0.3583 - val_loss: 1.6559 - val_accuracy: 0.3302

Epoch 00026: val_loss did not improve from 1.64559
Epoch 27/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6108 - accuracy: 0.3582 - val_loss: 1.6610 - val_accuracy: 0.3324

Epoch 00027: val_loss did not improve from 1.64559
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6088 - accuracy: 0.3639 - val_loss: 1.6669 - val_accuracy: 0.3275

Epoch 00028: val_loss did not improve from 1.64559
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6057 - accuracy: 0.3651 - val_loss: 1.6746 - val_accuracy: 0.3290

Epoch 00029: val_loss did not improve from 1.64559
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6030 - accuracy: 0.3710 - val_loss: 1.6810 - val_accuracy: 0.3227

Epoch 00030: val_loss did not improve from 1.64559
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6032 - accuracy: 0.3742 - val_loss: 1.6887 - val_accuracy: 0.3254

Epoch 00031: val_loss did not improve from 1.64559
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5992 - accuracy: 0.3792 - val_loss: 1.6948 - val_accuracy: 0.3218

Epoch 00032: val_loss did not improve from 1.64559
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6530 - accuracy: 0.3310
Testing Loss = 1.653012, Testing Accuracy = 0.330976
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.2740 - accuracy: 0.2236 - val_loss: 8.5529 - val_accuracy: 0.2573

Epoch 00001: val_loss improved from inf to 8.55289, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7045 - accuracy: 0.2732 - val_loss: 5.3647 - val_accuracy: 0.2949

Epoch 00002: val_loss improved from 8.55289 to 5.36470, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6008 - accuracy: 0.2892 - val_loss: 3.9973 - val_accuracy: 0.3012

Epoch 00003: val_loss improved from 5.36470 to 3.99727, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 4/100
83/83 [==============================] - 6s 70ms/step - loss: 3.6028 - accuracy: 0.2946 - val_loss: 3.2499 - val_accuracy: 0.3104

Epoch 00004: val_loss improved from 3.99727 to 3.24991, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 3.0090 - accuracy: 0.2999 - val_loss: 2.7666 - val_accuracy: 0.3156

Epoch 00005: val_loss improved from 3.24991 to 2.76663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.6091 - accuracy: 0.3094 - val_loss: 2.4380 - val_accuracy: 0.3179

Epoch 00006: val_loss improved from 2.76663 to 2.43802, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3281 - accuracy: 0.3104 - val_loss: 2.2029 - val_accuracy: 0.3210

Epoch 00007: val_loss improved from 2.43802 to 2.20294, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1292 - accuracy: 0.3144 - val_loss: 2.0375 - val_accuracy: 0.3206

Epoch 00008: val_loss improved from 2.20294 to 2.03748, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9865 - accuracy: 0.3149 - val_loss: 1.9203 - val_accuracy: 0.3229

Epoch 00009: val_loss improved from 2.03748 to 1.92033, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8845 - accuracy: 0.3179 - val_loss: 1.8368 - val_accuracy: 0.3226

Epoch 00010: val_loss improved from 1.92033 to 1.83679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8113 - accuracy: 0.3215 - val_loss: 1.7770 - val_accuracy: 0.3257

Epoch 00011: val_loss improved from 1.83679 to 1.77696, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7598 - accuracy: 0.3238 - val_loss: 1.7368 - val_accuracy: 0.3258

Epoch 00012: val_loss improved from 1.77696 to 1.73680, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7223 - accuracy: 0.3262 - val_loss: 1.7063 - val_accuracy: 0.3258

Epoch 00013: val_loss improved from 1.73680 to 1.70628, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6963 - accuracy: 0.3293 - val_loss: 1.6861 - val_accuracy: 0.3302

Epoch 00014: val_loss improved from 1.70628 to 1.68607, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6781 - accuracy: 0.3309 - val_loss: 1.6734 - val_accuracy: 0.3307

Epoch 00015: val_loss improved from 1.68607 to 1.67343, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6625 - accuracy: 0.3319 - val_loss: 1.6633 - val_accuracy: 0.3286

Epoch 00016: val_loss improved from 1.67343 to 1.66334, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6521 - accuracy: 0.3357 - val_loss: 1.6535 - val_accuracy: 0.3313

Epoch 00017: val_loss improved from 1.66334 to 1.65350, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6432 - accuracy: 0.3357 - val_loss: 1.6494 - val_accuracy: 0.3310

Epoch 00018: val_loss improved from 1.65350 to 1.64943, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6373 - accuracy: 0.3382 - val_loss: 1.6466 - val_accuracy: 0.3295

Epoch 00019: val_loss improved from 1.64943 to 1.64663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6321 - accuracy: 0.3420 - val_loss: 1.6441 - val_accuracy: 0.3297

Epoch 00020: val_loss improved from 1.64663 to 1.64408, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6278 - accuracy: 0.3432 - val_loss: 1.6463 - val_accuracy: 0.3293

Epoch 00021: val_loss did not improve from 1.64408
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6230 - accuracy: 0.3474 - val_loss: 1.6446 - val_accuracy: 0.3326

Epoch 00022: val_loss did not improve from 1.64408
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6207 - accuracy: 0.3465 - val_loss: 1.6475 - val_accuracy: 0.3302

Epoch 00023: val_loss did not improve from 1.64408
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6176 - accuracy: 0.3498 - val_loss: 1.6509 - val_accuracy: 0.3326

Epoch 00024: val_loss did not improve from 1.64408
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6149 - accuracy: 0.3526 - val_loss: 1.6545 - val_accuracy: 0.3290

Epoch 00025: val_loss did not improve from 1.64408
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6138 - accuracy: 0.3558 - val_loss: 1.6561 - val_accuracy: 0.3312

Epoch 00026: val_loss did not improve from 1.64408
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6120 - accuracy: 0.3592 - val_loss: 1.6591 - val_accuracy: 0.3294

Epoch 00027: val_loss did not improve from 1.64408
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6083 - accuracy: 0.3640 - val_loss: 1.6649 - val_accuracy: 0.3297

Epoch 00028: val_loss did not improve from 1.64408
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6063 - accuracy: 0.3655 - val_loss: 1.6703 - val_accuracy: 0.3299

Epoch 00029: val_loss did not improve from 1.64408
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6065 - accuracy: 0.3682 - val_loss: 1.6784 - val_accuracy: 0.3300

Epoch 00030: val_loss did not improve from 1.64408
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6511 - accuracy: 0.3335
Testing Loss = 1.651108, Testing Accuracy = 0.333507
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 70ms/step - loss: 12.1867 - accuracy: 0.2233 - val_loss: 8.4311 - val_accuracy: 0.2529

Epoch 00001: val_loss improved from inf to 8.43115, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6005 - accuracy: 0.2736 - val_loss: 5.2794 - val_accuracy: 0.2919

Epoch 00002: val_loss improved from 8.43115 to 5.27941, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5388 - accuracy: 0.2892 - val_loss: 3.9498 - val_accuracy: 0.3053

Epoch 00003: val_loss improved from 5.27941 to 3.94975, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5696 - accuracy: 0.2950 - val_loss: 3.2209 - val_accuracy: 0.3096

Epoch 00004: val_loss improved from 3.94975 to 3.22087, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9884 - accuracy: 0.3013 - val_loss: 2.7485 - val_accuracy: 0.3108

Epoch 00005: val_loss improved from 3.22087 to 2.74847, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5943 - accuracy: 0.3080 - val_loss: 2.4217 - val_accuracy: 0.3158

Epoch 00006: val_loss improved from 2.74847 to 2.42169, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3164 - accuracy: 0.3102 - val_loss: 2.1903 - val_accuracy: 0.3172

Epoch 00007: val_loss improved from 2.42169 to 2.19027, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1187 - accuracy: 0.3143 - val_loss: 2.0274 - val_accuracy: 0.3199

Epoch 00008: val_loss improved from 2.19027 to 2.02743, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 9/100
83/83 [==============================] - 6s 70ms/step - loss: 1.9778 - accuracy: 0.3176 - val_loss: 1.9120 - val_accuracy: 0.3198

Epoch 00009: val_loss improved from 2.02743 to 1.91198, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8791 - accuracy: 0.3187 - val_loss: 1.8303 - val_accuracy: 0.3224

Epoch 00010: val_loss improved from 1.91198 to 1.83033, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8068 - accuracy: 0.3222 - val_loss: 1.7724 - val_accuracy: 0.3222

Epoch 00011: val_loss improved from 1.83033 to 1.77243, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7546 - accuracy: 0.3247 - val_loss: 1.7311 - val_accuracy: 0.3248

Epoch 00012: val_loss improved from 1.77243 to 1.73113, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7190 - accuracy: 0.3265 - val_loss: 1.7048 - val_accuracy: 0.3270

Epoch 00013: val_loss improved from 1.73113 to 1.70484, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6935 - accuracy: 0.3274 - val_loss: 1.6829 - val_accuracy: 0.3301

Epoch 00014: val_loss improved from 1.70484 to 1.68291, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6756 - accuracy: 0.3296 - val_loss: 1.6678 - val_accuracy: 0.3277

Epoch 00015: val_loss improved from 1.68291 to 1.66782, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6596 - accuracy: 0.3331 - val_loss: 1.6600 - val_accuracy: 0.3282

Epoch 00016: val_loss improved from 1.66782 to 1.65999, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6505 - accuracy: 0.3375 - val_loss: 1.6525 - val_accuracy: 0.3295

Epoch 00017: val_loss improved from 1.65999 to 1.65255, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6421 - accuracy: 0.3369 - val_loss: 1.6475 - val_accuracy: 0.3289

Epoch 00018: val_loss improved from 1.65255 to 1.64747, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6359 - accuracy: 0.3380 - val_loss: 1.6441 - val_accuracy: 0.3273

Epoch 00019: val_loss improved from 1.64747 to 1.64413, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6295 - accuracy: 0.3412 - val_loss: 1.6427 - val_accuracy: 0.3308

Epoch 00020: val_loss improved from 1.64413 to 1.64270, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6257 - accuracy: 0.3441 - val_loss: 1.6414 - val_accuracy: 0.3319

Epoch 00021: val_loss improved from 1.64270 to 1.64139, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6225 - accuracy: 0.3445 - val_loss: 1.6420 - val_accuracy: 0.3332

Epoch 00022: val_loss did not improve from 1.64139
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6179 - accuracy: 0.3480 - val_loss: 1.6432 - val_accuracy: 0.3305

Epoch 00023: val_loss did not improve from 1.64139
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6163 - accuracy: 0.3487 - val_loss: 1.6448 - val_accuracy: 0.3312

Epoch 00024: val_loss did not improve from 1.64139
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6148 - accuracy: 0.3509 - val_loss: 1.6464 - val_accuracy: 0.3318

Epoch 00025: val_loss did not improve from 1.64139
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6113 - accuracy: 0.3543 - val_loss: 1.6480 - val_accuracy: 0.3327

Epoch 00026: val_loss did not improve from 1.64139
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6097 - accuracy: 0.3566 - val_loss: 1.6508 - val_accuracy: 0.3364

Epoch 00027: val_loss did not improve from 1.64139
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6064 - accuracy: 0.3612 - val_loss: 1.6551 - val_accuracy: 0.3322

Epoch 00028: val_loss did not improve from 1.64139
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6036 - accuracy: 0.3637 - val_loss: 1.6619 - val_accuracy: 0.3290

Epoch 00029: val_loss did not improve from 1.64139
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6035 - accuracy: 0.3676 - val_loss: 1.6672 - val_accuracy: 0.3296

Epoch 00030: val_loss did not improve from 1.64139
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5996 - accuracy: 0.3726 - val_loss: 1.6746 - val_accuracy: 0.3303

Epoch 00031: val_loss did not improve from 1.64139
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6484 - accuracy: 0.3321
Testing Loss = 1.648436, Testing Accuracy = 0.332093
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 77ms/step - loss: 12.1559 - accuracy: 0.2215 - val_loss: 8.3733 - val_accuracy: 0.2506

Epoch 00001: val_loss improved from inf to 8.37326, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.5494 - accuracy: 0.2740 - val_loss: 5.2401 - val_accuracy: 0.2953

Epoch 00002: val_loss improved from 8.37326 to 5.24006, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.5050 - accuracy: 0.2875 - val_loss: 3.9253 - val_accuracy: 0.3059

Epoch 00003: val_loss improved from 5.24006 to 3.92530, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 4/100
83/83 [==============================] - 6s 70ms/step - loss: 3.5470 - accuracy: 0.2965 - val_loss: 3.2036 - val_accuracy: 0.3107

Epoch 00004: val_loss improved from 3.92530 to 3.20364, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9736 - accuracy: 0.2994 - val_loss: 2.7378 - val_accuracy: 0.3127

Epoch 00005: val_loss improved from 3.20364 to 2.73783, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5839 - accuracy: 0.3047 - val_loss: 2.4160 - val_accuracy: 0.3171

Epoch 00006: val_loss improved from 2.73783 to 2.41602, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3097 - accuracy: 0.3098 - val_loss: 2.1867 - val_accuracy: 0.3216

Epoch 00007: val_loss improved from 2.41602 to 2.18669, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1158 - accuracy: 0.3154 - val_loss: 2.0242 - val_accuracy: 0.3209

Epoch 00008: val_loss improved from 2.18669 to 2.02425, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9763 - accuracy: 0.3199 - val_loss: 1.9097 - val_accuracy: 0.3236

Epoch 00009: val_loss improved from 2.02425 to 1.90970, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8754 - accuracy: 0.3210 - val_loss: 1.8287 - val_accuracy: 0.3262

Epoch 00010: val_loss improved from 1.90970 to 1.82868, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8062 - accuracy: 0.3205 - val_loss: 1.7715 - val_accuracy: 0.3240

Epoch 00011: val_loss improved from 1.82868 to 1.77152, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 12/100
83/83 [==============================] - 6s 70ms/step - loss: 1.7552 - accuracy: 0.3221 - val_loss: 1.7309 - val_accuracy: 0.3240

Epoch 00012: val_loss improved from 1.77152 to 1.73089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7206 - accuracy: 0.3277 - val_loss: 1.7032 - val_accuracy: 0.3268

Epoch 00013: val_loss improved from 1.73089 to 1.70318, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6942 - accuracy: 0.3264 - val_loss: 1.6832 - val_accuracy: 0.3283

Epoch 00014: val_loss improved from 1.70318 to 1.68316, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6757 - accuracy: 0.3280 - val_loss: 1.6696 - val_accuracy: 0.3259

Epoch 00015: val_loss improved from 1.68316 to 1.66964, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6627 - accuracy: 0.3320 - val_loss: 1.6594 - val_accuracy: 0.3282

Epoch 00016: val_loss improved from 1.66964 to 1.65938, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6503 - accuracy: 0.3334 - val_loss: 1.6512 - val_accuracy: 0.3309

Epoch 00017: val_loss improved from 1.65938 to 1.65119, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6440 - accuracy: 0.3347 - val_loss: 1.6476 - val_accuracy: 0.3298

Epoch 00018: val_loss improved from 1.65119 to 1.64761, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6376 - accuracy: 0.3357 - val_loss: 1.6445 - val_accuracy: 0.3275

Epoch 00019: val_loss improved from 1.64761 to 1.64450, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6316 - accuracy: 0.3377 - val_loss: 1.6419 - val_accuracy: 0.3322

Epoch 00020: val_loss improved from 1.64450 to 1.64193, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6278 - accuracy: 0.3425 - val_loss: 1.6425 - val_accuracy: 0.3302

Epoch 00021: val_loss did not improve from 1.64193
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6244 - accuracy: 0.3437 - val_loss: 1.6409 - val_accuracy: 0.3306

Epoch 00022: val_loss improved from 1.64193 to 1.64090, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6203 - accuracy: 0.3454 - val_loss: 1.6429 - val_accuracy: 0.3329

Epoch 00023: val_loss did not improve from 1.64090
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6178 - accuracy: 0.3459 - val_loss: 1.6441 - val_accuracy: 0.3309

Epoch 00024: val_loss did not improve from 1.64090
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6156 - accuracy: 0.3502 - val_loss: 1.6454 - val_accuracy: 0.3310

Epoch 00025: val_loss did not improve from 1.64090
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6149 - accuracy: 0.3511 - val_loss: 1.6467 - val_accuracy: 0.3296

Epoch 00026: val_loss did not improve from 1.64090
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6110 - accuracy: 0.3574 - val_loss: 1.6513 - val_accuracy: 0.3329

Epoch 00027: val_loss did not improve from 1.64090
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6094 - accuracy: 0.3569 - val_loss: 1.6550 - val_accuracy: 0.3292

Epoch 00028: val_loss did not improve from 1.64090
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6077 - accuracy: 0.3614 - val_loss: 1.6576 - val_accuracy: 0.3313

Epoch 00029: val_loss did not improve from 1.64090
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6050 - accuracy: 0.3652 - val_loss: 1.6665 - val_accuracy: 0.3257

Epoch 00030: val_loss did not improve from 1.64090
Epoch 31/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6034 - accuracy: 0.3683 - val_loss: 1.6737 - val_accuracy: 0.3242

Epoch 00031: val_loss did not improve from 1.64090
Epoch 32/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5996 - accuracy: 0.3741 - val_loss: 1.6830 - val_accuracy: 0.3259

Epoch 00032: val_loss did not improve from 1.64090
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6475 - accuracy: 0.3312
Testing Loss = 1.647547, Testing Accuracy = 0.331200
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.1829 - accuracy: 0.2219 - val_loss: 8.4391 - val_accuracy: 0.2566

Epoch 00001: val_loss improved from inf to 8.43913, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.5995 - accuracy: 0.2712 - val_loss: 5.2710 - val_accuracy: 0.2981

Epoch 00002: val_loss improved from 8.43913 to 5.27097, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5298 - accuracy: 0.2889 - val_loss: 3.9416 - val_accuracy: 0.3039

Epoch 00003: val_loss improved from 5.27097 to 3.94156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5569 - accuracy: 0.2957 - val_loss: 3.2112 - val_accuracy: 0.3110

Epoch 00004: val_loss improved from 3.94156 to 3.21118, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9778 - accuracy: 0.3020 - val_loss: 2.7398 - val_accuracy: 0.3149

Epoch 00005: val_loss improved from 3.21118 to 2.73981, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5852 - accuracy: 0.3083 - val_loss: 2.4155 - val_accuracy: 0.3178

Epoch 00006: val_loss improved from 2.73981 to 2.41550, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3107 - accuracy: 0.3111 - val_loss: 2.1875 - val_accuracy: 0.3229

Epoch 00007: val_loss improved from 2.41550 to 2.18752, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1152 - accuracy: 0.3119 - val_loss: 2.0254 - val_accuracy: 0.3225

Epoch 00008: val_loss improved from 2.18752 to 2.02536, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9755 - accuracy: 0.3181 - val_loss: 1.9108 - val_accuracy: 0.3248

Epoch 00009: val_loss improved from 2.02536 to 1.91084, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8765 - accuracy: 0.3197 - val_loss: 1.8288 - val_accuracy: 0.3256

Epoch 00010: val_loss improved from 1.91084 to 1.82885, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8055 - accuracy: 0.3241 - val_loss: 1.7716 - val_accuracy: 0.3259

Epoch 00011: val_loss improved from 1.82885 to 1.77164, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7566 - accuracy: 0.3241 - val_loss: 1.7319 - val_accuracy: 0.3276

Epoch 00012: val_loss improved from 1.77164 to 1.73193, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7206 - accuracy: 0.3244 - val_loss: 1.7043 - val_accuracy: 0.3269

Epoch 00013: val_loss improved from 1.73193 to 1.70431, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6942 - accuracy: 0.3282 - val_loss: 1.6848 - val_accuracy: 0.3246

Epoch 00014: val_loss improved from 1.70431 to 1.68482, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6751 - accuracy: 0.3323 - val_loss: 1.6699 - val_accuracy: 0.3291

Epoch 00015: val_loss improved from 1.68482 to 1.66988, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6616 - accuracy: 0.3333 - val_loss: 1.6614 - val_accuracy: 0.3305

Epoch 00016: val_loss improved from 1.66988 to 1.66136, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6517 - accuracy: 0.3329 - val_loss: 1.6531 - val_accuracy: 0.3304

Epoch 00017: val_loss improved from 1.66136 to 1.65311, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6428 - accuracy: 0.3386 - val_loss: 1.6491 - val_accuracy: 0.3282

Epoch 00018: val_loss improved from 1.65311 to 1.64914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6374 - accuracy: 0.3359 - val_loss: 1.6471 - val_accuracy: 0.3304

Epoch 00019: val_loss improved from 1.64914 to 1.64707, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6317 - accuracy: 0.3393 - val_loss: 1.6447 - val_accuracy: 0.3338

Epoch 00020: val_loss improved from 1.64707 to 1.64468, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6268 - accuracy: 0.3436 - val_loss: 1.6456 - val_accuracy: 0.3326

Epoch 00021: val_loss did not improve from 1.64468
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6250 - accuracy: 0.3455 - val_loss: 1.6449 - val_accuracy: 0.3308

Epoch 00022: val_loss did not improve from 1.64468
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6221 - accuracy: 0.3441 - val_loss: 1.6459 - val_accuracy: 0.3348

Epoch 00023: val_loss did not improve from 1.64468
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6188 - accuracy: 0.3509 - val_loss: 1.6496 - val_accuracy: 0.3315

Epoch 00024: val_loss did not improve from 1.64468
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6150 - accuracy: 0.3518 - val_loss: 1.6509 - val_accuracy: 0.3303

Epoch 00025: val_loss did not improve from 1.64468
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6161 - accuracy: 0.3523 - val_loss: 1.6541 - val_accuracy: 0.3337

Epoch 00026: val_loss did not improve from 1.64468
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6106 - accuracy: 0.3565 - val_loss: 1.6574 - val_accuracy: 0.3332

Epoch 00027: val_loss did not improve from 1.64468
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6113 - accuracy: 0.3598 - val_loss: 1.6595 - val_accuracy: 0.3337

Epoch 00028: val_loss did not improve from 1.64468
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6075 - accuracy: 0.3634 - val_loss: 1.6650 - val_accuracy: 0.3304

Epoch 00029: val_loss did not improve from 1.64468
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6058 - accuracy: 0.3664 - val_loss: 1.6762 - val_accuracy: 0.3294

Epoch 00030: val_loss did not improve from 1.64468
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 58s 4ms/step - loss: 1.6522 - accuracy: 0.3312
Testing Loss = 1.652165, Testing Accuracy = 0.331200
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 70ms/step - loss: 12.4191 - accuracy: 0.2169 - val_loss: 8.6974 - val_accuracy: 0.2433

Epoch 00001: val_loss improved from inf to 8.69740, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7749 - accuracy: 0.2716 - val_loss: 5.3980 - val_accuracy: 0.2938

Epoch 00002: val_loss improved from 8.69740 to 5.39796, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6198 - accuracy: 0.2897 - val_loss: 4.0028 - val_accuracy: 0.3072

Epoch 00003: val_loss improved from 5.39796 to 4.00281, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.6038 - accuracy: 0.2967 - val_loss: 3.2465 - val_accuracy: 0.3081

Epoch 00004: val_loss improved from 4.00281 to 3.24652, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 3.0060 - accuracy: 0.3046 - val_loss: 2.7645 - val_accuracy: 0.3140

Epoch 00005: val_loss improved from 3.24652 to 2.76452, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.6061 - accuracy: 0.3097 - val_loss: 2.4347 - val_accuracy: 0.3173

Epoch 00006: val_loss improved from 2.76452 to 2.43466, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.3258 - accuracy: 0.3132 - val_loss: 2.1999 - val_accuracy: 0.3200

Epoch 00007: val_loss improved from 2.43466 to 2.19992, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1275 - accuracy: 0.3145 - val_loss: 2.0352 - val_accuracy: 0.3245

Epoch 00008: val_loss improved from 2.19992 to 2.03523, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9856 - accuracy: 0.3205 - val_loss: 1.9180 - val_accuracy: 0.3243

Epoch 00009: val_loss improved from 2.03523 to 1.91805, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8825 - accuracy: 0.3216 - val_loss: 1.8354 - val_accuracy: 0.3246

Epoch 00010: val_loss improved from 1.91805 to 1.83542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8115 - accuracy: 0.3232 - val_loss: 1.7765 - val_accuracy: 0.3258

Epoch 00011: val_loss improved from 1.83542 to 1.77651, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7597 - accuracy: 0.3250 - val_loss: 1.7349 - val_accuracy: 0.3265

Epoch 00012: val_loss improved from 1.77651 to 1.73489, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7212 - accuracy: 0.3275 - val_loss: 1.7066 - val_accuracy: 0.3284

Epoch 00013: val_loss improved from 1.73489 to 1.70661, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6960 - accuracy: 0.3314 - val_loss: 1.6858 - val_accuracy: 0.3262

Epoch 00014: val_loss improved from 1.70661 to 1.68578, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6757 - accuracy: 0.3305 - val_loss: 1.6712 - val_accuracy: 0.3256

Epoch 00015: val_loss improved from 1.68578 to 1.67124, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6612 - accuracy: 0.3339 - val_loss: 1.6607 - val_accuracy: 0.3271

Epoch 00016: val_loss improved from 1.67124 to 1.66072, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6514 - accuracy: 0.3336 - val_loss: 1.6538 - val_accuracy: 0.3277

Epoch 00017: val_loss improved from 1.66072 to 1.65384, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6426 - accuracy: 0.3377 - val_loss: 1.6483 - val_accuracy: 0.3302

Epoch 00018: val_loss improved from 1.65384 to 1.64831, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6357 - accuracy: 0.3408 - val_loss: 1.6464 - val_accuracy: 0.3293

Epoch 00019: val_loss improved from 1.64831 to 1.64637, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6305 - accuracy: 0.3423 - val_loss: 1.6440 - val_accuracy: 0.3288

Epoch 00020: val_loss improved from 1.64637 to 1.64403, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6287 - accuracy: 0.3434 - val_loss: 1.6439 - val_accuracy: 0.3322

Epoch 00021: val_loss improved from 1.64403 to 1.64389, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6236 - accuracy: 0.3450 - val_loss: 1.6453 - val_accuracy: 0.3306

Epoch 00022: val_loss did not improve from 1.64389
Epoch 23/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6202 - accuracy: 0.3505 - val_loss: 1.6463 - val_accuracy: 0.3354

Epoch 00023: val_loss did not improve from 1.64389
Epoch 24/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6180 - accuracy: 0.3520 - val_loss: 1.6473 - val_accuracy: 0.3344

Epoch 00024: val_loss did not improve from 1.64389
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6130 - accuracy: 0.3560 - val_loss: 1.6507 - val_accuracy: 0.3356

Epoch 00025: val_loss did not improve from 1.64389
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6118 - accuracy: 0.3600 - val_loss: 1.6551 - val_accuracy: 0.3321

Epoch 00026: val_loss did not improve from 1.64389
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6097 - accuracy: 0.3595 - val_loss: 1.6585 - val_accuracy: 0.3347

Epoch 00027: val_loss did not improve from 1.64389
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6079 - accuracy: 0.3650 - val_loss: 1.6650 - val_accuracy: 0.3282

Epoch 00028: val_loss did not improve from 1.64389
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6060 - accuracy: 0.3664 - val_loss: 1.6698 - val_accuracy: 0.3304

Epoch 00029: val_loss did not improve from 1.64389
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6028 - accuracy: 0.3721 - val_loss: 1.6759 - val_accuracy: 0.3275

Epoch 00030: val_loss did not improve from 1.64389
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 58s 4ms/step - loss: 1.6505 - accuracy: 0.3338
Testing Loss = 1.650468, Testing Accuracy = 0.333805
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 80.78 +- 0.0579 %)
$W^-/W^-$ (auc = 79.91 +- 0.0604 %)
$Z/Z$ (auc = 63.91 +- 0.1337 %)
$W^+/W^-$ (auc = 64.30 +- 0.0796 %)
$W^+/Z$$ (auc = 64.69 +- 0.0789 %)
$W^-/Z$ (auc = 66.76 +- 0.0711 %)
The summarized testing accuracy = 33.26 +- 0.1267 %, with the loss = 1.6502 +- 0.002144


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-27 21:14:35.719122
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 15s 118ms/step - loss: 11.9518 - accuracy: 0.2500 - val_loss: 8.2688 - val_accuracy: 0.2800

Epoch 00001: val_loss improved from inf to 8.26877, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 2/100
83/83 [==============================] - 9s 111ms/step - loss: 6.5236 - accuracy: 0.2664 - val_loss: 5.2082 - val_accuracy: 0.2857

Epoch 00002: val_loss improved from 8.26877 to 5.20818, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 3/100
83/83 [==============================] - 9s 109ms/step - loss: 4.5213 - accuracy: 0.2767 - val_loss: 3.9362 - val_accuracy: 0.2896

Epoch 00003: val_loss improved from 5.20818 to 3.93618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 4/100
83/83 [==============================] - 9s 111ms/step - loss: 3.5774 - accuracy: 0.2801 - val_loss: 3.2291 - val_accuracy: 0.2956

Epoch 00004: val_loss improved from 3.93618 to 3.22906, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 5/100
83/83 [==============================] - 9s 109ms/step - loss: 3.0029 - accuracy: 0.2860 - val_loss: 2.7620 - val_accuracy: 0.3010

Epoch 00005: val_loss improved from 3.22906 to 2.76199, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 6/100
83/83 [==============================] - 9s 111ms/step - loss: 2.6115 - accuracy: 0.2903 - val_loss: 2.4374 - val_accuracy: 0.2988

Epoch 00006: val_loss improved from 2.76199 to 2.43744, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 7/100
83/83 [==============================] - 9s 110ms/step - loss: 2.3333 - accuracy: 0.2916 - val_loss: 2.2063 - val_accuracy: 0.3027

Epoch 00007: val_loss improved from 2.43744 to 2.20632, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 8/100
83/83 [==============================] - 9s 114ms/step - loss: 2.1359 - accuracy: 0.2912 - val_loss: 2.0413 - val_accuracy: 0.3021

Epoch 00008: val_loss improved from 2.20632 to 2.04128, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 9/100
83/83 [==============================] - 9s 112ms/step - loss: 1.9952 - accuracy: 0.2919 - val_loss: 1.9243 - val_accuracy: 0.3030

Epoch 00009: val_loss improved from 2.04128 to 1.92433, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 10/100
83/83 [==============================] - 10s 119ms/step - loss: 1.8957 - accuracy: 0.2943 - val_loss: 1.8417 - val_accuracy: 0.3021

Epoch 00010: val_loss improved from 1.92433 to 1.84167, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 11/100
83/83 [==============================] - 10s 120ms/step - loss: 1.8241 - accuracy: 0.2974 - val_loss: 1.7836 - val_accuracy: 0.3027

Epoch 00011: val_loss improved from 1.84167 to 1.78365, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 12/100
83/83 [==============================] - 10s 125ms/step - loss: 1.7756 - accuracy: 0.2977 - val_loss: 1.7441 - val_accuracy: 0.3023

Epoch 00012: val_loss improved from 1.78365 to 1.74409, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 13/100
83/83 [==============================] - 12s 138ms/step - loss: 1.7414 - accuracy: 0.2970 - val_loss: 1.7160 - val_accuracy: 0.3036

Epoch 00013: val_loss improved from 1.74409 to 1.71595, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 14/100
83/83 [==============================] - 12s 138ms/step - loss: 1.7166 - accuracy: 0.2957 - val_loss: 1.6958 - val_accuracy: 0.3037

Epoch 00014: val_loss improved from 1.71595 to 1.69578, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 15/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6996 - accuracy: 0.2945 - val_loss: 1.6822 - val_accuracy: 0.3038

Epoch 00015: val_loss improved from 1.69578 to 1.68216, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 16/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6854 - accuracy: 0.2995 - val_loss: 1.6712 - val_accuracy: 0.3024

Epoch 00016: val_loss improved from 1.68216 to 1.67123, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 17/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6780 - accuracy: 0.2985 - val_loss: 1.6631 - val_accuracy: 0.3063

Epoch 00017: val_loss improved from 1.67123 to 1.66313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 18/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6705 - accuracy: 0.3004 - val_loss: 1.6579 - val_accuracy: 0.3049

Epoch 00018: val_loss improved from 1.66313 to 1.65792, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 19/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6662 - accuracy: 0.2991 - val_loss: 1.6544 - val_accuracy: 0.3063

Epoch 00019: val_loss improved from 1.65792 to 1.65444, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 20/100
83/83 [==============================] - 11s 138ms/step - loss: 1.6617 - accuracy: 0.2995 - val_loss: 1.6508 - val_accuracy: 0.3074

Epoch 00020: val_loss improved from 1.65444 to 1.65081, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 21/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6599 - accuracy: 0.2999 - val_loss: 1.6493 - val_accuracy: 0.3047

Epoch 00021: val_loss improved from 1.65081 to 1.64935, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 22/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6573 - accuracy: 0.3002 - val_loss: 1.6460 - val_accuracy: 0.3075

Epoch 00022: val_loss improved from 1.64935 to 1.64599, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 23/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6553 - accuracy: 0.2989 - val_loss: 1.6457 - val_accuracy: 0.3075

Epoch 00023: val_loss improved from 1.64599 to 1.64572, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 24/100
83/83 [==============================] - 7s 82ms/step - loss: 1.6532 - accuracy: 0.3014 - val_loss: 1.6441 - val_accuracy: 0.3095

Epoch 00024: val_loss improved from 1.64572 to 1.64410, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 25/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6513 - accuracy: 0.3040 - val_loss: 1.6422 - val_accuracy: 0.3101

Epoch 00025: val_loss improved from 1.64410 to 1.64223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 26/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6502 - accuracy: 0.3032 - val_loss: 1.6418 - val_accuracy: 0.3076

Epoch 00026: val_loss improved from 1.64223 to 1.64179, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 27/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6494 - accuracy: 0.3003 - val_loss: 1.6419 - val_accuracy: 0.3075

Epoch 00027: val_loss did not improve from 1.64179
Epoch 28/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6481 - accuracy: 0.3035 - val_loss: 1.6410 - val_accuracy: 0.3081

Epoch 00028: val_loss improved from 1.64179 to 1.64103, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 29/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6471 - accuracy: 0.3033 - val_loss: 1.6401 - val_accuracy: 0.3079

Epoch 00029: val_loss improved from 1.64103 to 1.64015, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 30/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6464 - accuracy: 0.3031 - val_loss: 1.6413 - val_accuracy: 0.3070

Epoch 00030: val_loss did not improve from 1.64015
Epoch 31/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6462 - accuracy: 0.3037 - val_loss: 1.6396 - val_accuracy: 0.3069

Epoch 00031: val_loss improved from 1.64015 to 1.63960, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 32/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6457 - accuracy: 0.3037 - val_loss: 1.6398 - val_accuracy: 0.3063

Epoch 00032: val_loss did not improve from 1.63960
Epoch 33/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6444 - accuracy: 0.3034 - val_loss: 1.6404 - val_accuracy: 0.3082

Epoch 00033: val_loss did not improve from 1.63960
Epoch 34/100
83/83 [==============================] - 7s 81ms/step - loss: 1.6440 - accuracy: 0.3061 - val_loss: 1.6400 - val_accuracy: 0.3081

Epoch 00034: val_loss did not improve from 1.63960
Epoch 35/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6434 - accuracy: 0.3053 - val_loss: 1.6388 - val_accuracy: 0.3104

Epoch 00035: val_loss improved from 1.63960 to 1.63880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 36/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6432 - accuracy: 0.3054 - val_loss: 1.6394 - val_accuracy: 0.3091

Epoch 00036: val_loss did not improve from 1.63880
Epoch 37/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6422 - accuracy: 0.3069 - val_loss: 1.6396 - val_accuracy: 0.3087

Epoch 00037: val_loss did not improve from 1.63880
Epoch 38/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6413 - accuracy: 0.3071 - val_loss: 1.6394 - val_accuracy: 0.3105

Epoch 00038: val_loss did not improve from 1.63880
Epoch 39/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6423 - accuracy: 0.3053 - val_loss: 1.6404 - val_accuracy: 0.3082

Epoch 00039: val_loss did not improve from 1.63880
Epoch 40/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6408 - accuracy: 0.3065 - val_loss: 1.6397 - val_accuracy: 0.3071

Epoch 00040: val_loss did not improve from 1.63880
Epoch 41/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6401 - accuracy: 0.3094 - val_loss: 1.6410 - val_accuracy: 0.3102

Epoch 00041: val_loss did not improve from 1.63880
Epoch 42/100
83/83 [==============================] - 7s 88ms/step - loss: 1.6407 - accuracy: 0.3087 - val_loss: 1.6408 - val_accuracy: 0.3102

Epoch 00042: val_loss did not improve from 1.63880
Epoch 43/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6397 - accuracy: 0.3077 - val_loss: 1.6417 - val_accuracy: 0.3099

Epoch 00043: val_loss did not improve from 1.63880
Epoch 44/100
83/83 [==============================] - 10s 126ms/step - loss: 1.6380 - accuracy: 0.3097 - val_loss: 1.6416 - val_accuracy: 0.3081

Epoch 00044: val_loss did not improve from 1.63880
Epoch 45/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6388 - accuracy: 0.3099 - val_loss: 1.6410 - val_accuracy: 0.3088

Epoch 00045: val_loss did not improve from 1.63880
Epoch 00045: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 83s 6ms/step - loss: 1.6426 - accuracy: 0.3025
Testing Loss = 1.642648, Testing Accuracy = 0.302471
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 10s 113ms/step - loss: 11.9095 - accuracy: 0.2528 - val_loss: 8.2203 - val_accuracy: 0.2819

Epoch 00001: val_loss improved from inf to 8.22029, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 2/100
83/83 [==============================] - 9s 112ms/step - loss: 6.4874 - accuracy: 0.2730 - val_loss: 5.1824 - val_accuracy: 0.2871

Epoch 00002: val_loss improved from 8.22029 to 5.18242, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 3/100
83/83 [==============================] - 9s 107ms/step - loss: 4.5006 - accuracy: 0.2754 - val_loss: 3.9201 - val_accuracy: 0.2932

Epoch 00003: val_loss improved from 5.18242 to 3.92010, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 4/100
83/83 [==============================] - 9s 113ms/step - loss: 3.5618 - accuracy: 0.2797 - val_loss: 3.2168 - val_accuracy: 0.2979

Epoch 00004: val_loss improved from 3.92010 to 3.21679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 5/100
83/83 [==============================] - 10s 119ms/step - loss: 2.9923 - accuracy: 0.2863 - val_loss: 2.7560 - val_accuracy: 0.2985

Epoch 00005: val_loss improved from 3.21679 to 2.75598, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 6/100
83/83 [==============================] - 10s 120ms/step - loss: 2.6034 - accuracy: 0.2876 - val_loss: 2.4327 - val_accuracy: 0.3022

Epoch 00006: val_loss improved from 2.75598 to 2.43274, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 7/100
83/83 [==============================] - 11s 127ms/step - loss: 2.3272 - accuracy: 0.2901 - val_loss: 2.2018 - val_accuracy: 0.3018

Epoch 00007: val_loss improved from 2.43274 to 2.20182, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 8/100
83/83 [==============================] - 11s 135ms/step - loss: 2.1310 - accuracy: 0.2920 - val_loss: 2.0368 - val_accuracy: 0.3046

Epoch 00008: val_loss improved from 2.20182 to 2.03681, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 9/100
83/83 [==============================] - 11s 135ms/step - loss: 1.9916 - accuracy: 0.2909 - val_loss: 1.9218 - val_accuracy: 0.3011

Epoch 00009: val_loss improved from 2.03681 to 1.92183, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 10/100
83/83 [==============================] - 12s 138ms/step - loss: 1.8929 - accuracy: 0.2938 - val_loss: 1.8395 - val_accuracy: 0.3021

Epoch 00010: val_loss improved from 1.92183 to 1.83950, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 11/100
83/83 [==============================] - 9s 107ms/step - loss: 1.8231 - accuracy: 0.2938 - val_loss: 1.7832 - val_accuracy: 0.3021

Epoch 00011: val_loss improved from 1.83950 to 1.78324, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 12/100
83/83 [==============================] - 9s 113ms/step - loss: 1.7738 - accuracy: 0.2943 - val_loss: 1.7414 - val_accuracy: 0.3046

Epoch 00012: val_loss improved from 1.78324 to 1.74143, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 13/100
83/83 [==============================] - 9s 110ms/step - loss: 1.7402 - accuracy: 0.2973 - val_loss: 1.7131 - val_accuracy: 0.3043

Epoch 00013: val_loss improved from 1.74143 to 1.71312, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 14/100
83/83 [==============================] - 9s 112ms/step - loss: 1.7149 - accuracy: 0.2969 - val_loss: 1.6937 - val_accuracy: 0.3038

Epoch 00014: val_loss improved from 1.71312 to 1.69371, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 15/100
83/83 [==============================] - 9s 114ms/step - loss: 1.6982 - accuracy: 0.2972 - val_loss: 1.6797 - val_accuracy: 0.3037

Epoch 00015: val_loss improved from 1.69371 to 1.67973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 16/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6865 - accuracy: 0.2963 - val_loss: 1.6693 - val_accuracy: 0.3049

Epoch 00016: val_loss improved from 1.67973 to 1.66930, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 17/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6764 - accuracy: 0.3007 - val_loss: 1.6641 - val_accuracy: 0.3060

Epoch 00017: val_loss improved from 1.66930 to 1.66405, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 18/100
83/83 [==============================] - 11s 138ms/step - loss: 1.6697 - accuracy: 0.2987 - val_loss: 1.6583 - val_accuracy: 0.3047

Epoch 00018: val_loss improved from 1.66405 to 1.65829, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 19/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6655 - accuracy: 0.3007 - val_loss: 1.6543 - val_accuracy: 0.3065

Epoch 00019: val_loss improved from 1.65829 to 1.65432, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 20/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6605 - accuracy: 0.3012 - val_loss: 1.6506 - val_accuracy: 0.3039

Epoch 00020: val_loss improved from 1.65432 to 1.65056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 21/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6594 - accuracy: 0.2998 - val_loss: 1.6476 - val_accuracy: 0.3074

Epoch 00021: val_loss improved from 1.65056 to 1.64755, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 22/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6561 - accuracy: 0.3006 - val_loss: 1.6460 - val_accuracy: 0.3069

Epoch 00022: val_loss improved from 1.64755 to 1.64603, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 23/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6543 - accuracy: 0.2998 - val_loss: 1.6454 - val_accuracy: 0.3062

Epoch 00023: val_loss improved from 1.64603 to 1.64542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 24/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6516 - accuracy: 0.3023 - val_loss: 1.6443 - val_accuracy: 0.3063

Epoch 00024: val_loss improved from 1.64542 to 1.64427, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 25/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6503 - accuracy: 0.3029 - val_loss: 1.6430 - val_accuracy: 0.3047

Epoch 00025: val_loss improved from 1.64427 to 1.64299, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 26/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6501 - accuracy: 0.3013 - val_loss: 1.6416 - val_accuracy: 0.3078

Epoch 00026: val_loss improved from 1.64299 to 1.64156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 27/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6500 - accuracy: 0.3044 - val_loss: 1.6411 - val_accuracy: 0.3092

Epoch 00027: val_loss improved from 1.64156 to 1.64107, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 28/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6480 - accuracy: 0.3028 - val_loss: 1.6409 - val_accuracy: 0.3079

Epoch 00028: val_loss improved from 1.64107 to 1.64092, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 29/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6467 - accuracy: 0.3015 - val_loss: 1.6404 - val_accuracy: 0.3081

Epoch 00029: val_loss improved from 1.64092 to 1.64041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 30/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6471 - accuracy: 0.3033 - val_loss: 1.6396 - val_accuracy: 0.3072

Epoch 00030: val_loss improved from 1.64041 to 1.63955, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 31/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6461 - accuracy: 0.3019 - val_loss: 1.6405 - val_accuracy: 0.3056

Epoch 00031: val_loss did not improve from 1.63955
Epoch 32/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6447 - accuracy: 0.3045 - val_loss: 1.6395 - val_accuracy: 0.3089

Epoch 00032: val_loss improved from 1.63955 to 1.63948, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 33/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6449 - accuracy: 0.3049 - val_loss: 1.6390 - val_accuracy: 0.3085

Epoch 00033: val_loss improved from 1.63948 to 1.63897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 34/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6442 - accuracy: 0.3045 - val_loss: 1.6390 - val_accuracy: 0.3096

Epoch 00034: val_loss did not improve from 1.63897
Epoch 35/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6437 - accuracy: 0.3049 - val_loss: 1.6388 - val_accuracy: 0.3082

Epoch 00035: val_loss improved from 1.63897 to 1.63878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 36/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6420 - accuracy: 0.3046 - val_loss: 1.6392 - val_accuracy: 0.3107

Epoch 00036: val_loss did not improve from 1.63878
Epoch 37/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6429 - accuracy: 0.3062 - val_loss: 1.6382 - val_accuracy: 0.3128

Epoch 00037: val_loss improved from 1.63878 to 1.63820, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 38/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6416 - accuracy: 0.3083 - val_loss: 1.6391 - val_accuracy: 0.3074

Epoch 00038: val_loss did not improve from 1.63820
Epoch 39/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6404 - accuracy: 0.3072 - val_loss: 1.6381 - val_accuracy: 0.3089

Epoch 00039: val_loss improved from 1.63820 to 1.63813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 40/100
83/83 [==============================] - 10s 120ms/step - loss: 1.6410 - accuracy: 0.3071 - val_loss: 1.6387 - val_accuracy: 0.3096

Epoch 00040: val_loss did not improve from 1.63813
Epoch 41/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6410 - accuracy: 0.3074 - val_loss: 1.6395 - val_accuracy: 0.3079

Epoch 00041: val_loss did not improve from 1.63813
Epoch 42/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6400 - accuracy: 0.3077 - val_loss: 1.6401 - val_accuracy: 0.3070

Epoch 00042: val_loss did not improve from 1.63813
Epoch 43/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6409 - accuracy: 0.3067 - val_loss: 1.6392 - val_accuracy: 0.3104

Epoch 00043: val_loss did not improve from 1.63813
Epoch 44/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6393 - accuracy: 0.3068 - val_loss: 1.6391 - val_accuracy: 0.3083

Epoch 00044: val_loss did not improve from 1.63813
Epoch 45/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6388 - accuracy: 0.3070 - val_loss: 1.6396 - val_accuracy: 0.3077

Epoch 00045: val_loss did not improve from 1.63813
Epoch 46/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6387 - accuracy: 0.3080 - val_loss: 1.6404 - val_accuracy: 0.3098

Epoch 00046: val_loss did not improve from 1.63813
Epoch 47/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6381 - accuracy: 0.3091 - val_loss: 1.6397 - val_accuracy: 0.3104

Epoch 00047: val_loss did not improve from 1.63813
Epoch 00047: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 83s 6ms/step - loss: 1.6413 - accuracy: 0.3030
Testing Loss = 1.641299, Testing Accuracy = 0.302992
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 11s 130ms/step - loss: 11.9145 - accuracy: 0.2463 - val_loss: 8.2223 - val_accuracy: 0.2845

Epoch 00001: val_loss improved from inf to 8.22226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 2/100
83/83 [==============================] - 11s 133ms/step - loss: 6.4867 - accuracy: 0.2692 - val_loss: 5.1753 - val_accuracy: 0.2948

Epoch 00002: val_loss improved from 8.22226 to 5.17532, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 3/100
83/83 [==============================] - 11s 135ms/step - loss: 4.4995 - accuracy: 0.2773 - val_loss: 3.9170 - val_accuracy: 0.2962

Epoch 00003: val_loss improved from 5.17532 to 3.91700, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 4/100
83/83 [==============================] - 12s 139ms/step - loss: 3.5630 - accuracy: 0.2844 - val_loss: 3.2162 - val_accuracy: 0.3021

Epoch 00004: val_loss improved from 3.91700 to 3.21622, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 5/100
83/83 [==============================] - 9s 109ms/step - loss: 2.9940 - accuracy: 0.2853 - val_loss: 2.7577 - val_accuracy: 0.3005

Epoch 00005: val_loss improved from 3.21622 to 2.75772, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 6/100
83/83 [==============================] - 10s 114ms/step - loss: 2.6053 - accuracy: 0.2896 - val_loss: 2.4337 - val_accuracy: 0.3020

Epoch 00006: val_loss improved from 2.75772 to 2.43369, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 7/100
83/83 [==============================] - 12s 139ms/step - loss: 2.3310 - accuracy: 0.2923 - val_loss: 2.2039 - val_accuracy: 0.3033

Epoch 00007: val_loss improved from 2.43369 to 2.20391, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 8/100
83/83 [==============================] - 11s 132ms/step - loss: 2.1349 - accuracy: 0.2920 - val_loss: 2.0409 - val_accuracy: 0.3037

Epoch 00008: val_loss improved from 2.20391 to 2.04095, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 9/100
83/83 [==============================] - 12s 139ms/step - loss: 1.9954 - accuracy: 0.2909 - val_loss: 1.9245 - val_accuracy: 0.3030

Epoch 00009: val_loss improved from 2.04095 to 1.92446, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 10/100
83/83 [==============================] - 12s 139ms/step - loss: 1.8953 - accuracy: 0.2927 - val_loss: 1.8419 - val_accuracy: 0.3036

Epoch 00010: val_loss improved from 1.92446 to 1.84188, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 11/100
83/83 [==============================] - 9s 110ms/step - loss: 1.8255 - accuracy: 0.2971 - val_loss: 1.7837 - val_accuracy: 0.3067

Epoch 00011: val_loss improved from 1.84188 to 1.78369, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 12/100
83/83 [==============================] - 12s 139ms/step - loss: 1.7762 - accuracy: 0.2979 - val_loss: 1.7441 - val_accuracy: 0.3054

Epoch 00012: val_loss improved from 1.78369 to 1.74415, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 13/100
83/83 [==============================] - 12s 140ms/step - loss: 1.7404 - accuracy: 0.2967 - val_loss: 1.7157 - val_accuracy: 0.3027

Epoch 00013: val_loss improved from 1.74415 to 1.71570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 14/100
83/83 [==============================] - 12s 139ms/step - loss: 1.7163 - accuracy: 0.2973 - val_loss: 1.6954 - val_accuracy: 0.3049

Epoch 00014: val_loss improved from 1.71570 to 1.69542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 15/100
83/83 [==============================] - 12s 140ms/step - loss: 1.6994 - accuracy: 0.2978 - val_loss: 1.6821 - val_accuracy: 0.3044

Epoch 00015: val_loss improved from 1.69542 to 1.68213, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 16/100
83/83 [==============================] - 12s 140ms/step - loss: 1.6862 - accuracy: 0.2967 - val_loss: 1.6712 - val_accuracy: 0.3052

Epoch 00016: val_loss improved from 1.68213 to 1.67118, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 17/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6777 - accuracy: 0.3012 - val_loss: 1.6644 - val_accuracy: 0.3031

Epoch 00017: val_loss improved from 1.67118 to 1.66442, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 18/100
83/83 [==============================] - 8s 95ms/step - loss: 1.6707 - accuracy: 0.3003 - val_loss: 1.6583 - val_accuracy: 0.3051

Epoch 00018: val_loss improved from 1.66442 to 1.65830, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 19/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6652 - accuracy: 0.3005 - val_loss: 1.6544 - val_accuracy: 0.3058

Epoch 00019: val_loss improved from 1.65830 to 1.65438, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 20/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6618 - accuracy: 0.2991 - val_loss: 1.6507 - val_accuracy: 0.3054

Epoch 00020: val_loss improved from 1.65438 to 1.65075, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 21/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6598 - accuracy: 0.3020 - val_loss: 1.6502 - val_accuracy: 0.3059

Epoch 00021: val_loss improved from 1.65075 to 1.65019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 22/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6563 - accuracy: 0.2976 - val_loss: 1.6474 - val_accuracy: 0.3070

Epoch 00022: val_loss improved from 1.65019 to 1.64741, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 23/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6538 - accuracy: 0.3019 - val_loss: 1.6458 - val_accuracy: 0.3074

Epoch 00023: val_loss improved from 1.64741 to 1.64580, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 24/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6531 - accuracy: 0.3012 - val_loss: 1.6450 - val_accuracy: 0.3090

Epoch 00024: val_loss improved from 1.64580 to 1.64498, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 25/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6503 - accuracy: 0.3008 - val_loss: 1.6427 - val_accuracy: 0.3080

Epoch 00025: val_loss improved from 1.64498 to 1.64269, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 26/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6500 - accuracy: 0.3025 - val_loss: 1.6419 - val_accuracy: 0.3090

Epoch 00026: val_loss improved from 1.64269 to 1.64192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 27/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6489 - accuracy: 0.3033 - val_loss: 1.6409 - val_accuracy: 0.3088

Epoch 00027: val_loss improved from 1.64192 to 1.64090, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 28/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6474 - accuracy: 0.3034 - val_loss: 1.6416 - val_accuracy: 0.3104

Epoch 00028: val_loss did not improve from 1.64090
Epoch 29/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6474 - accuracy: 0.3019 - val_loss: 1.6402 - val_accuracy: 0.3106

Epoch 00029: val_loss improved from 1.64090 to 1.64022, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 30/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6458 - accuracy: 0.3050 - val_loss: 1.6392 - val_accuracy: 0.3087

Epoch 00030: val_loss improved from 1.64022 to 1.63916, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 31/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6454 - accuracy: 0.3044 - val_loss: 1.6408 - val_accuracy: 0.3099

Epoch 00031: val_loss did not improve from 1.63916
Epoch 32/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6450 - accuracy: 0.3039 - val_loss: 1.6397 - val_accuracy: 0.3091

Epoch 00032: val_loss did not improve from 1.63916
Epoch 33/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6448 - accuracy: 0.3039 - val_loss: 1.6389 - val_accuracy: 0.3105

Epoch 00033: val_loss improved from 1.63916 to 1.63891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 34/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6433 - accuracy: 0.3046 - val_loss: 1.6398 - val_accuracy: 0.3068

Epoch 00034: val_loss did not improve from 1.63891
Epoch 35/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6426 - accuracy: 0.3052 - val_loss: 1.6397 - val_accuracy: 0.3106

Epoch 00035: val_loss did not improve from 1.63891
Epoch 36/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6429 - accuracy: 0.3062 - val_loss: 1.6385 - val_accuracy: 0.3092

Epoch 00036: val_loss improved from 1.63891 to 1.63852, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 37/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6422 - accuracy: 0.3057 - val_loss: 1.6387 - val_accuracy: 0.3080

Epoch 00037: val_loss did not improve from 1.63852
Epoch 38/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6420 - accuracy: 0.3050 - val_loss: 1.6382 - val_accuracy: 0.3084

Epoch 00038: val_loss improved from 1.63852 to 1.63822, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 39/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6408 - accuracy: 0.3059 - val_loss: 1.6393 - val_accuracy: 0.3093

Epoch 00039: val_loss did not improve from 1.63822
Epoch 40/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6417 - accuracy: 0.3085 - val_loss: 1.6389 - val_accuracy: 0.3092

Epoch 00040: val_loss did not improve from 1.63822
Epoch 41/100
83/83 [==============================] - 10s 120ms/step - loss: 1.6391 - accuracy: 0.3075 - val_loss: 1.6397 - val_accuracy: 0.3087

Epoch 00041: val_loss did not improve from 1.63822
Epoch 42/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6398 - accuracy: 0.3082 - val_loss: 1.6392 - val_accuracy: 0.3085

Epoch 00042: val_loss did not improve from 1.63822
Epoch 43/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6391 - accuracy: 0.3076 - val_loss: 1.6395 - val_accuracy: 0.3103

Epoch 00043: val_loss did not improve from 1.63822
Epoch 44/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6388 - accuracy: 0.3107 - val_loss: 1.6413 - val_accuracy: 0.3107

Epoch 00044: val_loss did not improve from 1.63822
Epoch 45/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6380 - accuracy: 0.3084 - val_loss: 1.6408 - val_accuracy: 0.3078

Epoch 00045: val_loss did not improve from 1.63822
Epoch 46/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6387 - accuracy: 0.3094 - val_loss: 1.6405 - val_accuracy: 0.3104

Epoch 00046: val_loss did not improve from 1.63822
Epoch 47/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6382 - accuracy: 0.3117 - val_loss: 1.6408 - val_accuracy: 0.3074

Epoch 00047: val_loss did not improve from 1.63822
Epoch 48/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6382 - accuracy: 0.3089 - val_loss: 1.6417 - val_accuracy: 0.3089

Epoch 00048: val_loss did not improve from 1.63822
Epoch 00048: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 80s 6ms/step - loss: 1.6418 - accuracy: 0.3043
Testing Loss = 1.641765, Testing Accuracy = 0.304332
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 12s 135ms/step - loss: 11.9286 - accuracy: 0.2484 - val_loss: 8.2492 - val_accuracy: 0.2777

Epoch 00001: val_loss improved from inf to 8.24916, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 2/100
83/83 [==============================] - 11s 134ms/step - loss: 6.5102 - accuracy: 0.2730 - val_loss: 5.2022 - val_accuracy: 0.2937

Epoch 00002: val_loss improved from 8.24916 to 5.20223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 3/100
83/83 [==============================] - 11s 131ms/step - loss: 4.5169 - accuracy: 0.2799 - val_loss: 3.9320 - val_accuracy: 0.2893

Epoch 00003: val_loss improved from 5.20223 to 3.93201, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 4/100
83/83 [==============================] - 11s 137ms/step - loss: 3.5717 - accuracy: 0.2842 - val_loss: 3.2236 - val_accuracy: 0.2999

Epoch 00004: val_loss improved from 3.93201 to 3.22357, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 5/100
83/83 [==============================] - 9s 108ms/step - loss: 2.9979 - accuracy: 0.2867 - val_loss: 2.7586 - val_accuracy: 0.3038

Epoch 00005: val_loss improved from 3.22357 to 2.75861, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 6/100
83/83 [==============================] - 9s 112ms/step - loss: 2.6081 - accuracy: 0.2901 - val_loss: 2.4364 - val_accuracy: 0.3024

Epoch 00006: val_loss improved from 2.75861 to 2.43638, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 7/100
83/83 [==============================] - 9s 113ms/step - loss: 2.3316 - accuracy: 0.2880 - val_loss: 2.2036 - val_accuracy: 0.3053

Epoch 00007: val_loss improved from 2.43638 to 2.20357, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 8/100
83/83 [==============================] - 9s 108ms/step - loss: 2.1341 - accuracy: 0.2915 - val_loss: 2.0388 - val_accuracy: 0.3067

Epoch 00008: val_loss improved from 2.20357 to 2.03884, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 9/100
83/83 [==============================] - 9s 112ms/step - loss: 1.9942 - accuracy: 0.2932 - val_loss: 1.9246 - val_accuracy: 0.3035

Epoch 00009: val_loss improved from 2.03884 to 1.92465, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 10/100
83/83 [==============================] - 12s 139ms/step - loss: 1.8961 - accuracy: 0.2920 - val_loss: 1.8410 - val_accuracy: 0.3055

Epoch 00010: val_loss improved from 1.92465 to 1.84103, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 11/100
83/83 [==============================] - 12s 139ms/step - loss: 1.8255 - accuracy: 0.2939 - val_loss: 1.7839 - val_accuracy: 0.3036

Epoch 00011: val_loss improved from 1.84103 to 1.78395, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 12/100
83/83 [==============================] - 11s 138ms/step - loss: 1.7760 - accuracy: 0.2942 - val_loss: 1.7438 - val_accuracy: 0.3055

Epoch 00012: val_loss improved from 1.78395 to 1.74384, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 13/100
83/83 [==============================] - 11s 138ms/step - loss: 1.7412 - accuracy: 0.2973 - val_loss: 1.7153 - val_accuracy: 0.3037

Epoch 00013: val_loss improved from 1.74384 to 1.71535, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 14/100
83/83 [==============================] - 12s 138ms/step - loss: 1.7170 - accuracy: 0.2958 - val_loss: 1.6968 - val_accuracy: 0.3020

Epoch 00014: val_loss improved from 1.71535 to 1.69680, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 15/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6988 - accuracy: 0.2982 - val_loss: 1.6813 - val_accuracy: 0.3023

Epoch 00015: val_loss improved from 1.69680 to 1.68130, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 16/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6856 - accuracy: 0.2960 - val_loss: 1.6721 - val_accuracy: 0.3017

Epoch 00016: val_loss improved from 1.68130 to 1.67212, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 17/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6769 - accuracy: 0.2994 - val_loss: 1.6643 - val_accuracy: 0.3059

Epoch 00017: val_loss improved from 1.67212 to 1.66425, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 18/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6710 - accuracy: 0.2998 - val_loss: 1.6601 - val_accuracy: 0.3013

Epoch 00018: val_loss improved from 1.66425 to 1.66008, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 19/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6664 - accuracy: 0.3012 - val_loss: 1.6549 - val_accuracy: 0.3043

Epoch 00019: val_loss improved from 1.66008 to 1.65489, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 20/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6615 - accuracy: 0.3017 - val_loss: 1.6513 - val_accuracy: 0.3060

Epoch 00020: val_loss improved from 1.65489 to 1.65132, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 21/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6604 - accuracy: 0.2997 - val_loss: 1.6500 - val_accuracy: 0.3042

Epoch 00021: val_loss improved from 1.65132 to 1.64998, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 22/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6567 - accuracy: 0.3005 - val_loss: 1.6471 - val_accuracy: 0.3058

Epoch 00022: val_loss improved from 1.64998 to 1.64709, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 23/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6551 - accuracy: 0.3012 - val_loss: 1.6464 - val_accuracy: 0.3071

Epoch 00023: val_loss improved from 1.64709 to 1.64645, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 24/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6531 - accuracy: 0.3018 - val_loss: 1.6450 - val_accuracy: 0.3060

Epoch 00024: val_loss improved from 1.64645 to 1.64497, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 25/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6513 - accuracy: 0.3013 - val_loss: 1.6448 - val_accuracy: 0.3057

Epoch 00025: val_loss improved from 1.64497 to 1.64478, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 26/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6506 - accuracy: 0.3002 - val_loss: 1.6424 - val_accuracy: 0.3087

Epoch 00026: val_loss improved from 1.64478 to 1.64241, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 27/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6499 - accuracy: 0.3041 - val_loss: 1.6411 - val_accuracy: 0.3094

Epoch 00027: val_loss improved from 1.64241 to 1.64110, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 28/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6481 - accuracy: 0.3016 - val_loss: 1.6417 - val_accuracy: 0.3060

Epoch 00028: val_loss did not improve from 1.64110
Epoch 29/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6484 - accuracy: 0.3033 - val_loss: 1.6399 - val_accuracy: 0.3094

Epoch 00029: val_loss improved from 1.64110 to 1.63990, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 30/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6461 - accuracy: 0.3056 - val_loss: 1.6402 - val_accuracy: 0.3069

Epoch 00030: val_loss did not improve from 1.63990
Epoch 31/100
83/83 [==============================] - 7s 83ms/step - loss: 1.6458 - accuracy: 0.3043 - val_loss: 1.6403 - val_accuracy: 0.3107

Epoch 00031: val_loss did not improve from 1.63990
Epoch 32/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6457 - accuracy: 0.3049 - val_loss: 1.6395 - val_accuracy: 0.3087

Epoch 00032: val_loss improved from 1.63990 to 1.63953, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 33/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6452 - accuracy: 0.3060 - val_loss: 1.6397 - val_accuracy: 0.3111

Epoch 00033: val_loss did not improve from 1.63953
Epoch 34/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6443 - accuracy: 0.3044 - val_loss: 1.6403 - val_accuracy: 0.3080

Epoch 00034: val_loss did not improve from 1.63953
Epoch 35/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6436 - accuracy: 0.3057 - val_loss: 1.6397 - val_accuracy: 0.3102

Epoch 00035: val_loss did not improve from 1.63953
Epoch 36/100
83/83 [==============================] - 10s 121ms/step - loss: 1.6433 - accuracy: 0.3053 - val_loss: 1.6392 - val_accuracy: 0.3115

Epoch 00036: val_loss improved from 1.63953 to 1.63920, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 37/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6434 - accuracy: 0.3051 - val_loss: 1.6396 - val_accuracy: 0.3110

Epoch 00037: val_loss did not improve from 1.63920
Epoch 38/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6427 - accuracy: 0.3063 - val_loss: 1.6391 - val_accuracy: 0.3105

Epoch 00038: val_loss improved from 1.63920 to 1.63908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 39/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6413 - accuracy: 0.3057 - val_loss: 1.6386 - val_accuracy: 0.3100

Epoch 00039: val_loss improved from 1.63908 to 1.63858, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 40/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6418 - accuracy: 0.3052 - val_loss: 1.6394 - val_accuracy: 0.3106

Epoch 00040: val_loss did not improve from 1.63858
Epoch 41/100
83/83 [==============================] - 10s 121ms/step - loss: 1.6420 - accuracy: 0.3059 - val_loss: 1.6401 - val_accuracy: 0.3097

Epoch 00041: val_loss did not improve from 1.63858
Epoch 42/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6411 - accuracy: 0.3065 - val_loss: 1.6402 - val_accuracy: 0.3087

Epoch 00042: val_loss did not improve from 1.63858
Epoch 43/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6375 - accuracy: 0.3081 - val_loss: 1.6402 - val_accuracy: 0.3072

Epoch 00043: val_loss did not improve from 1.63858
Epoch 44/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6393 - accuracy: 0.3089 - val_loss: 1.6392 - val_accuracy: 0.3141

Epoch 00044: val_loss did not improve from 1.63858
Epoch 45/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6384 - accuracy: 0.3094 - val_loss: 1.6400 - val_accuracy: 0.3121

Epoch 00045: val_loss did not improve from 1.63858
Epoch 46/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6391 - accuracy: 0.3082 - val_loss: 1.6406 - val_accuracy: 0.3092

Epoch 00046: val_loss did not improve from 1.63858
Epoch 47/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6379 - accuracy: 0.3094 - val_loss: 1.6409 - val_accuracy: 0.3101

Epoch 00047: val_loss did not improve from 1.63858
Epoch 48/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6381 - accuracy: 0.3097 - val_loss: 1.6416 - val_accuracy: 0.3112

Epoch 00048: val_loss did not improve from 1.63858
Epoch 49/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6384 - accuracy: 0.3089 - val_loss: 1.6413 - val_accuracy: 0.3137

Epoch 00049: val_loss did not improve from 1.63858
Epoch 00049: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 81s 6ms/step - loss: 1.6410 - accuracy: 0.3017
Testing Loss = 1.641011, Testing Accuracy = 0.301727
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 12s 131ms/step - loss: 11.9043 - accuracy: 0.2452 - val_loss: 8.2198 - val_accuracy: 0.2756

Epoch 00001: val_loss improved from inf to 8.21984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 2/100
83/83 [==============================] - 10s 125ms/step - loss: 6.4932 - accuracy: 0.2682 - val_loss: 5.1915 - val_accuracy: 0.2892

Epoch 00002: val_loss improved from 8.21984 to 5.19147, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 3/100
83/83 [==============================] - 11s 137ms/step - loss: 4.5117 - accuracy: 0.2776 - val_loss: 3.9301 - val_accuracy: 0.2902

Epoch 00003: val_loss improved from 5.19147 to 3.93009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 4/100
83/83 [==============================] - 11s 138ms/step - loss: 3.5737 - accuracy: 0.2840 - val_loss: 3.2274 - val_accuracy: 0.2934

Epoch 00004: val_loss improved from 3.93009 to 3.22742, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 5/100
83/83 [==============================] - 10s 119ms/step - loss: 3.0033 - accuracy: 0.2857 - val_loss: 2.7632 - val_accuracy: 0.2998

Epoch 00005: val_loss improved from 3.22742 to 2.76318, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 6/100
83/83 [==============================] - 12s 138ms/step - loss: 2.6110 - accuracy: 0.2867 - val_loss: 2.4385 - val_accuracy: 0.3020

Epoch 00006: val_loss improved from 2.76318 to 2.43849, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 7/100
83/83 [==============================] - 9s 112ms/step - loss: 2.3357 - accuracy: 0.2863 - val_loss: 2.2065 - val_accuracy: 0.3027

Epoch 00007: val_loss improved from 2.43849 to 2.20646, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 8/100
83/83 [==============================] - 11s 138ms/step - loss: 2.1375 - accuracy: 0.2885 - val_loss: 2.0424 - val_accuracy: 0.3033

Epoch 00008: val_loss improved from 2.20646 to 2.04237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 9/100
83/83 [==============================] - 12s 138ms/step - loss: 1.9954 - accuracy: 0.2931 - val_loss: 1.9263 - val_accuracy: 0.3028

Epoch 00009: val_loss improved from 2.04237 to 1.92627, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 10/100
83/83 [==============================] - 11s 137ms/step - loss: 1.8985 - accuracy: 0.2934 - val_loss: 1.8438 - val_accuracy: 0.3021

Epoch 00010: val_loss improved from 1.92627 to 1.84381, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 11/100
83/83 [==============================] - 12s 139ms/step - loss: 1.8259 - accuracy: 0.2969 - val_loss: 1.7853 - val_accuracy: 0.3035

Epoch 00011: val_loss improved from 1.84381 to 1.78534, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 12/100
83/83 [==============================] - 11s 137ms/step - loss: 1.7766 - accuracy: 0.2957 - val_loss: 1.7433 - val_accuracy: 0.3049

Epoch 00012: val_loss improved from 1.78534 to 1.74331, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 13/100
83/83 [==============================] - 7s 86ms/step - loss: 1.7431 - accuracy: 0.2974 - val_loss: 1.7161 - val_accuracy: 0.3024

Epoch 00013: val_loss improved from 1.74331 to 1.71606, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 14/100
83/83 [==============================] - 7s 86ms/step - loss: 1.7176 - accuracy: 0.2969 - val_loss: 1.6951 - val_accuracy: 0.3053

Epoch 00014: val_loss improved from 1.71606 to 1.69510, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 15/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6997 - accuracy: 0.2972 - val_loss: 1.6813 - val_accuracy: 0.3039

Epoch 00015: val_loss improved from 1.69510 to 1.68133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 16/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6872 - accuracy: 0.3003 - val_loss: 1.6695 - val_accuracy: 0.3071

Epoch 00016: val_loss improved from 1.68133 to 1.66954, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 17/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6781 - accuracy: 0.2993 - val_loss: 1.6623 - val_accuracy: 0.3071

Epoch 00017: val_loss improved from 1.66954 to 1.66228, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 18/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6709 - accuracy: 0.2985 - val_loss: 1.6581 - val_accuracy: 0.3050

Epoch 00018: val_loss improved from 1.66228 to 1.65810, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 19/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6667 - accuracy: 0.2989 - val_loss: 1.6543 - val_accuracy: 0.3070

Epoch 00019: val_loss improved from 1.65810 to 1.65431, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 20/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6618 - accuracy: 0.2993 - val_loss: 1.6508 - val_accuracy: 0.3060

Epoch 00020: val_loss improved from 1.65431 to 1.65080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 21/100
83/83 [==============================] - 7s 83ms/step - loss: 1.6586 - accuracy: 0.3034 - val_loss: 1.6479 - val_accuracy: 0.3071

Epoch 00021: val_loss improved from 1.65080 to 1.64789, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 22/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6566 - accuracy: 0.3003 - val_loss: 1.6466 - val_accuracy: 0.3083

Epoch 00022: val_loss improved from 1.64789 to 1.64665, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 23/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6544 - accuracy: 0.2994 - val_loss: 1.6446 - val_accuracy: 0.3103

Epoch 00023: val_loss improved from 1.64665 to 1.64458, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 24/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6531 - accuracy: 0.3022 - val_loss: 1.6442 - val_accuracy: 0.3073

Epoch 00024: val_loss improved from 1.64458 to 1.64419, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 25/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6513 - accuracy: 0.2984 - val_loss: 1.6422 - val_accuracy: 0.3092

Epoch 00025: val_loss improved from 1.64419 to 1.64224, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 26/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6493 - accuracy: 0.3030 - val_loss: 1.6422 - val_accuracy: 0.3063

Epoch 00026: val_loss improved from 1.64224 to 1.64221, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 27/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6499 - accuracy: 0.3004 - val_loss: 1.6396 - val_accuracy: 0.3108

Epoch 00027: val_loss improved from 1.64221 to 1.63961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 28/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6479 - accuracy: 0.3012 - val_loss: 1.6398 - val_accuracy: 0.3092

Epoch 00028: val_loss did not improve from 1.63961
Epoch 29/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6469 - accuracy: 0.3023 - val_loss: 1.6405 - val_accuracy: 0.3094

Epoch 00029: val_loss did not improve from 1.63961
Epoch 30/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6458 - accuracy: 0.3037 - val_loss: 1.6399 - val_accuracy: 0.3086

Epoch 00030: val_loss did not improve from 1.63961
Epoch 31/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6454 - accuracy: 0.3052 - val_loss: 1.6388 - val_accuracy: 0.3096

Epoch 00031: val_loss improved from 1.63961 to 1.63878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 32/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6446 - accuracy: 0.3032 - val_loss: 1.6385 - val_accuracy: 0.3098

Epoch 00032: val_loss improved from 1.63878 to 1.63846, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 33/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6450 - accuracy: 0.3040 - val_loss: 1.6376 - val_accuracy: 0.3103

Epoch 00033: val_loss improved from 1.63846 to 1.63764, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 34/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6455 - accuracy: 0.3029 - val_loss: 1.6381 - val_accuracy: 0.3091

Epoch 00034: val_loss did not improve from 1.63764
Epoch 35/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6432 - accuracy: 0.3025 - val_loss: 1.6375 - val_accuracy: 0.3098

Epoch 00035: val_loss improved from 1.63764 to 1.63750, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 36/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6428 - accuracy: 0.3067 - val_loss: 1.6378 - val_accuracy: 0.3107

Epoch 00036: val_loss did not improve from 1.63750
Epoch 37/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6420 - accuracy: 0.3051 - val_loss: 1.6374 - val_accuracy: 0.3130

Epoch 00037: val_loss improved from 1.63750 to 1.63742, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 38/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6421 - accuracy: 0.3041 - val_loss: 1.6382 - val_accuracy: 0.3119

Epoch 00038: val_loss did not improve from 1.63742
Epoch 39/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6411 - accuracy: 0.3069 - val_loss: 1.6381 - val_accuracy: 0.3130

Epoch 00039: val_loss did not improve from 1.63742
Epoch 40/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6419 - accuracy: 0.3062 - val_loss: 1.6371 - val_accuracy: 0.3107

Epoch 00040: val_loss improved from 1.63742 to 1.63715, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 41/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6410 - accuracy: 0.3030 - val_loss: 1.6377 - val_accuracy: 0.3102

Epoch 00041: val_loss did not improve from 1.63715
Epoch 42/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6404 - accuracy: 0.3074 - val_loss: 1.6385 - val_accuracy: 0.3106

Epoch 00042: val_loss did not improve from 1.63715
Epoch 43/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6389 - accuracy: 0.3087 - val_loss: 1.6382 - val_accuracy: 0.3107

Epoch 00043: val_loss did not improve from 1.63715
Epoch 44/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6394 - accuracy: 0.3081 - val_loss: 1.6387 - val_accuracy: 0.3113

Epoch 00044: val_loss did not improve from 1.63715
Epoch 45/100
83/83 [==============================] - 11s 133ms/step - loss: 1.6398 - accuracy: 0.3082 - val_loss: 1.6381 - val_accuracy: 0.3103

Epoch 00045: val_loss did not improve from 1.63715
Epoch 46/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6388 - accuracy: 0.3091 - val_loss: 1.6394 - val_accuracy: 0.3092

Epoch 00046: val_loss did not improve from 1.63715
Epoch 47/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6376 - accuracy: 0.3101 - val_loss: 1.6399 - val_accuracy: 0.3106

Epoch 00047: val_loss did not improve from 1.63715
Epoch 48/100
83/83 [==============================] - 9s 110ms/step - loss: 1.6378 - accuracy: 0.3092 - val_loss: 1.6390 - val_accuracy: 0.3115

Epoch 00048: val_loss did not improve from 1.63715
Epoch 49/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6370 - accuracy: 0.3073 - val_loss: 1.6399 - val_accuracy: 0.3129

Epoch 00049: val_loss did not improve from 1.63715
Epoch 50/100
83/83 [==============================] - 10s 126ms/step - loss: 1.6380 - accuracy: 0.3083 - val_loss: 1.6412 - val_accuracy: 0.3084

Epoch 00050: val_loss did not improve from 1.63715
Epoch 00050: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 83s 6ms/step - loss: 1.6402 - accuracy: 0.3037
Testing Loss = 1.640246, Testing Accuracy = 0.303736
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 10s 110ms/step - loss: 11.8932 - accuracy: 0.2459 - val_loss: 8.1891 - val_accuracy: 0.2868

Epoch 00001: val_loss improved from inf to 8.18911, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 2/100
83/83 [==============================] - 12s 139ms/step - loss: 6.4619 - accuracy: 0.2679 - val_loss: 5.1660 - val_accuracy: 0.2892

Epoch 00002: val_loss improved from 8.18911 to 5.16604, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 3/100
83/83 [==============================] - 12s 139ms/step - loss: 4.4926 - accuracy: 0.2762 - val_loss: 3.9145 - val_accuracy: 0.2942

Epoch 00003: val_loss improved from 5.16604 to 3.91449, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 4/100
83/83 [==============================] - 12s 139ms/step - loss: 3.5633 - accuracy: 0.2828 - val_loss: 3.2171 - val_accuracy: 0.2963

Epoch 00004: val_loss improved from 3.91449 to 3.21707, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 5/100
83/83 [==============================] - 12s 139ms/step - loss: 2.9937 - accuracy: 0.2878 - val_loss: 2.7569 - val_accuracy: 0.2991

Epoch 00005: val_loss improved from 3.21707 to 2.75691, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 6/100
83/83 [==============================] - 12s 139ms/step - loss: 2.6056 - accuracy: 0.2899 - val_loss: 2.4324 - val_accuracy: 0.3011

Epoch 00006: val_loss improved from 2.75691 to 2.43239, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 7/100
83/83 [==============================] - 7s 86ms/step - loss: 2.3305 - accuracy: 0.2909 - val_loss: 2.2041 - val_accuracy: 0.3018

Epoch 00007: val_loss improved from 2.43239 to 2.20405, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 8/100
83/83 [==============================] - 7s 87ms/step - loss: 2.1336 - accuracy: 0.2921 - val_loss: 2.0391 - val_accuracy: 0.3033

Epoch 00008: val_loss improved from 2.20405 to 2.03911, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 9/100
83/83 [==============================] - 7s 86ms/step - loss: 1.9939 - accuracy: 0.2935 - val_loss: 1.9233 - val_accuracy: 0.3046

Epoch 00009: val_loss improved from 2.03911 to 1.92327, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 10/100
83/83 [==============================] - 7s 87ms/step - loss: 1.8958 - accuracy: 0.2951 - val_loss: 1.8422 - val_accuracy: 0.3026

Epoch 00010: val_loss improved from 1.92327 to 1.84219, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 11/100
83/83 [==============================] - 7s 86ms/step - loss: 1.8255 - accuracy: 0.2941 - val_loss: 1.7849 - val_accuracy: 0.3029

Epoch 00011: val_loss improved from 1.84219 to 1.78490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 12/100
83/83 [==============================] - 7s 86ms/step - loss: 1.7763 - accuracy: 0.2981 - val_loss: 1.7428 - val_accuracy: 0.3058

Epoch 00012: val_loss improved from 1.78490 to 1.74284, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 13/100
83/83 [==============================] - 7s 87ms/step - loss: 1.7406 - accuracy: 0.2952 - val_loss: 1.7143 - val_accuracy: 0.3054

Epoch 00013: val_loss improved from 1.74284 to 1.71431, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 14/100
83/83 [==============================] - 7s 87ms/step - loss: 1.7164 - accuracy: 0.2996 - val_loss: 1.6943 - val_accuracy: 0.3061

Epoch 00014: val_loss improved from 1.71431 to 1.69434, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 15/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6990 - accuracy: 0.2985 - val_loss: 1.6812 - val_accuracy: 0.3078

Epoch 00015: val_loss improved from 1.69434 to 1.68117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 16/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6870 - accuracy: 0.2975 - val_loss: 1.6717 - val_accuracy: 0.3059

Epoch 00016: val_loss improved from 1.68117 to 1.67174, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 17/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6784 - accuracy: 0.3000 - val_loss: 1.6650 - val_accuracy: 0.3052

Epoch 00017: val_loss improved from 1.67174 to 1.66501, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 18/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6709 - accuracy: 0.3007 - val_loss: 1.6581 - val_accuracy: 0.3066

Epoch 00018: val_loss improved from 1.66501 to 1.65812, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 19/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6648 - accuracy: 0.2998 - val_loss: 1.6545 - val_accuracy: 0.3073

Epoch 00019: val_loss improved from 1.65812 to 1.65446, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 20/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6616 - accuracy: 0.3018 - val_loss: 1.6516 - val_accuracy: 0.3063

Epoch 00020: val_loss improved from 1.65446 to 1.65159, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 21/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6598 - accuracy: 0.2985 - val_loss: 1.6495 - val_accuracy: 0.3049

Epoch 00021: val_loss improved from 1.65159 to 1.64946, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 22/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6569 - accuracy: 0.3011 - val_loss: 1.6468 - val_accuracy: 0.3077

Epoch 00022: val_loss improved from 1.64946 to 1.64684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 23/100
83/83 [==============================] - 11s 134ms/step - loss: 1.6546 - accuracy: 0.3018 - val_loss: 1.6461 - val_accuracy: 0.3063

Epoch 00023: val_loss improved from 1.64684 to 1.64611, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 24/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6533 - accuracy: 0.3034 - val_loss: 1.6452 - val_accuracy: 0.3104

Epoch 00024: val_loss improved from 1.64611 to 1.64525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 25/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6508 - accuracy: 0.3049 - val_loss: 1.6438 - val_accuracy: 0.3076

Epoch 00025: val_loss improved from 1.64525 to 1.64380, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 26/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6498 - accuracy: 0.3033 - val_loss: 1.6432 - val_accuracy: 0.3060

Epoch 00026: val_loss improved from 1.64380 to 1.64319, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 27/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6486 - accuracy: 0.3031 - val_loss: 1.6427 - val_accuracy: 0.3054

Epoch 00027: val_loss improved from 1.64319 to 1.64269, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 28/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6492 - accuracy: 0.3033 - val_loss: 1.6421 - val_accuracy: 0.3066

Epoch 00028: val_loss improved from 1.64269 to 1.64210, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 29/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6471 - accuracy: 0.3029 - val_loss: 1.6404 - val_accuracy: 0.3095

Epoch 00029: val_loss improved from 1.64210 to 1.64041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 30/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6464 - accuracy: 0.3049 - val_loss: 1.6422 - val_accuracy: 0.3088

Epoch 00030: val_loss did not improve from 1.64041
Epoch 31/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6458 - accuracy: 0.3067 - val_loss: 1.6412 - val_accuracy: 0.3079

Epoch 00031: val_loss did not improve from 1.64041
Epoch 32/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6444 - accuracy: 0.3051 - val_loss: 1.6416 - val_accuracy: 0.3088

Epoch 00032: val_loss did not improve from 1.64041
Epoch 33/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6438 - accuracy: 0.3056 - val_loss: 1.6410 - val_accuracy: 0.3102

Epoch 00033: val_loss did not improve from 1.64041
Epoch 34/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6445 - accuracy: 0.3032 - val_loss: 1.6411 - val_accuracy: 0.3092

Epoch 00034: val_loss did not improve from 1.64041
Epoch 35/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6432 - accuracy: 0.3071 - val_loss: 1.6404 - val_accuracy: 0.3090

Epoch 00035: val_loss did not improve from 1.64041
Epoch 36/100
83/83 [==============================] - 10s 120ms/step - loss: 1.6417 - accuracy: 0.3071 - val_loss: 1.6416 - val_accuracy: 0.3094

Epoch 00036: val_loss did not improve from 1.64041
Epoch 37/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6439 - accuracy: 0.3053 - val_loss: 1.6400 - val_accuracy: 0.3088

Epoch 00037: val_loss improved from 1.64041 to 1.64003, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 38/100
83/83 [==============================] - 11s 134ms/step - loss: 1.6408 - accuracy: 0.3098 - val_loss: 1.6405 - val_accuracy: 0.3099

Epoch 00038: val_loss did not improve from 1.64003
Epoch 39/100
83/83 [==============================] - 10s 118ms/step - loss: 1.6414 - accuracy: 0.3074 - val_loss: 1.6411 - val_accuracy: 0.3071

Epoch 00039: val_loss did not improve from 1.64003
Epoch 40/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6403 - accuracy: 0.3079 - val_loss: 1.6417 - val_accuracy: 0.3070

Epoch 00040: val_loss did not improve from 1.64003
Epoch 41/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6398 - accuracy: 0.3075 - val_loss: 1.6419 - val_accuracy: 0.3050

Epoch 00041: val_loss did not improve from 1.64003
Epoch 42/100
83/83 [==============================] - 11s 133ms/step - loss: 1.6395 - accuracy: 0.3086 - val_loss: 1.6423 - val_accuracy: 0.3077

Epoch 00042: val_loss did not improve from 1.64003
Epoch 43/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6388 - accuracy: 0.3085 - val_loss: 1.6428 - val_accuracy: 0.3060

Epoch 00043: val_loss did not improve from 1.64003
Epoch 44/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6387 - accuracy: 0.3094 - val_loss: 1.6428 - val_accuracy: 0.3089

Epoch 00044: val_loss did not improve from 1.64003
Epoch 45/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6390 - accuracy: 0.3074 - val_loss: 1.6431 - val_accuracy: 0.3104

Epoch 00045: val_loss did not improve from 1.64003
Epoch 46/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6380 - accuracy: 0.3135 - val_loss: 1.6447 - val_accuracy: 0.3068

Epoch 00046: val_loss did not improve from 1.64003
Epoch 47/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6375 - accuracy: 0.3110 - val_loss: 1.6455 - val_accuracy: 0.3066

Epoch 00047: val_loss did not improve from 1.64003
Epoch 00047: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 82s 6ms/step - loss: 1.6429 - accuracy: 0.3032
Testing Loss = 1.642895, Testing Accuracy = 0.303215
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 8s 89ms/step - loss: 11.9466 - accuracy: 0.2490 - val_loss: 8.2649 - val_accuracy: 0.2816

Epoch 00001: val_loss improved from inf to 8.26486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 2/100
83/83 [==============================] - 7s 87ms/step - loss: 6.5164 - accuracy: 0.2720 - val_loss: 5.2015 - val_accuracy: 0.2839

Epoch 00002: val_loss improved from 8.26486 to 5.20153, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 3/100
83/83 [==============================] - 7s 86ms/step - loss: 4.5140 - accuracy: 0.2783 - val_loss: 3.9300 - val_accuracy: 0.2883

Epoch 00003: val_loss improved from 5.20153 to 3.93003, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 4/100
83/83 [==============================] - 7s 88ms/step - loss: 3.5687 - accuracy: 0.2820 - val_loss: 3.2218 - val_accuracy: 0.2951

Epoch 00004: val_loss improved from 3.93003 to 3.22177, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 5/100
83/83 [==============================] - 7s 88ms/step - loss: 2.9968 - accuracy: 0.2892 - val_loss: 2.7580 - val_accuracy: 0.2980

Epoch 00005: val_loss improved from 3.22177 to 2.75801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 6/100
83/83 [==============================] - 7s 87ms/step - loss: 2.6057 - accuracy: 0.2865 - val_loss: 2.4318 - val_accuracy: 0.2995

Epoch 00006: val_loss improved from 2.75801 to 2.43180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 7/100
83/83 [==============================] - 7s 86ms/step - loss: 2.3284 - accuracy: 0.2888 - val_loss: 2.2022 - val_accuracy: 0.2987

Epoch 00007: val_loss improved from 2.43180 to 2.20219, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 8/100
83/83 [==============================] - 7s 81ms/step - loss: 2.1303 - accuracy: 0.2902 - val_loss: 2.0356 - val_accuracy: 0.3045

Epoch 00008: val_loss improved from 2.20219 to 2.03563, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 9/100
83/83 [==============================] - 7s 83ms/step - loss: 1.9898 - accuracy: 0.2920 - val_loss: 1.9204 - val_accuracy: 0.3045

Epoch 00009: val_loss improved from 2.03563 to 1.92037, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 10/100
83/83 [==============================] - 7s 85ms/step - loss: 1.8920 - accuracy: 0.2931 - val_loss: 1.8391 - val_accuracy: 0.3016

Epoch 00010: val_loss improved from 1.92037 to 1.83912, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 11/100
83/83 [==============================] - 7s 85ms/step - loss: 1.8235 - accuracy: 0.2932 - val_loss: 1.7821 - val_accuracy: 0.3021

Epoch 00011: val_loss improved from 1.83912 to 1.78214, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 12/100
83/83 [==============================] - 7s 85ms/step - loss: 1.7734 - accuracy: 0.2970 - val_loss: 1.7420 - val_accuracy: 0.3027

Epoch 00012: val_loss improved from 1.78214 to 1.74204, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 13/100
83/83 [==============================] - 7s 85ms/step - loss: 1.7383 - accuracy: 0.2966 - val_loss: 1.7125 - val_accuracy: 0.3039

Epoch 00013: val_loss improved from 1.74204 to 1.71250, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 14/100
83/83 [==============================] - 8s 95ms/step - loss: 1.7152 - accuracy: 0.3000 - val_loss: 1.6926 - val_accuracy: 0.3071

Epoch 00014: val_loss improved from 1.71250 to 1.69258, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 15/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6969 - accuracy: 0.2981 - val_loss: 1.6795 - val_accuracy: 0.3064

Epoch 00015: val_loss improved from 1.69258 to 1.67954, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 16/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6848 - accuracy: 0.2982 - val_loss: 1.6702 - val_accuracy: 0.3047

Epoch 00016: val_loss improved from 1.67954 to 1.67019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 17/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6776 - accuracy: 0.2962 - val_loss: 1.6632 - val_accuracy: 0.3041

Epoch 00017: val_loss improved from 1.67019 to 1.66321, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 18/100
83/83 [==============================] - 10s 116ms/step - loss: 1.6698 - accuracy: 0.3010 - val_loss: 1.6570 - val_accuracy: 0.3063

Epoch 00018: val_loss improved from 1.66321 to 1.65697, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 19/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6663 - accuracy: 0.2966 - val_loss: 1.6532 - val_accuracy: 0.3041

Epoch 00019: val_loss improved from 1.65697 to 1.65318, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 20/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6616 - accuracy: 0.3021 - val_loss: 1.6507 - val_accuracy: 0.3075

Epoch 00020: val_loss improved from 1.65318 to 1.65067, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 21/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6585 - accuracy: 0.3023 - val_loss: 1.6486 - val_accuracy: 0.3061

Epoch 00021: val_loss improved from 1.65067 to 1.64862, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 22/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6554 - accuracy: 0.3003 - val_loss: 1.6457 - val_accuracy: 0.3092

Epoch 00022: val_loss improved from 1.64862 to 1.64568, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 23/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6540 - accuracy: 0.3022 - val_loss: 1.6450 - val_accuracy: 0.3076

Epoch 00023: val_loss improved from 1.64568 to 1.64497, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 24/100
83/83 [==============================] - 10s 118ms/step - loss: 1.6524 - accuracy: 0.3001 - val_loss: 1.6433 - val_accuracy: 0.3077

Epoch 00024: val_loss improved from 1.64497 to 1.64327, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 25/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6510 - accuracy: 0.3028 - val_loss: 1.6420 - val_accuracy: 0.3099

Epoch 00025: val_loss improved from 1.64327 to 1.64199, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 26/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6496 - accuracy: 0.3017 - val_loss: 1.6413 - val_accuracy: 0.3063

Epoch 00026: val_loss improved from 1.64199 to 1.64133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 27/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6480 - accuracy: 0.3067 - val_loss: 1.6413 - val_accuracy: 0.3092

Epoch 00027: val_loss did not improve from 1.64133
Epoch 28/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6476 - accuracy: 0.3034 - val_loss: 1.6415 - val_accuracy: 0.3068

Epoch 00028: val_loss did not improve from 1.64133
Epoch 29/100
83/83 [==============================] - 11s 136ms/step - loss: 1.6476 - accuracy: 0.3010 - val_loss: 1.6408 - val_accuracy: 0.3092

Epoch 00029: val_loss improved from 1.64133 to 1.64083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 30/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6455 - accuracy: 0.3056 - val_loss: 1.6390 - val_accuracy: 0.3088

Epoch 00030: val_loss improved from 1.64083 to 1.63901, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 31/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6443 - accuracy: 0.3075 - val_loss: 1.6394 - val_accuracy: 0.3104

Epoch 00031: val_loss did not improve from 1.63901
Epoch 32/100
83/83 [==============================] - 11s 134ms/step - loss: 1.6443 - accuracy: 0.3036 - val_loss: 1.6400 - val_accuracy: 0.3079

Epoch 00032: val_loss did not improve from 1.63901
Epoch 33/100
83/83 [==============================] - 9s 110ms/step - loss: 1.6441 - accuracy: 0.3046 - val_loss: 1.6390 - val_accuracy: 0.3086

Epoch 00033: val_loss improved from 1.63901 to 1.63900, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 34/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6440 - accuracy: 0.3053 - val_loss: 1.6397 - val_accuracy: 0.3095

Epoch 00034: val_loss did not improve from 1.63900
Epoch 35/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6426 - accuracy: 0.3052 - val_loss: 1.6396 - val_accuracy: 0.3092

Epoch 00035: val_loss did not improve from 1.63900
Epoch 36/100
83/83 [==============================] - 9s 110ms/step - loss: 1.6420 - accuracy: 0.3063 - val_loss: 1.6391 - val_accuracy: 0.3106

Epoch 00036: val_loss did not improve from 1.63900
Epoch 37/100
83/83 [==============================] - 11s 133ms/step - loss: 1.6409 - accuracy: 0.3056 - val_loss: 1.6399 - val_accuracy: 0.3076

Epoch 00037: val_loss did not improve from 1.63900
Epoch 38/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6404 - accuracy: 0.3067 - val_loss: 1.6391 - val_accuracy: 0.3101

Epoch 00038: val_loss did not improve from 1.63900
Epoch 39/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6401 - accuracy: 0.3076 - val_loss: 1.6398 - val_accuracy: 0.3099

Epoch 00039: val_loss did not improve from 1.63900
Epoch 40/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6394 - accuracy: 0.3087 - val_loss: 1.6413 - val_accuracy: 0.3088

Epoch 00040: val_loss did not improve from 1.63900
Epoch 00040: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 81s 6ms/step - loss: 1.6425 - accuracy: 0.3035
Testing Loss = 1.642518, Testing Accuracy = 0.303513
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 12s 133ms/step - loss: 11.8410 - accuracy: 0.2481 - val_loss: 8.1458 - val_accuracy: 0.2747

Epoch 00001: val_loss improved from inf to 8.14580, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 2/100
83/83 [==============================] - 7s 86ms/step - loss: 6.4309 - accuracy: 0.2673 - val_loss: 5.1442 - val_accuracy: 0.2817

Epoch 00002: val_loss improved from 8.14580 to 5.14423, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 3/100
83/83 [==============================] - 7s 86ms/step - loss: 4.4748 - accuracy: 0.2803 - val_loss: 3.9011 - val_accuracy: 0.2948

Epoch 00003: val_loss improved from 5.14423 to 3.90110, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 4/100
83/83 [==============================] - 7s 85ms/step - loss: 3.5528 - accuracy: 0.2806 - val_loss: 3.2116 - val_accuracy: 0.2953

Epoch 00004: val_loss improved from 3.90110 to 3.21160, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 5/100
83/83 [==============================] - 7s 86ms/step - loss: 2.9889 - accuracy: 0.2828 - val_loss: 2.7521 - val_accuracy: 0.3016

Epoch 00005: val_loss improved from 3.21160 to 2.75206, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 6/100
83/83 [==============================] - 7s 87ms/step - loss: 2.6010 - accuracy: 0.2885 - val_loss: 2.4286 - val_accuracy: 0.3044

Epoch 00006: val_loss improved from 2.75206 to 2.42855, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 7/100
83/83 [==============================] - 7s 87ms/step - loss: 2.3268 - accuracy: 0.2880 - val_loss: 2.1998 - val_accuracy: 0.3031

Epoch 00007: val_loss improved from 2.42855 to 2.19981, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 8/100
83/83 [==============================] - 7s 88ms/step - loss: 2.1308 - accuracy: 0.2913 - val_loss: 2.0365 - val_accuracy: 0.3032

Epoch 00008: val_loss improved from 2.19981 to 2.03648, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 9/100
83/83 [==============================] - 7s 88ms/step - loss: 1.9921 - accuracy: 0.2923 - val_loss: 1.9201 - val_accuracy: 0.3045

Epoch 00009: val_loss improved from 2.03648 to 1.92011, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 10/100
83/83 [==============================] - 7s 84ms/step - loss: 1.8939 - accuracy: 0.2941 - val_loss: 1.8391 - val_accuracy: 0.3047

Epoch 00010: val_loss improved from 1.92011 to 1.83914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 11/100
83/83 [==============================] - 7s 85ms/step - loss: 1.8237 - accuracy: 0.2965 - val_loss: 1.7826 - val_accuracy: 0.3066

Epoch 00011: val_loss improved from 1.83914 to 1.78256, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 12/100
83/83 [==============================] - 7s 84ms/step - loss: 1.7741 - accuracy: 0.2956 - val_loss: 1.7425 - val_accuracy: 0.3056

Epoch 00012: val_loss improved from 1.78256 to 1.74254, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 13/100
83/83 [==============================] - 7s 85ms/step - loss: 1.7399 - accuracy: 0.2981 - val_loss: 1.7151 - val_accuracy: 0.3058

Epoch 00013: val_loss improved from 1.74254 to 1.71512, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 14/100
83/83 [==============================] - 7s 85ms/step - loss: 1.7163 - accuracy: 0.2964 - val_loss: 1.6949 - val_accuracy: 0.3063

Epoch 00014: val_loss improved from 1.71512 to 1.69486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 15/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6997 - accuracy: 0.2975 - val_loss: 1.6808 - val_accuracy: 0.3059

Epoch 00015: val_loss improved from 1.69486 to 1.68076, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 16/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6866 - accuracy: 0.2961 - val_loss: 1.6706 - val_accuracy: 0.3063

Epoch 00016: val_loss improved from 1.68076 to 1.67058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 17/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6772 - accuracy: 0.3002 - val_loss: 1.6651 - val_accuracy: 0.3056

Epoch 00017: val_loss improved from 1.67058 to 1.66506, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 18/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6715 - accuracy: 0.3005 - val_loss: 1.6597 - val_accuracy: 0.3039

Epoch 00018: val_loss improved from 1.66506 to 1.65971, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 19/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6675 - accuracy: 0.2988 - val_loss: 1.6536 - val_accuracy: 0.3088

Epoch 00019: val_loss improved from 1.65971 to 1.65362, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 20/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6631 - accuracy: 0.2995 - val_loss: 1.6503 - val_accuracy: 0.3067

Epoch 00020: val_loss improved from 1.65362 to 1.65029, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 21/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6590 - accuracy: 0.3014 - val_loss: 1.6485 - val_accuracy: 0.3085

Epoch 00021: val_loss improved from 1.65029 to 1.64853, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 22/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6568 - accuracy: 0.3021 - val_loss: 1.6465 - val_accuracy: 0.3081

Epoch 00022: val_loss improved from 1.64853 to 1.64649, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 23/100
83/83 [==============================] - 10s 118ms/step - loss: 1.6544 - accuracy: 0.3000 - val_loss: 1.6455 - val_accuracy: 0.3073

Epoch 00023: val_loss improved from 1.64649 to 1.64548, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 24/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6530 - accuracy: 0.3016 - val_loss: 1.6445 - val_accuracy: 0.3066

Epoch 00024: val_loss improved from 1.64548 to 1.64450, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 25/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6513 - accuracy: 0.3015 - val_loss: 1.6437 - val_accuracy: 0.3064

Epoch 00025: val_loss improved from 1.64450 to 1.64367, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 26/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6506 - accuracy: 0.3032 - val_loss: 1.6434 - val_accuracy: 0.3079

Epoch 00026: val_loss improved from 1.64367 to 1.64341, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 27/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6492 - accuracy: 0.3048 - val_loss: 1.6433 - val_accuracy: 0.3075

Epoch 00027: val_loss improved from 1.64341 to 1.64332, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 28/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6486 - accuracy: 0.3025 - val_loss: 1.6409 - val_accuracy: 0.3104

Epoch 00028: val_loss improved from 1.64332 to 1.64091, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 29/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6478 - accuracy: 0.3017 - val_loss: 1.6408 - val_accuracy: 0.3067

Epoch 00029: val_loss improved from 1.64091 to 1.64084, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 30/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6473 - accuracy: 0.3051 - val_loss: 1.6392 - val_accuracy: 0.3093

Epoch 00030: val_loss improved from 1.64084 to 1.63916, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 31/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6451 - accuracy: 0.3026 - val_loss: 1.6395 - val_accuracy: 0.3112

Epoch 00031: val_loss did not improve from 1.63916
Epoch 32/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6449 - accuracy: 0.3047 - val_loss: 1.6398 - val_accuracy: 0.3088

Epoch 00032: val_loss did not improve from 1.63916
Epoch 33/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6446 - accuracy: 0.3055 - val_loss: 1.6389 - val_accuracy: 0.3080

Epoch 00033: val_loss improved from 1.63916 to 1.63892, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 34/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6433 - accuracy: 0.3028 - val_loss: 1.6382 - val_accuracy: 0.3112

Epoch 00034: val_loss improved from 1.63892 to 1.63817, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 35/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6435 - accuracy: 0.3054 - val_loss: 1.6383 - val_accuracy: 0.3098

Epoch 00035: val_loss did not improve from 1.63817
Epoch 36/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6439 - accuracy: 0.3054 - val_loss: 1.6393 - val_accuracy: 0.3104

Epoch 00036: val_loss did not improve from 1.63817
Epoch 37/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6422 - accuracy: 0.3055 - val_loss: 1.6383 - val_accuracy: 0.3113

Epoch 00037: val_loss did not improve from 1.63817
Epoch 38/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6418 - accuracy: 0.3039 - val_loss: 1.6388 - val_accuracy: 0.3092

Epoch 00038: val_loss did not improve from 1.63817
Epoch 39/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6421 - accuracy: 0.3060 - val_loss: 1.6387 - val_accuracy: 0.3100

Epoch 00039: val_loss did not improve from 1.63817
Epoch 40/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6404 - accuracy: 0.3058 - val_loss: 1.6387 - val_accuracy: 0.3104

Epoch 00040: val_loss did not improve from 1.63817
Epoch 41/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6403 - accuracy: 0.3048 - val_loss: 1.6387 - val_accuracy: 0.3102

Epoch 00041: val_loss did not improve from 1.63817
Epoch 42/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6407 - accuracy: 0.3055 - val_loss: 1.6389 - val_accuracy: 0.3110

Epoch 00042: val_loss did not improve from 1.63817
Epoch 43/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6401 - accuracy: 0.3059 - val_loss: 1.6398 - val_accuracy: 0.3093

Epoch 00043: val_loss did not improve from 1.63817
Epoch 44/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6396 - accuracy: 0.3055 - val_loss: 1.6395 - val_accuracy: 0.3104

Epoch 00044: val_loss did not improve from 1.63817
Epoch 00044: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 84s 6ms/step - loss: 1.6411 - accuracy: 0.3043
Testing Loss = 1.641089, Testing Accuracy = 0.304257
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 8s 87ms/step - loss: 11.9019 - accuracy: 0.2462 - val_loss: 8.2031 - val_accuracy: 0.2721

Epoch 00001: val_loss improved from inf to 8.20314, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 2/100
83/83 [==============================] - 7s 85ms/step - loss: 6.4662 - accuracy: 0.2715 - val_loss: 5.1656 - val_accuracy: 0.2804

Epoch 00002: val_loss improved from 8.20314 to 5.16564, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 3/100
83/83 [==============================] - 7s 86ms/step - loss: 4.4859 - accuracy: 0.2784 - val_loss: 3.9105 - val_accuracy: 0.2909

Epoch 00003: val_loss improved from 5.16564 to 3.91046, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 4/100
83/83 [==============================] - 7s 86ms/step - loss: 3.5558 - accuracy: 0.2832 - val_loss: 3.2138 - val_accuracy: 0.2976

Epoch 00004: val_loss improved from 3.91046 to 3.21378, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 5/100
83/83 [==============================] - 7s 86ms/step - loss: 2.9902 - accuracy: 0.2864 - val_loss: 2.7537 - val_accuracy: 0.2990

Epoch 00005: val_loss improved from 3.21378 to 2.75368, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 6/100
83/83 [==============================] - 7s 85ms/step - loss: 2.6024 - accuracy: 0.2872 - val_loss: 2.4308 - val_accuracy: 0.3015

Epoch 00006: val_loss improved from 2.75368 to 2.43082, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 7/100
83/83 [==============================] - 7s 86ms/step - loss: 2.3272 - accuracy: 0.2927 - val_loss: 2.1997 - val_accuracy: 0.3039

Epoch 00007: val_loss improved from 2.43082 to 2.19969, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 8/100
83/83 [==============================] - 7s 85ms/step - loss: 2.1324 - accuracy: 0.2880 - val_loss: 2.0374 - val_accuracy: 0.3019

Epoch 00008: val_loss improved from 2.19969 to 2.03739, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 9/100
83/83 [==============================] - 7s 84ms/step - loss: 1.9914 - accuracy: 0.2924 - val_loss: 1.9215 - val_accuracy: 0.3020

Epoch 00009: val_loss improved from 2.03739 to 1.92152, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 10/100
83/83 [==============================] - 7s 84ms/step - loss: 1.8944 - accuracy: 0.2938 - val_loss: 1.8418 - val_accuracy: 0.3009

Epoch 00010: val_loss improved from 1.92152 to 1.84180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 11/100
83/83 [==============================] - 7s 84ms/step - loss: 1.8230 - accuracy: 0.2952 - val_loss: 1.7836 - val_accuracy: 0.3021

Epoch 00011: val_loss improved from 1.84180 to 1.78358, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 12/100
83/83 [==============================] - 7s 84ms/step - loss: 1.7738 - accuracy: 0.2991 - val_loss: 1.7426 - val_accuracy: 0.3045

Epoch 00012: val_loss improved from 1.78358 to 1.74264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 13/100
83/83 [==============================] - 7s 84ms/step - loss: 1.7400 - accuracy: 0.2962 - val_loss: 1.7150 - val_accuracy: 0.3062

Epoch 00013: val_loss improved from 1.74264 to 1.71500, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 14/100
83/83 [==============================] - 7s 84ms/step - loss: 1.7154 - accuracy: 0.2974 - val_loss: 1.6943 - val_accuracy: 0.3039

Epoch 00014: val_loss improved from 1.71500 to 1.69425, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 15/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6994 - accuracy: 0.2994 - val_loss: 1.6798 - val_accuracy: 0.3063

Epoch 00015: val_loss improved from 1.69425 to 1.67978, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 16/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6868 - accuracy: 0.2994 - val_loss: 1.6706 - val_accuracy: 0.3069

Epoch 00016: val_loss improved from 1.67978 to 1.67058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 17/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6785 - accuracy: 0.2998 - val_loss: 1.6638 - val_accuracy: 0.3044

Epoch 00017: val_loss improved from 1.67058 to 1.66384, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 18/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6701 - accuracy: 0.2990 - val_loss: 1.6586 - val_accuracy: 0.3064

Epoch 00018: val_loss improved from 1.66384 to 1.65864, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 19/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6657 - accuracy: 0.2981 - val_loss: 1.6549 - val_accuracy: 0.3059

Epoch 00019: val_loss improved from 1.65864 to 1.65487, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 20/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6622 - accuracy: 0.2993 - val_loss: 1.6514 - val_accuracy: 0.3049

Epoch 00020: val_loss improved from 1.65487 to 1.65144, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 21/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6593 - accuracy: 0.2991 - val_loss: 1.6484 - val_accuracy: 0.3059

Epoch 00021: val_loss improved from 1.65144 to 1.64842, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 22/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6566 - accuracy: 0.3021 - val_loss: 1.6461 - val_accuracy: 0.3063

Epoch 00022: val_loss improved from 1.64842 to 1.64614, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 23/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6557 - accuracy: 0.2982 - val_loss: 1.6449 - val_accuracy: 0.3068

Epoch 00023: val_loss improved from 1.64614 to 1.64494, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 24/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6527 - accuracy: 0.3023 - val_loss: 1.6438 - val_accuracy: 0.3065

Epoch 00024: val_loss improved from 1.64494 to 1.64384, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 25/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6510 - accuracy: 0.3022 - val_loss: 1.6430 - val_accuracy: 0.3074

Epoch 00025: val_loss improved from 1.64384 to 1.64298, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 26/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6502 - accuracy: 0.3018 - val_loss: 1.6431 - val_accuracy: 0.3080

Epoch 00026: val_loss did not improve from 1.64298
Epoch 27/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6504 - accuracy: 0.3032 - val_loss: 1.6427 - val_accuracy: 0.3060

Epoch 00027: val_loss improved from 1.64298 to 1.64270, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 28/100
83/83 [==============================] - 10s 116ms/step - loss: 1.6484 - accuracy: 0.3036 - val_loss: 1.6412 - val_accuracy: 0.3094

Epoch 00028: val_loss improved from 1.64270 to 1.64122, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 29/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6473 - accuracy: 0.3046 - val_loss: 1.6400 - val_accuracy: 0.3103

Epoch 00029: val_loss improved from 1.64122 to 1.63998, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 30/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6462 - accuracy: 0.3055 - val_loss: 1.6406 - val_accuracy: 0.3097

Epoch 00030: val_loss did not improve from 1.63998
Epoch 31/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6458 - accuracy: 0.3019 - val_loss: 1.6400 - val_accuracy: 0.3099

Epoch 00031: val_loss did not improve from 1.63998
Epoch 32/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6442 - accuracy: 0.3080 - val_loss: 1.6394 - val_accuracy: 0.3109

Epoch 00032: val_loss improved from 1.63998 to 1.63940, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 33/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6436 - accuracy: 0.3045 - val_loss: 1.6397 - val_accuracy: 0.3104

Epoch 00033: val_loss did not improve from 1.63940
Epoch 34/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6441 - accuracy: 0.3058 - val_loss: 1.6398 - val_accuracy: 0.3080

Epoch 00034: val_loss did not improve from 1.63940
Epoch 35/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6437 - accuracy: 0.3064 - val_loss: 1.6398 - val_accuracy: 0.3106

Epoch 00035: val_loss did not improve from 1.63940
Epoch 36/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6429 - accuracy: 0.3042 - val_loss: 1.6380 - val_accuracy: 0.3104

Epoch 00036: val_loss improved from 1.63940 to 1.63802, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 37/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6421 - accuracy: 0.3058 - val_loss: 1.6390 - val_accuracy: 0.3089

Epoch 00037: val_loss did not improve from 1.63802
Epoch 38/100
83/83 [==============================] - 11s 136ms/step - loss: 1.6419 - accuracy: 0.3060 - val_loss: 1.6381 - val_accuracy: 0.3126

Epoch 00038: val_loss did not improve from 1.63802
Epoch 39/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6423 - accuracy: 0.3049 - val_loss: 1.6382 - val_accuracy: 0.3133

Epoch 00039: val_loss did not improve from 1.63802
Epoch 40/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6411 - accuracy: 0.3057 - val_loss: 1.6389 - val_accuracy: 0.3109

Epoch 00040: val_loss did not improve from 1.63802
Epoch 41/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6404 - accuracy: 0.3081 - val_loss: 1.6387 - val_accuracy: 0.3115

Epoch 00041: val_loss did not improve from 1.63802
Epoch 42/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6413 - accuracy: 0.3046 - val_loss: 1.6384 - val_accuracy: 0.3105

Epoch 00042: val_loss did not improve from 1.63802
Epoch 43/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6410 - accuracy: 0.3076 - val_loss: 1.6393 - val_accuracy: 0.3130

Epoch 00043: val_loss did not improve from 1.63802
Epoch 44/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6395 - accuracy: 0.3065 - val_loss: 1.6398 - val_accuracy: 0.3123

Epoch 00044: val_loss did not improve from 1.63802
Epoch 45/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6380 - accuracy: 0.3087 - val_loss: 1.6383 - val_accuracy: 0.3134

Epoch 00045: val_loss did not improve from 1.63802
Epoch 46/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6378 - accuracy: 0.3118 - val_loss: 1.6388 - val_accuracy: 0.3093

Epoch 00046: val_loss did not improve from 1.63802
Epoch 00046: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 86s 6ms/step - loss: 1.6414 - accuracy: 0.3024
Testing Loss = 1.641360, Testing Accuracy = 0.302397
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 8s 87ms/step - loss: 11.8013 - accuracy: 0.2490 - val_loss: 8.0971 - val_accuracy: 0.2812

Epoch 00001: val_loss improved from inf to 8.09714, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 2/100
83/83 [==============================] - 7s 86ms/step - loss: 6.3886 - accuracy: 0.2702 - val_loss: 5.1085 - val_accuracy: 0.2877

Epoch 00002: val_loss improved from 8.09714 to 5.10847, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 3/100
83/83 [==============================] - 7s 86ms/step - loss: 4.4482 - accuracy: 0.2781 - val_loss: 3.8826 - val_accuracy: 0.2923

Epoch 00003: val_loss improved from 5.10847 to 3.88255, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 4/100
83/83 [==============================] - 7s 86ms/step - loss: 3.5368 - accuracy: 0.2808 - val_loss: 3.2014 - val_accuracy: 0.2969

Epoch 00004: val_loss improved from 3.88255 to 3.20137, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 5/100
83/83 [==============================] - 7s 87ms/step - loss: 2.9772 - accuracy: 0.2858 - val_loss: 2.7435 - val_accuracy: 0.3016

Epoch 00005: val_loss improved from 3.20137 to 2.74353, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 6/100
83/83 [==============================] - 7s 86ms/step - loss: 2.5947 - accuracy: 0.2874 - val_loss: 2.4244 - val_accuracy: 0.3056

Epoch 00006: val_loss improved from 2.74353 to 2.42440, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 7/100
83/83 [==============================] - 7s 82ms/step - loss: 2.3216 - accuracy: 0.2913 - val_loss: 2.1969 - val_accuracy: 0.3047

Epoch 00007: val_loss improved from 2.42440 to 2.19691, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 8/100
83/83 [==============================] - 7s 84ms/step - loss: 2.1287 - accuracy: 0.2913 - val_loss: 2.0337 - val_accuracy: 0.3024

Epoch 00008: val_loss improved from 2.19691 to 2.03366, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 9/100
83/83 [==============================] - 7s 85ms/step - loss: 1.9894 - accuracy: 0.2937 - val_loss: 1.9195 - val_accuracy: 0.3045

Epoch 00009: val_loss improved from 2.03366 to 1.91946, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 10/100
83/83 [==============================] - 7s 85ms/step - loss: 1.8918 - accuracy: 0.2941 - val_loss: 1.8384 - val_accuracy: 0.3022

Epoch 00010: val_loss improved from 1.91946 to 1.83840, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 11/100
83/83 [==============================] - 7s 84ms/step - loss: 1.8233 - accuracy: 0.2927 - val_loss: 1.7831 - val_accuracy: 0.3021

Epoch 00011: val_loss improved from 1.83840 to 1.78307, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 12/100
83/83 [==============================] - 7s 84ms/step - loss: 1.7743 - accuracy: 0.2955 - val_loss: 1.7421 - val_accuracy: 0.3051

Epoch 00012: val_loss improved from 1.78307 to 1.74213, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 13/100
83/83 [==============================] - 7s 80ms/step - loss: 1.7410 - accuracy: 0.2983 - val_loss: 1.7139 - val_accuracy: 0.3047

Epoch 00013: val_loss improved from 1.74213 to 1.71391, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 14/100
83/83 [==============================] - 6s 72ms/step - loss: 1.7164 - accuracy: 0.2969 - val_loss: 1.6944 - val_accuracy: 0.3067

Epoch 00014: val_loss improved from 1.71391 to 1.69442, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 15/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6985 - accuracy: 0.2991 - val_loss: 1.6810 - val_accuracy: 0.3047

Epoch 00015: val_loss improved from 1.69442 to 1.68101, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 16/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6857 - accuracy: 0.3005 - val_loss: 1.6703 - val_accuracy: 0.3053

Epoch 00016: val_loss improved from 1.68101 to 1.67026, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 17/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6769 - accuracy: 0.2988 - val_loss: 1.6640 - val_accuracy: 0.3051

Epoch 00017: val_loss improved from 1.67026 to 1.66397, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 18/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6719 - accuracy: 0.2991 - val_loss: 1.6581 - val_accuracy: 0.3059

Epoch 00018: val_loss improved from 1.66397 to 1.65806, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 19/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6664 - accuracy: 0.3023 - val_loss: 1.6546 - val_accuracy: 0.3069

Epoch 00019: val_loss improved from 1.65806 to 1.65463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 20/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6631 - accuracy: 0.2984 - val_loss: 1.6508 - val_accuracy: 0.3075

Epoch 00020: val_loss improved from 1.65463 to 1.65076, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 21/100
83/83 [==============================] - 6s 73ms/step - loss: 1.6584 - accuracy: 0.3017 - val_loss: 1.6501 - val_accuracy: 0.3048

Epoch 00021: val_loss improved from 1.65076 to 1.65012, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 22/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6565 - accuracy: 0.3018 - val_loss: 1.6473 - val_accuracy: 0.3084

Epoch 00022: val_loss improved from 1.65012 to 1.64731, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 23/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6549 - accuracy: 0.3005 - val_loss: 1.6461 - val_accuracy: 0.3083

Epoch 00023: val_loss improved from 1.64731 to 1.64611, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 24/100
83/83 [==============================] - 6s 73ms/step - loss: 1.6533 - accuracy: 0.3019 - val_loss: 1.6450 - val_accuracy: 0.3080

Epoch 00024: val_loss improved from 1.64611 to 1.64501, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 25/100
83/83 [==============================] - 6s 73ms/step - loss: 1.6530 - accuracy: 0.2993 - val_loss: 1.6430 - val_accuracy: 0.3095

Epoch 00025: val_loss improved from 1.64501 to 1.64304, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 26/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6492 - accuracy: 0.3035 - val_loss: 1.6422 - val_accuracy: 0.3086

Epoch 00026: val_loss improved from 1.64304 to 1.64224, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 27/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6495 - accuracy: 0.3039 - val_loss: 1.6420 - val_accuracy: 0.3121

Epoch 00027: val_loss improved from 1.64224 to 1.64197, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 28/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6487 - accuracy: 0.3027 - val_loss: 1.6415 - val_accuracy: 0.3104

Epoch 00028: val_loss improved from 1.64197 to 1.64147, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 29/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6467 - accuracy: 0.3027 - val_loss: 1.6401 - val_accuracy: 0.3115

Epoch 00029: val_loss improved from 1.64147 to 1.64014, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 30/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6456 - accuracy: 0.3030 - val_loss: 1.6402 - val_accuracy: 0.3109

Epoch 00030: val_loss did not improve from 1.64014
Epoch 31/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6451 - accuracy: 0.3045 - val_loss: 1.6400 - val_accuracy: 0.3095

Epoch 00031: val_loss improved from 1.64014 to 1.64004, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 32/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6460 - accuracy: 0.3064 - val_loss: 1.6401 - val_accuracy: 0.3089

Epoch 00032: val_loss did not improve from 1.64004
Epoch 33/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6447 - accuracy: 0.3045 - val_loss: 1.6409 - val_accuracy: 0.3097

Epoch 00033: val_loss did not improve from 1.64004
Epoch 34/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6428 - accuracy: 0.3041 - val_loss: 1.6395 - val_accuracy: 0.3094

Epoch 00034: val_loss improved from 1.64004 to 1.63947, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 35/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6427 - accuracy: 0.3069 - val_loss: 1.6402 - val_accuracy: 0.3094

Epoch 00035: val_loss did not improve from 1.63947
Epoch 36/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6416 - accuracy: 0.3062 - val_loss: 1.6391 - val_accuracy: 0.3108

Epoch 00036: val_loss improved from 1.63947 to 1.63911, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 37/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6421 - accuracy: 0.3067 - val_loss: 1.6389 - val_accuracy: 0.3090

Epoch 00037: val_loss improved from 1.63911 to 1.63890, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 38/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6409 - accuracy: 0.3087 - val_loss: 1.6389 - val_accuracy: 0.3099

Epoch 00038: val_loss did not improve from 1.63890
Epoch 39/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6401 - accuracy: 0.3072 - val_loss: 1.6399 - val_accuracy: 0.3096

Epoch 00039: val_loss did not improve from 1.63890
Epoch 40/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6400 - accuracy: 0.3073 - val_loss: 1.6401 - val_accuracy: 0.3100

Epoch 00040: val_loss did not improve from 1.63890
Epoch 41/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6393 - accuracy: 0.3087 - val_loss: 1.6397 - val_accuracy: 0.3104

Epoch 00041: val_loss did not improve from 1.63890
Epoch 42/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6395 - accuracy: 0.3091 - val_loss: 1.6413 - val_accuracy: 0.3111

Epoch 00042: val_loss did not improve from 1.63890
Epoch 43/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6379 - accuracy: 0.3082 - val_loss: 1.6412 - val_accuracy: 0.3102

Epoch 00043: val_loss did not improve from 1.63890
Epoch 44/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6383 - accuracy: 0.3103 - val_loss: 1.6416 - val_accuracy: 0.3084

Epoch 00044: val_loss did not improve from 1.63890
Epoch 45/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6383 - accuracy: 0.3089 - val_loss: 1.6423 - val_accuracy: 0.3076

Epoch 00045: val_loss did not improve from 1.63890
Epoch 46/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6377 - accuracy: 0.3110 - val_loss: 1.6437 - val_accuracy: 0.3074

Epoch 00046: val_loss did not improve from 1.63890
Epoch 47/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6366 - accuracy: 0.3110 - val_loss: 1.6441 - val_accuracy: 0.3100

Epoch 00047: val_loss did not improve from 1.63890
Epoch 00047: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 67s 5ms/step - loss: 1.6415 - accuracy: 0.3039
Testing Loss = 1.641476, Testing Accuracy = 0.303885
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 78.76 +- 0.0366 %)
$W^-/W^-$ (auc = 78.40 +- 0.0585 %)
$Z/Z$ (auc = 59.40 +- 0.0941 %)
$W^+/W^-$ (auc = 62.27 +- 0.0828 %)
$W^+/Z$$ (auc = 63.17 +- 0.0370 %)
$W^-/Z$ (auc = 65.65 +- 0.0446 %)
The summarized testing accuracy = 30.33 +- 0.0813 %, with the loss = 1.6416 +- 0.000790
