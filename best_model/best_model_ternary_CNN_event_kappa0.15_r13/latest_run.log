

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-27 21:14:35.719122
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 15s 118ms/step - loss: 11.9518 - accuracy: 0.2500 - val_loss: 8.2688 - val_accuracy: 0.2800

Epoch 00001: val_loss improved from inf to 8.26877, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 2/100
83/83 [==============================] - 9s 111ms/step - loss: 6.5236 - accuracy: 0.2664 - val_loss: 5.2082 - val_accuracy: 0.2857

Epoch 00002: val_loss improved from 8.26877 to 5.20818, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 3/100
83/83 [==============================] - 9s 109ms/step - loss: 4.5213 - accuracy: 0.2767 - val_loss: 3.9362 - val_accuracy: 0.2896

Epoch 00003: val_loss improved from 5.20818 to 3.93618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 4/100
83/83 [==============================] - 9s 111ms/step - loss: 3.5774 - accuracy: 0.2801 - val_loss: 3.2291 - val_accuracy: 0.2956

Epoch 00004: val_loss improved from 3.93618 to 3.22906, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 5/100
83/83 [==============================] - 9s 109ms/step - loss: 3.0029 - accuracy: 0.2860 - val_loss: 2.7620 - val_accuracy: 0.3010

Epoch 00005: val_loss improved from 3.22906 to 2.76199, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 6/100
83/83 [==============================] - 9s 111ms/step - loss: 2.6115 - accuracy: 0.2903 - val_loss: 2.4374 - val_accuracy: 0.2988

Epoch 00006: val_loss improved from 2.76199 to 2.43744, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 7/100
83/83 [==============================] - 9s 110ms/step - loss: 2.3333 - accuracy: 0.2916 - val_loss: 2.2063 - val_accuracy: 0.3027

Epoch 00007: val_loss improved from 2.43744 to 2.20632, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 8/100
83/83 [==============================] - 9s 114ms/step - loss: 2.1359 - accuracy: 0.2912 - val_loss: 2.0413 - val_accuracy: 0.3021

Epoch 00008: val_loss improved from 2.20632 to 2.04128, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 9/100
83/83 [==============================] - 9s 112ms/step - loss: 1.9952 - accuracy: 0.2919 - val_loss: 1.9243 - val_accuracy: 0.3030

Epoch 00009: val_loss improved from 2.04128 to 1.92433, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 10/100
83/83 [==============================] - 10s 119ms/step - loss: 1.8957 - accuracy: 0.2943 - val_loss: 1.8417 - val_accuracy: 0.3021

Epoch 00010: val_loss improved from 1.92433 to 1.84167, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 11/100
83/83 [==============================] - 10s 120ms/step - loss: 1.8241 - accuracy: 0.2974 - val_loss: 1.7836 - val_accuracy: 0.3027

Epoch 00011: val_loss improved from 1.84167 to 1.78365, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 12/100
83/83 [==============================] - 10s 125ms/step - loss: 1.7756 - accuracy: 0.2977 - val_loss: 1.7441 - val_accuracy: 0.3023

Epoch 00012: val_loss improved from 1.78365 to 1.74409, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 13/100
83/83 [==============================] - 12s 138ms/step - loss: 1.7414 - accuracy: 0.2970 - val_loss: 1.7160 - val_accuracy: 0.3036

Epoch 00013: val_loss improved from 1.74409 to 1.71595, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 14/100
83/83 [==============================] - 12s 138ms/step - loss: 1.7166 - accuracy: 0.2957 - val_loss: 1.6958 - val_accuracy: 0.3037

Epoch 00014: val_loss improved from 1.71595 to 1.69578, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 15/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6996 - accuracy: 0.2945 - val_loss: 1.6822 - val_accuracy: 0.3038

Epoch 00015: val_loss improved from 1.69578 to 1.68216, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 16/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6854 - accuracy: 0.2995 - val_loss: 1.6712 - val_accuracy: 0.3024

Epoch 00016: val_loss improved from 1.68216 to 1.67123, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 17/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6780 - accuracy: 0.2985 - val_loss: 1.6631 - val_accuracy: 0.3063

Epoch 00017: val_loss improved from 1.67123 to 1.66313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 18/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6705 - accuracy: 0.3004 - val_loss: 1.6579 - val_accuracy: 0.3049

Epoch 00018: val_loss improved from 1.66313 to 1.65792, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 19/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6662 - accuracy: 0.2991 - val_loss: 1.6544 - val_accuracy: 0.3063

Epoch 00019: val_loss improved from 1.65792 to 1.65444, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 20/100
83/83 [==============================] - 11s 138ms/step - loss: 1.6617 - accuracy: 0.2995 - val_loss: 1.6508 - val_accuracy: 0.3074

Epoch 00020: val_loss improved from 1.65444 to 1.65081, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 21/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6599 - accuracy: 0.2999 - val_loss: 1.6493 - val_accuracy: 0.3047

Epoch 00021: val_loss improved from 1.65081 to 1.64935, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 22/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6573 - accuracy: 0.3002 - val_loss: 1.6460 - val_accuracy: 0.3075

Epoch 00022: val_loss improved from 1.64935 to 1.64599, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 23/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6553 - accuracy: 0.2989 - val_loss: 1.6457 - val_accuracy: 0.3075

Epoch 00023: val_loss improved from 1.64599 to 1.64572, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 24/100
83/83 [==============================] - 7s 82ms/step - loss: 1.6532 - accuracy: 0.3014 - val_loss: 1.6441 - val_accuracy: 0.3095

Epoch 00024: val_loss improved from 1.64572 to 1.64410, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 25/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6513 - accuracy: 0.3040 - val_loss: 1.6422 - val_accuracy: 0.3101

Epoch 00025: val_loss improved from 1.64410 to 1.64223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 26/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6502 - accuracy: 0.3032 - val_loss: 1.6418 - val_accuracy: 0.3076

Epoch 00026: val_loss improved from 1.64223 to 1.64179, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 27/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6494 - accuracy: 0.3003 - val_loss: 1.6419 - val_accuracy: 0.3075

Epoch 00027: val_loss did not improve from 1.64179
Epoch 28/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6481 - accuracy: 0.3035 - val_loss: 1.6410 - val_accuracy: 0.3081

Epoch 00028: val_loss improved from 1.64179 to 1.64103, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 29/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6471 - accuracy: 0.3033 - val_loss: 1.6401 - val_accuracy: 0.3079

Epoch 00029: val_loss improved from 1.64103 to 1.64015, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 30/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6464 - accuracy: 0.3031 - val_loss: 1.6413 - val_accuracy: 0.3070

Epoch 00030: val_loss did not improve from 1.64015
Epoch 31/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6462 - accuracy: 0.3037 - val_loss: 1.6396 - val_accuracy: 0.3069

Epoch 00031: val_loss improved from 1.64015 to 1.63960, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 32/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6457 - accuracy: 0.3037 - val_loss: 1.6398 - val_accuracy: 0.3063

Epoch 00032: val_loss did not improve from 1.63960
Epoch 33/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6444 - accuracy: 0.3034 - val_loss: 1.6404 - val_accuracy: 0.3082

Epoch 00033: val_loss did not improve from 1.63960
Epoch 34/100
83/83 [==============================] - 7s 81ms/step - loss: 1.6440 - accuracy: 0.3061 - val_loss: 1.6400 - val_accuracy: 0.3081

Epoch 00034: val_loss did not improve from 1.63960
Epoch 35/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6434 - accuracy: 0.3053 - val_loss: 1.6388 - val_accuracy: 0.3104

Epoch 00035: val_loss improved from 1.63960 to 1.63880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/0
Epoch 36/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6432 - accuracy: 0.3054 - val_loss: 1.6394 - val_accuracy: 0.3091

Epoch 00036: val_loss did not improve from 1.63880
Epoch 37/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6422 - accuracy: 0.3069 - val_loss: 1.6396 - val_accuracy: 0.3087

Epoch 00037: val_loss did not improve from 1.63880
Epoch 38/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6413 - accuracy: 0.3071 - val_loss: 1.6394 - val_accuracy: 0.3105

Epoch 00038: val_loss did not improve from 1.63880
Epoch 39/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6423 - accuracy: 0.3053 - val_loss: 1.6404 - val_accuracy: 0.3082

Epoch 00039: val_loss did not improve from 1.63880
Epoch 40/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6408 - accuracy: 0.3065 - val_loss: 1.6397 - val_accuracy: 0.3071

Epoch 00040: val_loss did not improve from 1.63880
Epoch 41/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6401 - accuracy: 0.3094 - val_loss: 1.6410 - val_accuracy: 0.3102

Epoch 00041: val_loss did not improve from 1.63880
Epoch 42/100
83/83 [==============================] - 7s 88ms/step - loss: 1.6407 - accuracy: 0.3087 - val_loss: 1.6408 - val_accuracy: 0.3102

Epoch 00042: val_loss did not improve from 1.63880
Epoch 43/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6397 - accuracy: 0.3077 - val_loss: 1.6417 - val_accuracy: 0.3099

Epoch 00043: val_loss did not improve from 1.63880
Epoch 44/100
83/83 [==============================] - 10s 126ms/step - loss: 1.6380 - accuracy: 0.3097 - val_loss: 1.6416 - val_accuracy: 0.3081

Epoch 00044: val_loss did not improve from 1.63880
Epoch 45/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6388 - accuracy: 0.3099 - val_loss: 1.6410 - val_accuracy: 0.3088

Epoch 00045: val_loss did not improve from 1.63880
Epoch 00045: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 83s 6ms/step - loss: 1.6426 - accuracy: 0.3025
Testing Loss = 1.642648, Testing Accuracy = 0.302471
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 10s 113ms/step - loss: 11.9095 - accuracy: 0.2528 - val_loss: 8.2203 - val_accuracy: 0.2819

Epoch 00001: val_loss improved from inf to 8.22029, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 2/100
83/83 [==============================] - 9s 112ms/step - loss: 6.4874 - accuracy: 0.2730 - val_loss: 5.1824 - val_accuracy: 0.2871

Epoch 00002: val_loss improved from 8.22029 to 5.18242, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 3/100
83/83 [==============================] - 9s 107ms/step - loss: 4.5006 - accuracy: 0.2754 - val_loss: 3.9201 - val_accuracy: 0.2932

Epoch 00003: val_loss improved from 5.18242 to 3.92010, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 4/100
83/83 [==============================] - 9s 113ms/step - loss: 3.5618 - accuracy: 0.2797 - val_loss: 3.2168 - val_accuracy: 0.2979

Epoch 00004: val_loss improved from 3.92010 to 3.21679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 5/100
83/83 [==============================] - 10s 119ms/step - loss: 2.9923 - accuracy: 0.2863 - val_loss: 2.7560 - val_accuracy: 0.2985

Epoch 00005: val_loss improved from 3.21679 to 2.75598, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 6/100
83/83 [==============================] - 10s 120ms/step - loss: 2.6034 - accuracy: 0.2876 - val_loss: 2.4327 - val_accuracy: 0.3022

Epoch 00006: val_loss improved from 2.75598 to 2.43274, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 7/100
83/83 [==============================] - 11s 127ms/step - loss: 2.3272 - accuracy: 0.2901 - val_loss: 2.2018 - val_accuracy: 0.3018

Epoch 00007: val_loss improved from 2.43274 to 2.20182, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 8/100
83/83 [==============================] - 11s 135ms/step - loss: 2.1310 - accuracy: 0.2920 - val_loss: 2.0368 - val_accuracy: 0.3046

Epoch 00008: val_loss improved from 2.20182 to 2.03681, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 9/100
83/83 [==============================] - 11s 135ms/step - loss: 1.9916 - accuracy: 0.2909 - val_loss: 1.9218 - val_accuracy: 0.3011

Epoch 00009: val_loss improved from 2.03681 to 1.92183, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 10/100
83/83 [==============================] - 12s 138ms/step - loss: 1.8929 - accuracy: 0.2938 - val_loss: 1.8395 - val_accuracy: 0.3021

Epoch 00010: val_loss improved from 1.92183 to 1.83950, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 11/100
83/83 [==============================] - 9s 107ms/step - loss: 1.8231 - accuracy: 0.2938 - val_loss: 1.7832 - val_accuracy: 0.3021

Epoch 00011: val_loss improved from 1.83950 to 1.78324, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 12/100
83/83 [==============================] - 9s 113ms/step - loss: 1.7738 - accuracy: 0.2943 - val_loss: 1.7414 - val_accuracy: 0.3046

Epoch 00012: val_loss improved from 1.78324 to 1.74143, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 13/100
83/83 [==============================] - 9s 110ms/step - loss: 1.7402 - accuracy: 0.2973 - val_loss: 1.7131 - val_accuracy: 0.3043

Epoch 00013: val_loss improved from 1.74143 to 1.71312, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 14/100
83/83 [==============================] - 9s 112ms/step - loss: 1.7149 - accuracy: 0.2969 - val_loss: 1.6937 - val_accuracy: 0.3038

Epoch 00014: val_loss improved from 1.71312 to 1.69371, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 15/100
83/83 [==============================] - 9s 114ms/step - loss: 1.6982 - accuracy: 0.2972 - val_loss: 1.6797 - val_accuracy: 0.3037

Epoch 00015: val_loss improved from 1.69371 to 1.67973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 16/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6865 - accuracy: 0.2963 - val_loss: 1.6693 - val_accuracy: 0.3049

Epoch 00016: val_loss improved from 1.67973 to 1.66930, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 17/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6764 - accuracy: 0.3007 - val_loss: 1.6641 - val_accuracy: 0.3060

Epoch 00017: val_loss improved from 1.66930 to 1.66405, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 18/100
83/83 [==============================] - 11s 138ms/step - loss: 1.6697 - accuracy: 0.2987 - val_loss: 1.6583 - val_accuracy: 0.3047

Epoch 00018: val_loss improved from 1.66405 to 1.65829, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 19/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6655 - accuracy: 0.3007 - val_loss: 1.6543 - val_accuracy: 0.3065

Epoch 00019: val_loss improved from 1.65829 to 1.65432, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 20/100
83/83 [==============================] - 12s 138ms/step - loss: 1.6605 - accuracy: 0.3012 - val_loss: 1.6506 - val_accuracy: 0.3039

Epoch 00020: val_loss improved from 1.65432 to 1.65056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 21/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6594 - accuracy: 0.2998 - val_loss: 1.6476 - val_accuracy: 0.3074

Epoch 00021: val_loss improved from 1.65056 to 1.64755, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 22/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6561 - accuracy: 0.3006 - val_loss: 1.6460 - val_accuracy: 0.3069

Epoch 00022: val_loss improved from 1.64755 to 1.64603, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 23/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6543 - accuracy: 0.2998 - val_loss: 1.6454 - val_accuracy: 0.3062

Epoch 00023: val_loss improved from 1.64603 to 1.64542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 24/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6516 - accuracy: 0.3023 - val_loss: 1.6443 - val_accuracy: 0.3063

Epoch 00024: val_loss improved from 1.64542 to 1.64427, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 25/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6503 - accuracy: 0.3029 - val_loss: 1.6430 - val_accuracy: 0.3047

Epoch 00025: val_loss improved from 1.64427 to 1.64299, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 26/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6501 - accuracy: 0.3013 - val_loss: 1.6416 - val_accuracy: 0.3078

Epoch 00026: val_loss improved from 1.64299 to 1.64156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 27/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6500 - accuracy: 0.3044 - val_loss: 1.6411 - val_accuracy: 0.3092

Epoch 00027: val_loss improved from 1.64156 to 1.64107, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 28/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6480 - accuracy: 0.3028 - val_loss: 1.6409 - val_accuracy: 0.3079

Epoch 00028: val_loss improved from 1.64107 to 1.64092, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 29/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6467 - accuracy: 0.3015 - val_loss: 1.6404 - val_accuracy: 0.3081

Epoch 00029: val_loss improved from 1.64092 to 1.64041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 30/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6471 - accuracy: 0.3033 - val_loss: 1.6396 - val_accuracy: 0.3072

Epoch 00030: val_loss improved from 1.64041 to 1.63955, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 31/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6461 - accuracy: 0.3019 - val_loss: 1.6405 - val_accuracy: 0.3056

Epoch 00031: val_loss did not improve from 1.63955
Epoch 32/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6447 - accuracy: 0.3045 - val_loss: 1.6395 - val_accuracy: 0.3089

Epoch 00032: val_loss improved from 1.63955 to 1.63948, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 33/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6449 - accuracy: 0.3049 - val_loss: 1.6390 - val_accuracy: 0.3085

Epoch 00033: val_loss improved from 1.63948 to 1.63897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 34/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6442 - accuracy: 0.3045 - val_loss: 1.6390 - val_accuracy: 0.3096

Epoch 00034: val_loss did not improve from 1.63897
Epoch 35/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6437 - accuracy: 0.3049 - val_loss: 1.6388 - val_accuracy: 0.3082

Epoch 00035: val_loss improved from 1.63897 to 1.63878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 36/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6420 - accuracy: 0.3046 - val_loss: 1.6392 - val_accuracy: 0.3107

Epoch 00036: val_loss did not improve from 1.63878
Epoch 37/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6429 - accuracy: 0.3062 - val_loss: 1.6382 - val_accuracy: 0.3128

Epoch 00037: val_loss improved from 1.63878 to 1.63820, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 38/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6416 - accuracy: 0.3083 - val_loss: 1.6391 - val_accuracy: 0.3074

Epoch 00038: val_loss did not improve from 1.63820
Epoch 39/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6404 - accuracy: 0.3072 - val_loss: 1.6381 - val_accuracy: 0.3089

Epoch 00039: val_loss improved from 1.63820 to 1.63813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/1
Epoch 40/100
83/83 [==============================] - 10s 120ms/step - loss: 1.6410 - accuracy: 0.3071 - val_loss: 1.6387 - val_accuracy: 0.3096

Epoch 00040: val_loss did not improve from 1.63813
Epoch 41/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6410 - accuracy: 0.3074 - val_loss: 1.6395 - val_accuracy: 0.3079

Epoch 00041: val_loss did not improve from 1.63813
Epoch 42/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6400 - accuracy: 0.3077 - val_loss: 1.6401 - val_accuracy: 0.3070

Epoch 00042: val_loss did not improve from 1.63813
Epoch 43/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6409 - accuracy: 0.3067 - val_loss: 1.6392 - val_accuracy: 0.3104

Epoch 00043: val_loss did not improve from 1.63813
Epoch 44/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6393 - accuracy: 0.3068 - val_loss: 1.6391 - val_accuracy: 0.3083

Epoch 00044: val_loss did not improve from 1.63813
Epoch 45/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6388 - accuracy: 0.3070 - val_loss: 1.6396 - val_accuracy: 0.3077

Epoch 00045: val_loss did not improve from 1.63813
Epoch 46/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6387 - accuracy: 0.3080 - val_loss: 1.6404 - val_accuracy: 0.3098

Epoch 00046: val_loss did not improve from 1.63813
Epoch 47/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6381 - accuracy: 0.3091 - val_loss: 1.6397 - val_accuracy: 0.3104

Epoch 00047: val_loss did not improve from 1.63813
Epoch 00047: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 83s 6ms/step - loss: 1.6413 - accuracy: 0.3030
Testing Loss = 1.641299, Testing Accuracy = 0.302992
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 11s 130ms/step - loss: 11.9145 - accuracy: 0.2463 - val_loss: 8.2223 - val_accuracy: 0.2845

Epoch 00001: val_loss improved from inf to 8.22226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 2/100
83/83 [==============================] - 11s 133ms/step - loss: 6.4867 - accuracy: 0.2692 - val_loss: 5.1753 - val_accuracy: 0.2948

Epoch 00002: val_loss improved from 8.22226 to 5.17532, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 3/100
83/83 [==============================] - 11s 135ms/step - loss: 4.4995 - accuracy: 0.2773 - val_loss: 3.9170 - val_accuracy: 0.2962

Epoch 00003: val_loss improved from 5.17532 to 3.91700, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 4/100
83/83 [==============================] - 12s 139ms/step - loss: 3.5630 - accuracy: 0.2844 - val_loss: 3.2162 - val_accuracy: 0.3021

Epoch 00004: val_loss improved from 3.91700 to 3.21622, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 5/100
83/83 [==============================] - 9s 109ms/step - loss: 2.9940 - accuracy: 0.2853 - val_loss: 2.7577 - val_accuracy: 0.3005

Epoch 00005: val_loss improved from 3.21622 to 2.75772, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 6/100
83/83 [==============================] - 10s 114ms/step - loss: 2.6053 - accuracy: 0.2896 - val_loss: 2.4337 - val_accuracy: 0.3020

Epoch 00006: val_loss improved from 2.75772 to 2.43369, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 7/100
83/83 [==============================] - 12s 139ms/step - loss: 2.3310 - accuracy: 0.2923 - val_loss: 2.2039 - val_accuracy: 0.3033

Epoch 00007: val_loss improved from 2.43369 to 2.20391, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 8/100
83/83 [==============================] - 11s 132ms/step - loss: 2.1349 - accuracy: 0.2920 - val_loss: 2.0409 - val_accuracy: 0.3037

Epoch 00008: val_loss improved from 2.20391 to 2.04095, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 9/100
83/83 [==============================] - 12s 139ms/step - loss: 1.9954 - accuracy: 0.2909 - val_loss: 1.9245 - val_accuracy: 0.3030

Epoch 00009: val_loss improved from 2.04095 to 1.92446, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 10/100
83/83 [==============================] - 12s 139ms/step - loss: 1.8953 - accuracy: 0.2927 - val_loss: 1.8419 - val_accuracy: 0.3036

Epoch 00010: val_loss improved from 1.92446 to 1.84188, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 11/100
83/83 [==============================] - 9s 110ms/step - loss: 1.8255 - accuracy: 0.2971 - val_loss: 1.7837 - val_accuracy: 0.3067

Epoch 00011: val_loss improved from 1.84188 to 1.78369, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 12/100
83/83 [==============================] - 12s 139ms/step - loss: 1.7762 - accuracy: 0.2979 - val_loss: 1.7441 - val_accuracy: 0.3054

Epoch 00012: val_loss improved from 1.78369 to 1.74415, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 13/100
83/83 [==============================] - 12s 140ms/step - loss: 1.7404 - accuracy: 0.2967 - val_loss: 1.7157 - val_accuracy: 0.3027

Epoch 00013: val_loss improved from 1.74415 to 1.71570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 14/100
83/83 [==============================] - 12s 139ms/step - loss: 1.7163 - accuracy: 0.2973 - val_loss: 1.6954 - val_accuracy: 0.3049

Epoch 00014: val_loss improved from 1.71570 to 1.69542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 15/100
83/83 [==============================] - 12s 140ms/step - loss: 1.6994 - accuracy: 0.2978 - val_loss: 1.6821 - val_accuracy: 0.3044

Epoch 00015: val_loss improved from 1.69542 to 1.68213, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 16/100
83/83 [==============================] - 12s 140ms/step - loss: 1.6862 - accuracy: 0.2967 - val_loss: 1.6712 - val_accuracy: 0.3052

Epoch 00016: val_loss improved from 1.68213 to 1.67118, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 17/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6777 - accuracy: 0.3012 - val_loss: 1.6644 - val_accuracy: 0.3031

Epoch 00017: val_loss improved from 1.67118 to 1.66442, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 18/100
83/83 [==============================] - 8s 95ms/step - loss: 1.6707 - accuracy: 0.3003 - val_loss: 1.6583 - val_accuracy: 0.3051

Epoch 00018: val_loss improved from 1.66442 to 1.65830, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 19/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6652 - accuracy: 0.3005 - val_loss: 1.6544 - val_accuracy: 0.3058

Epoch 00019: val_loss improved from 1.65830 to 1.65438, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 20/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6618 - accuracy: 0.2991 - val_loss: 1.6507 - val_accuracy: 0.3054

Epoch 00020: val_loss improved from 1.65438 to 1.65075, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 21/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6598 - accuracy: 0.3020 - val_loss: 1.6502 - val_accuracy: 0.3059

Epoch 00021: val_loss improved from 1.65075 to 1.65019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 22/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6563 - accuracy: 0.2976 - val_loss: 1.6474 - val_accuracy: 0.3070

Epoch 00022: val_loss improved from 1.65019 to 1.64741, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 23/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6538 - accuracy: 0.3019 - val_loss: 1.6458 - val_accuracy: 0.3074

Epoch 00023: val_loss improved from 1.64741 to 1.64580, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 24/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6531 - accuracy: 0.3012 - val_loss: 1.6450 - val_accuracy: 0.3090

Epoch 00024: val_loss improved from 1.64580 to 1.64498, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 25/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6503 - accuracy: 0.3008 - val_loss: 1.6427 - val_accuracy: 0.3080

Epoch 00025: val_loss improved from 1.64498 to 1.64269, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 26/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6500 - accuracy: 0.3025 - val_loss: 1.6419 - val_accuracy: 0.3090

Epoch 00026: val_loss improved from 1.64269 to 1.64192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 27/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6489 - accuracy: 0.3033 - val_loss: 1.6409 - val_accuracy: 0.3088

Epoch 00027: val_loss improved from 1.64192 to 1.64090, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 28/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6474 - accuracy: 0.3034 - val_loss: 1.6416 - val_accuracy: 0.3104

Epoch 00028: val_loss did not improve from 1.64090
Epoch 29/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6474 - accuracy: 0.3019 - val_loss: 1.6402 - val_accuracy: 0.3106

Epoch 00029: val_loss improved from 1.64090 to 1.64022, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 30/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6458 - accuracy: 0.3050 - val_loss: 1.6392 - val_accuracy: 0.3087

Epoch 00030: val_loss improved from 1.64022 to 1.63916, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 31/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6454 - accuracy: 0.3044 - val_loss: 1.6408 - val_accuracy: 0.3099

Epoch 00031: val_loss did not improve from 1.63916
Epoch 32/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6450 - accuracy: 0.3039 - val_loss: 1.6397 - val_accuracy: 0.3091

Epoch 00032: val_loss did not improve from 1.63916
Epoch 33/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6448 - accuracy: 0.3039 - val_loss: 1.6389 - val_accuracy: 0.3105

Epoch 00033: val_loss improved from 1.63916 to 1.63891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 34/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6433 - accuracy: 0.3046 - val_loss: 1.6398 - val_accuracy: 0.3068

Epoch 00034: val_loss did not improve from 1.63891
Epoch 35/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6426 - accuracy: 0.3052 - val_loss: 1.6397 - val_accuracy: 0.3106

Epoch 00035: val_loss did not improve from 1.63891
Epoch 36/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6429 - accuracy: 0.3062 - val_loss: 1.6385 - val_accuracy: 0.3092

Epoch 00036: val_loss improved from 1.63891 to 1.63852, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 37/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6422 - accuracy: 0.3057 - val_loss: 1.6387 - val_accuracy: 0.3080

Epoch 00037: val_loss did not improve from 1.63852
Epoch 38/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6420 - accuracy: 0.3050 - val_loss: 1.6382 - val_accuracy: 0.3084

Epoch 00038: val_loss improved from 1.63852 to 1.63822, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/2
Epoch 39/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6408 - accuracy: 0.3059 - val_loss: 1.6393 - val_accuracy: 0.3093

Epoch 00039: val_loss did not improve from 1.63822
Epoch 40/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6417 - accuracy: 0.3085 - val_loss: 1.6389 - val_accuracy: 0.3092

Epoch 00040: val_loss did not improve from 1.63822
Epoch 41/100
83/83 [==============================] - 10s 120ms/step - loss: 1.6391 - accuracy: 0.3075 - val_loss: 1.6397 - val_accuracy: 0.3087

Epoch 00041: val_loss did not improve from 1.63822
Epoch 42/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6398 - accuracy: 0.3082 - val_loss: 1.6392 - val_accuracy: 0.3085

Epoch 00042: val_loss did not improve from 1.63822
Epoch 43/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6391 - accuracy: 0.3076 - val_loss: 1.6395 - val_accuracy: 0.3103

Epoch 00043: val_loss did not improve from 1.63822
Epoch 44/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6388 - accuracy: 0.3107 - val_loss: 1.6413 - val_accuracy: 0.3107

Epoch 00044: val_loss did not improve from 1.63822
Epoch 45/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6380 - accuracy: 0.3084 - val_loss: 1.6408 - val_accuracy: 0.3078

Epoch 00045: val_loss did not improve from 1.63822
Epoch 46/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6387 - accuracy: 0.3094 - val_loss: 1.6405 - val_accuracy: 0.3104

Epoch 00046: val_loss did not improve from 1.63822
Epoch 47/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6382 - accuracy: 0.3117 - val_loss: 1.6408 - val_accuracy: 0.3074

Epoch 00047: val_loss did not improve from 1.63822
Epoch 48/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6382 - accuracy: 0.3089 - val_loss: 1.6417 - val_accuracy: 0.3089

Epoch 00048: val_loss did not improve from 1.63822
Epoch 00048: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 80s 6ms/step - loss: 1.6418 - accuracy: 0.3043
Testing Loss = 1.641765, Testing Accuracy = 0.304332
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 12s 135ms/step - loss: 11.9286 - accuracy: 0.2484 - val_loss: 8.2492 - val_accuracy: 0.2777

Epoch 00001: val_loss improved from inf to 8.24916, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 2/100
83/83 [==============================] - 11s 134ms/step - loss: 6.5102 - accuracy: 0.2730 - val_loss: 5.2022 - val_accuracy: 0.2937

Epoch 00002: val_loss improved from 8.24916 to 5.20223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 3/100
83/83 [==============================] - 11s 131ms/step - loss: 4.5169 - accuracy: 0.2799 - val_loss: 3.9320 - val_accuracy: 0.2893

Epoch 00003: val_loss improved from 5.20223 to 3.93201, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 4/100
83/83 [==============================] - 11s 137ms/step - loss: 3.5717 - accuracy: 0.2842 - val_loss: 3.2236 - val_accuracy: 0.2999

Epoch 00004: val_loss improved from 3.93201 to 3.22357, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 5/100
83/83 [==============================] - 9s 108ms/step - loss: 2.9979 - accuracy: 0.2867 - val_loss: 2.7586 - val_accuracy: 0.3038

Epoch 00005: val_loss improved from 3.22357 to 2.75861, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 6/100
83/83 [==============================] - 9s 112ms/step - loss: 2.6081 - accuracy: 0.2901 - val_loss: 2.4364 - val_accuracy: 0.3024

Epoch 00006: val_loss improved from 2.75861 to 2.43638, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 7/100
83/83 [==============================] - 9s 113ms/step - loss: 2.3316 - accuracy: 0.2880 - val_loss: 2.2036 - val_accuracy: 0.3053

Epoch 00007: val_loss improved from 2.43638 to 2.20357, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 8/100
83/83 [==============================] - 9s 108ms/step - loss: 2.1341 - accuracy: 0.2915 - val_loss: 2.0388 - val_accuracy: 0.3067

Epoch 00008: val_loss improved from 2.20357 to 2.03884, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 9/100
83/83 [==============================] - 9s 112ms/step - loss: 1.9942 - accuracy: 0.2932 - val_loss: 1.9246 - val_accuracy: 0.3035

Epoch 00009: val_loss improved from 2.03884 to 1.92465, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 10/100
83/83 [==============================] - 12s 139ms/step - loss: 1.8961 - accuracy: 0.2920 - val_loss: 1.8410 - val_accuracy: 0.3055

Epoch 00010: val_loss improved from 1.92465 to 1.84103, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 11/100
83/83 [==============================] - 12s 139ms/step - loss: 1.8255 - accuracy: 0.2939 - val_loss: 1.7839 - val_accuracy: 0.3036

Epoch 00011: val_loss improved from 1.84103 to 1.78395, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 12/100
83/83 [==============================] - 11s 138ms/step - loss: 1.7760 - accuracy: 0.2942 - val_loss: 1.7438 - val_accuracy: 0.3055

Epoch 00012: val_loss improved from 1.78395 to 1.74384, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 13/100
83/83 [==============================] - 11s 138ms/step - loss: 1.7412 - accuracy: 0.2973 - val_loss: 1.7153 - val_accuracy: 0.3037

Epoch 00013: val_loss improved from 1.74384 to 1.71535, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 14/100
83/83 [==============================] - 12s 138ms/step - loss: 1.7170 - accuracy: 0.2958 - val_loss: 1.6968 - val_accuracy: 0.3020

Epoch 00014: val_loss improved from 1.71535 to 1.69680, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 15/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6988 - accuracy: 0.2982 - val_loss: 1.6813 - val_accuracy: 0.3023

Epoch 00015: val_loss improved from 1.69680 to 1.68130, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 16/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6856 - accuracy: 0.2960 - val_loss: 1.6721 - val_accuracy: 0.3017

Epoch 00016: val_loss improved from 1.68130 to 1.67212, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 17/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6769 - accuracy: 0.2994 - val_loss: 1.6643 - val_accuracy: 0.3059

Epoch 00017: val_loss improved from 1.67212 to 1.66425, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 18/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6710 - accuracy: 0.2998 - val_loss: 1.6601 - val_accuracy: 0.3013

Epoch 00018: val_loss improved from 1.66425 to 1.66008, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 19/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6664 - accuracy: 0.3012 - val_loss: 1.6549 - val_accuracy: 0.3043

Epoch 00019: val_loss improved from 1.66008 to 1.65489, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 20/100
83/83 [==============================] - 7s 87ms/step - loss: 1.6615 - accuracy: 0.3017 - val_loss: 1.6513 - val_accuracy: 0.3060

Epoch 00020: val_loss improved from 1.65489 to 1.65132, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 21/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6604 - accuracy: 0.2997 - val_loss: 1.6500 - val_accuracy: 0.3042

Epoch 00021: val_loss improved from 1.65132 to 1.64998, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 22/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6567 - accuracy: 0.3005 - val_loss: 1.6471 - val_accuracy: 0.3058

Epoch 00022: val_loss improved from 1.64998 to 1.64709, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 23/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6551 - accuracy: 0.3012 - val_loss: 1.6464 - val_accuracy: 0.3071

Epoch 00023: val_loss improved from 1.64709 to 1.64645, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 24/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6531 - accuracy: 0.3018 - val_loss: 1.6450 - val_accuracy: 0.3060

Epoch 00024: val_loss improved from 1.64645 to 1.64497, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 25/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6513 - accuracy: 0.3013 - val_loss: 1.6448 - val_accuracy: 0.3057

Epoch 00025: val_loss improved from 1.64497 to 1.64478, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 26/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6506 - accuracy: 0.3002 - val_loss: 1.6424 - val_accuracy: 0.3087

Epoch 00026: val_loss improved from 1.64478 to 1.64241, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 27/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6499 - accuracy: 0.3041 - val_loss: 1.6411 - val_accuracy: 0.3094

Epoch 00027: val_loss improved from 1.64241 to 1.64110, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 28/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6481 - accuracy: 0.3016 - val_loss: 1.6417 - val_accuracy: 0.3060

Epoch 00028: val_loss did not improve from 1.64110
Epoch 29/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6484 - accuracy: 0.3033 - val_loss: 1.6399 - val_accuracy: 0.3094

Epoch 00029: val_loss improved from 1.64110 to 1.63990, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 30/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6461 - accuracy: 0.3056 - val_loss: 1.6402 - val_accuracy: 0.3069

Epoch 00030: val_loss did not improve from 1.63990
Epoch 31/100
83/83 [==============================] - 7s 83ms/step - loss: 1.6458 - accuracy: 0.3043 - val_loss: 1.6403 - val_accuracy: 0.3107

Epoch 00031: val_loss did not improve from 1.63990
Epoch 32/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6457 - accuracy: 0.3049 - val_loss: 1.6395 - val_accuracy: 0.3087

Epoch 00032: val_loss improved from 1.63990 to 1.63953, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 33/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6452 - accuracy: 0.3060 - val_loss: 1.6397 - val_accuracy: 0.3111

Epoch 00033: val_loss did not improve from 1.63953
Epoch 34/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6443 - accuracy: 0.3044 - val_loss: 1.6403 - val_accuracy: 0.3080

Epoch 00034: val_loss did not improve from 1.63953
Epoch 35/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6436 - accuracy: 0.3057 - val_loss: 1.6397 - val_accuracy: 0.3102

Epoch 00035: val_loss did not improve from 1.63953
Epoch 36/100
83/83 [==============================] - 10s 121ms/step - loss: 1.6433 - accuracy: 0.3053 - val_loss: 1.6392 - val_accuracy: 0.3115

Epoch 00036: val_loss improved from 1.63953 to 1.63920, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 37/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6434 - accuracy: 0.3051 - val_loss: 1.6396 - val_accuracy: 0.3110

Epoch 00037: val_loss did not improve from 1.63920
Epoch 38/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6427 - accuracy: 0.3063 - val_loss: 1.6391 - val_accuracy: 0.3105

Epoch 00038: val_loss improved from 1.63920 to 1.63908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 39/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6413 - accuracy: 0.3057 - val_loss: 1.6386 - val_accuracy: 0.3100

Epoch 00039: val_loss improved from 1.63908 to 1.63858, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/3
Epoch 40/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6418 - accuracy: 0.3052 - val_loss: 1.6394 - val_accuracy: 0.3106

Epoch 00040: val_loss did not improve from 1.63858
Epoch 41/100
83/83 [==============================] - 10s 121ms/step - loss: 1.6420 - accuracy: 0.3059 - val_loss: 1.6401 - val_accuracy: 0.3097

Epoch 00041: val_loss did not improve from 1.63858
Epoch 42/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6411 - accuracy: 0.3065 - val_loss: 1.6402 - val_accuracy: 0.3087

Epoch 00042: val_loss did not improve from 1.63858
Epoch 43/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6375 - accuracy: 0.3081 - val_loss: 1.6402 - val_accuracy: 0.3072

Epoch 00043: val_loss did not improve from 1.63858
Epoch 44/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6393 - accuracy: 0.3089 - val_loss: 1.6392 - val_accuracy: 0.3141

Epoch 00044: val_loss did not improve from 1.63858
Epoch 45/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6384 - accuracy: 0.3094 - val_loss: 1.6400 - val_accuracy: 0.3121

Epoch 00045: val_loss did not improve from 1.63858
Epoch 46/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6391 - accuracy: 0.3082 - val_loss: 1.6406 - val_accuracy: 0.3092

Epoch 00046: val_loss did not improve from 1.63858
Epoch 47/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6379 - accuracy: 0.3094 - val_loss: 1.6409 - val_accuracy: 0.3101

Epoch 00047: val_loss did not improve from 1.63858
Epoch 48/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6381 - accuracy: 0.3097 - val_loss: 1.6416 - val_accuracy: 0.3112

Epoch 00048: val_loss did not improve from 1.63858
Epoch 49/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6384 - accuracy: 0.3089 - val_loss: 1.6413 - val_accuracy: 0.3137

Epoch 00049: val_loss did not improve from 1.63858
Epoch 00049: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 81s 6ms/step - loss: 1.6410 - accuracy: 0.3017
Testing Loss = 1.641011, Testing Accuracy = 0.301727
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 12s 131ms/step - loss: 11.9043 - accuracy: 0.2452 - val_loss: 8.2198 - val_accuracy: 0.2756

Epoch 00001: val_loss improved from inf to 8.21984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 2/100
83/83 [==============================] - 10s 125ms/step - loss: 6.4932 - accuracy: 0.2682 - val_loss: 5.1915 - val_accuracy: 0.2892

Epoch 00002: val_loss improved from 8.21984 to 5.19147, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 3/100
83/83 [==============================] - 11s 137ms/step - loss: 4.5117 - accuracy: 0.2776 - val_loss: 3.9301 - val_accuracy: 0.2902

Epoch 00003: val_loss improved from 5.19147 to 3.93009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 4/100
83/83 [==============================] - 11s 138ms/step - loss: 3.5737 - accuracy: 0.2840 - val_loss: 3.2274 - val_accuracy: 0.2934

Epoch 00004: val_loss improved from 3.93009 to 3.22742, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 5/100
83/83 [==============================] - 10s 119ms/step - loss: 3.0033 - accuracy: 0.2857 - val_loss: 2.7632 - val_accuracy: 0.2998

Epoch 00005: val_loss improved from 3.22742 to 2.76318, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 6/100
83/83 [==============================] - 12s 138ms/step - loss: 2.6110 - accuracy: 0.2867 - val_loss: 2.4385 - val_accuracy: 0.3020

Epoch 00006: val_loss improved from 2.76318 to 2.43849, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 7/100
83/83 [==============================] - 9s 112ms/step - loss: 2.3357 - accuracy: 0.2863 - val_loss: 2.2065 - val_accuracy: 0.3027

Epoch 00007: val_loss improved from 2.43849 to 2.20646, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 8/100
83/83 [==============================] - 11s 138ms/step - loss: 2.1375 - accuracy: 0.2885 - val_loss: 2.0424 - val_accuracy: 0.3033

Epoch 00008: val_loss improved from 2.20646 to 2.04237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 9/100
83/83 [==============================] - 12s 138ms/step - loss: 1.9954 - accuracy: 0.2931 - val_loss: 1.9263 - val_accuracy: 0.3028

Epoch 00009: val_loss improved from 2.04237 to 1.92627, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 10/100
83/83 [==============================] - 11s 137ms/step - loss: 1.8985 - accuracy: 0.2934 - val_loss: 1.8438 - val_accuracy: 0.3021

Epoch 00010: val_loss improved from 1.92627 to 1.84381, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 11/100
83/83 [==============================] - 12s 139ms/step - loss: 1.8259 - accuracy: 0.2969 - val_loss: 1.7853 - val_accuracy: 0.3035

Epoch 00011: val_loss improved from 1.84381 to 1.78534, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 12/100
83/83 [==============================] - 11s 137ms/step - loss: 1.7766 - accuracy: 0.2957 - val_loss: 1.7433 - val_accuracy: 0.3049

Epoch 00012: val_loss improved from 1.78534 to 1.74331, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 13/100
83/83 [==============================] - 7s 86ms/step - loss: 1.7431 - accuracy: 0.2974 - val_loss: 1.7161 - val_accuracy: 0.3024

Epoch 00013: val_loss improved from 1.74331 to 1.71606, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 14/100
83/83 [==============================] - 7s 86ms/step - loss: 1.7176 - accuracy: 0.2969 - val_loss: 1.6951 - val_accuracy: 0.3053

Epoch 00014: val_loss improved from 1.71606 to 1.69510, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 15/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6997 - accuracy: 0.2972 - val_loss: 1.6813 - val_accuracy: 0.3039

Epoch 00015: val_loss improved from 1.69510 to 1.68133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 16/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6872 - accuracy: 0.3003 - val_loss: 1.6695 - val_accuracy: 0.3071

Epoch 00016: val_loss improved from 1.68133 to 1.66954, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 17/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6781 - accuracy: 0.2993 - val_loss: 1.6623 - val_accuracy: 0.3071

Epoch 00017: val_loss improved from 1.66954 to 1.66228, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 18/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6709 - accuracy: 0.2985 - val_loss: 1.6581 - val_accuracy: 0.3050

Epoch 00018: val_loss improved from 1.66228 to 1.65810, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 19/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6667 - accuracy: 0.2989 - val_loss: 1.6543 - val_accuracy: 0.3070

Epoch 00019: val_loss improved from 1.65810 to 1.65431, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 20/100
83/83 [==============================] - 7s 86ms/step - loss: 1.6618 - accuracy: 0.2993 - val_loss: 1.6508 - val_accuracy: 0.3060

Epoch 00020: val_loss improved from 1.65431 to 1.65080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 21/100
83/83 [==============================] - 7s 83ms/step - loss: 1.6586 - accuracy: 0.3034 - val_loss: 1.6479 - val_accuracy: 0.3071

Epoch 00021: val_loss improved from 1.65080 to 1.64789, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 22/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6566 - accuracy: 0.3003 - val_loss: 1.6466 - val_accuracy: 0.3083

Epoch 00022: val_loss improved from 1.64789 to 1.64665, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 23/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6544 - accuracy: 0.2994 - val_loss: 1.6446 - val_accuracy: 0.3103

Epoch 00023: val_loss improved from 1.64665 to 1.64458, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 24/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6531 - accuracy: 0.3022 - val_loss: 1.6442 - val_accuracy: 0.3073

Epoch 00024: val_loss improved from 1.64458 to 1.64419, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 25/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6513 - accuracy: 0.2984 - val_loss: 1.6422 - val_accuracy: 0.3092

Epoch 00025: val_loss improved from 1.64419 to 1.64224, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 26/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6493 - accuracy: 0.3030 - val_loss: 1.6422 - val_accuracy: 0.3063

Epoch 00026: val_loss improved from 1.64224 to 1.64221, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 27/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6499 - accuracy: 0.3004 - val_loss: 1.6396 - val_accuracy: 0.3108

Epoch 00027: val_loss improved from 1.64221 to 1.63961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 28/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6479 - accuracy: 0.3012 - val_loss: 1.6398 - val_accuracy: 0.3092

Epoch 00028: val_loss did not improve from 1.63961
Epoch 29/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6469 - accuracy: 0.3023 - val_loss: 1.6405 - val_accuracy: 0.3094

Epoch 00029: val_loss did not improve from 1.63961
Epoch 30/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6458 - accuracy: 0.3037 - val_loss: 1.6399 - val_accuracy: 0.3086

Epoch 00030: val_loss did not improve from 1.63961
Epoch 31/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6454 - accuracy: 0.3052 - val_loss: 1.6388 - val_accuracy: 0.3096

Epoch 00031: val_loss improved from 1.63961 to 1.63878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 32/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6446 - accuracy: 0.3032 - val_loss: 1.6385 - val_accuracy: 0.3098

Epoch 00032: val_loss improved from 1.63878 to 1.63846, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 33/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6450 - accuracy: 0.3040 - val_loss: 1.6376 - val_accuracy: 0.3103

Epoch 00033: val_loss improved from 1.63846 to 1.63764, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 34/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6455 - accuracy: 0.3029 - val_loss: 1.6381 - val_accuracy: 0.3091

Epoch 00034: val_loss did not improve from 1.63764
Epoch 35/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6432 - accuracy: 0.3025 - val_loss: 1.6375 - val_accuracy: 0.3098

Epoch 00035: val_loss improved from 1.63764 to 1.63750, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 36/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6428 - accuracy: 0.3067 - val_loss: 1.6378 - val_accuracy: 0.3107

Epoch 00036: val_loss did not improve from 1.63750
Epoch 37/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6420 - accuracy: 0.3051 - val_loss: 1.6374 - val_accuracy: 0.3130

Epoch 00037: val_loss improved from 1.63750 to 1.63742, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 38/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6421 - accuracy: 0.3041 - val_loss: 1.6382 - val_accuracy: 0.3119

Epoch 00038: val_loss did not improve from 1.63742
Epoch 39/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6411 - accuracy: 0.3069 - val_loss: 1.6381 - val_accuracy: 0.3130

Epoch 00039: val_loss did not improve from 1.63742
Epoch 40/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6419 - accuracy: 0.3062 - val_loss: 1.6371 - val_accuracy: 0.3107

Epoch 00040: val_loss improved from 1.63742 to 1.63715, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/4
Epoch 41/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6410 - accuracy: 0.3030 - val_loss: 1.6377 - val_accuracy: 0.3102

Epoch 00041: val_loss did not improve from 1.63715
Epoch 42/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6404 - accuracy: 0.3074 - val_loss: 1.6385 - val_accuracy: 0.3106

Epoch 00042: val_loss did not improve from 1.63715
Epoch 43/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6389 - accuracy: 0.3087 - val_loss: 1.6382 - val_accuracy: 0.3107

Epoch 00043: val_loss did not improve from 1.63715
Epoch 44/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6394 - accuracy: 0.3081 - val_loss: 1.6387 - val_accuracy: 0.3113

Epoch 00044: val_loss did not improve from 1.63715
Epoch 45/100
83/83 [==============================] - 11s 133ms/step - loss: 1.6398 - accuracy: 0.3082 - val_loss: 1.6381 - val_accuracy: 0.3103

Epoch 00045: val_loss did not improve from 1.63715
Epoch 46/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6388 - accuracy: 0.3091 - val_loss: 1.6394 - val_accuracy: 0.3092

Epoch 00046: val_loss did not improve from 1.63715
Epoch 47/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6376 - accuracy: 0.3101 - val_loss: 1.6399 - val_accuracy: 0.3106

Epoch 00047: val_loss did not improve from 1.63715
Epoch 48/100
83/83 [==============================] - 9s 110ms/step - loss: 1.6378 - accuracy: 0.3092 - val_loss: 1.6390 - val_accuracy: 0.3115

Epoch 00048: val_loss did not improve from 1.63715
Epoch 49/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6370 - accuracy: 0.3073 - val_loss: 1.6399 - val_accuracy: 0.3129

Epoch 00049: val_loss did not improve from 1.63715
Epoch 50/100
83/83 [==============================] - 10s 126ms/step - loss: 1.6380 - accuracy: 0.3083 - val_loss: 1.6412 - val_accuracy: 0.3084

Epoch 00050: val_loss did not improve from 1.63715
Epoch 00050: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 83s 6ms/step - loss: 1.6402 - accuracy: 0.3037
Testing Loss = 1.640246, Testing Accuracy = 0.303736
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 10s 110ms/step - loss: 11.8932 - accuracy: 0.2459 - val_loss: 8.1891 - val_accuracy: 0.2868

Epoch 00001: val_loss improved from inf to 8.18911, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 2/100
83/83 [==============================] - 12s 139ms/step - loss: 6.4619 - accuracy: 0.2679 - val_loss: 5.1660 - val_accuracy: 0.2892

Epoch 00002: val_loss improved from 8.18911 to 5.16604, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 3/100
83/83 [==============================] - 12s 139ms/step - loss: 4.4926 - accuracy: 0.2762 - val_loss: 3.9145 - val_accuracy: 0.2942

Epoch 00003: val_loss improved from 5.16604 to 3.91449, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 4/100
83/83 [==============================] - 12s 139ms/step - loss: 3.5633 - accuracy: 0.2828 - val_loss: 3.2171 - val_accuracy: 0.2963

Epoch 00004: val_loss improved from 3.91449 to 3.21707, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 5/100
83/83 [==============================] - 12s 139ms/step - loss: 2.9937 - accuracy: 0.2878 - val_loss: 2.7569 - val_accuracy: 0.2991

Epoch 00005: val_loss improved from 3.21707 to 2.75691, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 6/100
83/83 [==============================] - 12s 139ms/step - loss: 2.6056 - accuracy: 0.2899 - val_loss: 2.4324 - val_accuracy: 0.3011

Epoch 00006: val_loss improved from 2.75691 to 2.43239, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 7/100
83/83 [==============================] - 7s 86ms/step - loss: 2.3305 - accuracy: 0.2909 - val_loss: 2.2041 - val_accuracy: 0.3018

Epoch 00007: val_loss improved from 2.43239 to 2.20405, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 8/100
83/83 [==============================] - 7s 87ms/step - loss: 2.1336 - accuracy: 0.2921 - val_loss: 2.0391 - val_accuracy: 0.3033

Epoch 00008: val_loss improved from 2.20405 to 2.03911, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 9/100
83/83 [==============================] - 7s 86ms/step - loss: 1.9939 - accuracy: 0.2935 - val_loss: 1.9233 - val_accuracy: 0.3046

Epoch 00009: val_loss improved from 2.03911 to 1.92327, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 10/100
83/83 [==============================] - 7s 87ms/step - loss: 1.8958 - accuracy: 0.2951 - val_loss: 1.8422 - val_accuracy: 0.3026

Epoch 00010: val_loss improved from 1.92327 to 1.84219, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 11/100
83/83 [==============================] - 7s 86ms/step - loss: 1.8255 - accuracy: 0.2941 - val_loss: 1.7849 - val_accuracy: 0.3029

Epoch 00011: val_loss improved from 1.84219 to 1.78490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 12/100
83/83 [==============================] - 7s 86ms/step - loss: 1.7763 - accuracy: 0.2981 - val_loss: 1.7428 - val_accuracy: 0.3058

Epoch 00012: val_loss improved from 1.78490 to 1.74284, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 13/100
83/83 [==============================] - 7s 87ms/step - loss: 1.7406 - accuracy: 0.2952 - val_loss: 1.7143 - val_accuracy: 0.3054

Epoch 00013: val_loss improved from 1.74284 to 1.71431, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 14/100
83/83 [==============================] - 7s 87ms/step - loss: 1.7164 - accuracy: 0.2996 - val_loss: 1.6943 - val_accuracy: 0.3061

Epoch 00014: val_loss improved from 1.71431 to 1.69434, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 15/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6990 - accuracy: 0.2985 - val_loss: 1.6812 - val_accuracy: 0.3078

Epoch 00015: val_loss improved from 1.69434 to 1.68117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 16/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6870 - accuracy: 0.2975 - val_loss: 1.6717 - val_accuracy: 0.3059

Epoch 00016: val_loss improved from 1.68117 to 1.67174, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 17/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6784 - accuracy: 0.3000 - val_loss: 1.6650 - val_accuracy: 0.3052

Epoch 00017: val_loss improved from 1.67174 to 1.66501, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 18/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6709 - accuracy: 0.3007 - val_loss: 1.6581 - val_accuracy: 0.3066

Epoch 00018: val_loss improved from 1.66501 to 1.65812, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 19/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6648 - accuracy: 0.2998 - val_loss: 1.6545 - val_accuracy: 0.3073

Epoch 00019: val_loss improved from 1.65812 to 1.65446, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 20/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6616 - accuracy: 0.3018 - val_loss: 1.6516 - val_accuracy: 0.3063

Epoch 00020: val_loss improved from 1.65446 to 1.65159, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 21/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6598 - accuracy: 0.2985 - val_loss: 1.6495 - val_accuracy: 0.3049

Epoch 00021: val_loss improved from 1.65159 to 1.64946, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 22/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6569 - accuracy: 0.3011 - val_loss: 1.6468 - val_accuracy: 0.3077

Epoch 00022: val_loss improved from 1.64946 to 1.64684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 23/100
83/83 [==============================] - 11s 134ms/step - loss: 1.6546 - accuracy: 0.3018 - val_loss: 1.6461 - val_accuracy: 0.3063

Epoch 00023: val_loss improved from 1.64684 to 1.64611, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 24/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6533 - accuracy: 0.3034 - val_loss: 1.6452 - val_accuracy: 0.3104

Epoch 00024: val_loss improved from 1.64611 to 1.64525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 25/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6508 - accuracy: 0.3049 - val_loss: 1.6438 - val_accuracy: 0.3076

Epoch 00025: val_loss improved from 1.64525 to 1.64380, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 26/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6498 - accuracy: 0.3033 - val_loss: 1.6432 - val_accuracy: 0.3060

Epoch 00026: val_loss improved from 1.64380 to 1.64319, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 27/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6486 - accuracy: 0.3031 - val_loss: 1.6427 - val_accuracy: 0.3054

Epoch 00027: val_loss improved from 1.64319 to 1.64269, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 28/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6492 - accuracy: 0.3033 - val_loss: 1.6421 - val_accuracy: 0.3066

Epoch 00028: val_loss improved from 1.64269 to 1.64210, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 29/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6471 - accuracy: 0.3029 - val_loss: 1.6404 - val_accuracy: 0.3095

Epoch 00029: val_loss improved from 1.64210 to 1.64041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 30/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6464 - accuracy: 0.3049 - val_loss: 1.6422 - val_accuracy: 0.3088

Epoch 00030: val_loss did not improve from 1.64041
Epoch 31/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6458 - accuracy: 0.3067 - val_loss: 1.6412 - val_accuracy: 0.3079

Epoch 00031: val_loss did not improve from 1.64041
Epoch 32/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6444 - accuracy: 0.3051 - val_loss: 1.6416 - val_accuracy: 0.3088

Epoch 00032: val_loss did not improve from 1.64041
Epoch 33/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6438 - accuracy: 0.3056 - val_loss: 1.6410 - val_accuracy: 0.3102

Epoch 00033: val_loss did not improve from 1.64041
Epoch 34/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6445 - accuracy: 0.3032 - val_loss: 1.6411 - val_accuracy: 0.3092

Epoch 00034: val_loss did not improve from 1.64041
Epoch 35/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6432 - accuracy: 0.3071 - val_loss: 1.6404 - val_accuracy: 0.3090

Epoch 00035: val_loss did not improve from 1.64041
Epoch 36/100
83/83 [==============================] - 10s 120ms/step - loss: 1.6417 - accuracy: 0.3071 - val_loss: 1.6416 - val_accuracy: 0.3094

Epoch 00036: val_loss did not improve from 1.64041
Epoch 37/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6439 - accuracy: 0.3053 - val_loss: 1.6400 - val_accuracy: 0.3088

Epoch 00037: val_loss improved from 1.64041 to 1.64003, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/5
Epoch 38/100
83/83 [==============================] - 11s 134ms/step - loss: 1.6408 - accuracy: 0.3098 - val_loss: 1.6405 - val_accuracy: 0.3099

Epoch 00038: val_loss did not improve from 1.64003
Epoch 39/100
83/83 [==============================] - 10s 118ms/step - loss: 1.6414 - accuracy: 0.3074 - val_loss: 1.6411 - val_accuracy: 0.3071

Epoch 00039: val_loss did not improve from 1.64003
Epoch 40/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6403 - accuracy: 0.3079 - val_loss: 1.6417 - val_accuracy: 0.3070

Epoch 00040: val_loss did not improve from 1.64003
Epoch 41/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6398 - accuracy: 0.3075 - val_loss: 1.6419 - val_accuracy: 0.3050

Epoch 00041: val_loss did not improve from 1.64003
Epoch 42/100
83/83 [==============================] - 11s 133ms/step - loss: 1.6395 - accuracy: 0.3086 - val_loss: 1.6423 - val_accuracy: 0.3077

Epoch 00042: val_loss did not improve from 1.64003
Epoch 43/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6388 - accuracy: 0.3085 - val_loss: 1.6428 - val_accuracy: 0.3060

Epoch 00043: val_loss did not improve from 1.64003
Epoch 44/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6387 - accuracy: 0.3094 - val_loss: 1.6428 - val_accuracy: 0.3089

Epoch 00044: val_loss did not improve from 1.64003
Epoch 45/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6390 - accuracy: 0.3074 - val_loss: 1.6431 - val_accuracy: 0.3104

Epoch 00045: val_loss did not improve from 1.64003
Epoch 46/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6380 - accuracy: 0.3135 - val_loss: 1.6447 - val_accuracy: 0.3068

Epoch 00046: val_loss did not improve from 1.64003
Epoch 47/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6375 - accuracy: 0.3110 - val_loss: 1.6455 - val_accuracy: 0.3066

Epoch 00047: val_loss did not improve from 1.64003
Epoch 00047: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 82s 6ms/step - loss: 1.6429 - accuracy: 0.3032
Testing Loss = 1.642895, Testing Accuracy = 0.303215
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 8s 89ms/step - loss: 11.9466 - accuracy: 0.2490 - val_loss: 8.2649 - val_accuracy: 0.2816

Epoch 00001: val_loss improved from inf to 8.26486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 2/100
83/83 [==============================] - 7s 87ms/step - loss: 6.5164 - accuracy: 0.2720 - val_loss: 5.2015 - val_accuracy: 0.2839

Epoch 00002: val_loss improved from 8.26486 to 5.20153, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 3/100
83/83 [==============================] - 7s 86ms/step - loss: 4.5140 - accuracy: 0.2783 - val_loss: 3.9300 - val_accuracy: 0.2883

Epoch 00003: val_loss improved from 5.20153 to 3.93003, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 4/100
83/83 [==============================] - 7s 88ms/step - loss: 3.5687 - accuracy: 0.2820 - val_loss: 3.2218 - val_accuracy: 0.2951

Epoch 00004: val_loss improved from 3.93003 to 3.22177, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 5/100
83/83 [==============================] - 7s 88ms/step - loss: 2.9968 - accuracy: 0.2892 - val_loss: 2.7580 - val_accuracy: 0.2980

Epoch 00005: val_loss improved from 3.22177 to 2.75801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 6/100
83/83 [==============================] - 7s 87ms/step - loss: 2.6057 - accuracy: 0.2865 - val_loss: 2.4318 - val_accuracy: 0.2995

Epoch 00006: val_loss improved from 2.75801 to 2.43180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 7/100
83/83 [==============================] - 7s 86ms/step - loss: 2.3284 - accuracy: 0.2888 - val_loss: 2.2022 - val_accuracy: 0.2987

Epoch 00007: val_loss improved from 2.43180 to 2.20219, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 8/100
83/83 [==============================] - 7s 81ms/step - loss: 2.1303 - accuracy: 0.2902 - val_loss: 2.0356 - val_accuracy: 0.3045

Epoch 00008: val_loss improved from 2.20219 to 2.03563, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 9/100
83/83 [==============================] - 7s 83ms/step - loss: 1.9898 - accuracy: 0.2920 - val_loss: 1.9204 - val_accuracy: 0.3045

Epoch 00009: val_loss improved from 2.03563 to 1.92037, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 10/100
83/83 [==============================] - 7s 85ms/step - loss: 1.8920 - accuracy: 0.2931 - val_loss: 1.8391 - val_accuracy: 0.3016

Epoch 00010: val_loss improved from 1.92037 to 1.83912, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 11/100
83/83 [==============================] - 7s 85ms/step - loss: 1.8235 - accuracy: 0.2932 - val_loss: 1.7821 - val_accuracy: 0.3021

Epoch 00011: val_loss improved from 1.83912 to 1.78214, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 12/100
83/83 [==============================] - 7s 85ms/step - loss: 1.7734 - accuracy: 0.2970 - val_loss: 1.7420 - val_accuracy: 0.3027

Epoch 00012: val_loss improved from 1.78214 to 1.74204, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 13/100
83/83 [==============================] - 7s 85ms/step - loss: 1.7383 - accuracy: 0.2966 - val_loss: 1.7125 - val_accuracy: 0.3039

Epoch 00013: val_loss improved from 1.74204 to 1.71250, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 14/100
83/83 [==============================] - 8s 95ms/step - loss: 1.7152 - accuracy: 0.3000 - val_loss: 1.6926 - val_accuracy: 0.3071

Epoch 00014: val_loss improved from 1.71250 to 1.69258, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 15/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6969 - accuracy: 0.2981 - val_loss: 1.6795 - val_accuracy: 0.3064

Epoch 00015: val_loss improved from 1.69258 to 1.67954, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 16/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6848 - accuracy: 0.2982 - val_loss: 1.6702 - val_accuracy: 0.3047

Epoch 00016: val_loss improved from 1.67954 to 1.67019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 17/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6776 - accuracy: 0.2962 - val_loss: 1.6632 - val_accuracy: 0.3041

Epoch 00017: val_loss improved from 1.67019 to 1.66321, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 18/100
83/83 [==============================] - 10s 116ms/step - loss: 1.6698 - accuracy: 0.3010 - val_loss: 1.6570 - val_accuracy: 0.3063

Epoch 00018: val_loss improved from 1.66321 to 1.65697, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 19/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6663 - accuracy: 0.2966 - val_loss: 1.6532 - val_accuracy: 0.3041

Epoch 00019: val_loss improved from 1.65697 to 1.65318, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 20/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6616 - accuracy: 0.3021 - val_loss: 1.6507 - val_accuracy: 0.3075

Epoch 00020: val_loss improved from 1.65318 to 1.65067, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 21/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6585 - accuracy: 0.3023 - val_loss: 1.6486 - val_accuracy: 0.3061

Epoch 00021: val_loss improved from 1.65067 to 1.64862, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 22/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6554 - accuracy: 0.3003 - val_loss: 1.6457 - val_accuracy: 0.3092

Epoch 00022: val_loss improved from 1.64862 to 1.64568, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 23/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6540 - accuracy: 0.3022 - val_loss: 1.6450 - val_accuracy: 0.3076

Epoch 00023: val_loss improved from 1.64568 to 1.64497, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 24/100
83/83 [==============================] - 10s 118ms/step - loss: 1.6524 - accuracy: 0.3001 - val_loss: 1.6433 - val_accuracy: 0.3077

Epoch 00024: val_loss improved from 1.64497 to 1.64327, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 25/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6510 - accuracy: 0.3028 - val_loss: 1.6420 - val_accuracy: 0.3099

Epoch 00025: val_loss improved from 1.64327 to 1.64199, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 26/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6496 - accuracy: 0.3017 - val_loss: 1.6413 - val_accuracy: 0.3063

Epoch 00026: val_loss improved from 1.64199 to 1.64133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 27/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6480 - accuracy: 0.3067 - val_loss: 1.6413 - val_accuracy: 0.3092

Epoch 00027: val_loss did not improve from 1.64133
Epoch 28/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6476 - accuracy: 0.3034 - val_loss: 1.6415 - val_accuracy: 0.3068

Epoch 00028: val_loss did not improve from 1.64133
Epoch 29/100
83/83 [==============================] - 11s 136ms/step - loss: 1.6476 - accuracy: 0.3010 - val_loss: 1.6408 - val_accuracy: 0.3092

Epoch 00029: val_loss improved from 1.64133 to 1.64083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 30/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6455 - accuracy: 0.3056 - val_loss: 1.6390 - val_accuracy: 0.3088

Epoch 00030: val_loss improved from 1.64083 to 1.63901, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 31/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6443 - accuracy: 0.3075 - val_loss: 1.6394 - val_accuracy: 0.3104

Epoch 00031: val_loss did not improve from 1.63901
Epoch 32/100
83/83 [==============================] - 11s 134ms/step - loss: 1.6443 - accuracy: 0.3036 - val_loss: 1.6400 - val_accuracy: 0.3079

Epoch 00032: val_loss did not improve from 1.63901
Epoch 33/100
83/83 [==============================] - 9s 110ms/step - loss: 1.6441 - accuracy: 0.3046 - val_loss: 1.6390 - val_accuracy: 0.3086

Epoch 00033: val_loss improved from 1.63901 to 1.63900, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/6
Epoch 34/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6440 - accuracy: 0.3053 - val_loss: 1.6397 - val_accuracy: 0.3095

Epoch 00034: val_loss did not improve from 1.63900
Epoch 35/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6426 - accuracy: 0.3052 - val_loss: 1.6396 - val_accuracy: 0.3092

Epoch 00035: val_loss did not improve from 1.63900
Epoch 36/100
83/83 [==============================] - 9s 110ms/step - loss: 1.6420 - accuracy: 0.3063 - val_loss: 1.6391 - val_accuracy: 0.3106

Epoch 00036: val_loss did not improve from 1.63900
Epoch 37/100
83/83 [==============================] - 11s 133ms/step - loss: 1.6409 - accuracy: 0.3056 - val_loss: 1.6399 - val_accuracy: 0.3076

Epoch 00037: val_loss did not improve from 1.63900
Epoch 38/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6404 - accuracy: 0.3067 - val_loss: 1.6391 - val_accuracy: 0.3101

Epoch 00038: val_loss did not improve from 1.63900
Epoch 39/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6401 - accuracy: 0.3076 - val_loss: 1.6398 - val_accuracy: 0.3099

Epoch 00039: val_loss did not improve from 1.63900
Epoch 40/100
83/83 [==============================] - 12s 139ms/step - loss: 1.6394 - accuracy: 0.3087 - val_loss: 1.6413 - val_accuracy: 0.3088

Epoch 00040: val_loss did not improve from 1.63900
Epoch 00040: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 81s 6ms/step - loss: 1.6425 - accuracy: 0.3035
Testing Loss = 1.642518, Testing Accuracy = 0.303513
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 12s 133ms/step - loss: 11.8410 - accuracy: 0.2481 - val_loss: 8.1458 - val_accuracy: 0.2747

Epoch 00001: val_loss improved from inf to 8.14580, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 2/100
83/83 [==============================] - 7s 86ms/step - loss: 6.4309 - accuracy: 0.2673 - val_loss: 5.1442 - val_accuracy: 0.2817

Epoch 00002: val_loss improved from 8.14580 to 5.14423, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 3/100
83/83 [==============================] - 7s 86ms/step - loss: 4.4748 - accuracy: 0.2803 - val_loss: 3.9011 - val_accuracy: 0.2948

Epoch 00003: val_loss improved from 5.14423 to 3.90110, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 4/100
83/83 [==============================] - 7s 85ms/step - loss: 3.5528 - accuracy: 0.2806 - val_loss: 3.2116 - val_accuracy: 0.2953

Epoch 00004: val_loss improved from 3.90110 to 3.21160, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 5/100
83/83 [==============================] - 7s 86ms/step - loss: 2.9889 - accuracy: 0.2828 - val_loss: 2.7521 - val_accuracy: 0.3016

Epoch 00005: val_loss improved from 3.21160 to 2.75206, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 6/100
83/83 [==============================] - 7s 87ms/step - loss: 2.6010 - accuracy: 0.2885 - val_loss: 2.4286 - val_accuracy: 0.3044

Epoch 00006: val_loss improved from 2.75206 to 2.42855, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 7/100
83/83 [==============================] - 7s 87ms/step - loss: 2.3268 - accuracy: 0.2880 - val_loss: 2.1998 - val_accuracy: 0.3031

Epoch 00007: val_loss improved from 2.42855 to 2.19981, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 8/100
83/83 [==============================] - 7s 88ms/step - loss: 2.1308 - accuracy: 0.2913 - val_loss: 2.0365 - val_accuracy: 0.3032

Epoch 00008: val_loss improved from 2.19981 to 2.03648, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 9/100
83/83 [==============================] - 7s 88ms/step - loss: 1.9921 - accuracy: 0.2923 - val_loss: 1.9201 - val_accuracy: 0.3045

Epoch 00009: val_loss improved from 2.03648 to 1.92011, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 10/100
83/83 [==============================] - 7s 84ms/step - loss: 1.8939 - accuracy: 0.2941 - val_loss: 1.8391 - val_accuracy: 0.3047

Epoch 00010: val_loss improved from 1.92011 to 1.83914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 11/100
83/83 [==============================] - 7s 85ms/step - loss: 1.8237 - accuracy: 0.2965 - val_loss: 1.7826 - val_accuracy: 0.3066

Epoch 00011: val_loss improved from 1.83914 to 1.78256, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 12/100
83/83 [==============================] - 7s 84ms/step - loss: 1.7741 - accuracy: 0.2956 - val_loss: 1.7425 - val_accuracy: 0.3056

Epoch 00012: val_loss improved from 1.78256 to 1.74254, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 13/100
83/83 [==============================] - 7s 85ms/step - loss: 1.7399 - accuracy: 0.2981 - val_loss: 1.7151 - val_accuracy: 0.3058

Epoch 00013: val_loss improved from 1.74254 to 1.71512, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 14/100
83/83 [==============================] - 7s 85ms/step - loss: 1.7163 - accuracy: 0.2964 - val_loss: 1.6949 - val_accuracy: 0.3063

Epoch 00014: val_loss improved from 1.71512 to 1.69486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 15/100
83/83 [==============================] - 7s 85ms/step - loss: 1.6997 - accuracy: 0.2975 - val_loss: 1.6808 - val_accuracy: 0.3059

Epoch 00015: val_loss improved from 1.69486 to 1.68076, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 16/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6866 - accuracy: 0.2961 - val_loss: 1.6706 - val_accuracy: 0.3063

Epoch 00016: val_loss improved from 1.68076 to 1.67058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 17/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6772 - accuracy: 0.3002 - val_loss: 1.6651 - val_accuracy: 0.3056

Epoch 00017: val_loss improved from 1.67058 to 1.66506, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 18/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6715 - accuracy: 0.3005 - val_loss: 1.6597 - val_accuracy: 0.3039

Epoch 00018: val_loss improved from 1.66506 to 1.65971, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 19/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6675 - accuracy: 0.2988 - val_loss: 1.6536 - val_accuracy: 0.3088

Epoch 00019: val_loss improved from 1.65971 to 1.65362, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 20/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6631 - accuracy: 0.2995 - val_loss: 1.6503 - val_accuracy: 0.3067

Epoch 00020: val_loss improved from 1.65362 to 1.65029, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 21/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6590 - accuracy: 0.3014 - val_loss: 1.6485 - val_accuracy: 0.3085

Epoch 00021: val_loss improved from 1.65029 to 1.64853, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 22/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6568 - accuracy: 0.3021 - val_loss: 1.6465 - val_accuracy: 0.3081

Epoch 00022: val_loss improved from 1.64853 to 1.64649, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 23/100
83/83 [==============================] - 10s 118ms/step - loss: 1.6544 - accuracy: 0.3000 - val_loss: 1.6455 - val_accuracy: 0.3073

Epoch 00023: val_loss improved from 1.64649 to 1.64548, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 24/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6530 - accuracy: 0.3016 - val_loss: 1.6445 - val_accuracy: 0.3066

Epoch 00024: val_loss improved from 1.64548 to 1.64450, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 25/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6513 - accuracy: 0.3015 - val_loss: 1.6437 - val_accuracy: 0.3064

Epoch 00025: val_loss improved from 1.64450 to 1.64367, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 26/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6506 - accuracy: 0.3032 - val_loss: 1.6434 - val_accuracy: 0.3079

Epoch 00026: val_loss improved from 1.64367 to 1.64341, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 27/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6492 - accuracy: 0.3048 - val_loss: 1.6433 - val_accuracy: 0.3075

Epoch 00027: val_loss improved from 1.64341 to 1.64332, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 28/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6486 - accuracy: 0.3025 - val_loss: 1.6409 - val_accuracy: 0.3104

Epoch 00028: val_loss improved from 1.64332 to 1.64091, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 29/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6478 - accuracy: 0.3017 - val_loss: 1.6408 - val_accuracy: 0.3067

Epoch 00029: val_loss improved from 1.64091 to 1.64084, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 30/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6473 - accuracy: 0.3051 - val_loss: 1.6392 - val_accuracy: 0.3093

Epoch 00030: val_loss improved from 1.64084 to 1.63916, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 31/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6451 - accuracy: 0.3026 - val_loss: 1.6395 - val_accuracy: 0.3112

Epoch 00031: val_loss did not improve from 1.63916
Epoch 32/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6449 - accuracy: 0.3047 - val_loss: 1.6398 - val_accuracy: 0.3088

Epoch 00032: val_loss did not improve from 1.63916
Epoch 33/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6446 - accuracy: 0.3055 - val_loss: 1.6389 - val_accuracy: 0.3080

Epoch 00033: val_loss improved from 1.63916 to 1.63892, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 34/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6433 - accuracy: 0.3028 - val_loss: 1.6382 - val_accuracy: 0.3112

Epoch 00034: val_loss improved from 1.63892 to 1.63817, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/7
Epoch 35/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6435 - accuracy: 0.3054 - val_loss: 1.6383 - val_accuracy: 0.3098

Epoch 00035: val_loss did not improve from 1.63817
Epoch 36/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6439 - accuracy: 0.3054 - val_loss: 1.6393 - val_accuracy: 0.3104

Epoch 00036: val_loss did not improve from 1.63817
Epoch 37/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6422 - accuracy: 0.3055 - val_loss: 1.6383 - val_accuracy: 0.3113

Epoch 00037: val_loss did not improve from 1.63817
Epoch 38/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6418 - accuracy: 0.3039 - val_loss: 1.6388 - val_accuracy: 0.3092

Epoch 00038: val_loss did not improve from 1.63817
Epoch 39/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6421 - accuracy: 0.3060 - val_loss: 1.6387 - val_accuracy: 0.3100

Epoch 00039: val_loss did not improve from 1.63817
Epoch 40/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6404 - accuracy: 0.3058 - val_loss: 1.6387 - val_accuracy: 0.3104

Epoch 00040: val_loss did not improve from 1.63817
Epoch 41/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6403 - accuracy: 0.3048 - val_loss: 1.6387 - val_accuracy: 0.3102

Epoch 00041: val_loss did not improve from 1.63817
Epoch 42/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6407 - accuracy: 0.3055 - val_loss: 1.6389 - val_accuracy: 0.3110

Epoch 00042: val_loss did not improve from 1.63817
Epoch 43/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6401 - accuracy: 0.3059 - val_loss: 1.6398 - val_accuracy: 0.3093

Epoch 00043: val_loss did not improve from 1.63817
Epoch 44/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6396 - accuracy: 0.3055 - val_loss: 1.6395 - val_accuracy: 0.3104

Epoch 00044: val_loss did not improve from 1.63817
Epoch 00044: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 84s 6ms/step - loss: 1.6411 - accuracy: 0.3043
Testing Loss = 1.641089, Testing Accuracy = 0.304257
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 8s 87ms/step - loss: 11.9019 - accuracy: 0.2462 - val_loss: 8.2031 - val_accuracy: 0.2721

Epoch 00001: val_loss improved from inf to 8.20314, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 2/100
83/83 [==============================] - 7s 85ms/step - loss: 6.4662 - accuracy: 0.2715 - val_loss: 5.1656 - val_accuracy: 0.2804

Epoch 00002: val_loss improved from 8.20314 to 5.16564, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 3/100
83/83 [==============================] - 7s 86ms/step - loss: 4.4859 - accuracy: 0.2784 - val_loss: 3.9105 - val_accuracy: 0.2909

Epoch 00003: val_loss improved from 5.16564 to 3.91046, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 4/100
83/83 [==============================] - 7s 86ms/step - loss: 3.5558 - accuracy: 0.2832 - val_loss: 3.2138 - val_accuracy: 0.2976

Epoch 00004: val_loss improved from 3.91046 to 3.21378, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 5/100
83/83 [==============================] - 7s 86ms/step - loss: 2.9902 - accuracy: 0.2864 - val_loss: 2.7537 - val_accuracy: 0.2990

Epoch 00005: val_loss improved from 3.21378 to 2.75368, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 6/100
83/83 [==============================] - 7s 85ms/step - loss: 2.6024 - accuracy: 0.2872 - val_loss: 2.4308 - val_accuracy: 0.3015

Epoch 00006: val_loss improved from 2.75368 to 2.43082, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 7/100
83/83 [==============================] - 7s 86ms/step - loss: 2.3272 - accuracy: 0.2927 - val_loss: 2.1997 - val_accuracy: 0.3039

Epoch 00007: val_loss improved from 2.43082 to 2.19969, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 8/100
83/83 [==============================] - 7s 85ms/step - loss: 2.1324 - accuracy: 0.2880 - val_loss: 2.0374 - val_accuracy: 0.3019

Epoch 00008: val_loss improved from 2.19969 to 2.03739, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 9/100
83/83 [==============================] - 7s 84ms/step - loss: 1.9914 - accuracy: 0.2924 - val_loss: 1.9215 - val_accuracy: 0.3020

Epoch 00009: val_loss improved from 2.03739 to 1.92152, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 10/100
83/83 [==============================] - 7s 84ms/step - loss: 1.8944 - accuracy: 0.2938 - val_loss: 1.8418 - val_accuracy: 0.3009

Epoch 00010: val_loss improved from 1.92152 to 1.84180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 11/100
83/83 [==============================] - 7s 84ms/step - loss: 1.8230 - accuracy: 0.2952 - val_loss: 1.7836 - val_accuracy: 0.3021

Epoch 00011: val_loss improved from 1.84180 to 1.78358, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 12/100
83/83 [==============================] - 7s 84ms/step - loss: 1.7738 - accuracy: 0.2991 - val_loss: 1.7426 - val_accuracy: 0.3045

Epoch 00012: val_loss improved from 1.78358 to 1.74264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 13/100
83/83 [==============================] - 7s 84ms/step - loss: 1.7400 - accuracy: 0.2962 - val_loss: 1.7150 - val_accuracy: 0.3062

Epoch 00013: val_loss improved from 1.74264 to 1.71500, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 14/100
83/83 [==============================] - 7s 84ms/step - loss: 1.7154 - accuracy: 0.2974 - val_loss: 1.6943 - val_accuracy: 0.3039

Epoch 00014: val_loss improved from 1.71500 to 1.69425, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 15/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6994 - accuracy: 0.2994 - val_loss: 1.6798 - val_accuracy: 0.3063

Epoch 00015: val_loss improved from 1.69425 to 1.67978, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 16/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6868 - accuracy: 0.2994 - val_loss: 1.6706 - val_accuracy: 0.3069

Epoch 00016: val_loss improved from 1.67978 to 1.67058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 17/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6785 - accuracy: 0.2998 - val_loss: 1.6638 - val_accuracy: 0.3044

Epoch 00017: val_loss improved from 1.67058 to 1.66384, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 18/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6701 - accuracy: 0.2990 - val_loss: 1.6586 - val_accuracy: 0.3064

Epoch 00018: val_loss improved from 1.66384 to 1.65864, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 19/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6657 - accuracy: 0.2981 - val_loss: 1.6549 - val_accuracy: 0.3059

Epoch 00019: val_loss improved from 1.65864 to 1.65487, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 20/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6622 - accuracy: 0.2993 - val_loss: 1.6514 - val_accuracy: 0.3049

Epoch 00020: val_loss improved from 1.65487 to 1.65144, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 21/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6593 - accuracy: 0.2991 - val_loss: 1.6484 - val_accuracy: 0.3059

Epoch 00021: val_loss improved from 1.65144 to 1.64842, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 22/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6566 - accuracy: 0.3021 - val_loss: 1.6461 - val_accuracy: 0.3063

Epoch 00022: val_loss improved from 1.64842 to 1.64614, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 23/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6557 - accuracy: 0.2982 - val_loss: 1.6449 - val_accuracy: 0.3068

Epoch 00023: val_loss improved from 1.64614 to 1.64494, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 24/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6527 - accuracy: 0.3023 - val_loss: 1.6438 - val_accuracy: 0.3065

Epoch 00024: val_loss improved from 1.64494 to 1.64384, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 25/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6510 - accuracy: 0.3022 - val_loss: 1.6430 - val_accuracy: 0.3074

Epoch 00025: val_loss improved from 1.64384 to 1.64298, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 26/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6502 - accuracy: 0.3018 - val_loss: 1.6431 - val_accuracy: 0.3080

Epoch 00026: val_loss did not improve from 1.64298
Epoch 27/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6504 - accuracy: 0.3032 - val_loss: 1.6427 - val_accuracy: 0.3060

Epoch 00027: val_loss improved from 1.64298 to 1.64270, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 28/100
83/83 [==============================] - 10s 116ms/step - loss: 1.6484 - accuracy: 0.3036 - val_loss: 1.6412 - val_accuracy: 0.3094

Epoch 00028: val_loss improved from 1.64270 to 1.64122, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 29/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6473 - accuracy: 0.3046 - val_loss: 1.6400 - val_accuracy: 0.3103

Epoch 00029: val_loss improved from 1.64122 to 1.63998, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 30/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6462 - accuracy: 0.3055 - val_loss: 1.6406 - val_accuracy: 0.3097

Epoch 00030: val_loss did not improve from 1.63998
Epoch 31/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6458 - accuracy: 0.3019 - val_loss: 1.6400 - val_accuracy: 0.3099

Epoch 00031: val_loss did not improve from 1.63998
Epoch 32/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6442 - accuracy: 0.3080 - val_loss: 1.6394 - val_accuracy: 0.3109

Epoch 00032: val_loss improved from 1.63998 to 1.63940, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 33/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6436 - accuracy: 0.3045 - val_loss: 1.6397 - val_accuracy: 0.3104

Epoch 00033: val_loss did not improve from 1.63940
Epoch 34/100
83/83 [==============================] - 9s 111ms/step - loss: 1.6441 - accuracy: 0.3058 - val_loss: 1.6398 - val_accuracy: 0.3080

Epoch 00034: val_loss did not improve from 1.63940
Epoch 35/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6437 - accuracy: 0.3064 - val_loss: 1.6398 - val_accuracy: 0.3106

Epoch 00035: val_loss did not improve from 1.63940
Epoch 36/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6429 - accuracy: 0.3042 - val_loss: 1.6380 - val_accuracy: 0.3104

Epoch 00036: val_loss improved from 1.63940 to 1.63802, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/8
Epoch 37/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6421 - accuracy: 0.3058 - val_loss: 1.6390 - val_accuracy: 0.3089

Epoch 00037: val_loss did not improve from 1.63802
Epoch 38/100
83/83 [==============================] - 11s 136ms/step - loss: 1.6419 - accuracy: 0.3060 - val_loss: 1.6381 - val_accuracy: 0.3126

Epoch 00038: val_loss did not improve from 1.63802
Epoch 39/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6423 - accuracy: 0.3049 - val_loss: 1.6382 - val_accuracy: 0.3133

Epoch 00039: val_loss did not improve from 1.63802
Epoch 40/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6411 - accuracy: 0.3057 - val_loss: 1.6389 - val_accuracy: 0.3109

Epoch 00040: val_loss did not improve from 1.63802
Epoch 41/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6404 - accuracy: 0.3081 - val_loss: 1.6387 - val_accuracy: 0.3115

Epoch 00041: val_loss did not improve from 1.63802
Epoch 42/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6413 - accuracy: 0.3046 - val_loss: 1.6384 - val_accuracy: 0.3105

Epoch 00042: val_loss did not improve from 1.63802
Epoch 43/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6410 - accuracy: 0.3076 - val_loss: 1.6393 - val_accuracy: 0.3130

Epoch 00043: val_loss did not improve from 1.63802
Epoch 44/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6395 - accuracy: 0.3065 - val_loss: 1.6398 - val_accuracy: 0.3123

Epoch 00044: val_loss did not improve from 1.63802
Epoch 45/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6380 - accuracy: 0.3087 - val_loss: 1.6383 - val_accuracy: 0.3134

Epoch 00045: val_loss did not improve from 1.63802
Epoch 46/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6378 - accuracy: 0.3118 - val_loss: 1.6388 - val_accuracy: 0.3093

Epoch 00046: val_loss did not improve from 1.63802
Epoch 00046: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 86s 6ms/step - loss: 1.6414 - accuracy: 0.3024
Testing Loss = 1.641360, Testing Accuracy = 0.302397
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 8s 87ms/step - loss: 11.8013 - accuracy: 0.2490 - val_loss: 8.0971 - val_accuracy: 0.2812

Epoch 00001: val_loss improved from inf to 8.09714, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 2/100
83/83 [==============================] - 7s 86ms/step - loss: 6.3886 - accuracy: 0.2702 - val_loss: 5.1085 - val_accuracy: 0.2877

Epoch 00002: val_loss improved from 8.09714 to 5.10847, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 3/100
83/83 [==============================] - 7s 86ms/step - loss: 4.4482 - accuracy: 0.2781 - val_loss: 3.8826 - val_accuracy: 0.2923

Epoch 00003: val_loss improved from 5.10847 to 3.88255, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 4/100
83/83 [==============================] - 7s 86ms/step - loss: 3.5368 - accuracy: 0.2808 - val_loss: 3.2014 - val_accuracy: 0.2969

Epoch 00004: val_loss improved from 3.88255 to 3.20137, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 5/100
83/83 [==============================] - 7s 87ms/step - loss: 2.9772 - accuracy: 0.2858 - val_loss: 2.7435 - val_accuracy: 0.3016

Epoch 00005: val_loss improved from 3.20137 to 2.74353, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 6/100
83/83 [==============================] - 7s 86ms/step - loss: 2.5947 - accuracy: 0.2874 - val_loss: 2.4244 - val_accuracy: 0.3056

Epoch 00006: val_loss improved from 2.74353 to 2.42440, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 7/100
83/83 [==============================] - 7s 82ms/step - loss: 2.3216 - accuracy: 0.2913 - val_loss: 2.1969 - val_accuracy: 0.3047

Epoch 00007: val_loss improved from 2.42440 to 2.19691, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 8/100
83/83 [==============================] - 7s 84ms/step - loss: 2.1287 - accuracy: 0.2913 - val_loss: 2.0337 - val_accuracy: 0.3024

Epoch 00008: val_loss improved from 2.19691 to 2.03366, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 9/100
83/83 [==============================] - 7s 85ms/step - loss: 1.9894 - accuracy: 0.2937 - val_loss: 1.9195 - val_accuracy: 0.3045

Epoch 00009: val_loss improved from 2.03366 to 1.91946, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 10/100
83/83 [==============================] - 7s 85ms/step - loss: 1.8918 - accuracy: 0.2941 - val_loss: 1.8384 - val_accuracy: 0.3022

Epoch 00010: val_loss improved from 1.91946 to 1.83840, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 11/100
83/83 [==============================] - 7s 84ms/step - loss: 1.8233 - accuracy: 0.2927 - val_loss: 1.7831 - val_accuracy: 0.3021

Epoch 00011: val_loss improved from 1.83840 to 1.78307, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 12/100
83/83 [==============================] - 7s 84ms/step - loss: 1.7743 - accuracy: 0.2955 - val_loss: 1.7421 - val_accuracy: 0.3051

Epoch 00012: val_loss improved from 1.78307 to 1.74213, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 13/100
83/83 [==============================] - 7s 80ms/step - loss: 1.7410 - accuracy: 0.2983 - val_loss: 1.7139 - val_accuracy: 0.3047

Epoch 00013: val_loss improved from 1.74213 to 1.71391, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 14/100
83/83 [==============================] - 6s 72ms/step - loss: 1.7164 - accuracy: 0.2969 - val_loss: 1.6944 - val_accuracy: 0.3067

Epoch 00014: val_loss improved from 1.71391 to 1.69442, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 15/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6985 - accuracy: 0.2991 - val_loss: 1.6810 - val_accuracy: 0.3047

Epoch 00015: val_loss improved from 1.69442 to 1.68101, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 16/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6857 - accuracy: 0.3005 - val_loss: 1.6703 - val_accuracy: 0.3053

Epoch 00016: val_loss improved from 1.68101 to 1.67026, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 17/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6769 - accuracy: 0.2988 - val_loss: 1.6640 - val_accuracy: 0.3051

Epoch 00017: val_loss improved from 1.67026 to 1.66397, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 18/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6719 - accuracy: 0.2991 - val_loss: 1.6581 - val_accuracy: 0.3059

Epoch 00018: val_loss improved from 1.66397 to 1.65806, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 19/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6664 - accuracy: 0.3023 - val_loss: 1.6546 - val_accuracy: 0.3069

Epoch 00019: val_loss improved from 1.65806 to 1.65463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 20/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6631 - accuracy: 0.2984 - val_loss: 1.6508 - val_accuracy: 0.3075

Epoch 00020: val_loss improved from 1.65463 to 1.65076, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 21/100
83/83 [==============================] - 6s 73ms/step - loss: 1.6584 - accuracy: 0.3017 - val_loss: 1.6501 - val_accuracy: 0.3048

Epoch 00021: val_loss improved from 1.65076 to 1.65012, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 22/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6565 - accuracy: 0.3018 - val_loss: 1.6473 - val_accuracy: 0.3084

Epoch 00022: val_loss improved from 1.65012 to 1.64731, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 23/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6549 - accuracy: 0.3005 - val_loss: 1.6461 - val_accuracy: 0.3083

Epoch 00023: val_loss improved from 1.64731 to 1.64611, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 24/100
83/83 [==============================] - 6s 73ms/step - loss: 1.6533 - accuracy: 0.3019 - val_loss: 1.6450 - val_accuracy: 0.3080

Epoch 00024: val_loss improved from 1.64611 to 1.64501, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 25/100
83/83 [==============================] - 6s 73ms/step - loss: 1.6530 - accuracy: 0.2993 - val_loss: 1.6430 - val_accuracy: 0.3095

Epoch 00025: val_loss improved from 1.64501 to 1.64304, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 26/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6492 - accuracy: 0.3035 - val_loss: 1.6422 - val_accuracy: 0.3086

Epoch 00026: val_loss improved from 1.64304 to 1.64224, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 27/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6495 - accuracy: 0.3039 - val_loss: 1.6420 - val_accuracy: 0.3121

Epoch 00027: val_loss improved from 1.64224 to 1.64197, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 28/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6487 - accuracy: 0.3027 - val_loss: 1.6415 - val_accuracy: 0.3104

Epoch 00028: val_loss improved from 1.64197 to 1.64147, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 29/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6467 - accuracy: 0.3027 - val_loss: 1.6401 - val_accuracy: 0.3115

Epoch 00029: val_loss improved from 1.64147 to 1.64014, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 30/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6456 - accuracy: 0.3030 - val_loss: 1.6402 - val_accuracy: 0.3109

Epoch 00030: val_loss did not improve from 1.64014
Epoch 31/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6451 - accuracy: 0.3045 - val_loss: 1.6400 - val_accuracy: 0.3095

Epoch 00031: val_loss improved from 1.64014 to 1.64004, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 32/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6460 - accuracy: 0.3064 - val_loss: 1.6401 - val_accuracy: 0.3089

Epoch 00032: val_loss did not improve from 1.64004
Epoch 33/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6447 - accuracy: 0.3045 - val_loss: 1.6409 - val_accuracy: 0.3097

Epoch 00033: val_loss did not improve from 1.64004
Epoch 34/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6428 - accuracy: 0.3041 - val_loss: 1.6395 - val_accuracy: 0.3094

Epoch 00034: val_loss improved from 1.64004 to 1.63947, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 35/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6427 - accuracy: 0.3069 - val_loss: 1.6402 - val_accuracy: 0.3094

Epoch 00035: val_loss did not improve from 1.63947
Epoch 36/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6416 - accuracy: 0.3062 - val_loss: 1.6391 - val_accuracy: 0.3108

Epoch 00036: val_loss improved from 1.63947 to 1.63911, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 37/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6421 - accuracy: 0.3067 - val_loss: 1.6389 - val_accuracy: 0.3090

Epoch 00037: val_loss improved from 1.63911 to 1.63890, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r13/Try/9
Epoch 38/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6409 - accuracy: 0.3087 - val_loss: 1.6389 - val_accuracy: 0.3099

Epoch 00038: val_loss did not improve from 1.63890
Epoch 39/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6401 - accuracy: 0.3072 - val_loss: 1.6399 - val_accuracy: 0.3096

Epoch 00039: val_loss did not improve from 1.63890
Epoch 40/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6400 - accuracy: 0.3073 - val_loss: 1.6401 - val_accuracy: 0.3100

Epoch 00040: val_loss did not improve from 1.63890
Epoch 41/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6393 - accuracy: 0.3087 - val_loss: 1.6397 - val_accuracy: 0.3104

Epoch 00041: val_loss did not improve from 1.63890
Epoch 42/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6395 - accuracy: 0.3091 - val_loss: 1.6413 - val_accuracy: 0.3111

Epoch 00042: val_loss did not improve from 1.63890
Epoch 43/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6379 - accuracy: 0.3082 - val_loss: 1.6412 - val_accuracy: 0.3102

Epoch 00043: val_loss did not improve from 1.63890
Epoch 44/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6383 - accuracy: 0.3103 - val_loss: 1.6416 - val_accuracy: 0.3084

Epoch 00044: val_loss did not improve from 1.63890
Epoch 45/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6383 - accuracy: 0.3089 - val_loss: 1.6423 - val_accuracy: 0.3076

Epoch 00045: val_loss did not improve from 1.63890
Epoch 46/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6377 - accuracy: 0.3110 - val_loss: 1.6437 - val_accuracy: 0.3074

Epoch 00046: val_loss did not improve from 1.63890
Epoch 47/100
83/83 [==============================] - 6s 71ms/step - loss: 1.6366 - accuracy: 0.3110 - val_loss: 1.6441 - val_accuracy: 0.3100

Epoch 00047: val_loss did not improve from 1.63890
Epoch 00047: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 67s 5ms/step - loss: 1.6415 - accuracy: 0.3039
Testing Loss = 1.641476, Testing Accuracy = 0.303885
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 78.76 +- 0.0366 %)
$W^-/W^-$ (auc = 78.40 +- 0.0585 %)
$Z/Z$ (auc = 59.40 +- 0.0941 %)
$W^+/W^-$ (auc = 62.27 +- 0.0828 %)
$W^+/Z$$ (auc = 63.17 +- 0.0370 %)
$W^-/Z$ (auc = 65.65 +- 0.0446 %)
The summarized testing accuracy = 30.33 +- 0.0813 %, with the loss = 1.6416 +- 0.000790
