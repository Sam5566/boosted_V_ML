

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-27 17:40:33.656979
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 19s 73ms/step - loss: 12.3663 - accuracy: 0.2003 - val_loss: 8.6351 - val_accuracy: 0.1991

Epoch 00001: val_loss improved from inf to 8.63513, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6773 - accuracy: 0.2546 - val_loss: 5.3500 - val_accuracy: 0.2346

Epoch 00002: val_loss improved from 8.63513 to 5.34998, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5217 - accuracy: 0.2875 - val_loss: 3.9568 - val_accuracy: 0.2945

Epoch 00003: val_loss improved from 5.34998 to 3.95679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 4/100
83/83 [==============================] - 6s 70ms/step - loss: 3.5328 - accuracy: 0.3011 - val_loss: 3.2083 - val_accuracy: 0.3146

Epoch 00004: val_loss improved from 3.95679 to 3.20831, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 5/100
83/83 [==============================] - 10s 122ms/step - loss: 2.9518 - accuracy: 0.3061 - val_loss: 2.7272 - val_accuracy: 0.3217

Epoch 00005: val_loss improved from 3.20831 to 2.72719, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 6/100
83/83 [==============================] - 10s 120ms/step - loss: 2.5587 - accuracy: 0.3146 - val_loss: 2.3985 - val_accuracy: 0.3269

Epoch 00006: val_loss improved from 2.72719 to 2.39852, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 7/100
83/83 [==============================] - 10s 123ms/step - loss: 2.2854 - accuracy: 0.3183 - val_loss: 2.1682 - val_accuracy: 0.3295

Epoch 00007: val_loss improved from 2.39852 to 2.16819, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 8/100
83/83 [==============================] - 10s 121ms/step - loss: 2.0914 - accuracy: 0.3218 - val_loss: 2.0028 - val_accuracy: 0.3375

Epoch 00008: val_loss improved from 2.16819 to 2.00279, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 9/100
83/83 [==============================] - 10s 124ms/step - loss: 1.9524 - accuracy: 0.3286 - val_loss: 1.8921 - val_accuracy: 0.3382

Epoch 00009: val_loss improved from 2.00279 to 1.89214, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 10/100
83/83 [==============================] - 11s 128ms/step - loss: 1.8541 - accuracy: 0.3316 - val_loss: 1.8103 - val_accuracy: 0.3427

Epoch 00010: val_loss improved from 1.89214 to 1.81033, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 11/100
83/83 [==============================] - 11s 127ms/step - loss: 1.7824 - accuracy: 0.3363 - val_loss: 1.7498 - val_accuracy: 0.3482

Epoch 00011: val_loss improved from 1.81033 to 1.74976, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 12/100
83/83 [==============================] - 11s 129ms/step - loss: 1.7327 - accuracy: 0.3414 - val_loss: 1.7108 - val_accuracy: 0.3463

Epoch 00012: val_loss improved from 1.74976 to 1.71080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 13/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6948 - accuracy: 0.3431 - val_loss: 1.6862 - val_accuracy: 0.3437

Epoch 00013: val_loss improved from 1.71080 to 1.68618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 14/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6677 - accuracy: 0.3497 - val_loss: 1.6668 - val_accuracy: 0.3438

Epoch 00014: val_loss improved from 1.68618 to 1.66685, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 15/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6485 - accuracy: 0.3521 - val_loss: 1.6576 - val_accuracy: 0.3416

Epoch 00015: val_loss improved from 1.66685 to 1.65763, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 16/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6335 - accuracy: 0.3566 - val_loss: 1.6447 - val_accuracy: 0.3429

Epoch 00016: val_loss improved from 1.65763 to 1.64468, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 17/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6234 - accuracy: 0.3566 - val_loss: 1.6400 - val_accuracy: 0.3485

Epoch 00017: val_loss improved from 1.64468 to 1.63995, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 18/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6121 - accuracy: 0.3617 - val_loss: 1.6279 - val_accuracy: 0.3519

Epoch 00018: val_loss improved from 1.63995 to 1.62791, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 19/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6036 - accuracy: 0.3671 - val_loss: 1.6237 - val_accuracy: 0.3547

Epoch 00019: val_loss improved from 1.62791 to 1.62371, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/0
Epoch 20/100
83/83 [==============================] - 10s 122ms/step - loss: 1.5998 - accuracy: 0.3704 - val_loss: 1.6257 - val_accuracy: 0.3482

Epoch 00020: val_loss did not improve from 1.62371
Epoch 21/100
83/83 [==============================] - 9s 113ms/step - loss: 1.5942 - accuracy: 0.3726 - val_loss: 1.6257 - val_accuracy: 0.3513

Epoch 00021: val_loss did not improve from 1.62371
Epoch 22/100
83/83 [==============================] - 9s 102ms/step - loss: 1.5895 - accuracy: 0.3737 - val_loss: 1.6244 - val_accuracy: 0.3542

Epoch 00022: val_loss did not improve from 1.62371
Epoch 23/100
83/83 [==============================] - 11s 130ms/step - loss: 1.5847 - accuracy: 0.3764 - val_loss: 1.6264 - val_accuracy: 0.3530

Epoch 00023: val_loss did not improve from 1.62371
Epoch 24/100
83/83 [==============================] - 10s 116ms/step - loss: 1.5804 - accuracy: 0.3796 - val_loss: 1.6311 - val_accuracy: 0.3504

Epoch 00024: val_loss did not improve from 1.62371
Epoch 25/100
83/83 [==============================] - 10s 124ms/step - loss: 1.5782 - accuracy: 0.3829 - val_loss: 1.6330 - val_accuracy: 0.3481

Epoch 00025: val_loss did not improve from 1.62371
Epoch 26/100
83/83 [==============================] - 8s 99ms/step - loss: 1.5724 - accuracy: 0.3894 - val_loss: 1.6339 - val_accuracy: 0.3522

Epoch 00026: val_loss did not improve from 1.62371
Epoch 27/100
83/83 [==============================] - 9s 108ms/step - loss: 1.5672 - accuracy: 0.3941 - val_loss: 1.6385 - val_accuracy: 0.3543

Epoch 00027: val_loss did not improve from 1.62371
Epoch 28/100
83/83 [==============================] - 11s 133ms/step - loss: 1.5658 - accuracy: 0.3955 - val_loss: 1.6448 - val_accuracy: 0.3549

Epoch 00028: val_loss did not improve from 1.62371
Epoch 29/100
83/83 [==============================] - 11s 133ms/step - loss: 1.5603 - accuracy: 0.4037 - val_loss: 1.6507 - val_accuracy: 0.3532

Epoch 00029: val_loss did not improve from 1.62371
Epoch 00029: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 79s 6ms/step - loss: 1.6353 - accuracy: 0.3472
Testing Loss = 1.635319, Testing Accuracy = 0.347202
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 81ms/step - loss: 12.3671 - accuracy: 0.2049 - val_loss: 8.6369 - val_accuracy: 0.2106

Epoch 00001: val_loss improved from inf to 8.63687, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 2/100
83/83 [==============================] - 7s 80ms/step - loss: 6.6826 - accuracy: 0.2678 - val_loss: 5.3645 - val_accuracy: 0.2665

Epoch 00002: val_loss improved from 8.63687 to 5.36454, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 3/100
83/83 [==============================] - 7s 81ms/step - loss: 4.5480 - accuracy: 0.2921 - val_loss: 3.9846 - val_accuracy: 0.2984

Epoch 00003: val_loss improved from 5.36454 to 3.98456, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 4/100
83/83 [==============================] - 10s 121ms/step - loss: 3.5563 - accuracy: 0.3054 - val_loss: 3.2305 - val_accuracy: 0.3175

Epoch 00004: val_loss improved from 3.98456 to 3.23054, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 5/100
83/83 [==============================] - 11s 126ms/step - loss: 2.9696 - accuracy: 0.3121 - val_loss: 2.7474 - val_accuracy: 0.3186

Epoch 00005: val_loss improved from 3.23054 to 2.74743, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 6/100
83/83 [==============================] - 10s 118ms/step - loss: 2.5765 - accuracy: 0.3173 - val_loss: 2.4141 - val_accuracy: 0.3257

Epoch 00006: val_loss improved from 2.74743 to 2.41413, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 7/100
83/83 [==============================] - 10s 124ms/step - loss: 2.2993 - accuracy: 0.3187 - val_loss: 2.1798 - val_accuracy: 0.3292

Epoch 00007: val_loss improved from 2.41413 to 2.17981, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 8/100
83/83 [==============================] - 10s 121ms/step - loss: 2.1022 - accuracy: 0.3243 - val_loss: 2.0204 - val_accuracy: 0.3276

Epoch 00008: val_loss improved from 2.17981 to 2.02041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 9/100
83/83 [==============================] - 10s 122ms/step - loss: 1.9624 - accuracy: 0.3285 - val_loss: 1.8968 - val_accuracy: 0.3382

Epoch 00009: val_loss improved from 2.02041 to 1.89681, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 10/100
83/83 [==============================] - 10s 126ms/step - loss: 1.8626 - accuracy: 0.3341 - val_loss: 1.8170 - val_accuracy: 0.3380

Epoch 00010: val_loss improved from 1.89681 to 1.81700, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 11/100
83/83 [==============================] - 10s 120ms/step - loss: 1.7892 - accuracy: 0.3377 - val_loss: 1.7567 - val_accuracy: 0.3439

Epoch 00011: val_loss improved from 1.81700 to 1.75672, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 12/100
83/83 [==============================] - 10s 122ms/step - loss: 1.7371 - accuracy: 0.3422 - val_loss: 1.7208 - val_accuracy: 0.3428

Epoch 00012: val_loss improved from 1.75672 to 1.72077, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 13/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6997 - accuracy: 0.3458 - val_loss: 1.6896 - val_accuracy: 0.3462

Epoch 00013: val_loss improved from 1.72077 to 1.68958, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 14/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6708 - accuracy: 0.3478 - val_loss: 1.6689 - val_accuracy: 0.3457

Epoch 00014: val_loss improved from 1.68958 to 1.66891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 15/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6503 - accuracy: 0.3542 - val_loss: 1.6565 - val_accuracy: 0.3499

Epoch 00015: val_loss improved from 1.66891 to 1.65652, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 16/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6352 - accuracy: 0.3583 - val_loss: 1.6408 - val_accuracy: 0.3528

Epoch 00016: val_loss improved from 1.65652 to 1.64082, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 17/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6217 - accuracy: 0.3626 - val_loss: 1.6356 - val_accuracy: 0.3538

Epoch 00017: val_loss improved from 1.64082 to 1.63560, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 18/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6135 - accuracy: 0.3647 - val_loss: 1.6258 - val_accuracy: 0.3588

Epoch 00018: val_loss improved from 1.63560 to 1.62577, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 19/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6072 - accuracy: 0.3669 - val_loss: 1.6270 - val_accuracy: 0.3556

Epoch 00019: val_loss did not improve from 1.62577
Epoch 20/100
83/83 [==============================] - 9s 112ms/step - loss: 1.5980 - accuracy: 0.3696 - val_loss: 1.6188 - val_accuracy: 0.3618

Epoch 00020: val_loss improved from 1.62577 to 1.61883, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 21/100
83/83 [==============================] - 9s 114ms/step - loss: 1.5918 - accuracy: 0.3733 - val_loss: 1.6171 - val_accuracy: 0.3625

Epoch 00021: val_loss improved from 1.61883 to 1.61715, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/1
Epoch 22/100
83/83 [==============================] - 10s 119ms/step - loss: 1.5880 - accuracy: 0.3765 - val_loss: 1.6213 - val_accuracy: 0.3592

Epoch 00022: val_loss did not improve from 1.61715
Epoch 23/100
83/83 [==============================] - 8s 101ms/step - loss: 1.5862 - accuracy: 0.3782 - val_loss: 1.6293 - val_accuracy: 0.3543

Epoch 00023: val_loss did not improve from 1.61715
Epoch 24/100
83/83 [==============================] - 9s 111ms/step - loss: 1.5812 - accuracy: 0.3815 - val_loss: 1.6270 - val_accuracy: 0.3577

Epoch 00024: val_loss did not improve from 1.61715
Epoch 25/100
83/83 [==============================] - 11s 128ms/step - loss: 1.5757 - accuracy: 0.3852 - val_loss: 1.6284 - val_accuracy: 0.3587

Epoch 00025: val_loss did not improve from 1.61715
Epoch 26/100
83/83 [==============================] - 8s 99ms/step - loss: 1.5740 - accuracy: 0.3889 - val_loss: 1.6314 - val_accuracy: 0.3594

Epoch 00026: val_loss did not improve from 1.61715
Epoch 27/100
83/83 [==============================] - 9s 108ms/step - loss: 1.5691 - accuracy: 0.3921 - val_loss: 1.6354 - val_accuracy: 0.3607

Epoch 00027: val_loss did not improve from 1.61715
Epoch 28/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5659 - accuracy: 0.3977 - val_loss: 1.6415 - val_accuracy: 0.3580

Epoch 00028: val_loss did not improve from 1.61715
Epoch 29/100
83/83 [==============================] - 11s 131ms/step - loss: 1.5617 - accuracy: 0.4016 - val_loss: 1.6469 - val_accuracy: 0.3572

Epoch 00029: val_loss did not improve from 1.61715
Epoch 30/100
83/83 [==============================] - 11s 130ms/step - loss: 1.5563 - accuracy: 0.4050 - val_loss: 1.6534 - val_accuracy: 0.3589

Epoch 00030: val_loss did not improve from 1.61715
Epoch 31/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5519 - accuracy: 0.4150 - val_loss: 1.6628 - val_accuracy: 0.3572

Epoch 00031: val_loss did not improve from 1.61715
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 75s 6ms/step - loss: 1.6305 - accuracy: 0.3511
Testing Loss = 1.630521, Testing Accuracy = 0.351146
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 8s 84ms/step - loss: 12.3639 - accuracy: 0.2053 - val_loss: 8.6314 - val_accuracy: 0.2273

Epoch 00001: val_loss improved from inf to 8.63141, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 2/100
83/83 [==============================] - 7s 89ms/step - loss: 6.6802 - accuracy: 0.2674 - val_loss: 5.3533 - val_accuracy: 0.2718

Epoch 00002: val_loss improved from 8.63141 to 5.35330, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 3/100
83/83 [==============================] - 8s 96ms/step - loss: 4.5460 - accuracy: 0.2907 - val_loss: 3.9824 - val_accuracy: 0.3006

Epoch 00003: val_loss improved from 5.35330 to 3.98240, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 4/100
83/83 [==============================] - 9s 104ms/step - loss: 3.5554 - accuracy: 0.3045 - val_loss: 3.2330 - val_accuracy: 0.3147

Epoch 00004: val_loss improved from 3.98240 to 3.23301, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 5/100
83/83 [==============================] - 8s 98ms/step - loss: 2.9696 - accuracy: 0.3107 - val_loss: 2.7442 - val_accuracy: 0.3231

Epoch 00005: val_loss improved from 3.23301 to 2.74420, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 6/100
83/83 [==============================] - 8s 101ms/step - loss: 2.5768 - accuracy: 0.3159 - val_loss: 2.4142 - val_accuracy: 0.3257

Epoch 00006: val_loss improved from 2.74420 to 2.41417, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 7/100
83/83 [==============================] - 8s 101ms/step - loss: 2.3001 - accuracy: 0.3213 - val_loss: 2.1823 - val_accuracy: 0.3300

Epoch 00007: val_loss improved from 2.41417 to 2.18226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 8/100
83/83 [==============================] - 8s 99ms/step - loss: 2.1037 - accuracy: 0.3211 - val_loss: 2.0155 - val_accuracy: 0.3312

Epoch 00008: val_loss improved from 2.18226 to 2.01552, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 9/100
83/83 [==============================] - 9s 105ms/step - loss: 1.9624 - accuracy: 0.3280 - val_loss: 1.8977 - val_accuracy: 0.3349

Epoch 00009: val_loss improved from 2.01552 to 1.89772, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 10/100
83/83 [==============================] - 8s 100ms/step - loss: 1.8608 - accuracy: 0.3327 - val_loss: 1.8180 - val_accuracy: 0.3394

Epoch 00010: val_loss improved from 1.89772 to 1.81805, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 11/100
83/83 [==============================] - 9s 104ms/step - loss: 1.7891 - accuracy: 0.3344 - val_loss: 1.7583 - val_accuracy: 0.3406

Epoch 00011: val_loss improved from 1.81805 to 1.75835, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 12/100
83/83 [==============================] - 9s 103ms/step - loss: 1.7380 - accuracy: 0.3378 - val_loss: 1.7147 - val_accuracy: 0.3439

Epoch 00012: val_loss improved from 1.75835 to 1.71470, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 13/100
83/83 [==============================] - 8s 99ms/step - loss: 1.6996 - accuracy: 0.3433 - val_loss: 1.6863 - val_accuracy: 0.3444

Epoch 00013: val_loss improved from 1.71470 to 1.68629, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 14/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6720 - accuracy: 0.3466 - val_loss: 1.6720 - val_accuracy: 0.3446

Epoch 00014: val_loss improved from 1.68629 to 1.67203, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 15/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6520 - accuracy: 0.3503 - val_loss: 1.6554 - val_accuracy: 0.3507

Epoch 00015: val_loss improved from 1.67203 to 1.65538, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 16/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6383 - accuracy: 0.3515 - val_loss: 1.6478 - val_accuracy: 0.3462

Epoch 00016: val_loss improved from 1.65538 to 1.64782, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 17/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6234 - accuracy: 0.3572 - val_loss: 1.6432 - val_accuracy: 0.3481

Epoch 00017: val_loss improved from 1.64782 to 1.64325, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 18/100
83/83 [==============================] - 8s 98ms/step - loss: 1.6166 - accuracy: 0.3591 - val_loss: 1.6322 - val_accuracy: 0.3507

Epoch 00018: val_loss improved from 1.64325 to 1.63217, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 19/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6078 - accuracy: 0.3634 - val_loss: 1.6290 - val_accuracy: 0.3527

Epoch 00019: val_loss improved from 1.63217 to 1.62897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 20/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6014 - accuracy: 0.3650 - val_loss: 1.6343 - val_accuracy: 0.3477

Epoch 00020: val_loss did not improve from 1.62897
Epoch 21/100
83/83 [==============================] - 8s 99ms/step - loss: 1.5987 - accuracy: 0.3687 - val_loss: 1.6350 - val_accuracy: 0.3482

Epoch 00021: val_loss did not improve from 1.62897
Epoch 22/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5894 - accuracy: 0.3703 - val_loss: 1.6273 - val_accuracy: 0.3542

Epoch 00022: val_loss improved from 1.62897 to 1.62727, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 23/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5847 - accuracy: 0.3764 - val_loss: 1.6252 - val_accuracy: 0.3575

Epoch 00023: val_loss improved from 1.62727 to 1.62525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/2
Epoch 24/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5839 - accuracy: 0.3794 - val_loss: 1.6314 - val_accuracy: 0.3536

Epoch 00024: val_loss did not improve from 1.62525
Epoch 25/100
83/83 [==============================] - 11s 130ms/step - loss: 1.5788 - accuracy: 0.3791 - val_loss: 1.6341 - val_accuracy: 0.3531

Epoch 00025: val_loss did not improve from 1.62525
Epoch 26/100
83/83 [==============================] - 11s 130ms/step - loss: 1.5741 - accuracy: 0.3870 - val_loss: 1.6365 - val_accuracy: 0.3573

Epoch 00026: val_loss did not improve from 1.62525
Epoch 27/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5711 - accuracy: 0.3907 - val_loss: 1.6372 - val_accuracy: 0.3560

Epoch 00027: val_loss did not improve from 1.62525
Epoch 28/100
83/83 [==============================] - 11s 130ms/step - loss: 1.5656 - accuracy: 0.3956 - val_loss: 1.6432 - val_accuracy: 0.3560

Epoch 00028: val_loss did not improve from 1.62525
Epoch 29/100
83/83 [==============================] - 11s 128ms/step - loss: 1.5636 - accuracy: 0.3992 - val_loss: 1.6484 - val_accuracy: 0.3561

Epoch 00029: val_loss did not improve from 1.62525
Epoch 30/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5589 - accuracy: 0.4061 - val_loss: 1.6560 - val_accuracy: 0.3512

Epoch 00030: val_loss did not improve from 1.62525
Epoch 31/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5518 - accuracy: 0.4147 - val_loss: 1.6695 - val_accuracy: 0.3512

Epoch 00031: val_loss did not improve from 1.62525
Epoch 32/100
83/83 [==============================] - 8s 100ms/step - loss: 1.5513 - accuracy: 0.4136 - val_loss: 1.6769 - val_accuracy: 0.3524

Epoch 00032: val_loss did not improve from 1.62525
Epoch 33/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5434 - accuracy: 0.4226 - val_loss: 1.6863 - val_accuracy: 0.3493

Epoch 00033: val_loss did not improve from 1.62525
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 67s 5ms/step - loss: 1.6350 - accuracy: 0.3454
Testing Loss = 1.635039, Testing Accuracy = 0.345415
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 9s 105ms/step - loss: 12.3821 - accuracy: 0.2087 - val_loss: 8.6688 - val_accuracy: 0.2243

Epoch 00001: val_loss improved from inf to 8.66881, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 2/100
83/83 [==============================] - 8s 99ms/step - loss: 6.7179 - accuracy: 0.2736 - val_loss: 5.3955 - val_accuracy: 0.2705

Epoch 00002: val_loss improved from 8.66881 to 5.39549, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 3/100
83/83 [==============================] - 9s 103ms/step - loss: 4.5704 - accuracy: 0.2944 - val_loss: 3.9977 - val_accuracy: 0.2992

Epoch 00003: val_loss improved from 5.39549 to 3.99772, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 4/100
83/83 [==============================] - 8s 98ms/step - loss: 3.5658 - accuracy: 0.3043 - val_loss: 3.2377 - val_accuracy: 0.3149

Epoch 00004: val_loss improved from 3.99772 to 3.23768, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 5/100
83/83 [==============================] - 9s 103ms/step - loss: 2.9721 - accuracy: 0.3134 - val_loss: 2.7506 - val_accuracy: 0.3215

Epoch 00005: val_loss improved from 3.23768 to 2.75063, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 6/100
83/83 [==============================] - 9s 105ms/step - loss: 2.5752 - accuracy: 0.3158 - val_loss: 2.4132 - val_accuracy: 0.3262

Epoch 00006: val_loss improved from 2.75063 to 2.41319, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 7/100
83/83 [==============================] - 8s 98ms/step - loss: 2.2969 - accuracy: 0.3248 - val_loss: 2.1814 - val_accuracy: 0.3302

Epoch 00007: val_loss improved from 2.41319 to 2.18141, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 8/100
83/83 [==============================] - 9s 104ms/step - loss: 2.1025 - accuracy: 0.3257 - val_loss: 2.0140 - val_accuracy: 0.3360

Epoch 00008: val_loss improved from 2.18141 to 2.01405, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 9/100
83/83 [==============================] - 9s 104ms/step - loss: 1.9598 - accuracy: 0.3302 - val_loss: 1.8992 - val_accuracy: 0.3352

Epoch 00009: val_loss improved from 2.01405 to 1.89916, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 10/100
83/83 [==============================] - 8s 96ms/step - loss: 1.8593 - accuracy: 0.3348 - val_loss: 1.8159 - val_accuracy: 0.3409

Epoch 00010: val_loss improved from 1.89916 to 1.81585, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 11/100
83/83 [==============================] - 9s 103ms/step - loss: 1.7878 - accuracy: 0.3408 - val_loss: 1.7609 - val_accuracy: 0.3404

Epoch 00011: val_loss improved from 1.81585 to 1.76090, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 12/100
83/83 [==============================] - 9s 105ms/step - loss: 1.7352 - accuracy: 0.3446 - val_loss: 1.7227 - val_accuracy: 0.3386

Epoch 00012: val_loss improved from 1.76090 to 1.72266, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 13/100
83/83 [==============================] - 8s 97ms/step - loss: 1.6976 - accuracy: 0.3463 - val_loss: 1.6938 - val_accuracy: 0.3439

Epoch 00013: val_loss improved from 1.72266 to 1.69378, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 14/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6676 - accuracy: 0.3552 - val_loss: 1.6666 - val_accuracy: 0.3526

Epoch 00014: val_loss improved from 1.69378 to 1.66665, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 15/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6507 - accuracy: 0.3557 - val_loss: 1.6628 - val_accuracy: 0.3448

Epoch 00015: val_loss improved from 1.66665 to 1.66280, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 16/100
83/83 [==============================] - 8s 98ms/step - loss: 1.6328 - accuracy: 0.3584 - val_loss: 1.6447 - val_accuracy: 0.3488

Epoch 00016: val_loss improved from 1.66280 to 1.64467, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 17/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6205 - accuracy: 0.3647 - val_loss: 1.6357 - val_accuracy: 0.3531

Epoch 00017: val_loss improved from 1.64467 to 1.63570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 18/100
83/83 [==============================] - 8s 98ms/step - loss: 1.6129 - accuracy: 0.3676 - val_loss: 1.6331 - val_accuracy: 0.3548

Epoch 00018: val_loss improved from 1.63570 to 1.63306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 19/100
83/83 [==============================] - 11s 133ms/step - loss: 1.6059 - accuracy: 0.3700 - val_loss: 1.6347 - val_accuracy: 0.3526

Epoch 00019: val_loss did not improve from 1.63306
Epoch 20/100
83/83 [==============================] - 9s 103ms/step - loss: 1.5971 - accuracy: 0.3761 - val_loss: 1.6291 - val_accuracy: 0.3556

Epoch 00020: val_loss improved from 1.63306 to 1.62912, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 21/100
83/83 [==============================] - 11s 131ms/step - loss: 1.5904 - accuracy: 0.3775 - val_loss: 1.6265 - val_accuracy: 0.3599

Epoch 00021: val_loss improved from 1.62912 to 1.62654, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/3
Epoch 22/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5862 - accuracy: 0.3810 - val_loss: 1.6325 - val_accuracy: 0.3540

Epoch 00022: val_loss did not improve from 1.62654
Epoch 23/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5823 - accuracy: 0.3864 - val_loss: 1.6286 - val_accuracy: 0.3576

Epoch 00023: val_loss did not improve from 1.62654
Epoch 24/100
83/83 [==============================] - 11s 133ms/step - loss: 1.5768 - accuracy: 0.3907 - val_loss: 1.6338 - val_accuracy: 0.3573

Epoch 00024: val_loss did not improve from 1.62654
Epoch 25/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5710 - accuracy: 0.3940 - val_loss: 1.6403 - val_accuracy: 0.3558

Epoch 00025: val_loss did not improve from 1.62654
Epoch 26/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5673 - accuracy: 0.3992 - val_loss: 1.6451 - val_accuracy: 0.3544

Epoch 00026: val_loss did not improve from 1.62654
Epoch 27/100
83/83 [==============================] - 11s 131ms/step - loss: 1.5625 - accuracy: 0.4074 - val_loss: 1.6523 - val_accuracy: 0.3518

Epoch 00027: val_loss did not improve from 1.62654
Epoch 28/100
83/83 [==============================] - 11s 134ms/step - loss: 1.5573 - accuracy: 0.4095 - val_loss: 1.6633 - val_accuracy: 0.3534

Epoch 00028: val_loss did not improve from 1.62654
Epoch 29/100
83/83 [==============================] - 9s 108ms/step - loss: 1.5508 - accuracy: 0.4157 - val_loss: 1.6788 - val_accuracy: 0.3489

Epoch 00029: val_loss did not improve from 1.62654
Epoch 30/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5463 - accuracy: 0.4226 - val_loss: 1.6888 - val_accuracy: 0.3515

Epoch 00030: val_loss did not improve from 1.62654
Epoch 31/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5387 - accuracy: 0.4310 - val_loss: 1.7029 - val_accuracy: 0.3511

Epoch 00031: val_loss did not improve from 1.62654
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.6391 - accuracy: 0.3494
Testing Loss = 1.639059, Testing Accuracy = 0.349360
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 10s 105ms/step - loss: 12.3277 - accuracy: 0.2060 - val_loss: 8.5817 - val_accuracy: 0.2247

Epoch 00001: val_loss improved from inf to 8.58168, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 2/100
83/83 [==============================] - 9s 105ms/step - loss: 6.6387 - accuracy: 0.2674 - val_loss: 5.3223 - val_accuracy: 0.2712

Epoch 00002: val_loss improved from 8.58168 to 5.32226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 3/100
83/83 [==============================] - 9s 103ms/step - loss: 4.5198 - accuracy: 0.2883 - val_loss: 3.9669 - val_accuracy: 0.2987

Epoch 00003: val_loss improved from 5.32226 to 3.96692, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 4/100
83/83 [==============================] - 9s 106ms/step - loss: 3.5387 - accuracy: 0.3038 - val_loss: 3.2193 - val_accuracy: 0.3144

Epoch 00004: val_loss improved from 3.96692 to 3.21933, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 5/100
83/83 [==============================] - 9s 110ms/step - loss: 2.9570 - accuracy: 0.3115 - val_loss: 2.7371 - val_accuracy: 0.3254

Epoch 00005: val_loss improved from 3.21933 to 2.73710, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 6/100
83/83 [==============================] - 9s 103ms/step - loss: 2.5688 - accuracy: 0.3153 - val_loss: 2.4084 - val_accuracy: 0.3260

Epoch 00006: val_loss improved from 2.73710 to 2.40839, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 7/100
83/83 [==============================] - 10s 115ms/step - loss: 2.2943 - accuracy: 0.3230 - val_loss: 2.1755 - val_accuracy: 0.3281

Epoch 00007: val_loss improved from 2.40839 to 2.17551, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 8/100
83/83 [==============================] - 9s 107ms/step - loss: 2.0985 - accuracy: 0.3250 - val_loss: 2.0118 - val_accuracy: 0.3393

Epoch 00008: val_loss improved from 2.17551 to 2.01176, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 9/100
83/83 [==============================] - 10s 116ms/step - loss: 1.9584 - accuracy: 0.3271 - val_loss: 1.8922 - val_accuracy: 0.3420

Epoch 00009: val_loss improved from 2.01176 to 1.89220, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 10/100
83/83 [==============================] - 10s 116ms/step - loss: 1.8594 - accuracy: 0.3331 - val_loss: 1.8139 - val_accuracy: 0.3408

Epoch 00010: val_loss improved from 1.89220 to 1.81386, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 11/100
83/83 [==============================] - 9s 109ms/step - loss: 1.7866 - accuracy: 0.3348 - val_loss: 1.7612 - val_accuracy: 0.3393

Epoch 00011: val_loss improved from 1.81386 to 1.76122, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 12/100
83/83 [==============================] - 10s 121ms/step - loss: 1.7360 - accuracy: 0.3417 - val_loss: 1.7211 - val_accuracy: 0.3416

Epoch 00012: val_loss improved from 1.76122 to 1.72108, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 13/100
83/83 [==============================] - 10s 121ms/step - loss: 1.6978 - accuracy: 0.3430 - val_loss: 1.6847 - val_accuracy: 0.3468

Epoch 00013: val_loss improved from 1.72108 to 1.68469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 14/100
83/83 [==============================] - 10s 120ms/step - loss: 1.6710 - accuracy: 0.3485 - val_loss: 1.6645 - val_accuracy: 0.3488

Epoch 00014: val_loss improved from 1.68469 to 1.66447, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 15/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6501 - accuracy: 0.3527 - val_loss: 1.6547 - val_accuracy: 0.3482

Epoch 00015: val_loss improved from 1.66447 to 1.65467, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 16/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6340 - accuracy: 0.3561 - val_loss: 1.6397 - val_accuracy: 0.3524

Epoch 00016: val_loss improved from 1.65467 to 1.63974, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 17/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6244 - accuracy: 0.3595 - val_loss: 1.6356 - val_accuracy: 0.3523

Epoch 00017: val_loss improved from 1.63974 to 1.63563, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 18/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6113 - accuracy: 0.3618 - val_loss: 1.6324 - val_accuracy: 0.3531

Epoch 00018: val_loss improved from 1.63563 to 1.63240, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 19/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6046 - accuracy: 0.3646 - val_loss: 1.6240 - val_accuracy: 0.3561

Epoch 00019: val_loss improved from 1.63240 to 1.62397, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 20/100
83/83 [==============================] - 11s 135ms/step - loss: 1.6001 - accuracy: 0.3708 - val_loss: 1.6225 - val_accuracy: 0.3578

Epoch 00020: val_loss improved from 1.62397 to 1.62247, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 21/100
83/83 [==============================] - 11s 131ms/step - loss: 1.5928 - accuracy: 0.3734 - val_loss: 1.6222 - val_accuracy: 0.3546

Epoch 00021: val_loss improved from 1.62247 to 1.62221, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/4
Epoch 22/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5887 - accuracy: 0.3740 - val_loss: 1.6236 - val_accuracy: 0.3566

Epoch 00022: val_loss did not improve from 1.62221
Epoch 23/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5846 - accuracy: 0.3773 - val_loss: 1.6254 - val_accuracy: 0.3567

Epoch 00023: val_loss did not improve from 1.62221
Epoch 24/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5807 - accuracy: 0.3829 - val_loss: 1.6278 - val_accuracy: 0.3549

Epoch 00024: val_loss did not improve from 1.62221
Epoch 25/100
83/83 [==============================] - 11s 130ms/step - loss: 1.5748 - accuracy: 0.3883 - val_loss: 1.6292 - val_accuracy: 0.3598

Epoch 00025: val_loss did not improve from 1.62221
Epoch 26/100
83/83 [==============================] - 8s 90ms/step - loss: 1.5715 - accuracy: 0.3905 - val_loss: 1.6321 - val_accuracy: 0.3579

Epoch 00026: val_loss did not improve from 1.62221
Epoch 27/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5686 - accuracy: 0.3949 - val_loss: 1.6365 - val_accuracy: 0.3562

Epoch 00027: val_loss did not improve from 1.62221
Epoch 28/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5614 - accuracy: 0.3986 - val_loss: 1.6389 - val_accuracy: 0.3590

Epoch 00028: val_loss did not improve from 1.62221
Epoch 29/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5596 - accuracy: 0.4035 - val_loss: 1.6485 - val_accuracy: 0.3544

Epoch 00029: val_loss did not improve from 1.62221
Epoch 30/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5555 - accuracy: 0.4084 - val_loss: 1.6547 - val_accuracy: 0.3560

Epoch 00030: val_loss did not improve from 1.62221
Epoch 31/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5520 - accuracy: 0.4120 - val_loss: 1.6659 - val_accuracy: 0.3513

Epoch 00031: val_loss did not improve from 1.62221
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 66s 5ms/step - loss: 1.6341 - accuracy: 0.3456
Testing Loss = 1.634099, Testing Accuracy = 0.345564
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 10s 104ms/step - loss: 12.4159 - accuracy: 0.2110 - val_loss: 8.7059 - val_accuracy: 0.2034

Epoch 00001: val_loss improved from inf to 8.70591, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 2/100
83/83 [==============================] - 9s 104ms/step - loss: 6.7416 - accuracy: 0.2736 - val_loss: 5.4099 - val_accuracy: 0.2553

Epoch 00002: val_loss improved from 8.70591 to 5.40990, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 3/100
83/83 [==============================] - 8s 99ms/step - loss: 4.5799 - accuracy: 0.2936 - val_loss: 4.0156 - val_accuracy: 0.2885

Epoch 00003: val_loss improved from 5.40990 to 4.01555, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 4/100
83/83 [==============================] - 9s 104ms/step - loss: 3.5715 - accuracy: 0.3007 - val_loss: 3.2414 - val_accuracy: 0.3180

Epoch 00004: val_loss improved from 4.01555 to 3.24136, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 5/100
83/83 [==============================] - 9s 105ms/step - loss: 2.9753 - accuracy: 0.3094 - val_loss: 2.7514 - val_accuracy: 0.3203

Epoch 00005: val_loss improved from 3.24136 to 2.75136, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 6/100
83/83 [==============================] - 8s 97ms/step - loss: 2.5772 - accuracy: 0.3192 - val_loss: 2.4179 - val_accuracy: 0.3248

Epoch 00006: val_loss improved from 2.75136 to 2.41792, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 7/100
83/83 [==============================] - 9s 103ms/step - loss: 2.2972 - accuracy: 0.3247 - val_loss: 2.1807 - val_accuracy: 0.3284

Epoch 00007: val_loss improved from 2.41792 to 2.18066, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 8/100
83/83 [==============================] - 9s 102ms/step - loss: 2.1010 - accuracy: 0.3251 - val_loss: 2.0139 - val_accuracy: 0.3339

Epoch 00008: val_loss improved from 2.18066 to 2.01389, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 9/100
83/83 [==============================] - 8s 97ms/step - loss: 1.9585 - accuracy: 0.3285 - val_loss: 1.8984 - val_accuracy: 0.3384

Epoch 00009: val_loss improved from 2.01389 to 1.89836, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 10/100
83/83 [==============================] - 9s 106ms/step - loss: 1.8573 - accuracy: 0.3343 - val_loss: 1.8124 - val_accuracy: 0.3437

Epoch 00010: val_loss improved from 1.89836 to 1.81244, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 11/100
83/83 [==============================] - 9s 104ms/step - loss: 1.7865 - accuracy: 0.3390 - val_loss: 1.7580 - val_accuracy: 0.3428

Epoch 00011: val_loss improved from 1.81244 to 1.75795, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 12/100
83/83 [==============================] - 8s 98ms/step - loss: 1.7351 - accuracy: 0.3410 - val_loss: 1.7191 - val_accuracy: 0.3390

Epoch 00012: val_loss improved from 1.75795 to 1.71909, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 13/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6966 - accuracy: 0.3472 - val_loss: 1.6912 - val_accuracy: 0.3443

Epoch 00013: val_loss improved from 1.71909 to 1.69120, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 14/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6684 - accuracy: 0.3520 - val_loss: 1.6701 - val_accuracy: 0.3439

Epoch 00014: val_loss improved from 1.69120 to 1.67008, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 15/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6473 - accuracy: 0.3542 - val_loss: 1.6571 - val_accuracy: 0.3466

Epoch 00015: val_loss improved from 1.67008 to 1.65709, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 16/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6340 - accuracy: 0.3590 - val_loss: 1.6413 - val_accuracy: 0.3503

Epoch 00016: val_loss improved from 1.65709 to 1.64134, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 17/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6210 - accuracy: 0.3619 - val_loss: 1.6358 - val_accuracy: 0.3515

Epoch 00017: val_loss improved from 1.64134 to 1.63579, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 18/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6108 - accuracy: 0.3653 - val_loss: 1.6296 - val_accuracy: 0.3528

Epoch 00018: val_loss improved from 1.63579 to 1.62960, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 19/100
83/83 [==============================] - 11s 134ms/step - loss: 1.6022 - accuracy: 0.3698 - val_loss: 1.6275 - val_accuracy: 0.3539

Epoch 00019: val_loss improved from 1.62960 to 1.62753, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 20/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5952 - accuracy: 0.3723 - val_loss: 1.6236 - val_accuracy: 0.3550

Epoch 00020: val_loss improved from 1.62753 to 1.62362, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/5
Epoch 21/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5884 - accuracy: 0.3760 - val_loss: 1.6263 - val_accuracy: 0.3554

Epoch 00021: val_loss did not improve from 1.62362
Epoch 22/100
83/83 [==============================] - 11s 133ms/step - loss: 1.5861 - accuracy: 0.3810 - val_loss: 1.6272 - val_accuracy: 0.3545

Epoch 00022: val_loss did not improve from 1.62362
Epoch 23/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5810 - accuracy: 0.3854 - val_loss: 1.6298 - val_accuracy: 0.3560

Epoch 00023: val_loss did not improve from 1.62362
Epoch 24/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5752 - accuracy: 0.3884 - val_loss: 1.6325 - val_accuracy: 0.3581

Epoch 00024: val_loss did not improve from 1.62362
Epoch 25/100
83/83 [==============================] - 7s 80ms/step - loss: 1.5723 - accuracy: 0.3904 - val_loss: 1.6359 - val_accuracy: 0.3562

Epoch 00025: val_loss did not improve from 1.62362
Epoch 26/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5665 - accuracy: 0.3978 - val_loss: 1.6406 - val_accuracy: 0.3560

Epoch 00026: val_loss did not improve from 1.62362
Epoch 27/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5634 - accuracy: 0.3998 - val_loss: 1.6527 - val_accuracy: 0.3512

Epoch 00027: val_loss did not improve from 1.62362
Epoch 28/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5581 - accuracy: 0.4050 - val_loss: 1.6618 - val_accuracy: 0.3498

Epoch 00028: val_loss did not improve from 1.62362
Epoch 29/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5538 - accuracy: 0.4111 - val_loss: 1.6709 - val_accuracy: 0.3492

Epoch 00029: val_loss did not improve from 1.62362
Epoch 30/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5481 - accuracy: 0.4158 - val_loss: 1.6835 - val_accuracy: 0.3460

Epoch 00030: val_loss did not improve from 1.62362
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 68s 5ms/step - loss: 1.6357 - accuracy: 0.3497
Testing Loss = 1.635704, Testing Accuracy = 0.349732
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 9s 104ms/step - loss: 12.4396 - accuracy: 0.2068 - val_loss: 8.7332 - val_accuracy: 0.2130

Epoch 00001: val_loss improved from inf to 8.73324, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 2/100
83/83 [==============================] - 8s 97ms/step - loss: 6.7714 - accuracy: 0.2705 - val_loss: 5.4316 - val_accuracy: 0.2638

Epoch 00002: val_loss improved from 8.73324 to 5.43163, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 3/100
83/83 [==============================] - 9s 102ms/step - loss: 4.6033 - accuracy: 0.2876 - val_loss: 4.0253 - val_accuracy: 0.2935

Epoch 00003: val_loss improved from 5.43163 to 4.02528, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 4/100
83/83 [==============================] - 9s 104ms/step - loss: 3.5831 - accuracy: 0.3022 - val_loss: 3.2506 - val_accuracy: 0.3128

Epoch 00004: val_loss improved from 4.02528 to 3.25056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 5/100
83/83 [==============================] - 8s 99ms/step - loss: 2.9838 - accuracy: 0.3110 - val_loss: 2.7597 - val_accuracy: 0.3203

Epoch 00005: val_loss improved from 3.25056 to 2.75966, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 6/100
83/83 [==============================] - 9s 105ms/step - loss: 2.5837 - accuracy: 0.3167 - val_loss: 2.4229 - val_accuracy: 0.3256

Epoch 00006: val_loss improved from 2.75966 to 2.42289, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 7/100
83/83 [==============================] - 8s 99ms/step - loss: 2.3054 - accuracy: 0.3204 - val_loss: 2.1811 - val_accuracy: 0.3351

Epoch 00007: val_loss improved from 2.42289 to 2.18105, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 8/100
83/83 [==============================] - 9s 103ms/step - loss: 2.1071 - accuracy: 0.3240 - val_loss: 2.0195 - val_accuracy: 0.3339

Epoch 00008: val_loss improved from 2.18105 to 2.01951, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 9/100
83/83 [==============================] - 9s 104ms/step - loss: 1.9651 - accuracy: 0.3275 - val_loss: 1.9018 - val_accuracy: 0.3360

Epoch 00009: val_loss improved from 2.01951 to 1.90183, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 10/100
83/83 [==============================] - 9s 109ms/step - loss: 1.8645 - accuracy: 0.3327 - val_loss: 1.8212 - val_accuracy: 0.3372

Epoch 00010: val_loss improved from 1.90183 to 1.82117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 11/100
83/83 [==============================] - 9s 104ms/step - loss: 1.7919 - accuracy: 0.3345 - val_loss: 1.7592 - val_accuracy: 0.3423

Epoch 00011: val_loss improved from 1.82117 to 1.75922, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 12/100
83/83 [==============================] - 9s 108ms/step - loss: 1.7388 - accuracy: 0.3383 - val_loss: 1.7197 - val_accuracy: 0.3435

Epoch 00012: val_loss improved from 1.75922 to 1.71971, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 13/100
83/83 [==============================] - 9s 104ms/step - loss: 1.7019 - accuracy: 0.3440 - val_loss: 1.6935 - val_accuracy: 0.3396

Epoch 00013: val_loss improved from 1.71971 to 1.69352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 14/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6729 - accuracy: 0.3475 - val_loss: 1.6721 - val_accuracy: 0.3413

Epoch 00014: val_loss improved from 1.69352 to 1.67206, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 15/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6538 - accuracy: 0.3508 - val_loss: 1.6580 - val_accuracy: 0.3422

Epoch 00015: val_loss improved from 1.67206 to 1.65801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 16/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6369 - accuracy: 0.3541 - val_loss: 1.6437 - val_accuracy: 0.3484

Epoch 00016: val_loss improved from 1.65801 to 1.64368, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 17/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6247 - accuracy: 0.3565 - val_loss: 1.6339 - val_accuracy: 0.3508

Epoch 00017: val_loss improved from 1.64368 to 1.63392, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 18/100
83/83 [==============================] - 11s 134ms/step - loss: 1.6138 - accuracy: 0.3595 - val_loss: 1.6291 - val_accuracy: 0.3540

Epoch 00018: val_loss improved from 1.63392 to 1.62914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 19/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6062 - accuracy: 0.3648 - val_loss: 1.6238 - val_accuracy: 0.3550

Epoch 00019: val_loss improved from 1.62914 to 1.62381, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 20/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6000 - accuracy: 0.3681 - val_loss: 1.6198 - val_accuracy: 0.3551

Epoch 00020: val_loss improved from 1.62381 to 1.61984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/6
Epoch 21/100
83/83 [==============================] - 11s 130ms/step - loss: 1.5930 - accuracy: 0.3719 - val_loss: 1.6209 - val_accuracy: 0.3560

Epoch 00021: val_loss did not improve from 1.61984
Epoch 22/100
83/83 [==============================] - 11s 131ms/step - loss: 1.5902 - accuracy: 0.3733 - val_loss: 1.6252 - val_accuracy: 0.3512

Epoch 00022: val_loss did not improve from 1.61984
Epoch 23/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5840 - accuracy: 0.3778 - val_loss: 1.6234 - val_accuracy: 0.3567

Epoch 00023: val_loss did not improve from 1.61984
Epoch 24/100
83/83 [==============================] - 11s 133ms/step - loss: 1.5799 - accuracy: 0.3835 - val_loss: 1.6271 - val_accuracy: 0.3554

Epoch 00024: val_loss did not improve from 1.61984
Epoch 25/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5757 - accuracy: 0.3854 - val_loss: 1.6289 - val_accuracy: 0.3586

Epoch 00025: val_loss did not improve from 1.61984
Epoch 26/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5715 - accuracy: 0.3894 - val_loss: 1.6330 - val_accuracy: 0.3587

Epoch 00026: val_loss did not improve from 1.61984
Epoch 27/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5709 - accuracy: 0.3898 - val_loss: 1.6377 - val_accuracy: 0.3562

Epoch 00027: val_loss did not improve from 1.61984
Epoch 28/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5688 - accuracy: 0.3970 - val_loss: 1.6399 - val_accuracy: 0.3567

Epoch 00028: val_loss did not improve from 1.61984
Epoch 29/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5632 - accuracy: 0.3981 - val_loss: 1.6462 - val_accuracy: 0.3570

Epoch 00029: val_loss did not improve from 1.61984
Epoch 30/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5545 - accuracy: 0.4063 - val_loss: 1.6571 - val_accuracy: 0.3556

Epoch 00030: val_loss did not improve from 1.61984
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 67s 5ms/step - loss: 1.6330 - accuracy: 0.3463
Testing Loss = 1.632959, Testing Accuracy = 0.346308
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 9s 103ms/step - loss: 12.2682 - accuracy: 0.2149 - val_loss: 8.5364 - val_accuracy: 0.2224

Epoch 00001: val_loss improved from inf to 8.53638, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 2/100
83/83 [==============================] - 8s 99ms/step - loss: 6.6384 - accuracy: 0.2749 - val_loss: 5.3409 - val_accuracy: 0.2704

Epoch 00002: val_loss improved from 8.53638 to 5.34087, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 3/100
83/83 [==============================] - 9s 105ms/step - loss: 4.5428 - accuracy: 0.2914 - val_loss: 3.9813 - val_accuracy: 0.2997

Epoch 00003: val_loss improved from 5.34087 to 3.98134, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 4/100
83/83 [==============================] - 9s 106ms/step - loss: 3.5563 - accuracy: 0.3045 - val_loss: 3.2345 - val_accuracy: 0.3139

Epoch 00004: val_loss improved from 3.98134 to 3.23453, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 5/100
83/83 [==============================] - 8s 101ms/step - loss: 2.9724 - accuracy: 0.3115 - val_loss: 2.7535 - val_accuracy: 0.3189

Epoch 00005: val_loss improved from 3.23453 to 2.75346, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 6/100
83/83 [==============================] - 9s 106ms/step - loss: 2.5785 - accuracy: 0.3153 - val_loss: 2.4146 - val_accuracy: 0.3264

Epoch 00006: val_loss improved from 2.75346 to 2.41463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 7/100
83/83 [==============================] - 9s 104ms/step - loss: 2.3014 - accuracy: 0.3221 - val_loss: 2.1787 - val_accuracy: 0.3305

Epoch 00007: val_loss improved from 2.41463 to 2.17870, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 8/100
83/83 [==============================] - 9s 111ms/step - loss: 2.1042 - accuracy: 0.3263 - val_loss: 2.0207 - val_accuracy: 0.3280

Epoch 00008: val_loss improved from 2.17870 to 2.02073, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 9/100
83/83 [==============================] - 9s 110ms/step - loss: 1.9636 - accuracy: 0.3282 - val_loss: 1.9018 - val_accuracy: 0.3321

Epoch 00009: val_loss improved from 2.02073 to 1.90176, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 10/100
83/83 [==============================] - 9s 110ms/step - loss: 1.8627 - accuracy: 0.3334 - val_loss: 1.8212 - val_accuracy: 0.3335

Epoch 00010: val_loss improved from 1.90176 to 1.82121, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 11/100
83/83 [==============================] - 9s 110ms/step - loss: 1.7906 - accuracy: 0.3355 - val_loss: 1.7612 - val_accuracy: 0.3421

Epoch 00011: val_loss improved from 1.82121 to 1.76122, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 12/100
83/83 [==============================] - 9s 113ms/step - loss: 1.7373 - accuracy: 0.3425 - val_loss: 1.7190 - val_accuracy: 0.3444

Epoch 00012: val_loss improved from 1.76122 to 1.71897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 13/100
83/83 [==============================] - 9s 113ms/step - loss: 1.7017 - accuracy: 0.3434 - val_loss: 1.6920 - val_accuracy: 0.3464

Epoch 00013: val_loss improved from 1.71897 to 1.69196, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 14/100
83/83 [==============================] - 10s 116ms/step - loss: 1.6744 - accuracy: 0.3465 - val_loss: 1.6728 - val_accuracy: 0.3385

Epoch 00014: val_loss improved from 1.69196 to 1.67282, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 15/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6525 - accuracy: 0.3520 - val_loss: 1.6582 - val_accuracy: 0.3426

Epoch 00015: val_loss improved from 1.67282 to 1.65820, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 16/100
83/83 [==============================] - 10s 121ms/step - loss: 1.6363 - accuracy: 0.3546 - val_loss: 1.6456 - val_accuracy: 0.3476

Epoch 00016: val_loss improved from 1.65820 to 1.64558, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 17/100
83/83 [==============================] - 11s 133ms/step - loss: 1.6251 - accuracy: 0.3614 - val_loss: 1.6329 - val_accuracy: 0.3536

Epoch 00017: val_loss improved from 1.64558 to 1.63287, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 18/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6153 - accuracy: 0.3631 - val_loss: 1.6358 - val_accuracy: 0.3479

Epoch 00018: val_loss did not improve from 1.63287
Epoch 19/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6065 - accuracy: 0.3624 - val_loss: 1.6305 - val_accuracy: 0.3519

Epoch 00019: val_loss improved from 1.63287 to 1.63055, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 20/100
83/83 [==============================] - 11s 132ms/step - loss: 1.5995 - accuracy: 0.3681 - val_loss: 1.6261 - val_accuracy: 0.3569

Epoch 00020: val_loss improved from 1.63055 to 1.62608, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 21/100
83/83 [==============================] - 11s 130ms/step - loss: 1.5934 - accuracy: 0.3729 - val_loss: 1.6227 - val_accuracy: 0.3548

Epoch 00021: val_loss improved from 1.62608 to 1.62266, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 22/100
83/83 [==============================] - 11s 131ms/step - loss: 1.5896 - accuracy: 0.3745 - val_loss: 1.6262 - val_accuracy: 0.3521

Epoch 00022: val_loss did not improve from 1.62266
Epoch 23/100
83/83 [==============================] - 11s 129ms/step - loss: 1.5839 - accuracy: 0.3784 - val_loss: 1.6224 - val_accuracy: 0.3554

Epoch 00023: val_loss improved from 1.62266 to 1.62241, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/7
Epoch 24/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5787 - accuracy: 0.3814 - val_loss: 1.6301 - val_accuracy: 0.3532

Epoch 00024: val_loss did not improve from 1.62241
Epoch 25/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5772 - accuracy: 0.3865 - val_loss: 1.6281 - val_accuracy: 0.3582

Epoch 00025: val_loss did not improve from 1.62241
Epoch 26/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5713 - accuracy: 0.3907 - val_loss: 1.6352 - val_accuracy: 0.3557

Epoch 00026: val_loss did not improve from 1.62241
Epoch 27/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5690 - accuracy: 0.3914 - val_loss: 1.6361 - val_accuracy: 0.3561

Epoch 00027: val_loss did not improve from 1.62241
Epoch 28/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5643 - accuracy: 0.3976 - val_loss: 1.6415 - val_accuracy: 0.3583

Epoch 00028: val_loss did not improve from 1.62241
Epoch 29/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5595 - accuracy: 0.4030 - val_loss: 1.6501 - val_accuracy: 0.3587

Epoch 00029: val_loss did not improve from 1.62241
Epoch 30/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5577 - accuracy: 0.4054 - val_loss: 1.6566 - val_accuracy: 0.3569

Epoch 00030: val_loss did not improve from 1.62241
Epoch 31/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5537 - accuracy: 0.4121 - val_loss: 1.6659 - val_accuracy: 0.3491

Epoch 00031: val_loss did not improve from 1.62241
Epoch 32/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5456 - accuracy: 0.4199 - val_loss: 1.6777 - val_accuracy: 0.3521

Epoch 00032: val_loss did not improve from 1.62241
Epoch 33/100
83/83 [==============================] - 7s 79ms/step - loss: 1.5433 - accuracy: 0.4245 - val_loss: 1.6836 - val_accuracy: 0.3544

Epoch 00033: val_loss did not improve from 1.62241
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 72s 5ms/step - loss: 1.6356 - accuracy: 0.3479
Testing Loss = 1.635589, Testing Accuracy = 0.347946
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 9s 104ms/step - loss: 12.3670 - accuracy: 0.2029 - val_loss: 8.6325 - val_accuracy: 0.1975

Epoch 00001: val_loss improved from inf to 8.63247, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 2/100
83/83 [==============================] - 9s 105ms/step - loss: 6.6748 - accuracy: 0.2564 - val_loss: 5.3354 - val_accuracy: 0.2616

Epoch 00002: val_loss improved from 8.63247 to 5.33545, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 3/100
83/83 [==============================] - 8s 97ms/step - loss: 4.5197 - accuracy: 0.2914 - val_loss: 3.9660 - val_accuracy: 0.2929

Epoch 00003: val_loss improved from 5.33545 to 3.96599, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 4/100
83/83 [==============================] - 9s 102ms/step - loss: 3.5356 - accuracy: 0.2995 - val_loss: 3.2171 - val_accuracy: 0.3146

Epoch 00004: val_loss improved from 3.96599 to 3.21713, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 5/100
83/83 [==============================] - 9s 102ms/step - loss: 2.9546 - accuracy: 0.3097 - val_loss: 2.7319 - val_accuracy: 0.3253

Epoch 00005: val_loss improved from 3.21713 to 2.73186, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 6/100
83/83 [==============================] - 8s 96ms/step - loss: 2.5636 - accuracy: 0.3153 - val_loss: 2.4006 - val_accuracy: 0.3305

Epoch 00006: val_loss improved from 2.73186 to 2.40056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 7/100
83/83 [==============================] - 9s 105ms/step - loss: 2.2908 - accuracy: 0.3181 - val_loss: 2.1709 - val_accuracy: 0.3320

Epoch 00007: val_loss improved from 2.40056 to 2.17093, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 8/100
83/83 [==============================] - 9s 102ms/step - loss: 2.0944 - accuracy: 0.3285 - val_loss: 2.0086 - val_accuracy: 0.3316

Epoch 00008: val_loss improved from 2.17093 to 2.00862, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 9/100
83/83 [==============================] - 9s 102ms/step - loss: 1.9566 - accuracy: 0.3277 - val_loss: 1.8957 - val_accuracy: 0.3368

Epoch 00009: val_loss improved from 2.00862 to 1.89566, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 10/100
83/83 [==============================] - 8s 96ms/step - loss: 1.8581 - accuracy: 0.3326 - val_loss: 1.8111 - val_accuracy: 0.3427

Epoch 00010: val_loss improved from 1.89566 to 1.81113, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 11/100
83/83 [==============================] - 9s 106ms/step - loss: 1.7859 - accuracy: 0.3358 - val_loss: 1.7535 - val_accuracy: 0.3430

Epoch 00011: val_loss improved from 1.81113 to 1.75347, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 12/100
83/83 [==============================] - 11s 132ms/step - loss: 1.7364 - accuracy: 0.3404 - val_loss: 1.7163 - val_accuracy: 0.3450

Epoch 00012: val_loss improved from 1.75347 to 1.71629, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 13/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6977 - accuracy: 0.3444 - val_loss: 1.6898 - val_accuracy: 0.3441

Epoch 00013: val_loss improved from 1.71629 to 1.68976, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 14/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6724 - accuracy: 0.3484 - val_loss: 1.6739 - val_accuracy: 0.3388

Epoch 00014: val_loss improved from 1.68976 to 1.67395, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 15/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6512 - accuracy: 0.3518 - val_loss: 1.6537 - val_accuracy: 0.3479

Epoch 00015: val_loss improved from 1.67395 to 1.65367, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 16/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6352 - accuracy: 0.3572 - val_loss: 1.6490 - val_accuracy: 0.3499

Epoch 00016: val_loss improved from 1.65367 to 1.64901, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 17/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6218 - accuracy: 0.3586 - val_loss: 1.6328 - val_accuracy: 0.3558

Epoch 00017: val_loss improved from 1.64901 to 1.63282, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 18/100
83/83 [==============================] - 11s 133ms/step - loss: 1.6150 - accuracy: 0.3618 - val_loss: 1.6326 - val_accuracy: 0.3579

Epoch 00018: val_loss improved from 1.63282 to 1.63265, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 19/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6056 - accuracy: 0.3675 - val_loss: 1.6294 - val_accuracy: 0.3544

Epoch 00019: val_loss improved from 1.63265 to 1.62938, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 20/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5989 - accuracy: 0.3700 - val_loss: 1.6283 - val_accuracy: 0.3583

Epoch 00020: val_loss improved from 1.62938 to 1.62831, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 21/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5953 - accuracy: 0.3741 - val_loss: 1.6283 - val_accuracy: 0.3549

Epoch 00021: val_loss improved from 1.62831 to 1.62827, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 22/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5875 - accuracy: 0.3764 - val_loss: 1.6287 - val_accuracy: 0.3591

Epoch 00022: val_loss did not improve from 1.62827
Epoch 23/100
83/83 [==============================] - 7s 83ms/step - loss: 1.5855 - accuracy: 0.3801 - val_loss: 1.6260 - val_accuracy: 0.3554

Epoch 00023: val_loss improved from 1.62827 to 1.62600, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/8
Epoch 24/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5803 - accuracy: 0.3830 - val_loss: 1.6318 - val_accuracy: 0.3568

Epoch 00024: val_loss did not improve from 1.62600
Epoch 25/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5751 - accuracy: 0.3896 - val_loss: 1.6353 - val_accuracy: 0.3564

Epoch 00025: val_loss did not improve from 1.62600
Epoch 26/100
83/83 [==============================] - 7s 83ms/step - loss: 1.5717 - accuracy: 0.3927 - val_loss: 1.6400 - val_accuracy: 0.3566

Epoch 00026: val_loss did not improve from 1.62600
Epoch 27/100
83/83 [==============================] - 7s 83ms/step - loss: 1.5667 - accuracy: 0.3966 - val_loss: 1.6440 - val_accuracy: 0.3532

Epoch 00027: val_loss did not improve from 1.62600
Epoch 28/100
83/83 [==============================] - 7s 79ms/step - loss: 1.5616 - accuracy: 0.4012 - val_loss: 1.6527 - val_accuracy: 0.3547

Epoch 00028: val_loss did not improve from 1.62600
Epoch 29/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5562 - accuracy: 0.4092 - val_loss: 1.6575 - val_accuracy: 0.3513

Epoch 00029: val_loss did not improve from 1.62600
Epoch 30/100
83/83 [==============================] - 7s 82ms/step - loss: 1.5488 - accuracy: 0.4148 - val_loss: 1.6698 - val_accuracy: 0.3546

Epoch 00030: val_loss did not improve from 1.62600
Epoch 31/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5473 - accuracy: 0.4191 - val_loss: 1.6814 - val_accuracy: 0.3515

Epoch 00031: val_loss did not improve from 1.62600
Epoch 32/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5389 - accuracy: 0.4274 - val_loss: 1.6922 - val_accuracy: 0.3471

Epoch 00032: val_loss did not improve from 1.62600
Epoch 33/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5322 - accuracy: 0.4340 - val_loss: 1.7051 - val_accuracy: 0.3509

Epoch 00033: val_loss did not improve from 1.62600
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 77s 6ms/step - loss: 1.6398 - accuracy: 0.3462
Testing Loss = 1.639843, Testing Accuracy = 0.346234
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 10s 104ms/step - loss: 12.2465 - accuracy: 0.2066 - val_loss: 8.4898 - val_accuracy: 0.2189

Epoch 00001: val_loss improved from inf to 8.48985, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 2/100
83/83 [==============================] - 9s 106ms/step - loss: 6.5730 - accuracy: 0.2712 - val_loss: 5.2859 - val_accuracy: 0.2819

Epoch 00002: val_loss improved from 8.48985 to 5.28590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 3/100
83/83 [==============================] - 9s 104ms/step - loss: 4.4975 - accuracy: 0.2916 - val_loss: 3.9539 - val_accuracy: 0.3055

Epoch 00003: val_loss improved from 5.28590 to 3.95391, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 4/100
83/83 [==============================] - 9s 113ms/step - loss: 3.5368 - accuracy: 0.3026 - val_loss: 3.2186 - val_accuracy: 0.3166

Epoch 00004: val_loss improved from 3.95391 to 3.21860, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 5/100
83/83 [==============================] - 9s 113ms/step - loss: 2.9618 - accuracy: 0.3084 - val_loss: 2.7457 - val_accuracy: 0.3170

Epoch 00005: val_loss improved from 3.21860 to 2.74575, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 6/100
83/83 [==============================] - 9s 110ms/step - loss: 2.5726 - accuracy: 0.3158 - val_loss: 2.4104 - val_accuracy: 0.3267

Epoch 00006: val_loss improved from 2.74575 to 2.41040, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 7/100
83/83 [==============================] - 9s 113ms/step - loss: 2.2998 - accuracy: 0.3225 - val_loss: 2.1785 - val_accuracy: 0.3271

Epoch 00007: val_loss improved from 2.41040 to 2.17854, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 8/100
83/83 [==============================] - 10s 117ms/step - loss: 2.1036 - accuracy: 0.3261 - val_loss: 2.0162 - val_accuracy: 0.3305

Epoch 00008: val_loss improved from 2.17854 to 2.01618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 9/100
83/83 [==============================] - 11s 132ms/step - loss: 1.9643 - accuracy: 0.3262 - val_loss: 1.9015 - val_accuracy: 0.3335

Epoch 00009: val_loss improved from 2.01618 to 1.90148, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 10/100
83/83 [==============================] - 9s 106ms/step - loss: 1.8629 - accuracy: 0.3314 - val_loss: 1.8178 - val_accuracy: 0.3392

Epoch 00010: val_loss improved from 1.90148 to 1.81779, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 11/100
83/83 [==============================] - 11s 130ms/step - loss: 1.7924 - accuracy: 0.3330 - val_loss: 1.7577 - val_accuracy: 0.3442

Epoch 00011: val_loss improved from 1.81779 to 1.75773, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 12/100
83/83 [==============================] - 11s 131ms/step - loss: 1.7384 - accuracy: 0.3356 - val_loss: 1.7193 - val_accuracy: 0.3395

Epoch 00012: val_loss improved from 1.75773 to 1.71927, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 13/100
83/83 [==============================] - 11s 131ms/step - loss: 1.7008 - accuracy: 0.3418 - val_loss: 1.6876 - val_accuracy: 0.3479

Epoch 00013: val_loss improved from 1.71927 to 1.68757, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 14/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6765 - accuracy: 0.3450 - val_loss: 1.6753 - val_accuracy: 0.3417

Epoch 00014: val_loss improved from 1.68757 to 1.67528, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 15/100
83/83 [==============================] - 11s 131ms/step - loss: 1.6545 - accuracy: 0.3488 - val_loss: 1.6571 - val_accuracy: 0.3455

Epoch 00015: val_loss improved from 1.67528 to 1.65706, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 16/100
83/83 [==============================] - 11s 132ms/step - loss: 1.6391 - accuracy: 0.3526 - val_loss: 1.6506 - val_accuracy: 0.3437

Epoch 00016: val_loss improved from 1.65706 to 1.65058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 17/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6274 - accuracy: 0.3554 - val_loss: 1.6391 - val_accuracy: 0.3504

Epoch 00017: val_loss improved from 1.65058 to 1.63913, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 18/100
83/83 [==============================] - 7s 84ms/step - loss: 1.6171 - accuracy: 0.3612 - val_loss: 1.6331 - val_accuracy: 0.3513

Epoch 00018: val_loss improved from 1.63913 to 1.63309, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 19/100
83/83 [==============================] - 7s 83ms/step - loss: 1.6099 - accuracy: 0.3619 - val_loss: 1.6252 - val_accuracy: 0.3542

Epoch 00019: val_loss improved from 1.63309 to 1.62523, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 20/100
83/83 [==============================] - 7s 83ms/step - loss: 1.6047 - accuracy: 0.3647 - val_loss: 1.6311 - val_accuracy: 0.3526

Epoch 00020: val_loss did not improve from 1.62523
Epoch 21/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5981 - accuracy: 0.3692 - val_loss: 1.6219 - val_accuracy: 0.3545

Epoch 00021: val_loss improved from 1.62523 to 1.62186, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r11/Try/9
Epoch 22/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5931 - accuracy: 0.3697 - val_loss: 1.6243 - val_accuracy: 0.3539

Epoch 00022: val_loss did not improve from 1.62186
Epoch 23/100
83/83 [==============================] - 7s 83ms/step - loss: 1.5867 - accuracy: 0.3767 - val_loss: 1.6249 - val_accuracy: 0.3534

Epoch 00023: val_loss did not improve from 1.62186
Epoch 24/100
83/83 [==============================] - 7s 83ms/step - loss: 1.5833 - accuracy: 0.3779 - val_loss: 1.6251 - val_accuracy: 0.3542

Epoch 00024: val_loss did not improve from 1.62186
Epoch 25/100
83/83 [==============================] - 7s 79ms/step - loss: 1.5800 - accuracy: 0.3825 - val_loss: 1.6306 - val_accuracy: 0.3534

Epoch 00025: val_loss did not improve from 1.62186
Epoch 26/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5766 - accuracy: 0.3853 - val_loss: 1.6301 - val_accuracy: 0.3556

Epoch 00026: val_loss did not improve from 1.62186
Epoch 27/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5728 - accuracy: 0.3910 - val_loss: 1.6333 - val_accuracy: 0.3573

Epoch 00027: val_loss did not improve from 1.62186
Epoch 28/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5736 - accuracy: 0.3924 - val_loss: 1.6452 - val_accuracy: 0.3547

Epoch 00028: val_loss did not improve from 1.62186
Epoch 29/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5638 - accuracy: 0.3981 - val_loss: 1.6473 - val_accuracy: 0.3576

Epoch 00029: val_loss did not improve from 1.62186
Epoch 30/100
83/83 [==============================] - 7s 84ms/step - loss: 1.5613 - accuracy: 0.4005 - val_loss: 1.6510 - val_accuracy: 0.3568

Epoch 00030: val_loss did not improve from 1.62186
Epoch 31/100
83/83 [==============================] - 7s 81ms/step - loss: 1.5554 - accuracy: 0.4085 - val_loss: 1.6601 - val_accuracy: 0.3540

Epoch 00031: val_loss did not improve from 1.62186
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.6328 - accuracy: 0.3473
Testing Loss = 1.632806, Testing Accuracy = 0.347276
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 82.03 +- 0.0624 %)
$W^-/W^-$ (auc = 81.51 +- 0.0881 %)
$Z/Z$ (auc = 67.58 +- 0.1982 %)
$W^+/W^-$ (auc = 66.62 +- 0.1184 %)
$W^+/Z$$ (auc = 65.96 +- 0.0755 %)
$W^-/Z$ (auc = 67.79 +- 0.0717 %)
The summarized testing accuracy = 34.76 +- 0.1818 %, with the loss = 1.6351 +- 0.002658
