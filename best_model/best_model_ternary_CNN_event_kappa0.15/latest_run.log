

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-22 20:28:14.159237
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 9s 70ms/step - loss: 12.5373 - accuracy: 0.1962 - val_loss: 8.8425 - val_accuracy: 0.2094

Epoch 00001: val_loss improved from inf to 8.84249, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8987 - accuracy: 0.2038 - val_loss: 5.4355 - val_accuracy: 0.2092

Epoch 00002: val_loss improved from 8.84249 to 5.43549, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.6437 - accuracy: 0.2116 - val_loss: 4.0084 - val_accuracy: 0.2140

Epoch 00003: val_loss improved from 5.43549 to 4.00841, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5525 - accuracy: 0.2460 - val_loss: 3.1898 - val_accuracy: 0.2887

Epoch 00004: val_loss improved from 4.00841 to 3.18977, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8968 - accuracy: 0.2911 - val_loss: 2.6973 - val_accuracy: 0.3087

Epoch 00005: val_loss improved from 3.18977 to 2.69730, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5046 - accuracy: 0.3006 - val_loss: 2.3583 - val_accuracy: 0.3219

Epoch 00006: val_loss improved from 2.69730 to 2.35829, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2380 - accuracy: 0.3105 - val_loss: 2.1282 - val_accuracy: 0.3251

Epoch 00007: val_loss improved from 2.35829 to 2.12823, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0498 - accuracy: 0.3193 - val_loss: 1.9628 - val_accuracy: 0.3313

Epoch 00008: val_loss improved from 2.12823 to 1.96279, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9163 - accuracy: 0.3271 - val_loss: 1.8513 - val_accuracy: 0.3345

Epoch 00009: val_loss improved from 1.96279 to 1.85133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8236 - accuracy: 0.3347 - val_loss: 1.7747 - val_accuracy: 0.3413

Epoch 00010: val_loss improved from 1.85133 to 1.77469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 11/100
83/83 [==============================] - 6s 70ms/step - loss: 1.7556 - accuracy: 0.3433 - val_loss: 1.7219 - val_accuracy: 0.3456

Epoch 00011: val_loss improved from 1.77469 to 1.72187, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7075 - accuracy: 0.3475 - val_loss: 1.6831 - val_accuracy: 0.3498

Epoch 00012: val_loss improved from 1.72187 to 1.68308, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6693 - accuracy: 0.3595 - val_loss: 1.6551 - val_accuracy: 0.3572

Epoch 00013: val_loss improved from 1.68308 to 1.65514, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6392 - accuracy: 0.3690 - val_loss: 1.6271 - val_accuracy: 0.3616

Epoch 00014: val_loss improved from 1.65514 to 1.62711, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6162 - accuracy: 0.3723 - val_loss: 1.6111 - val_accuracy: 0.3671

Epoch 00015: val_loss improved from 1.62711 to 1.61111, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5962 - accuracy: 0.3810 - val_loss: 1.5961 - val_accuracy: 0.3751

Epoch 00016: val_loss improved from 1.61111 to 1.59613, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5806 - accuracy: 0.3893 - val_loss: 1.5916 - val_accuracy: 0.3804

Epoch 00017: val_loss improved from 1.59613 to 1.59161, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5723 - accuracy: 0.3926 - val_loss: 1.5844 - val_accuracy: 0.3828

Epoch 00018: val_loss improved from 1.59161 to 1.58439, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5615 - accuracy: 0.3950 - val_loss: 1.5751 - val_accuracy: 0.3874

Epoch 00019: val_loss improved from 1.58439 to 1.57506, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5492 - accuracy: 0.4012 - val_loss: 1.5739 - val_accuracy: 0.3894

Epoch 00020: val_loss improved from 1.57506 to 1.57394, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5406 - accuracy: 0.4083 - val_loss: 1.5699 - val_accuracy: 0.3873

Epoch 00021: val_loss improved from 1.57394 to 1.56992, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5325 - accuracy: 0.4135 - val_loss: 1.5672 - val_accuracy: 0.3954

Epoch 00022: val_loss improved from 1.56992 to 1.56722, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5241 - accuracy: 0.4192 - val_loss: 1.5689 - val_accuracy: 0.3912

Epoch 00023: val_loss did not improve from 1.56722
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5202 - accuracy: 0.4231 - val_loss: 1.5706 - val_accuracy: 0.3911

Epoch 00024: val_loss did not improve from 1.56722
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5153 - accuracy: 0.4239 - val_loss: 1.5688 - val_accuracy: 0.3955

Epoch 00025: val_loss did not improve from 1.56722
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5065 - accuracy: 0.4307 - val_loss: 1.5714 - val_accuracy: 0.3923

Epoch 00026: val_loss did not improve from 1.56722
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5011 - accuracy: 0.4345 - val_loss: 1.5735 - val_accuracy: 0.3950

Epoch 00027: val_loss did not improve from 1.56722
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4928 - accuracy: 0.4418 - val_loss: 1.5778 - val_accuracy: 0.3924

Epoch 00028: val_loss did not improve from 1.56722
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4828 - accuracy: 0.4483 - val_loss: 1.5839 - val_accuracy: 0.3919

Epoch 00029: val_loss did not improve from 1.56722
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4776 - accuracy: 0.4542 - val_loss: 1.5920 - val_accuracy: 0.3912

Epoch 00030: val_loss did not improve from 1.56722
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4661 - accuracy: 0.4579 - val_loss: 1.5975 - val_accuracy: 0.3940

Epoch 00031: val_loss did not improve from 1.56722
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4562 - accuracy: 0.4673 - val_loss: 1.6139 - val_accuracy: 0.3936

Epoch 00032: val_loss did not improve from 1.56722
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.5722 - accuracy: 0.3909
Testing Loss = 1.572234, Testing Accuracy = 0.390890
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4927 - accuracy: 0.1972 - val_loss: 8.7857 - val_accuracy: 0.2097

Epoch 00001: val_loss improved from inf to 8.78573, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8606 - accuracy: 0.2072 - val_loss: 5.4182 - val_accuracy: 0.2088

Epoch 00002: val_loss improved from 8.78573 to 5.41816, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6294 - accuracy: 0.2180 - val_loss: 4.0016 - val_accuracy: 0.2317

Epoch 00003: val_loss improved from 5.41816 to 4.00163, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5134 - accuracy: 0.2786 - val_loss: 3.2213 - val_accuracy: 0.2725

Epoch 00004: val_loss improved from 4.00163 to 3.22129, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9097 - accuracy: 0.2923 - val_loss: 2.7115 - val_accuracy: 0.3098

Epoch 00005: val_loss improved from 3.22129 to 2.71148, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5189 - accuracy: 0.3039 - val_loss: 2.3749 - val_accuracy: 0.3222

Epoch 00006: val_loss improved from 2.71148 to 2.37490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 7/100
83/83 [==============================] - 6s 70ms/step - loss: 2.2514 - accuracy: 0.3114 - val_loss: 2.1364 - val_accuracy: 0.3264

Epoch 00007: val_loss improved from 2.37490 to 2.13639, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0600 - accuracy: 0.3187 - val_loss: 1.9754 - val_accuracy: 0.3294

Epoch 00008: val_loss improved from 2.13639 to 1.97545, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9249 - accuracy: 0.3249 - val_loss: 1.8625 - val_accuracy: 0.3343

Epoch 00009: val_loss improved from 1.97545 to 1.86249, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8318 - accuracy: 0.3320 - val_loss: 1.7850 - val_accuracy: 0.3378

Epoch 00010: val_loss improved from 1.86249 to 1.78500, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7629 - accuracy: 0.3393 - val_loss: 1.7311 - val_accuracy: 0.3409

Epoch 00011: val_loss improved from 1.78500 to 1.73109, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7166 - accuracy: 0.3410 - val_loss: 1.6905 - val_accuracy: 0.3439

Epoch 00012: val_loss improved from 1.73109 to 1.69051, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6802 - accuracy: 0.3504 - val_loss: 1.6613 - val_accuracy: 0.3483

Epoch 00013: val_loss improved from 1.69051 to 1.66131, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6520 - accuracy: 0.3570 - val_loss: 1.6442 - val_accuracy: 0.3573

Epoch 00014: val_loss improved from 1.66131 to 1.64417, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6299 - accuracy: 0.3635 - val_loss: 1.6259 - val_accuracy: 0.3638

Epoch 00015: val_loss improved from 1.64417 to 1.62586, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6109 - accuracy: 0.3715 - val_loss: 1.6115 - val_accuracy: 0.3629

Epoch 00016: val_loss improved from 1.62586 to 1.61154, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5951 - accuracy: 0.3779 - val_loss: 1.6010 - val_accuracy: 0.3688

Epoch 00017: val_loss improved from 1.61154 to 1.60101, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5831 - accuracy: 0.3847 - val_loss: 1.5920 - val_accuracy: 0.3762

Epoch 00018: val_loss improved from 1.60101 to 1.59195, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5727 - accuracy: 0.3924 - val_loss: 1.5847 - val_accuracy: 0.3763

Epoch 00019: val_loss improved from 1.59195 to 1.58475, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5609 - accuracy: 0.3977 - val_loss: 1.5792 - val_accuracy: 0.3785

Epoch 00020: val_loss improved from 1.58475 to 1.57917, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5531 - accuracy: 0.4046 - val_loss: 1.5762 - val_accuracy: 0.3869

Epoch 00021: val_loss improved from 1.57917 to 1.57615, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5461 - accuracy: 0.4056 - val_loss: 1.5767 - val_accuracy: 0.3817

Epoch 00022: val_loss did not improve from 1.57615
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5353 - accuracy: 0.4130 - val_loss: 1.5753 - val_accuracy: 0.3851

Epoch 00023: val_loss improved from 1.57615 to 1.57532, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5254 - accuracy: 0.4205 - val_loss: 1.5760 - val_accuracy: 0.3881

Epoch 00024: val_loss did not improve from 1.57532
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5188 - accuracy: 0.4263 - val_loss: 1.5772 - val_accuracy: 0.3880

Epoch 00025: val_loss did not improve from 1.57532
Epoch 26/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5119 - accuracy: 0.4286 - val_loss: 1.5825 - val_accuracy: 0.3901

Epoch 00026: val_loss did not improve from 1.57532
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5082 - accuracy: 0.4331 - val_loss: 1.5819 - val_accuracy: 0.3918

Epoch 00027: val_loss did not improve from 1.57532
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5003 - accuracy: 0.4377 - val_loss: 1.5869 - val_accuracy: 0.3895

Epoch 00028: val_loss did not improve from 1.57532
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4910 - accuracy: 0.4453 - val_loss: 1.5880 - val_accuracy: 0.3897

Epoch 00029: val_loss did not improve from 1.57532
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4860 - accuracy: 0.4487 - val_loss: 1.5958 - val_accuracy: 0.3910

Epoch 00030: val_loss did not improve from 1.57532
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4747 - accuracy: 0.4579 - val_loss: 1.6032 - val_accuracy: 0.3919

Epoch 00031: val_loss did not improve from 1.57532
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4659 - accuracy: 0.4627 - val_loss: 1.6069 - val_accuracy: 0.3905

Epoch 00032: val_loss did not improve from 1.57532
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4577 - accuracy: 0.4700 - val_loss: 1.6194 - val_accuracy: 0.3913

Epoch 00033: val_loss did not improve from 1.57532
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5776 - accuracy: 0.3938
Testing Loss = 1.577644, Testing Accuracy = 0.393793
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.5052 - accuracy: 0.1946 - val_loss: 8.7748 - val_accuracy: 0.2037

Epoch 00001: val_loss improved from inf to 8.77483, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8360 - accuracy: 0.2049 - val_loss: 5.3865 - val_accuracy: 0.2103

Epoch 00002: val_loss improved from 8.77483 to 5.38655, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.6079 - accuracy: 0.2116 - val_loss: 3.9842 - val_accuracy: 0.2130

Epoch 00003: val_loss improved from 5.38655 to 3.98417, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5253 - accuracy: 0.2568 - val_loss: 3.1818 - val_accuracy: 0.2870

Epoch 00004: val_loss improved from 3.98417 to 3.18180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8881 - accuracy: 0.2947 - val_loss: 2.6896 - val_accuracy: 0.3116

Epoch 00005: val_loss improved from 3.18180 to 2.68962, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5010 - accuracy: 0.3021 - val_loss: 2.3548 - val_accuracy: 0.3202

Epoch 00006: val_loss improved from 2.68962 to 2.35483, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2340 - accuracy: 0.3090 - val_loss: 2.1248 - val_accuracy: 0.3239

Epoch 00007: val_loss improved from 2.35483 to 2.12477, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0472 - accuracy: 0.3176 - val_loss: 1.9629 - val_accuracy: 0.3300

Epoch 00008: val_loss improved from 2.12477 to 1.96288, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9133 - accuracy: 0.3283 - val_loss: 1.8507 - val_accuracy: 0.3332

Epoch 00009: val_loss improved from 1.96288 to 1.85072, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8211 - accuracy: 0.3330 - val_loss: 1.7749 - val_accuracy: 0.3391

Epoch 00010: val_loss improved from 1.85072 to 1.77486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7548 - accuracy: 0.3371 - val_loss: 1.7192 - val_accuracy: 0.3448

Epoch 00011: val_loss improved from 1.77486 to 1.71915, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7063 - accuracy: 0.3473 - val_loss: 1.6861 - val_accuracy: 0.3449

Epoch 00012: val_loss improved from 1.71915 to 1.68608, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6668 - accuracy: 0.3566 - val_loss: 1.6554 - val_accuracy: 0.3611

Epoch 00013: val_loss improved from 1.68608 to 1.65539, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6407 - accuracy: 0.3648 - val_loss: 1.6309 - val_accuracy: 0.3654

Epoch 00014: val_loss improved from 1.65539 to 1.63092, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6185 - accuracy: 0.3723 - val_loss: 1.6121 - val_accuracy: 0.3690

Epoch 00015: val_loss improved from 1.63092 to 1.61206, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5992 - accuracy: 0.3808 - val_loss: 1.5993 - val_accuracy: 0.3748

Epoch 00016: val_loss improved from 1.61206 to 1.59934, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5846 - accuracy: 0.3869 - val_loss: 1.5881 - val_accuracy: 0.3813

Epoch 00017: val_loss improved from 1.59934 to 1.58806, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5707 - accuracy: 0.3950 - val_loss: 1.5827 - val_accuracy: 0.3813

Epoch 00018: val_loss improved from 1.58806 to 1.58271, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5600 - accuracy: 0.3990 - val_loss: 1.5757 - val_accuracy: 0.3850

Epoch 00019: val_loss improved from 1.58271 to 1.57570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5469 - accuracy: 0.4072 - val_loss: 1.5739 - val_accuracy: 0.3872

Epoch 00020: val_loss improved from 1.57570 to 1.57392, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 21/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5402 - accuracy: 0.4111 - val_loss: 1.5768 - val_accuracy: 0.3873

Epoch 00021: val_loss did not improve from 1.57392
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5305 - accuracy: 0.4160 - val_loss: 1.5727 - val_accuracy: 0.3895

Epoch 00022: val_loss improved from 1.57392 to 1.57273, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5250 - accuracy: 0.4199 - val_loss: 1.5708 - val_accuracy: 0.3911

Epoch 00023: val_loss improved from 1.57273 to 1.57076, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5221 - accuracy: 0.4245 - val_loss: 1.5764 - val_accuracy: 0.3862

Epoch 00024: val_loss did not improve from 1.57076
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5100 - accuracy: 0.4306 - val_loss: 1.5719 - val_accuracy: 0.3899

Epoch 00025: val_loss did not improve from 1.57076
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5042 - accuracy: 0.4357 - val_loss: 1.5773 - val_accuracy: 0.3898

Epoch 00026: val_loss did not improve from 1.57076
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4954 - accuracy: 0.4393 - val_loss: 1.5820 - val_accuracy: 0.3898

Epoch 00027: val_loss did not improve from 1.57076
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4842 - accuracy: 0.4475 - val_loss: 1.5860 - val_accuracy: 0.3905

Epoch 00028: val_loss did not improve from 1.57076
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4769 - accuracy: 0.4539 - val_loss: 1.5913 - val_accuracy: 0.3909

Epoch 00029: val_loss did not improve from 1.57076
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4683 - accuracy: 0.4596 - val_loss: 1.5955 - val_accuracy: 0.3939

Epoch 00030: val_loss did not improve from 1.57076
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4614 - accuracy: 0.4650 - val_loss: 1.6073 - val_accuracy: 0.3933

Epoch 00031: val_loss did not improve from 1.57076
Epoch 32/100
83/83 [==============================] - 6s 70ms/step - loss: 1.4544 - accuracy: 0.4721 - val_loss: 1.6164 - val_accuracy: 0.3919

Epoch 00032: val_loss did not improve from 1.57076
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4413 - accuracy: 0.4814 - val_loss: 1.6267 - val_accuracy: 0.3901

Epoch 00033: val_loss did not improve from 1.57076
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5735 - accuracy: 0.3969
Testing Loss = 1.573541, Testing Accuracy = 0.396919
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.5227 - accuracy: 0.1979 - val_loss: 8.8103 - val_accuracy: 0.2084

Epoch 00001: val_loss improved from inf to 8.81027, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8720 - accuracy: 0.2058 - val_loss: 5.4186 - val_accuracy: 0.2114

Epoch 00002: val_loss improved from 8.81027 to 5.41859, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6340 - accuracy: 0.2092 - val_loss: 4.0054 - val_accuracy: 0.2137

Epoch 00003: val_loss improved from 5.41859 to 4.00536, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.5519 - accuracy: 0.2475 - val_loss: 3.1911 - val_accuracy: 0.2857

Epoch 00004: val_loss improved from 4.00536 to 3.19106, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8956 - accuracy: 0.2921 - val_loss: 2.6931 - val_accuracy: 0.3099

Epoch 00005: val_loss improved from 3.19106 to 2.69313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5037 - accuracy: 0.3041 - val_loss: 2.3581 - val_accuracy: 0.3181

Epoch 00006: val_loss improved from 2.69313 to 2.35812, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2348 - accuracy: 0.3117 - val_loss: 2.1208 - val_accuracy: 0.3316

Epoch 00007: val_loss improved from 2.35812 to 2.12077, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0470 - accuracy: 0.3201 - val_loss: 1.9588 - val_accuracy: 0.3282

Epoch 00008: val_loss improved from 2.12077 to 1.95880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9136 - accuracy: 0.3276 - val_loss: 1.8471 - val_accuracy: 0.3324

Epoch 00009: val_loss improved from 1.95880 to 1.84705, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8195 - accuracy: 0.3388 - val_loss: 1.7741 - val_accuracy: 0.3354

Epoch 00010: val_loss improved from 1.84705 to 1.77406, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7533 - accuracy: 0.3419 - val_loss: 1.7204 - val_accuracy: 0.3411

Epoch 00011: val_loss improved from 1.77406 to 1.72039, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7043 - accuracy: 0.3470 - val_loss: 1.6794 - val_accuracy: 0.3496

Epoch 00012: val_loss improved from 1.72039 to 1.67939, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6672 - accuracy: 0.3547 - val_loss: 1.6571 - val_accuracy: 0.3592

Epoch 00013: val_loss improved from 1.67939 to 1.65707, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6379 - accuracy: 0.3638 - val_loss: 1.6243 - val_accuracy: 0.3672

Epoch 00014: val_loss improved from 1.65707 to 1.62435, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6164 - accuracy: 0.3732 - val_loss: 1.6066 - val_accuracy: 0.3724

Epoch 00015: val_loss improved from 1.62435 to 1.60660, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 16/100
83/83 [==============================] - 6s 72ms/step - loss: 1.5957 - accuracy: 0.3821 - val_loss: 1.5923 - val_accuracy: 0.3794

Epoch 00016: val_loss improved from 1.60660 to 1.59230, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5792 - accuracy: 0.3895 - val_loss: 1.5837 - val_accuracy: 0.3844

Epoch 00017: val_loss improved from 1.59230 to 1.58372, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5659 - accuracy: 0.3955 - val_loss: 1.5807 - val_accuracy: 0.3842

Epoch 00018: val_loss improved from 1.58372 to 1.58067, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5593 - accuracy: 0.3994 - val_loss: 1.5709 - val_accuracy: 0.3868

Epoch 00019: val_loss improved from 1.58067 to 1.57089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5459 - accuracy: 0.4052 - val_loss: 1.5665 - val_accuracy: 0.3936

Epoch 00020: val_loss improved from 1.57089 to 1.56652, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5405 - accuracy: 0.4093 - val_loss: 1.5659 - val_accuracy: 0.3913

Epoch 00021: val_loss improved from 1.56652 to 1.56587, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5313 - accuracy: 0.4146 - val_loss: 1.5662 - val_accuracy: 0.3885

Epoch 00022: val_loss did not improve from 1.56587
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5264 - accuracy: 0.4160 - val_loss: 1.5656 - val_accuracy: 0.3924

Epoch 00023: val_loss improved from 1.56587 to 1.56562, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5165 - accuracy: 0.4221 - val_loss: 1.5655 - val_accuracy: 0.3916

Epoch 00024: val_loss improved from 1.56562 to 1.56554, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5120 - accuracy: 0.4273 - val_loss: 1.5662 - val_accuracy: 0.3937

Epoch 00025: val_loss did not improve from 1.56554
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5024 - accuracy: 0.4349 - val_loss: 1.5700 - val_accuracy: 0.3939

Epoch 00026: val_loss did not improve from 1.56554
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4968 - accuracy: 0.4374 - val_loss: 1.5729 - val_accuracy: 0.3931

Epoch 00027: val_loss did not improve from 1.56554
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4918 - accuracy: 0.4381 - val_loss: 1.5783 - val_accuracy: 0.3941

Epoch 00028: val_loss did not improve from 1.56554
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4787 - accuracy: 0.4505 - val_loss: 1.5836 - val_accuracy: 0.3952

Epoch 00029: val_loss did not improve from 1.56554
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4755 - accuracy: 0.4502 - val_loss: 1.5840 - val_accuracy: 0.3977

Epoch 00030: val_loss did not improve from 1.56554
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4690 - accuracy: 0.4576 - val_loss: 1.5884 - val_accuracy: 0.3929

Epoch 00031: val_loss did not improve from 1.56554
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4596 - accuracy: 0.4639 - val_loss: 1.5958 - val_accuracy: 0.3959

Epoch 00032: val_loss did not improve from 1.56554
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4509 - accuracy: 0.4697 - val_loss: 1.6042 - val_accuracy: 0.3952

Epoch 00033: val_loss did not improve from 1.56554
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5683 - accuracy: 0.3957
Testing Loss = 1.568257, Testing Accuracy = 0.395653
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.4247 - accuracy: 0.1980 - val_loss: 8.6878 - val_accuracy: 0.2040

Epoch 00001: val_loss improved from inf to 8.68782, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7675 - accuracy: 0.2073 - val_loss: 5.3400 - val_accuracy: 0.2113

Epoch 00002: val_loss improved from 8.68782 to 5.34000, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5735 - accuracy: 0.2131 - val_loss: 3.9639 - val_accuracy: 0.2279

Epoch 00003: val_loss improved from 5.34000 to 3.96388, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.4882 - accuracy: 0.2696 - val_loss: 3.1709 - val_accuracy: 0.2876

Epoch 00004: val_loss improved from 3.96388 to 3.17087, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 2.8844 - accuracy: 0.2956 - val_loss: 2.6874 - val_accuracy: 0.3072

Epoch 00005: val_loss improved from 3.17087 to 2.68736, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5008 - accuracy: 0.3064 - val_loss: 2.3591 - val_accuracy: 0.3203

Epoch 00006: val_loss improved from 2.68736 to 2.35914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2358 - accuracy: 0.3136 - val_loss: 2.1234 - val_accuracy: 0.3269

Epoch 00007: val_loss improved from 2.35914 to 2.12342, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 8/100
83/83 [==============================] - 6s 70ms/step - loss: 2.0486 - accuracy: 0.3206 - val_loss: 1.9648 - val_accuracy: 0.3360

Epoch 00008: val_loss improved from 2.12342 to 1.96481, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9175 - accuracy: 0.3293 - val_loss: 1.8542 - val_accuracy: 0.3345

Epoch 00009: val_loss improved from 1.96481 to 1.85422, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8240 - accuracy: 0.3341 - val_loss: 1.7783 - val_accuracy: 0.3413

Epoch 00010: val_loss improved from 1.85422 to 1.77833, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7573 - accuracy: 0.3425 - val_loss: 1.7246 - val_accuracy: 0.3437

Epoch 00011: val_loss improved from 1.77833 to 1.72455, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7087 - accuracy: 0.3474 - val_loss: 1.6857 - val_accuracy: 0.3507

Epoch 00012: val_loss improved from 1.72455 to 1.68570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6704 - accuracy: 0.3572 - val_loss: 1.6574 - val_accuracy: 0.3588

Epoch 00013: val_loss improved from 1.68570 to 1.65745, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6413 - accuracy: 0.3652 - val_loss: 1.6299 - val_accuracy: 0.3601

Epoch 00014: val_loss improved from 1.65745 to 1.62993, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6205 - accuracy: 0.3707 - val_loss: 1.6123 - val_accuracy: 0.3674

Epoch 00015: val_loss improved from 1.62993 to 1.61231, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 16/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6000 - accuracy: 0.3786 - val_loss: 1.5973 - val_accuracy: 0.3764

Epoch 00016: val_loss improved from 1.61231 to 1.59730, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5841 - accuracy: 0.3864 - val_loss: 1.5866 - val_accuracy: 0.3776

Epoch 00017: val_loss improved from 1.59730 to 1.58657, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5725 - accuracy: 0.3927 - val_loss: 1.5796 - val_accuracy: 0.3816

Epoch 00018: val_loss improved from 1.58657 to 1.57956, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5597 - accuracy: 0.3978 - val_loss: 1.5752 - val_accuracy: 0.3830

Epoch 00019: val_loss improved from 1.57956 to 1.57523, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5518 - accuracy: 0.4030 - val_loss: 1.5721 - val_accuracy: 0.3877

Epoch 00020: val_loss improved from 1.57523 to 1.57207, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5408 - accuracy: 0.4093 - val_loss: 1.5723 - val_accuracy: 0.3885

Epoch 00021: val_loss did not improve from 1.57207
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5341 - accuracy: 0.4129 - val_loss: 1.5710 - val_accuracy: 0.3844

Epoch 00022: val_loss improved from 1.57207 to 1.57097, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5283 - accuracy: 0.4190 - val_loss: 1.5657 - val_accuracy: 0.3958

Epoch 00023: val_loss improved from 1.57097 to 1.56572, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5214 - accuracy: 0.4208 - val_loss: 1.5652 - val_accuracy: 0.3916

Epoch 00024: val_loss improved from 1.56572 to 1.56517, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5149 - accuracy: 0.4243 - val_loss: 1.5684 - val_accuracy: 0.3934

Epoch 00025: val_loss did not improve from 1.56517
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5073 - accuracy: 0.4288 - val_loss: 1.5684 - val_accuracy: 0.3923

Epoch 00026: val_loss did not improve from 1.56517
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5068 - accuracy: 0.4312 - val_loss: 1.5706 - val_accuracy: 0.3916

Epoch 00027: val_loss did not improve from 1.56517
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4945 - accuracy: 0.4378 - val_loss: 1.5709 - val_accuracy: 0.3959

Epoch 00028: val_loss did not improve from 1.56517
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4900 - accuracy: 0.4429 - val_loss: 1.5736 - val_accuracy: 0.3948

Epoch 00029: val_loss did not improve from 1.56517
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4792 - accuracy: 0.4478 - val_loss: 1.5812 - val_accuracy: 0.3945

Epoch 00030: val_loss did not improve from 1.56517
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4754 - accuracy: 0.4520 - val_loss: 1.5880 - val_accuracy: 0.3946

Epoch 00031: val_loss did not improve from 1.56517
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4698 - accuracy: 0.4569 - val_loss: 1.5912 - val_accuracy: 0.3943

Epoch 00032: val_loss did not improve from 1.56517
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4599 - accuracy: 0.4650 - val_loss: 1.5957 - val_accuracy: 0.3944

Epoch 00033: val_loss did not improve from 1.56517
Epoch 34/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4505 - accuracy: 0.4716 - val_loss: 1.6054 - val_accuracy: 0.3933

Epoch 00034: val_loss did not improve from 1.56517
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.5696 - accuracy: 0.3930
Testing Loss = 1.569588, Testing Accuracy = 0.392974
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4846 - accuracy: 0.1936 - val_loss: 8.7526 - val_accuracy: 0.2091

Epoch 00001: val_loss improved from inf to 8.75262, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8201 - accuracy: 0.2065 - val_loss: 5.3787 - val_accuracy: 0.2100

Epoch 00002: val_loss improved from 8.75262 to 5.37870, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6025 - accuracy: 0.2151 - val_loss: 3.9807 - val_accuracy: 0.2290

Epoch 00003: val_loss improved from 5.37870 to 3.98070, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5035 - accuracy: 0.2725 - val_loss: 3.1835 - val_accuracy: 0.2912

Epoch 00004: val_loss improved from 3.98070 to 3.18352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8964 - accuracy: 0.2932 - val_loss: 2.7014 - val_accuracy: 0.3113

Epoch 00005: val_loss improved from 3.18352 to 2.70138, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5110 - accuracy: 0.3025 - val_loss: 2.3640 - val_accuracy: 0.3183

Epoch 00006: val_loss improved from 2.70138 to 2.36398, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2423 - accuracy: 0.3108 - val_loss: 2.1302 - val_accuracy: 0.3268

Epoch 00007: val_loss improved from 2.36398 to 2.13021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0552 - accuracy: 0.3184 - val_loss: 1.9678 - val_accuracy: 0.3292

Epoch 00008: val_loss improved from 2.13021 to 1.96778, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9207 - accuracy: 0.3245 - val_loss: 1.8570 - val_accuracy: 0.3338

Epoch 00009: val_loss improved from 1.96778 to 1.85698, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8287 - accuracy: 0.3295 - val_loss: 1.7806 - val_accuracy: 0.3365

Epoch 00010: val_loss improved from 1.85698 to 1.78060, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7600 - accuracy: 0.3392 - val_loss: 1.7259 - val_accuracy: 0.3406

Epoch 00011: val_loss improved from 1.78060 to 1.72594, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7106 - accuracy: 0.3479 - val_loss: 1.6861 - val_accuracy: 0.3488

Epoch 00012: val_loss improved from 1.72594 to 1.68609, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6757 - accuracy: 0.3543 - val_loss: 1.6610 - val_accuracy: 0.3541

Epoch 00013: val_loss improved from 1.68609 to 1.66100, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6466 - accuracy: 0.3620 - val_loss: 1.6423 - val_accuracy: 0.3588

Epoch 00014: val_loss improved from 1.66100 to 1.64230, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6232 - accuracy: 0.3694 - val_loss: 1.6196 - val_accuracy: 0.3648

Epoch 00015: val_loss improved from 1.64230 to 1.61962, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6048 - accuracy: 0.3745 - val_loss: 1.6073 - val_accuracy: 0.3661

Epoch 00016: val_loss improved from 1.61962 to 1.60735, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 17/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5924 - accuracy: 0.3837 - val_loss: 1.5952 - val_accuracy: 0.3759

Epoch 00017: val_loss improved from 1.60735 to 1.59516, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5780 - accuracy: 0.3909 - val_loss: 1.5878 - val_accuracy: 0.3779

Epoch 00018: val_loss improved from 1.59516 to 1.58782, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5669 - accuracy: 0.3954 - val_loss: 1.5826 - val_accuracy: 0.3805

Epoch 00019: val_loss improved from 1.58782 to 1.58258, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5553 - accuracy: 0.4004 - val_loss: 1.5764 - val_accuracy: 0.3865

Epoch 00020: val_loss improved from 1.58258 to 1.57642, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5434 - accuracy: 0.4111 - val_loss: 1.5764 - val_accuracy: 0.3867

Epoch 00021: val_loss did not improve from 1.57642
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5359 - accuracy: 0.4127 - val_loss: 1.5731 - val_accuracy: 0.3890

Epoch 00022: val_loss improved from 1.57642 to 1.57309, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5268 - accuracy: 0.4214 - val_loss: 1.5753 - val_accuracy: 0.3904

Epoch 00023: val_loss did not improve from 1.57309
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5187 - accuracy: 0.4231 - val_loss: 1.5759 - val_accuracy: 0.3904

Epoch 00024: val_loss did not improve from 1.57309
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5161 - accuracy: 0.4281 - val_loss: 1.5748 - val_accuracy: 0.3888

Epoch 00025: val_loss did not improve from 1.57309
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5087 - accuracy: 0.4331 - val_loss: 1.5854 - val_accuracy: 0.3822

Epoch 00026: val_loss did not improve from 1.57309
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5060 - accuracy: 0.4350 - val_loss: 1.5808 - val_accuracy: 0.3919

Epoch 00027: val_loss did not improve from 1.57309
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4934 - accuracy: 0.4433 - val_loss: 1.5851 - val_accuracy: 0.3869

Epoch 00028: val_loss did not improve from 1.57309
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4852 - accuracy: 0.4502 - val_loss: 1.5925 - val_accuracy: 0.3853

Epoch 00029: val_loss did not improve from 1.57309
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4767 - accuracy: 0.4557 - val_loss: 1.5938 - val_accuracy: 0.3891

Epoch 00030: val_loss did not improve from 1.57309
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4645 - accuracy: 0.4645 - val_loss: 1.6046 - val_accuracy: 0.3870

Epoch 00031: val_loss did not improve from 1.57309
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4585 - accuracy: 0.4695 - val_loss: 1.6121 - val_accuracy: 0.3886

Epoch 00032: val_loss did not improve from 1.57309
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.5762 - accuracy: 0.3919
Testing Loss = 1.576241, Testing Accuracy = 0.391858
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4684 - accuracy: 0.1979 - val_loss: 8.7391 - val_accuracy: 0.2104

Epoch 00001: val_loss improved from inf to 8.73907, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8080 - accuracy: 0.2078 - val_loss: 5.3689 - val_accuracy: 0.2112

Epoch 00002: val_loss improved from 8.73907 to 5.36888, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5896 - accuracy: 0.2151 - val_loss: 3.9718 - val_accuracy: 0.2359

Epoch 00003: val_loss improved from 5.36888 to 3.97183, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4897 - accuracy: 0.2747 - val_loss: 3.1748 - val_accuracy: 0.2964

Epoch 00004: val_loss improved from 3.97183 to 3.17478, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8840 - accuracy: 0.2970 - val_loss: 2.6878 - val_accuracy: 0.3163

Epoch 00005: val_loss improved from 3.17478 to 2.68783, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5031 - accuracy: 0.3040 - val_loss: 2.3580 - val_accuracy: 0.3191

Epoch 00006: val_loss improved from 2.68783 to 2.35803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2381 - accuracy: 0.3138 - val_loss: 2.1244 - val_accuracy: 0.3263

Epoch 00007: val_loss improved from 2.35803 to 2.12443, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0505 - accuracy: 0.3217 - val_loss: 1.9646 - val_accuracy: 0.3288

Epoch 00008: val_loss improved from 2.12443 to 1.96460, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9180 - accuracy: 0.3273 - val_loss: 1.8549 - val_accuracy: 0.3354

Epoch 00009: val_loss improved from 1.96460 to 1.85487, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8252 - accuracy: 0.3333 - val_loss: 1.7787 - val_accuracy: 0.3388

Epoch 00010: val_loss improved from 1.85487 to 1.77874, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7585 - accuracy: 0.3401 - val_loss: 1.7252 - val_accuracy: 0.3475

Epoch 00011: val_loss improved from 1.77874 to 1.72516, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7085 - accuracy: 0.3473 - val_loss: 1.6859 - val_accuracy: 0.3514

Epoch 00012: val_loss improved from 1.72516 to 1.68588, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6751 - accuracy: 0.3547 - val_loss: 1.6575 - val_accuracy: 0.3624

Epoch 00013: val_loss improved from 1.68588 to 1.65749, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6439 - accuracy: 0.3614 - val_loss: 1.6351 - val_accuracy: 0.3665

Epoch 00014: val_loss improved from 1.65749 to 1.63509, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6210 - accuracy: 0.3711 - val_loss: 1.6155 - val_accuracy: 0.3660

Epoch 00015: val_loss improved from 1.63509 to 1.61554, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6031 - accuracy: 0.3791 - val_loss: 1.6015 - val_accuracy: 0.3713

Epoch 00016: val_loss improved from 1.61554 to 1.60146, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5885 - accuracy: 0.3843 - val_loss: 1.5921 - val_accuracy: 0.3785

Epoch 00017: val_loss improved from 1.60146 to 1.59210, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5728 - accuracy: 0.3943 - val_loss: 1.5846 - val_accuracy: 0.3848

Epoch 00018: val_loss improved from 1.59210 to 1.58463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5613 - accuracy: 0.3966 - val_loss: 1.5802 - val_accuracy: 0.3857

Epoch 00019: val_loss improved from 1.58463 to 1.58022, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5517 - accuracy: 0.4046 - val_loss: 1.5753 - val_accuracy: 0.3872

Epoch 00020: val_loss improved from 1.58022 to 1.57529, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5453 - accuracy: 0.4080 - val_loss: 1.5726 - val_accuracy: 0.3851

Epoch 00021: val_loss improved from 1.57529 to 1.57258, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5348 - accuracy: 0.4136 - val_loss: 1.5715 - val_accuracy: 0.3886

Epoch 00022: val_loss improved from 1.57258 to 1.57150, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5292 - accuracy: 0.4178 - val_loss: 1.5741 - val_accuracy: 0.3866

Epoch 00023: val_loss did not improve from 1.57150
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5208 - accuracy: 0.4259 - val_loss: 1.5728 - val_accuracy: 0.3900

Epoch 00024: val_loss did not improve from 1.57150
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5132 - accuracy: 0.4292 - val_loss: 1.5729 - val_accuracy: 0.3906

Epoch 00025: val_loss did not improve from 1.57150
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5093 - accuracy: 0.4320 - val_loss: 1.5759 - val_accuracy: 0.3906

Epoch 00026: val_loss did not improve from 1.57150
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4992 - accuracy: 0.4395 - val_loss: 1.5772 - val_accuracy: 0.3916

Epoch 00027: val_loss did not improve from 1.57150
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4893 - accuracy: 0.4467 - val_loss: 1.5805 - val_accuracy: 0.3930

Epoch 00028: val_loss did not improve from 1.57150
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4809 - accuracy: 0.4505 - val_loss: 1.5852 - val_accuracy: 0.3918

Epoch 00029: val_loss did not improve from 1.57150
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4728 - accuracy: 0.4554 - val_loss: 1.5907 - val_accuracy: 0.3943

Epoch 00030: val_loss did not improve from 1.57150
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4673 - accuracy: 0.4577 - val_loss: 1.6021 - val_accuracy: 0.3909

Epoch 00031: val_loss did not improve from 1.57150
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4550 - accuracy: 0.4713 - val_loss: 1.6102 - val_accuracy: 0.3897

Epoch 00032: val_loss did not improve from 1.57150
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5748 - accuracy: 0.3890
Testing Loss = 1.574837, Testing Accuracy = 0.388955
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.5392 - accuracy: 0.1973 - val_loss: 8.8285 - val_accuracy: 0.2101

Epoch 00001: val_loss improved from inf to 8.82846, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8828 - accuracy: 0.2021 - val_loss: 5.4226 - val_accuracy: 0.2090

Epoch 00002: val_loss improved from 8.82846 to 5.42264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6360 - accuracy: 0.2098 - val_loss: 4.0054 - val_accuracy: 0.2113

Epoch 00003: val_loss improved from 5.42264 to 4.00537, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.6006 - accuracy: 0.2182 - val_loss: 3.2452 - val_accuracy: 0.2282

Epoch 00004: val_loss improved from 4.00537 to 3.24522, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9196 - accuracy: 0.2737 - val_loss: 2.6916 - val_accuracy: 0.3008

Epoch 00005: val_loss improved from 3.24522 to 2.69157, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5031 - accuracy: 0.2961 - val_loss: 2.3554 - val_accuracy: 0.3132

Epoch 00006: val_loss improved from 2.69157 to 2.35536, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2327 - accuracy: 0.3065 - val_loss: 2.1198 - val_accuracy: 0.3189

Epoch 00007: val_loss improved from 2.35536 to 2.11983, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0444 - accuracy: 0.3184 - val_loss: 1.9571 - val_accuracy: 0.3286

Epoch 00008: val_loss improved from 2.11983 to 1.95711, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9116 - accuracy: 0.3258 - val_loss: 1.8498 - val_accuracy: 0.3326

Epoch 00009: val_loss improved from 1.95711 to 1.84984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8205 - accuracy: 0.3287 - val_loss: 1.7718 - val_accuracy: 0.3351

Epoch 00010: val_loss improved from 1.84984 to 1.77175, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7540 - accuracy: 0.3359 - val_loss: 1.7202 - val_accuracy: 0.3403

Epoch 00011: val_loss improved from 1.77175 to 1.72016, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7071 - accuracy: 0.3430 - val_loss: 1.6828 - val_accuracy: 0.3452

Epoch 00012: val_loss improved from 1.72016 to 1.68280, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6729 - accuracy: 0.3500 - val_loss: 1.6537 - val_accuracy: 0.3523

Epoch 00013: val_loss improved from 1.68280 to 1.65370, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6478 - accuracy: 0.3556 - val_loss: 1.6343 - val_accuracy: 0.3548

Epoch 00014: val_loss improved from 1.65370 to 1.63433, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6263 - accuracy: 0.3623 - val_loss: 1.6208 - val_accuracy: 0.3641

Epoch 00015: val_loss improved from 1.63433 to 1.62083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6070 - accuracy: 0.3723 - val_loss: 1.6016 - val_accuracy: 0.3683

Epoch 00016: val_loss improved from 1.62083 to 1.60156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5929 - accuracy: 0.3778 - val_loss: 1.5877 - val_accuracy: 0.3754

Epoch 00017: val_loss improved from 1.60156 to 1.58769, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5792 - accuracy: 0.3847 - val_loss: 1.5804 - val_accuracy: 0.3822

Epoch 00018: val_loss improved from 1.58769 to 1.58042, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5668 - accuracy: 0.3900 - val_loss: 1.5740 - val_accuracy: 0.3883

Epoch 00019: val_loss improved from 1.58042 to 1.57401, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5569 - accuracy: 0.3982 - val_loss: 1.5702 - val_accuracy: 0.3870

Epoch 00020: val_loss improved from 1.57401 to 1.57019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5476 - accuracy: 0.4062 - val_loss: 1.5690 - val_accuracy: 0.3930

Epoch 00021: val_loss improved from 1.57019 to 1.56903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5405 - accuracy: 0.4077 - val_loss: 1.5651 - val_accuracy: 0.3908

Epoch 00022: val_loss improved from 1.56903 to 1.56505, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5316 - accuracy: 0.4128 - val_loss: 1.5637 - val_accuracy: 0.3913

Epoch 00023: val_loss improved from 1.56505 to 1.56375, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5273 - accuracy: 0.4150 - val_loss: 1.5637 - val_accuracy: 0.3949

Epoch 00024: val_loss improved from 1.56375 to 1.56368, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5201 - accuracy: 0.4200 - val_loss: 1.5637 - val_accuracy: 0.3972

Epoch 00025: val_loss did not improve from 1.56368
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5107 - accuracy: 0.4270 - val_loss: 1.5657 - val_accuracy: 0.3968

Epoch 00026: val_loss did not improve from 1.56368
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5064 - accuracy: 0.4314 - val_loss: 1.5654 - val_accuracy: 0.3981

Epoch 00027: val_loss did not improve from 1.56368
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4993 - accuracy: 0.4362 - val_loss: 1.5739 - val_accuracy: 0.3970

Epoch 00028: val_loss did not improve from 1.56368
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4942 - accuracy: 0.4406 - val_loss: 1.5745 - val_accuracy: 0.3974

Epoch 00029: val_loss did not improve from 1.56368
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4821 - accuracy: 0.4459 - val_loss: 1.5778 - val_accuracy: 0.4003

Epoch 00030: val_loss did not improve from 1.56368
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4781 - accuracy: 0.4519 - val_loss: 1.5807 - val_accuracy: 0.3954

Epoch 00031: val_loss did not improve from 1.56368
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4737 - accuracy: 0.4542 - val_loss: 1.5811 - val_accuracy: 0.3996

Epoch 00032: val_loss did not improve from 1.56368
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4651 - accuracy: 0.4604 - val_loss: 1.5863 - val_accuracy: 0.3995

Epoch 00033: val_loss did not improve from 1.56368
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5682 - accuracy: 0.3925
Testing Loss = 1.568187, Testing Accuracy = 0.392453
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4240 - accuracy: 0.1980 - val_loss: 8.6929 - val_accuracy: 0.2082

Epoch 00001: val_loss improved from inf to 8.69287, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7778 - accuracy: 0.2063 - val_loss: 5.3484 - val_accuracy: 0.2100

Epoch 00002: val_loss improved from 8.69287 to 5.34839, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5782 - accuracy: 0.2128 - val_loss: 3.9642 - val_accuracy: 0.2239

Epoch 00003: val_loss improved from 5.34839 to 3.96423, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4870 - accuracy: 0.2763 - val_loss: 3.1824 - val_accuracy: 0.2813

Epoch 00004: val_loss improved from 3.96423 to 3.18237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 2.8818 - accuracy: 0.2969 - val_loss: 2.6852 - val_accuracy: 0.3092

Epoch 00005: val_loss improved from 3.18237 to 2.68517, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5000 - accuracy: 0.3054 - val_loss: 2.3565 - val_accuracy: 0.3192

Epoch 00006: val_loss improved from 2.68517 to 2.35653, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2352 - accuracy: 0.3149 - val_loss: 2.1231 - val_accuracy: 0.3258

Epoch 00007: val_loss improved from 2.35653 to 2.12308, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0481 - accuracy: 0.3215 - val_loss: 1.9622 - val_accuracy: 0.3303

Epoch 00008: val_loss improved from 2.12308 to 1.96220, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9144 - accuracy: 0.3279 - val_loss: 1.8506 - val_accuracy: 0.3351

Epoch 00009: val_loss improved from 1.96220 to 1.85056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8237 - accuracy: 0.3321 - val_loss: 1.7737 - val_accuracy: 0.3392

Epoch 00010: val_loss improved from 1.85056 to 1.77371, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7578 - accuracy: 0.3413 - val_loss: 1.7219 - val_accuracy: 0.3426

Epoch 00011: val_loss improved from 1.77371 to 1.72186, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7070 - accuracy: 0.3485 - val_loss: 1.6804 - val_accuracy: 0.3488

Epoch 00012: val_loss improved from 1.72186 to 1.68035, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6712 - accuracy: 0.3544 - val_loss: 1.6518 - val_accuracy: 0.3573

Epoch 00013: val_loss improved from 1.68035 to 1.65185, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6425 - accuracy: 0.3617 - val_loss: 1.6289 - val_accuracy: 0.3646

Epoch 00014: val_loss improved from 1.65185 to 1.62891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6190 - accuracy: 0.3739 - val_loss: 1.6096 - val_accuracy: 0.3683

Epoch 00015: val_loss improved from 1.62891 to 1.60963, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5992 - accuracy: 0.3800 - val_loss: 1.5947 - val_accuracy: 0.3752

Epoch 00016: val_loss improved from 1.60963 to 1.59473, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5850 - accuracy: 0.3857 - val_loss: 1.5823 - val_accuracy: 0.3842

Epoch 00017: val_loss improved from 1.59473 to 1.58231, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5708 - accuracy: 0.3931 - val_loss: 1.5795 - val_accuracy: 0.3848

Epoch 00018: val_loss improved from 1.58231 to 1.57946, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5582 - accuracy: 0.3988 - val_loss: 1.5711 - val_accuracy: 0.3869

Epoch 00019: val_loss improved from 1.57946 to 1.57113, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5536 - accuracy: 0.3992 - val_loss: 1.5705 - val_accuracy: 0.3904

Epoch 00020: val_loss improved from 1.57113 to 1.57046, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5397 - accuracy: 0.4095 - val_loss: 1.5670 - val_accuracy: 0.3924

Epoch 00021: val_loss improved from 1.57046 to 1.56699, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5318 - accuracy: 0.4153 - val_loss: 1.5669 - val_accuracy: 0.3934

Epoch 00022: val_loss improved from 1.56699 to 1.56688, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5250 - accuracy: 0.4212 - val_loss: 1.5643 - val_accuracy: 0.3951

Epoch 00023: val_loss improved from 1.56688 to 1.56430, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5169 - accuracy: 0.4240 - val_loss: 1.5653 - val_accuracy: 0.3980

Epoch 00024: val_loss did not improve from 1.56430
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5124 - accuracy: 0.4281 - val_loss: 1.5700 - val_accuracy: 0.3927

Epoch 00025: val_loss did not improve from 1.56430
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5032 - accuracy: 0.4343 - val_loss: 1.5695 - val_accuracy: 0.3947

Epoch 00026: val_loss did not improve from 1.56430
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4971 - accuracy: 0.4353 - val_loss: 1.5727 - val_accuracy: 0.3967

Epoch 00027: val_loss did not improve from 1.56430
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4909 - accuracy: 0.4413 - val_loss: 1.5765 - val_accuracy: 0.3936

Epoch 00028: val_loss did not improve from 1.56430
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4831 - accuracy: 0.4450 - val_loss: 1.5816 - val_accuracy: 0.3937

Epoch 00029: val_loss did not improve from 1.56430
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4749 - accuracy: 0.4523 - val_loss: 1.5942 - val_accuracy: 0.3911

Epoch 00030: val_loss did not improve from 1.56430
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4833 - accuracy: 0.4517 - val_loss: 1.5860 - val_accuracy: 0.3935

Epoch 00031: val_loss did not improve from 1.56430
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4753 - accuracy: 0.4518 - val_loss: 1.5894 - val_accuracy: 0.3967

Epoch 00032: val_loss did not improve from 1.56430
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4696 - accuracy: 0.4579 - val_loss: 1.5879 - val_accuracy: 0.3971

Epoch 00033: val_loss did not improve from 1.56430
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.5728 - accuracy: 0.3913
Testing Loss = 1.572784, Testing Accuracy = 0.391262
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4848 - accuracy: 0.1962 - val_loss: 8.7848 - val_accuracy: 0.2108

Epoch 00001: val_loss improved from inf to 8.78479, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8490 - accuracy: 0.2073 - val_loss: 5.4011 - val_accuracy: 0.2138

Epoch 00002: val_loss improved from 8.78479 to 5.40108, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5859 - accuracy: 0.2350 - val_loss: 3.9494 - val_accuracy: 0.2637

Epoch 00003: val_loss improved from 5.40108 to 3.94941, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4906 - accuracy: 0.2892 - val_loss: 3.1908 - val_accuracy: 0.2956

Epoch 00004: val_loss improved from 3.94941 to 3.19082, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8995 - accuracy: 0.2997 - val_loss: 2.7007 - val_accuracy: 0.3119

Epoch 00005: val_loss improved from 3.19082 to 2.70070, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5153 - accuracy: 0.3091 - val_loss: 2.3720 - val_accuracy: 0.3176

Epoch 00006: val_loss improved from 2.70070 to 2.37202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2461 - accuracy: 0.3173 - val_loss: 2.1359 - val_accuracy: 0.3262

Epoch 00007: val_loss improved from 2.37202 to 2.13585, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0581 - accuracy: 0.3236 - val_loss: 1.9720 - val_accuracy: 0.3325

Epoch 00008: val_loss improved from 2.13585 to 1.97203, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9259 - accuracy: 0.3293 - val_loss: 1.8618 - val_accuracy: 0.3380

Epoch 00009: val_loss improved from 1.97203 to 1.86175, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8301 - accuracy: 0.3397 - val_loss: 1.7826 - val_accuracy: 0.3398

Epoch 00010: val_loss improved from 1.86175 to 1.78264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7620 - accuracy: 0.3420 - val_loss: 1.7273 - val_accuracy: 0.3461

Epoch 00011: val_loss improved from 1.78264 to 1.72734, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7108 - accuracy: 0.3500 - val_loss: 1.6889 - val_accuracy: 0.3468

Epoch 00012: val_loss improved from 1.72734 to 1.68892, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6752 - accuracy: 0.3564 - val_loss: 1.6668 - val_accuracy: 0.3569

Epoch 00013: val_loss improved from 1.68892 to 1.66684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6447 - accuracy: 0.3659 - val_loss: 1.6372 - val_accuracy: 0.3678

Epoch 00014: val_loss improved from 1.66684 to 1.63724, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6207 - accuracy: 0.3718 - val_loss: 1.6168 - val_accuracy: 0.3693

Epoch 00015: val_loss improved from 1.63724 to 1.61677, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6022 - accuracy: 0.3823 - val_loss: 1.6039 - val_accuracy: 0.3712

Epoch 00016: val_loss improved from 1.61677 to 1.60393, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5862 - accuracy: 0.3902 - val_loss: 1.5951 - val_accuracy: 0.3799

Epoch 00017: val_loss improved from 1.60393 to 1.59513, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5739 - accuracy: 0.3938 - val_loss: 1.5871 - val_accuracy: 0.3774

Epoch 00018: val_loss improved from 1.59513 to 1.58710, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5632 - accuracy: 0.3977 - val_loss: 1.5816 - val_accuracy: 0.3826

Epoch 00019: val_loss improved from 1.58710 to 1.58156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5536 - accuracy: 0.4034 - val_loss: 1.5775 - val_accuracy: 0.3853

Epoch 00020: val_loss improved from 1.58156 to 1.57746, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5481 - accuracy: 0.4044 - val_loss: 1.5766 - val_accuracy: 0.3842

Epoch 00021: val_loss improved from 1.57746 to 1.57661, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5361 - accuracy: 0.4135 - val_loss: 1.5737 - val_accuracy: 0.3863

Epoch 00022: val_loss improved from 1.57661 to 1.57365, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5248 - accuracy: 0.4208 - val_loss: 1.5822 - val_accuracy: 0.3846

Epoch 00023: val_loss did not improve from 1.57365
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5224 - accuracy: 0.4222 - val_loss: 1.5771 - val_accuracy: 0.3880

Epoch 00024: val_loss did not improve from 1.57365
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5126 - accuracy: 0.4294 - val_loss: 1.5826 - val_accuracy: 0.3871

Epoch 00025: val_loss did not improve from 1.57365
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5026 - accuracy: 0.4375 - val_loss: 1.5802 - val_accuracy: 0.3901

Epoch 00026: val_loss did not improve from 1.57365
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4965 - accuracy: 0.4415 - val_loss: 1.5868 - val_accuracy: 0.3889

Epoch 00027: val_loss did not improve from 1.57365
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4897 - accuracy: 0.4459 - val_loss: 1.5909 - val_accuracy: 0.3903

Epoch 00028: val_loss did not improve from 1.57365
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4803 - accuracy: 0.4539 - val_loss: 1.5996 - val_accuracy: 0.3889

Epoch 00029: val_loss did not improve from 1.57365
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4707 - accuracy: 0.4613 - val_loss: 1.6106 - val_accuracy: 0.3892

Epoch 00030: val_loss did not improve from 1.57365
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4638 - accuracy: 0.4648 - val_loss: 1.6165 - val_accuracy: 0.3916

Epoch 00031: val_loss did not improve from 1.57365
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4537 - accuracy: 0.4716 - val_loss: 1.6326 - val_accuracy: 0.3857

Epoch 00032: val_loss did not improve from 1.57365
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.5771 - accuracy: 0.3956
Testing Loss = 1.577116, Testing Accuracy = 0.395579
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 84.25 +- 0.0646 %)
$W^-/W^-$ (auc = 83.48 +- 0.1145 %)
$Z/Z$ (auc = 76.17 +- 0.3279 %)
$W^+/W^-$ (auc = 70.66 +- 0.2382 %)
$W^+/Z$$ (auc = 67.43 +- 0.1203 %)
$W^-/Z$ (auc = 68.96 +- 0.1042 %)
The summarized testing accuracy = 39.30 +- 0.2347 %, with the loss = 1.5730 +- 0.003325
