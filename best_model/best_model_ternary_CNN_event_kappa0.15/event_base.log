

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-04 16:55:56.596783
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 43467.
Epoch 1/100
84/84 [==============================] - 11s 74ms/step - loss: 12.3746 - accuracy: 0.2021 - val_loss: 8.6259 - val_accuracy: 0.2082

Epoch 00001: val_loss improved from inf to 8.62589, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 2/100
84/84 [==============================] - 6s 70ms/step - loss: 6.7064 - accuracy: 0.2095 - val_loss: 5.2869 - val_accuracy: 0.2103

Epoch 00002: val_loss improved from 8.62589 to 5.28695, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 3/100
84/84 [==============================] - 6s 70ms/step - loss: 4.5246 - accuracy: 0.2159 - val_loss: 3.9249 - val_accuracy: 0.2198

Epoch 00003: val_loss improved from 5.28695 to 3.92485, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 4/100
84/84 [==============================] - 6s 70ms/step - loss: 3.4791 - accuracy: 0.2510 - val_loss: 3.1304 - val_accuracy: 0.2841

Epoch 00004: val_loss improved from 3.92485 to 3.13042, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 5/100
84/84 [==============================] - 6s 68ms/step - loss: 2.8460 - accuracy: 0.2969 - val_loss: 2.6530 - val_accuracy: 0.3084

Epoch 00005: val_loss improved from 3.13042 to 2.65300, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 6/100
84/84 [==============================] - 6s 69ms/step - loss: 2.4697 - accuracy: 0.3072 - val_loss: 2.3340 - val_accuracy: 0.3185

Epoch 00006: val_loss improved from 2.65300 to 2.33402, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 7/100
84/84 [==============================] - 6s 69ms/step - loss: 2.2086 - accuracy: 0.3157 - val_loss: 2.1118 - val_accuracy: 0.3288

Epoch 00007: val_loss improved from 2.33402 to 2.11182, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 8/100
84/84 [==============================] - 6s 68ms/step - loss: 2.0241 - accuracy: 0.3264 - val_loss: 1.9574 - val_accuracy: 0.3324

Epoch 00008: val_loss improved from 2.11182 to 1.95743, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 9/100
84/84 [==============================] - 6s 69ms/step - loss: 1.8908 - accuracy: 0.3397 - val_loss: 1.8399 - val_accuracy: 0.3435

Epoch 00009: val_loss improved from 1.95743 to 1.83995, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 10/100
84/84 [==============================] - 6s 68ms/step - loss: 1.8000 - accuracy: 0.3488 - val_loss: 1.7662 - val_accuracy: 0.3509

Epoch 00010: val_loss improved from 1.83995 to 1.76616, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 11/100
84/84 [==============================] - 6s 68ms/step - loss: 1.7342 - accuracy: 0.3557 - val_loss: 1.7232 - val_accuracy: 0.3513

Epoch 00011: val_loss improved from 1.76616 to 1.72322, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 12/100
84/84 [==============================] - 6s 68ms/step - loss: 1.6819 - accuracy: 0.3670 - val_loss: 1.6760 - val_accuracy: 0.3623

Epoch 00012: val_loss improved from 1.72322 to 1.67598, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 13/100
84/84 [==============================] - 6s 67ms/step - loss: 1.6462 - accuracy: 0.3710 - val_loss: 1.6538 - val_accuracy: 0.3660

Epoch 00013: val_loss improved from 1.67598 to 1.65382, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 14/100
84/84 [==============================] - 6s 68ms/step - loss: 1.6197 - accuracy: 0.3776 - val_loss: 1.6337 - val_accuracy: 0.3704

Epoch 00014: val_loss improved from 1.65382 to 1.63372, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 15/100
84/84 [==============================] - 6s 69ms/step - loss: 1.5960 - accuracy: 0.3863 - val_loss: 1.6118 - val_accuracy: 0.3791

Epoch 00015: val_loss improved from 1.63372 to 1.61185, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 16/100
84/84 [==============================] - 6s 68ms/step - loss: 1.5832 - accuracy: 0.3891 - val_loss: 1.5972 - val_accuracy: 0.3824

Epoch 00016: val_loss improved from 1.61185 to 1.59721, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 17/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5633 - accuracy: 0.3973 - val_loss: 1.5960 - val_accuracy: 0.3799

Epoch 00017: val_loss improved from 1.59721 to 1.59597, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 18/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5497 - accuracy: 0.4038 - val_loss: 1.5874 - val_accuracy: 0.3854

Epoch 00018: val_loss improved from 1.59597 to 1.58737, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 19/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5405 - accuracy: 0.4093 - val_loss: 1.5923 - val_accuracy: 0.3855

Epoch 00019: val_loss did not improve from 1.58737
Epoch 20/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5312 - accuracy: 0.4134 - val_loss: 1.5809 - val_accuracy: 0.3884

Epoch 00020: val_loss improved from 1.58737 to 1.58089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 21/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5226 - accuracy: 0.4199 - val_loss: 1.5842 - val_accuracy: 0.3884

Epoch 00021: val_loss did not improve from 1.58089
Epoch 22/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5146 - accuracy: 0.4254 - val_loss: 1.5885 - val_accuracy: 0.3846

Epoch 00022: val_loss did not improve from 1.58089
Epoch 23/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5080 - accuracy: 0.4285 - val_loss: 1.5828 - val_accuracy: 0.3913

Epoch 00023: val_loss did not improve from 1.58089
Epoch 24/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5014 - accuracy: 0.4337 - val_loss: 1.5905 - val_accuracy: 0.3836

Epoch 00024: val_loss did not improve from 1.58089
Epoch 25/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4924 - accuracy: 0.4388 - val_loss: 1.5906 - val_accuracy: 0.3873

Epoch 00025: val_loss did not improve from 1.58089
Epoch 26/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4870 - accuracy: 0.4421 - val_loss: 1.6036 - val_accuracy: 0.3805

Epoch 00026: val_loss did not improve from 1.58089
Epoch 27/100
84/84 [==============================] - 6s 68ms/step - loss: 1.4844 - accuracy: 0.4468 - val_loss: 1.6000 - val_accuracy: 0.3901

Epoch 00027: val_loss did not improve from 1.58089
Epoch 28/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4704 - accuracy: 0.4530 - val_loss: 1.6047 - val_accuracy: 0.3894

Epoch 00028: val_loss did not improve from 1.58089
Epoch 29/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4620 - accuracy: 0.4588 - val_loss: 1.6047 - val_accuracy: 0.3867

Epoch 00029: val_loss did not improve from 1.58089
Epoch 30/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4493 - accuracy: 0.4707 - val_loss: 1.6102 - val_accuracy: 0.3874

Epoch 00030: val_loss did not improve from 1.58089
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13584/13584 [==============================] - 54s 4ms/step - loss: 1.5721 - accuracy: 0.3830
Testing Loss = 1.572143, Testing Accuracy = 0.382951
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 43467.
Epoch 1/100
84/84 [==============================] - 6s 66ms/step - loss: 12.5413 - accuracy: 0.1985 - val_loss: 8.8309 - val_accuracy: 0.2071

Epoch 00001: val_loss improved from inf to 8.83092, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 2/100
84/84 [==============================] - 5s 64ms/step - loss: 6.8747 - accuracy: 0.2091 - val_loss: 5.4164 - val_accuracy: 0.2108

Epoch 00002: val_loss improved from 8.83092 to 5.41642, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 3/100
84/84 [==============================] - 5s 65ms/step - loss: 4.6129 - accuracy: 0.2202 - val_loss: 3.9804 - val_accuracy: 0.2345

Epoch 00003: val_loss improved from 5.41642 to 3.98042, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 4/100
84/84 [==============================] - 6s 66ms/step - loss: 3.4853 - accuracy: 0.2839 - val_loss: 3.1749 - val_accuracy: 0.2944

Epoch 00004: val_loss improved from 3.98042 to 3.17487, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 5/100
84/84 [==============================] - 6s 66ms/step - loss: 2.8828 - accuracy: 0.2971 - val_loss: 2.6878 - val_accuracy: 0.3103

Epoch 00005: val_loss improved from 3.17487 to 2.68775, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 6/100
84/84 [==============================] - 6s 66ms/step - loss: 2.4969 - accuracy: 0.3050 - val_loss: 2.3607 - val_accuracy: 0.3096

Epoch 00006: val_loss improved from 2.68775 to 2.36072, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 7/100
84/84 [==============================] - 6s 65ms/step - loss: 2.2283 - accuracy: 0.3140 - val_loss: 2.1309 - val_accuracy: 0.3171

Epoch 00007: val_loss improved from 2.36072 to 2.13088, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 8/100
84/84 [==============================] - 6s 65ms/step - loss: 2.0407 - accuracy: 0.3249 - val_loss: 1.9703 - val_accuracy: 0.3291

Epoch 00008: val_loss improved from 2.13088 to 1.97030, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 9/100
84/84 [==============================] - 5s 65ms/step - loss: 1.9104 - accuracy: 0.3307 - val_loss: 1.8622 - val_accuracy: 0.3394

Epoch 00009: val_loss improved from 1.97030 to 1.86221, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 10/100
84/84 [==============================] - 5s 64ms/step - loss: 1.8157 - accuracy: 0.3390 - val_loss: 1.7876 - val_accuracy: 0.3426

Epoch 00010: val_loss improved from 1.86221 to 1.78761, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 11/100
84/84 [==============================] - 5s 64ms/step - loss: 1.7472 - accuracy: 0.3491 - val_loss: 1.7254 - val_accuracy: 0.3505

Epoch 00011: val_loss improved from 1.78761 to 1.72542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 12/100
84/84 [==============================] - 6s 66ms/step - loss: 1.7018 - accuracy: 0.3520 - val_loss: 1.6921 - val_accuracy: 0.3534

Epoch 00012: val_loss improved from 1.72542 to 1.69207, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 13/100
84/84 [==============================] - 6s 65ms/step - loss: 1.6591 - accuracy: 0.3632 - val_loss: 1.6557 - val_accuracy: 0.3659

Epoch 00013: val_loss improved from 1.69207 to 1.65565, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 14/100
84/84 [==============================] - 6s 65ms/step - loss: 1.6325 - accuracy: 0.3718 - val_loss: 1.6397 - val_accuracy: 0.3665

Epoch 00014: val_loss improved from 1.65565 to 1.63974, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 15/100
84/84 [==============================] - 6s 66ms/step - loss: 1.6089 - accuracy: 0.3771 - val_loss: 1.6246 - val_accuracy: 0.3705

Epoch 00015: val_loss improved from 1.63974 to 1.62461, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 16/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5937 - accuracy: 0.3849 - val_loss: 1.6019 - val_accuracy: 0.3820

Epoch 00016: val_loss improved from 1.62461 to 1.60194, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 17/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5723 - accuracy: 0.3925 - val_loss: 1.5956 - val_accuracy: 0.3817

Epoch 00017: val_loss improved from 1.60194 to 1.59556, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 18/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5608 - accuracy: 0.3983 - val_loss: 1.5882 - val_accuracy: 0.3857

Epoch 00018: val_loss improved from 1.59556 to 1.58820, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 19/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5484 - accuracy: 0.4044 - val_loss: 1.5954 - val_accuracy: 0.3813

Epoch 00019: val_loss did not improve from 1.58820
Epoch 20/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5398 - accuracy: 0.4085 - val_loss: 1.5821 - val_accuracy: 0.3933

Epoch 00020: val_loss improved from 1.58820 to 1.58211, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 21/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5301 - accuracy: 0.4162 - val_loss: 1.5845 - val_accuracy: 0.3909

Epoch 00021: val_loss did not improve from 1.58211
Epoch 22/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5207 - accuracy: 0.4190 - val_loss: 1.5835 - val_accuracy: 0.3904

Epoch 00022: val_loss did not improve from 1.58211
Epoch 23/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5155 - accuracy: 0.4248 - val_loss: 1.5835 - val_accuracy: 0.3925

Epoch 00023: val_loss did not improve from 1.58211
Epoch 24/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5039 - accuracy: 0.4320 - val_loss: 1.5844 - val_accuracy: 0.3948

Epoch 00024: val_loss did not improve from 1.58211
Epoch 25/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5003 - accuracy: 0.4344 - val_loss: 1.5853 - val_accuracy: 0.3950

Epoch 00025: val_loss did not improve from 1.58211
Epoch 26/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4922 - accuracy: 0.4387 - val_loss: 1.5990 - val_accuracy: 0.3866

Epoch 00026: val_loss did not improve from 1.58211
Epoch 27/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4812 - accuracy: 0.4466 - val_loss: 1.5884 - val_accuracy: 0.3979

Epoch 00027: val_loss did not improve from 1.58211
Epoch 28/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4752 - accuracy: 0.4491 - val_loss: 1.5960 - val_accuracy: 0.3944

Epoch 00028: val_loss did not improve from 1.58211
Epoch 29/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4655 - accuracy: 0.4552 - val_loss: 1.6044 - val_accuracy: 0.3943

Epoch 00029: val_loss did not improve from 1.58211
Epoch 30/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4594 - accuracy: 0.4626 - val_loss: 1.6036 - val_accuracy: 0.3939

Epoch 00030: val_loss did not improve from 1.58211
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13584/13584 [==============================] - 55s 4ms/step - loss: 1.5712 - accuracy: 0.3835
Testing Loss = 1.571184, Testing Accuracy = 0.383539
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 43467.
Epoch 1/100
84/84 [==============================] - 6s 65ms/step - loss: 12.4695 - accuracy: 0.1980 - val_loss: 8.7531 - val_accuracy: 0.2080

Epoch 00001: val_loss improved from inf to 8.75308, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 2/100
84/84 [==============================] - 5s 64ms/step - loss: 6.8185 - accuracy: 0.2077 - val_loss: 5.3795 - val_accuracy: 0.2091

Epoch 00002: val_loss improved from 8.75308 to 5.37945, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 3/100
84/84 [==============================] - 5s 65ms/step - loss: 4.5905 - accuracy: 0.2201 - val_loss: 3.9653 - val_accuracy: 0.2414

Epoch 00003: val_loss improved from 5.37945 to 3.96528, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 4/100
84/84 [==============================] - 5s 64ms/step - loss: 3.4795 - accuracy: 0.2809 - val_loss: 3.1828 - val_accuracy: 0.2811

Epoch 00004: val_loss improved from 3.96528 to 3.18277, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 5/100
84/84 [==============================] - 6s 66ms/step - loss: 2.8816 - accuracy: 0.2966 - val_loss: 2.6885 - val_accuracy: 0.3017

Epoch 00005: val_loss improved from 3.18277 to 2.68848, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 6/100
84/84 [==============================] - 6s 65ms/step - loss: 2.4960 - accuracy: 0.3053 - val_loss: 2.3582 - val_accuracy: 0.3146

Epoch 00006: val_loss improved from 2.68848 to 2.35817, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 7/100
84/84 [==============================] - 5s 65ms/step - loss: 2.2293 - accuracy: 0.3130 - val_loss: 2.1354 - val_accuracy: 0.3158

Epoch 00007: val_loss improved from 2.35817 to 2.13540, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 8/100
84/84 [==============================] - 5s 64ms/step - loss: 2.0442 - accuracy: 0.3218 - val_loss: 1.9735 - val_accuracy: 0.3270

Epoch 00008: val_loss improved from 2.13540 to 1.97346, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 9/100
84/84 [==============================] - 5s 65ms/step - loss: 1.9100 - accuracy: 0.3300 - val_loss: 1.8635 - val_accuracy: 0.3365

Epoch 00009: val_loss improved from 1.97346 to 1.86351, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 10/100
84/84 [==============================] - 5s 65ms/step - loss: 1.8207 - accuracy: 0.3325 - val_loss: 1.7886 - val_accuracy: 0.3384

Epoch 00010: val_loss improved from 1.86351 to 1.78857, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 11/100
84/84 [==============================] - 6s 66ms/step - loss: 1.7545 - accuracy: 0.3410 - val_loss: 1.7361 - val_accuracy: 0.3435

Epoch 00011: val_loss improved from 1.78857 to 1.73614, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 12/100
84/84 [==============================] - 6s 65ms/step - loss: 1.7029 - accuracy: 0.3506 - val_loss: 1.6974 - val_accuracy: 0.3453

Epoch 00012: val_loss improved from 1.73614 to 1.69737, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 13/100
84/84 [==============================] - 6s 66ms/step - loss: 1.6664 - accuracy: 0.3553 - val_loss: 1.6702 - val_accuracy: 0.3525

Epoch 00013: val_loss improved from 1.69737 to 1.67019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 14/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6407 - accuracy: 0.3633 - val_loss: 1.6442 - val_accuracy: 0.3626

Epoch 00014: val_loss improved from 1.67019 to 1.64424, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 15/100
84/84 [==============================] - 6s 65ms/step - loss: 1.6186 - accuracy: 0.3703 - val_loss: 1.6312 - val_accuracy: 0.3654

Epoch 00015: val_loss improved from 1.64424 to 1.63121, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 16/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5991 - accuracy: 0.3756 - val_loss: 1.6235 - val_accuracy: 0.3664

Epoch 00016: val_loss improved from 1.63121 to 1.62348, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 17/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5878 - accuracy: 0.3833 - val_loss: 1.6052 - val_accuracy: 0.3747

Epoch 00017: val_loss improved from 1.62348 to 1.60524, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 18/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5712 - accuracy: 0.3917 - val_loss: 1.6052 - val_accuracy: 0.3745

Epoch 00018: val_loss improved from 1.60524 to 1.60523, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 19/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5633 - accuracy: 0.3933 - val_loss: 1.5966 - val_accuracy: 0.3757

Epoch 00019: val_loss improved from 1.60523 to 1.59661, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 20/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5540 - accuracy: 0.3979 - val_loss: 1.5933 - val_accuracy: 0.3788

Epoch 00020: val_loss improved from 1.59661 to 1.59327, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 21/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5404 - accuracy: 0.4062 - val_loss: 1.5931 - val_accuracy: 0.3807

Epoch 00021: val_loss improved from 1.59327 to 1.59306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 22/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5322 - accuracy: 0.4088 - val_loss: 1.5936 - val_accuracy: 0.3812

Epoch 00022: val_loss did not improve from 1.59306
Epoch 23/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5240 - accuracy: 0.4179 - val_loss: 1.5948 - val_accuracy: 0.3821

Epoch 00023: val_loss did not improve from 1.59306
Epoch 24/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5176 - accuracy: 0.4217 - val_loss: 1.5927 - val_accuracy: 0.3855

Epoch 00024: val_loss improved from 1.59306 to 1.59269, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 25/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5086 - accuracy: 0.4236 - val_loss: 1.5908 - val_accuracy: 0.3878

Epoch 00025: val_loss improved from 1.59269 to 1.59080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 26/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4987 - accuracy: 0.4348 - val_loss: 1.5883 - val_accuracy: 0.3892

Epoch 00026: val_loss improved from 1.59080 to 1.58826, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 27/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4919 - accuracy: 0.4366 - val_loss: 1.5931 - val_accuracy: 0.3903

Epoch 00027: val_loss did not improve from 1.58826
Epoch 28/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4871 - accuracy: 0.4437 - val_loss: 1.5931 - val_accuracy: 0.3903

Epoch 00028: val_loss did not improve from 1.58826
Epoch 29/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4815 - accuracy: 0.4482 - val_loss: 1.5968 - val_accuracy: 0.3906

Epoch 00029: val_loss did not improve from 1.58826
Epoch 30/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4728 - accuracy: 0.4535 - val_loss: 1.5997 - val_accuracy: 0.3931

Epoch 00030: val_loss did not improve from 1.58826
Epoch 31/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4611 - accuracy: 0.4610 - val_loss: 1.6008 - val_accuracy: 0.3933

Epoch 00031: val_loss did not improve from 1.58826
Epoch 32/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4545 - accuracy: 0.4668 - val_loss: 1.6164 - val_accuracy: 0.3915

Epoch 00032: val_loss did not improve from 1.58826
Epoch 33/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4436 - accuracy: 0.4736 - val_loss: 1.6179 - val_accuracy: 0.3925

Epoch 00033: val_loss did not improve from 1.58826
Epoch 34/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4373 - accuracy: 0.4777 - val_loss: 1.6340 - val_accuracy: 0.3889

Epoch 00034: val_loss did not improve from 1.58826
Epoch 35/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4280 - accuracy: 0.4820 - val_loss: 1.6383 - val_accuracy: 0.3914

Epoch 00035: val_loss did not improve from 1.58826
Epoch 36/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4158 - accuracy: 0.4903 - val_loss: 1.6518 - val_accuracy: 0.3909

Epoch 00036: val_loss did not improve from 1.58826
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13584/13584 [==============================] - 49s 4ms/step - loss: 1.5803 - accuracy: 0.3845
Testing Loss = 1.580301, Testing Accuracy = 0.384496
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 43467.
Epoch 1/100
84/84 [==============================] - 19s 212ms/step - loss: 12.3377 - accuracy: 0.2009 - val_loss: 8.5807 - val_accuracy: 0.2074

Epoch 00001: val_loss improved from inf to 8.58066, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 2/100
84/84 [==============================] - 18s 214ms/step - loss: 6.6798 - accuracy: 0.2044 - val_loss: 5.2771 - val_accuracy: 0.2094

Epoch 00002: val_loss improved from 8.58066 to 5.27710, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 3/100
84/84 [==============================] - 18s 214ms/step - loss: 4.5207 - accuracy: 0.2151 - val_loss: 3.9260 - val_accuracy: 0.2170

Epoch 00003: val_loss improved from 5.27710 to 3.92599, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 4/100
84/84 [==============================] - 6s 65ms/step - loss: 3.4515 - accuracy: 0.2742 - val_loss: 3.1449 - val_accuracy: 0.2786

Epoch 00004: val_loss improved from 3.92599 to 3.14494, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 5/100
84/84 [==============================] - 6s 65ms/step - loss: 2.8617 - accuracy: 0.2935 - val_loss: 2.6704 - val_accuracy: 0.3032

Epoch 00005: val_loss improved from 3.14494 to 2.67040, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 6/100
84/84 [==============================] - 5s 65ms/step - loss: 2.4834 - accuracy: 0.3029 - val_loss: 2.3545 - val_accuracy: 0.3069

Epoch 00006: val_loss improved from 2.67040 to 2.35454, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 7/100
84/84 [==============================] - 6s 66ms/step - loss: 2.2220 - accuracy: 0.3153 - val_loss: 2.1293 - val_accuracy: 0.3157

Epoch 00007: val_loss improved from 2.35454 to 2.12934, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 8/100
84/84 [==============================] - 6s 65ms/step - loss: 2.0360 - accuracy: 0.3184 - val_loss: 1.9678 - val_accuracy: 0.3286

Epoch 00008: val_loss improved from 2.12934 to 1.96776, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 9/100
84/84 [==============================] - 6s 65ms/step - loss: 1.9059 - accuracy: 0.3293 - val_loss: 1.8583 - val_accuracy: 0.3390

Epoch 00009: val_loss improved from 1.96776 to 1.85831, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 10/100
84/84 [==============================] - 5s 65ms/step - loss: 1.8158 - accuracy: 0.3328 - val_loss: 1.7835 - val_accuracy: 0.3417

Epoch 00010: val_loss improved from 1.85831 to 1.78350, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 11/100
84/84 [==============================] - 5s 65ms/step - loss: 1.7464 - accuracy: 0.3461 - val_loss: 1.7278 - val_accuracy: 0.3473

Epoch 00011: val_loss improved from 1.78350 to 1.72778, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 12/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6990 - accuracy: 0.3512 - val_loss: 1.6897 - val_accuracy: 0.3555

Epoch 00012: val_loss improved from 1.72778 to 1.68971, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 13/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6625 - accuracy: 0.3599 - val_loss: 1.6581 - val_accuracy: 0.3610

Epoch 00013: val_loss improved from 1.68971 to 1.65813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 14/100
84/84 [==============================] - 6s 65ms/step - loss: 1.6331 - accuracy: 0.3676 - val_loss: 1.6437 - val_accuracy: 0.3613

Epoch 00014: val_loss improved from 1.65813 to 1.64372, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 15/100
84/84 [==============================] - 5s 64ms/step - loss: 1.6115 - accuracy: 0.3762 - val_loss: 1.6296 - val_accuracy: 0.3644

Epoch 00015: val_loss improved from 1.64372 to 1.62958, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 16/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5906 - accuracy: 0.3846 - val_loss: 1.6126 - val_accuracy: 0.3690

Epoch 00016: val_loss improved from 1.62958 to 1.61257, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 17/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5780 - accuracy: 0.3891 - val_loss: 1.5995 - val_accuracy: 0.3745

Epoch 00017: val_loss improved from 1.61257 to 1.59949, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 18/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5619 - accuracy: 0.3967 - val_loss: 1.5991 - val_accuracy: 0.3758

Epoch 00018: val_loss improved from 1.59949 to 1.59915, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 19/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5510 - accuracy: 0.4018 - val_loss: 1.5928 - val_accuracy: 0.3783

Epoch 00019: val_loss improved from 1.59915 to 1.59276, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 20/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5415 - accuracy: 0.4078 - val_loss: 1.5837 - val_accuracy: 0.3841

Epoch 00020: val_loss improved from 1.59276 to 1.58372, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 21/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5325 - accuracy: 0.4104 - val_loss: 1.5982 - val_accuracy: 0.3770

Epoch 00021: val_loss did not improve from 1.58372
Epoch 22/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5242 - accuracy: 0.4155 - val_loss: 1.5848 - val_accuracy: 0.3856

Epoch 00022: val_loss did not improve from 1.58372
Epoch 23/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5158 - accuracy: 0.4224 - val_loss: 1.5827 - val_accuracy: 0.3890

Epoch 00023: val_loss improved from 1.58372 to 1.58272, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 24/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5063 - accuracy: 0.4284 - val_loss: 1.5786 - val_accuracy: 0.3887

Epoch 00024: val_loss improved from 1.58272 to 1.57857, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 25/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5042 - accuracy: 0.4320 - val_loss: 1.5909 - val_accuracy: 0.3849

Epoch 00025: val_loss did not improve from 1.57857
Epoch 26/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4951 - accuracy: 0.4388 - val_loss: 1.5841 - val_accuracy: 0.3898

Epoch 00026: val_loss did not improve from 1.57857
Epoch 27/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4878 - accuracy: 0.4390 - val_loss: 1.5829 - val_accuracy: 0.3924

Epoch 00027: val_loss did not improve from 1.57857
Epoch 28/100
84/84 [==============================] - 13s 157ms/step - loss: 1.4800 - accuracy: 0.4473 - val_loss: 1.5887 - val_accuracy: 0.3909

Epoch 00028: val_loss did not improve from 1.57857
Epoch 29/100
84/84 [==============================] - 17s 200ms/step - loss: 1.4727 - accuracy: 0.4518 - val_loss: 1.5926 - val_accuracy: 0.3917

Epoch 00029: val_loss did not improve from 1.57857
Epoch 30/100
84/84 [==============================] - 19s 227ms/step - loss: 1.4667 - accuracy: 0.4562 - val_loss: 1.5969 - val_accuracy: 0.3936

Epoch 00030: val_loss did not improve from 1.57857
Epoch 31/100
84/84 [==============================] - 18s 212ms/step - loss: 1.4636 - accuracy: 0.4610 - val_loss: 1.6531 - val_accuracy: 0.3703

Epoch 00031: val_loss did not improve from 1.57857
Epoch 32/100
84/84 [==============================] - 19s 227ms/step - loss: 1.4540 - accuracy: 0.4639 - val_loss: 1.6513 - val_accuracy: 0.3783

Epoch 00032: val_loss did not improve from 1.57857
Epoch 33/100
84/84 [==============================] - 18s 209ms/step - loss: 1.4367 - accuracy: 0.4760 - val_loss: 1.6252 - val_accuracy: 0.3888

Epoch 00033: val_loss did not improve from 1.57857
Epoch 34/100
84/84 [==============================] - 17s 205ms/step - loss: 1.4291 - accuracy: 0.4839 - val_loss: 1.6279 - val_accuracy: 0.3938

Epoch 00034: val_loss did not improve from 1.57857
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13584/13584 [==============================] - 46s 3ms/step - loss: 1.5704 - accuracy: 0.3882
Testing Loss = 1.570374, Testing Accuracy = 0.388177
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 43467.
Epoch 1/100
84/84 [==============================] - 7s 72ms/step - loss: 12.3511 - accuracy: 0.2002 - val_loss: 8.5949 - val_accuracy: 0.2083

Epoch 00001: val_loss improved from inf to 8.59493, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 2/100
84/84 [==============================] - 5s 64ms/step - loss: 6.6780 - accuracy: 0.2082 - val_loss: 5.2670 - val_accuracy: 0.2110

Epoch 00002: val_loss improved from 8.59493 to 5.26696, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 3/100
84/84 [==============================] - 5s 65ms/step - loss: 4.5095 - accuracy: 0.2151 - val_loss: 3.9135 - val_accuracy: 0.2172

Epoch 00003: val_loss improved from 5.26696 to 3.91352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 4/100
84/84 [==============================] - 6s 65ms/step - loss: 3.4556 - accuracy: 0.2605 - val_loss: 3.1355 - val_accuracy: 0.2802

Epoch 00004: val_loss improved from 3.91352 to 3.13548, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 5/100
84/84 [==============================] - 6s 65ms/step - loss: 2.8455 - accuracy: 0.2945 - val_loss: 2.6545 - val_accuracy: 0.3035

Epoch 00005: val_loss improved from 3.13548 to 2.65455, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 6/100
84/84 [==============================] - 5s 64ms/step - loss: 2.4692 - accuracy: 0.3054 - val_loss: 2.3382 - val_accuracy: 0.3157

Epoch 00006: val_loss improved from 2.65455 to 2.33820, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 7/100
84/84 [==============================] - 5s 65ms/step - loss: 2.2069 - accuracy: 0.3163 - val_loss: 2.1114 - val_accuracy: 0.3270

Epoch 00007: val_loss improved from 2.33820 to 2.11135, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 8/100
84/84 [==============================] - 6s 65ms/step - loss: 2.0250 - accuracy: 0.3280 - val_loss: 1.9550 - val_accuracy: 0.3385

Epoch 00008: val_loss improved from 2.11135 to 1.95495, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 9/100
84/84 [==============================] - 5s 65ms/step - loss: 1.8947 - accuracy: 0.3342 - val_loss: 1.8454 - val_accuracy: 0.3438

Epoch 00009: val_loss improved from 1.95495 to 1.84536, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 10/100
84/84 [==============================] - 6s 65ms/step - loss: 1.8006 - accuracy: 0.3453 - val_loss: 1.7711 - val_accuracy: 0.3479

Epoch 00010: val_loss improved from 1.84536 to 1.77110, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 11/100
84/84 [==============================] - 5s 65ms/step - loss: 1.7358 - accuracy: 0.3530 - val_loss: 1.7189 - val_accuracy: 0.3547

Epoch 00011: val_loss improved from 1.77110 to 1.71891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 12/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6860 - accuracy: 0.3622 - val_loss: 1.6808 - val_accuracy: 0.3597

Epoch 00012: val_loss improved from 1.71891 to 1.68078, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 13/100
84/84 [==============================] - 6s 65ms/step - loss: 1.6501 - accuracy: 0.3700 - val_loss: 1.6486 - val_accuracy: 0.3703

Epoch 00013: val_loss improved from 1.68078 to 1.64863, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 14/100
84/84 [==============================] - 6s 65ms/step - loss: 1.6223 - accuracy: 0.3778 - val_loss: 1.6337 - val_accuracy: 0.3712

Epoch 00014: val_loss improved from 1.64863 to 1.63368, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 15/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6006 - accuracy: 0.3836 - val_loss: 1.6134 - val_accuracy: 0.3784

Epoch 00015: val_loss improved from 1.63368 to 1.61335, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 16/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5788 - accuracy: 0.3927 - val_loss: 1.6054 - val_accuracy: 0.3792

Epoch 00016: val_loss improved from 1.61335 to 1.60541, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 17/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5638 - accuracy: 0.3993 - val_loss: 1.6079 - val_accuracy: 0.3765

Epoch 00017: val_loss did not improve from 1.60541
Epoch 18/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5545 - accuracy: 0.4048 - val_loss: 1.5959 - val_accuracy: 0.3826

Epoch 00018: val_loss improved from 1.60541 to 1.59590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 19/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5405 - accuracy: 0.4099 - val_loss: 1.5859 - val_accuracy: 0.3886

Epoch 00019: val_loss improved from 1.59590 to 1.58586, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 20/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5351 - accuracy: 0.4129 - val_loss: 1.5938 - val_accuracy: 0.3854

Epoch 00020: val_loss did not improve from 1.58586
Epoch 21/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5237 - accuracy: 0.4193 - val_loss: 1.5927 - val_accuracy: 0.3870

Epoch 00021: val_loss did not improve from 1.58586
Epoch 22/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5146 - accuracy: 0.4252 - val_loss: 1.5872 - val_accuracy: 0.3897

Epoch 00022: val_loss did not improve from 1.58586
Epoch 23/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5063 - accuracy: 0.4306 - val_loss: 1.5913 - val_accuracy: 0.3881

Epoch 00023: val_loss did not improve from 1.58586
Epoch 24/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4984 - accuracy: 0.4360 - val_loss: 1.5913 - val_accuracy: 0.3888

Epoch 00024: val_loss did not improve from 1.58586
Epoch 25/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4888 - accuracy: 0.4450 - val_loss: 1.5919 - val_accuracy: 0.3940

Epoch 00025: val_loss did not improve from 1.58586
Epoch 26/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4883 - accuracy: 0.4465 - val_loss: 1.6350 - val_accuracy: 0.3736

Epoch 00026: val_loss did not improve from 1.58586
Epoch 27/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4806 - accuracy: 0.4500 - val_loss: 1.6404 - val_accuracy: 0.3783

Epoch 00027: val_loss did not improve from 1.58586
Epoch 28/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4640 - accuracy: 0.4595 - val_loss: 1.6133 - val_accuracy: 0.3923

Epoch 00028: val_loss did not improve from 1.58586
Epoch 29/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4522 - accuracy: 0.4705 - val_loss: 1.6203 - val_accuracy: 0.3896

Epoch 00029: val_loss did not improve from 1.58586
Epoch 00029: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13584/13584 [==============================] - 55s 4ms/step - loss: 1.5764 - accuracy: 0.3831
Testing Loss = 1.576427, Testing Accuracy = 0.383098
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 43467.
Epoch 1/100
84/84 [==============================] - 6s 66ms/step - loss: 12.4247 - accuracy: 0.2020 - val_loss: 8.6998 - val_accuracy: 0.2053

Epoch 00001: val_loss improved from inf to 8.69981, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 2/100
84/84 [==============================] - 6s 65ms/step - loss: 6.7756 - accuracy: 0.2084 - val_loss: 5.3461 - val_accuracy: 0.2077

Epoch 00002: val_loss improved from 8.69981 to 5.34610, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 3/100
84/84 [==============================] - 5s 65ms/step - loss: 4.5625 - accuracy: 0.2184 - val_loss: 3.9437 - val_accuracy: 0.2262

Epoch 00003: val_loss improved from 5.34610 to 3.94366, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 4/100
84/84 [==============================] - 5s 65ms/step - loss: 3.4649 - accuracy: 0.2753 - val_loss: 3.1664 - val_accuracy: 0.2852

Epoch 00004: val_loss improved from 3.94366 to 3.16642, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 5/100
84/84 [==============================] - 5s 64ms/step - loss: 2.8693 - accuracy: 0.2945 - val_loss: 2.6793 - val_accuracy: 0.3033

Epoch 00005: val_loss improved from 3.16642 to 2.67927, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 6/100
84/84 [==============================] - 6s 65ms/step - loss: 2.4909 - accuracy: 0.3029 - val_loss: 2.3623 - val_accuracy: 0.3021

Epoch 00006: val_loss improved from 2.67927 to 2.36227, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 7/100
84/84 [==============================] - 5s 65ms/step - loss: 2.2236 - accuracy: 0.3112 - val_loss: 2.1297 - val_accuracy: 0.3167

Epoch 00007: val_loss improved from 2.36227 to 2.12972, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 8/100
84/84 [==============================] - 6s 66ms/step - loss: 2.0388 - accuracy: 0.3223 - val_loss: 1.9744 - val_accuracy: 0.3283

Epoch 00008: val_loss improved from 2.12972 to 1.97445, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 9/100
84/84 [==============================] - 6s 65ms/step - loss: 1.9058 - accuracy: 0.3302 - val_loss: 1.8584 - val_accuracy: 0.3382

Epoch 00009: val_loss improved from 1.97445 to 1.85845, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 10/100
84/84 [==============================] - 5s 65ms/step - loss: 1.8147 - accuracy: 0.3375 - val_loss: 1.7827 - val_accuracy: 0.3442

Epoch 00010: val_loss improved from 1.85845 to 1.78266, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 11/100
84/84 [==============================] - 6s 65ms/step - loss: 1.7472 - accuracy: 0.3452 - val_loss: 1.7296 - val_accuracy: 0.3465

Epoch 00011: val_loss improved from 1.78266 to 1.72959, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 12/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6982 - accuracy: 0.3551 - val_loss: 1.6917 - val_accuracy: 0.3517

Epoch 00012: val_loss improved from 1.72959 to 1.69173, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 13/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6597 - accuracy: 0.3648 - val_loss: 1.6585 - val_accuracy: 0.3598

Epoch 00013: val_loss improved from 1.69173 to 1.65850, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 14/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6327 - accuracy: 0.3713 - val_loss: 1.6382 - val_accuracy: 0.3664

Epoch 00014: val_loss improved from 1.65850 to 1.63820, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 15/100
84/84 [==============================] - 6s 65ms/step - loss: 1.6070 - accuracy: 0.3808 - val_loss: 1.6184 - val_accuracy: 0.3707

Epoch 00015: val_loss improved from 1.63820 to 1.61837, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 16/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5893 - accuracy: 0.3861 - val_loss: 1.6106 - val_accuracy: 0.3740

Epoch 00016: val_loss improved from 1.61837 to 1.61056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 17/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5727 - accuracy: 0.3935 - val_loss: 1.6033 - val_accuracy: 0.3776

Epoch 00017: val_loss improved from 1.61056 to 1.60333, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 18/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5611 - accuracy: 0.3982 - val_loss: 1.6006 - val_accuracy: 0.3770

Epoch 00018: val_loss improved from 1.60333 to 1.60059, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 19/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5492 - accuracy: 0.4028 - val_loss: 1.5944 - val_accuracy: 0.3826

Epoch 00019: val_loss improved from 1.60059 to 1.59440, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 20/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5386 - accuracy: 0.4089 - val_loss: 1.5981 - val_accuracy: 0.3818

Epoch 00020: val_loss did not improve from 1.59440
Epoch 21/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5287 - accuracy: 0.4162 - val_loss: 1.5879 - val_accuracy: 0.3885

Epoch 00021: val_loss improved from 1.59440 to 1.58790, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 22/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5211 - accuracy: 0.4218 - val_loss: 1.5924 - val_accuracy: 0.3902

Epoch 00022: val_loss did not improve from 1.58790
Epoch 23/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5113 - accuracy: 0.4276 - val_loss: 1.5852 - val_accuracy: 0.3887

Epoch 00023: val_loss improved from 1.58790 to 1.58519, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 24/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5037 - accuracy: 0.4358 - val_loss: 1.5859 - val_accuracy: 0.3935

Epoch 00024: val_loss did not improve from 1.58519
Epoch 25/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5015 - accuracy: 0.4354 - val_loss: 1.5829 - val_accuracy: 0.3935

Epoch 00025: val_loss improved from 1.58519 to 1.58291, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 26/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4942 - accuracy: 0.4392 - val_loss: 1.5998 - val_accuracy: 0.3907

Epoch 00026: val_loss did not improve from 1.58291
Epoch 27/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4790 - accuracy: 0.4500 - val_loss: 1.5974 - val_accuracy: 0.3911

Epoch 00027: val_loss did not improve from 1.58291
Epoch 28/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4678 - accuracy: 0.4575 - val_loss: 1.5966 - val_accuracy: 0.3923

Epoch 00028: val_loss did not improve from 1.58291
Epoch 29/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4629 - accuracy: 0.4637 - val_loss: 1.6137 - val_accuracy: 0.3874

Epoch 00029: val_loss did not improve from 1.58291
Epoch 30/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4515 - accuracy: 0.4677 - val_loss: 1.6119 - val_accuracy: 0.3941

Epoch 00030: val_loss did not improve from 1.58291
Epoch 31/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4400 - accuracy: 0.4788 - val_loss: 1.6141 - val_accuracy: 0.3950

Epoch 00031: val_loss did not improve from 1.58291
Epoch 32/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4293 - accuracy: 0.4840 - val_loss: 1.6354 - val_accuracy: 0.3885

Epoch 00032: val_loss did not improve from 1.58291
Epoch 33/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4281 - accuracy: 0.4897 - val_loss: 1.6562 - val_accuracy: 0.3773

Epoch 00033: val_loss did not improve from 1.58291
Epoch 34/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4224 - accuracy: 0.4909 - val_loss: 1.6869 - val_accuracy: 0.3809

Epoch 00034: val_loss did not improve from 1.58291
Epoch 35/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4048 - accuracy: 0.5033 - val_loss: 1.7185 - val_accuracy: 0.3804

Epoch 00035: val_loss did not improve from 1.58291
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13584/13584 [==============================] - 54s 4ms/step - loss: 1.5745 - accuracy: 0.3869
Testing Loss = 1.574526, Testing Accuracy = 0.386852
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 43467.
Epoch 1/100
84/84 [==============================] - 6s 66ms/step - loss: 12.4529 - accuracy: 0.1975 - val_loss: 8.7311 - val_accuracy: 0.2088

Epoch 00001: val_loss improved from inf to 8.73112, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 2/100
84/84 [==============================] - 5s 65ms/step - loss: 6.8021 - accuracy: 0.2081 - val_loss: 5.3681 - val_accuracy: 0.2096

Epoch 00002: val_loss improved from 8.73112 to 5.36815, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 3/100
84/84 [==============================] - 5s 64ms/step - loss: 4.5908 - accuracy: 0.2126 - val_loss: 3.9754 - val_accuracy: 0.2196

Epoch 00003: val_loss improved from 5.36815 to 3.97543, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 4/100
84/84 [==============================] - 5s 65ms/step - loss: 3.4965 - accuracy: 0.2687 - val_loss: 3.1697 - val_accuracy: 0.2822

Epoch 00004: val_loss improved from 3.97543 to 3.16970, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 5/100
84/84 [==============================] - 6s 65ms/step - loss: 2.8808 - accuracy: 0.2916 - val_loss: 2.6873 - val_accuracy: 0.3003

Epoch 00005: val_loss improved from 3.16970 to 2.68733, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 6/100
84/84 [==============================] - 5s 65ms/step - loss: 2.4943 - accuracy: 0.3011 - val_loss: 2.3606 - val_accuracy: 0.3080

Epoch 00006: val_loss improved from 2.68733 to 2.36060, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 7/100
84/84 [==============================] - 6s 66ms/step - loss: 2.2285 - accuracy: 0.3116 - val_loss: 2.1304 - val_accuracy: 0.3185

Epoch 00007: val_loss improved from 2.36060 to 2.13038, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 8/100
84/84 [==============================] - 5s 65ms/step - loss: 2.0411 - accuracy: 0.3223 - val_loss: 1.9718 - val_accuracy: 0.3313

Epoch 00008: val_loss improved from 2.13038 to 1.97184, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 9/100
84/84 [==============================] - 6s 66ms/step - loss: 1.9106 - accuracy: 0.3272 - val_loss: 1.8577 - val_accuracy: 0.3403

Epoch 00009: val_loss improved from 1.97184 to 1.85771, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 10/100
84/84 [==============================] - 5s 65ms/step - loss: 1.8168 - accuracy: 0.3366 - val_loss: 1.7829 - val_accuracy: 0.3414

Epoch 00010: val_loss improved from 1.85771 to 1.78289, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 11/100
84/84 [==============================] - 5s 65ms/step - loss: 1.7486 - accuracy: 0.3467 - val_loss: 1.7259 - val_accuracy: 0.3517

Epoch 00011: val_loss improved from 1.78289 to 1.72592, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 12/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6974 - accuracy: 0.3542 - val_loss: 1.6882 - val_accuracy: 0.3547

Epoch 00012: val_loss improved from 1.72592 to 1.68819, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 13/100
84/84 [==============================] - 6s 65ms/step - loss: 1.6620 - accuracy: 0.3603 - val_loss: 1.6608 - val_accuracy: 0.3595

Epoch 00013: val_loss improved from 1.68819 to 1.66084, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 14/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6294 - accuracy: 0.3684 - val_loss: 1.6372 - val_accuracy: 0.3648

Epoch 00014: val_loss improved from 1.66084 to 1.63720, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 15/100
84/84 [==============================] - 6s 67ms/step - loss: 1.6113 - accuracy: 0.3750 - val_loss: 1.6166 - val_accuracy: 0.3707

Epoch 00015: val_loss improved from 1.63720 to 1.61661, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 16/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5925 - accuracy: 0.3824 - val_loss: 1.6177 - val_accuracy: 0.3665

Epoch 00016: val_loss did not improve from 1.61661
Epoch 17/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5804 - accuracy: 0.3872 - val_loss: 1.5909 - val_accuracy: 0.3798

Epoch 00017: val_loss improved from 1.61661 to 1.59085, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 18/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5666 - accuracy: 0.3942 - val_loss: 1.5860 - val_accuracy: 0.3820

Epoch 00018: val_loss improved from 1.59085 to 1.58601, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 19/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5505 - accuracy: 0.4026 - val_loss: 1.5927 - val_accuracy: 0.3802

Epoch 00019: val_loss did not improve from 1.58601
Epoch 20/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5436 - accuracy: 0.4068 - val_loss: 1.5914 - val_accuracy: 0.3807

Epoch 00020: val_loss did not improve from 1.58601
Epoch 21/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5362 - accuracy: 0.4081 - val_loss: 1.5871 - val_accuracy: 0.3853

Epoch 00021: val_loss did not improve from 1.58601
Epoch 22/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5291 - accuracy: 0.4141 - val_loss: 1.5828 - val_accuracy: 0.3883

Epoch 00022: val_loss improved from 1.58601 to 1.58276, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 23/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5189 - accuracy: 0.4197 - val_loss: 1.5820 - val_accuracy: 0.3883

Epoch 00023: val_loss improved from 1.58276 to 1.58203, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 24/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5115 - accuracy: 0.4245 - val_loss: 1.5835 - val_accuracy: 0.3892

Epoch 00024: val_loss did not improve from 1.58203
Epoch 25/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5044 - accuracy: 0.4301 - val_loss: 1.5940 - val_accuracy: 0.3868

Epoch 00025: val_loss did not improve from 1.58203
Epoch 26/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4945 - accuracy: 0.4370 - val_loss: 1.5829 - val_accuracy: 0.3928

Epoch 00026: val_loss did not improve from 1.58203
Epoch 27/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4903 - accuracy: 0.4390 - val_loss: 1.5879 - val_accuracy: 0.3903

Epoch 00027: val_loss did not improve from 1.58203
Epoch 28/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4815 - accuracy: 0.4455 - val_loss: 1.5925 - val_accuracy: 0.3903

Epoch 00028: val_loss did not improve from 1.58203
Epoch 29/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4747 - accuracy: 0.4483 - val_loss: 1.5940 - val_accuracy: 0.3915

Epoch 00029: val_loss did not improve from 1.58203
Epoch 30/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4661 - accuracy: 0.4590 - val_loss: 1.5969 - val_accuracy: 0.3905

Epoch 00030: val_loss did not improve from 1.58203
Epoch 31/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4578 - accuracy: 0.4623 - val_loss: 1.5992 - val_accuracy: 0.3924

Epoch 00031: val_loss did not improve from 1.58203
Epoch 32/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4508 - accuracy: 0.4670 - val_loss: 1.6262 - val_accuracy: 0.3810

Epoch 00032: val_loss did not improve from 1.58203
Epoch 33/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4451 - accuracy: 0.4702 - val_loss: 1.6400 - val_accuracy: 0.3762

Epoch 00033: val_loss did not improve from 1.58203
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13584/13584 [==============================] - 54s 4ms/step - loss: 1.5717 - accuracy: 0.3833
Testing Loss = 1.571671, Testing Accuracy = 0.383319
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 43467.
Epoch 1/100
84/84 [==============================] - 6s 67ms/step - loss: 12.4946 - accuracy: 0.1983 - val_loss: 8.7770 - val_accuracy: 0.2061

Epoch 00001: val_loss improved from inf to 8.77695, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 2/100
84/84 [==============================] - 5s 65ms/step - loss: 6.8405 - accuracy: 0.2061 - val_loss: 5.3975 - val_accuracy: 0.2107

Epoch 00002: val_loss improved from 8.77695 to 5.39751, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 3/100
84/84 [==============================] - 6s 65ms/step - loss: 4.6103 - accuracy: 0.2129 - val_loss: 3.9888 - val_accuracy: 0.2173

Epoch 00003: val_loss improved from 5.39751 to 3.98878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 4/100
84/84 [==============================] - 6s 65ms/step - loss: 3.5130 - accuracy: 0.2621 - val_loss: 3.1700 - val_accuracy: 0.2880

Epoch 00004: val_loss improved from 3.98878 to 3.17000, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 5/100
84/84 [==============================] - 6s 67ms/step - loss: 2.8764 - accuracy: 0.2947 - val_loss: 2.6813 - val_accuracy: 0.3054

Epoch 00005: val_loss improved from 3.17000 to 2.68133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 6/100
84/84 [==============================] - 6s 65ms/step - loss: 2.4920 - accuracy: 0.3058 - val_loss: 2.3581 - val_accuracy: 0.3098

Epoch 00006: val_loss improved from 2.68133 to 2.35813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 7/100
84/84 [==============================] - 6s 65ms/step - loss: 2.2207 - accuracy: 0.3147 - val_loss: 2.1238 - val_accuracy: 0.3226

Epoch 00007: val_loss improved from 2.35813 to 2.12383, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 8/100
84/84 [==============================] - 6s 65ms/step - loss: 2.0334 - accuracy: 0.3262 - val_loss: 1.9596 - val_accuracy: 0.3351

Epoch 00008: val_loss improved from 2.12383 to 1.95961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 9/100
84/84 [==============================] - 5s 65ms/step - loss: 1.9023 - accuracy: 0.3353 - val_loss: 1.8556 - val_accuracy: 0.3381

Epoch 00009: val_loss improved from 1.95961 to 1.85560, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 10/100
84/84 [==============================] - 5s 65ms/step - loss: 1.8083 - accuracy: 0.3429 - val_loss: 1.7769 - val_accuracy: 0.3432

Epoch 00010: val_loss improved from 1.85560 to 1.77694, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 11/100
84/84 [==============================] - 5s 65ms/step - loss: 1.7404 - accuracy: 0.3528 - val_loss: 1.7275 - val_accuracy: 0.3508

Epoch 00011: val_loss improved from 1.77694 to 1.72750, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 12/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6913 - accuracy: 0.3617 - val_loss: 1.6792 - val_accuracy: 0.3646

Epoch 00012: val_loss improved from 1.72750 to 1.67923, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 13/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6559 - accuracy: 0.3667 - val_loss: 1.6559 - val_accuracy: 0.3640

Epoch 00013: val_loss improved from 1.67923 to 1.65591, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 14/100
84/84 [==============================] - 5s 65ms/step - loss: 1.6262 - accuracy: 0.3767 - val_loss: 1.6320 - val_accuracy: 0.3721

Epoch 00014: val_loss improved from 1.65591 to 1.63202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 15/100
84/84 [==============================] - 6s 65ms/step - loss: 1.6045 - accuracy: 0.3817 - val_loss: 1.6124 - val_accuracy: 0.3797

Epoch 00015: val_loss improved from 1.63202 to 1.61244, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 16/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5837 - accuracy: 0.3901 - val_loss: 1.6115 - val_accuracy: 0.3757

Epoch 00016: val_loss improved from 1.61244 to 1.61151, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 17/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5687 - accuracy: 0.3977 - val_loss: 1.6056 - val_accuracy: 0.3779

Epoch 00017: val_loss improved from 1.61151 to 1.60560, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 18/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5545 - accuracy: 0.4029 - val_loss: 1.5920 - val_accuracy: 0.3832

Epoch 00018: val_loss improved from 1.60560 to 1.59198, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 19/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5457 - accuracy: 0.4085 - val_loss: 1.5916 - val_accuracy: 0.3874

Epoch 00019: val_loss improved from 1.59198 to 1.59161, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 20/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5351 - accuracy: 0.4119 - val_loss: 1.5890 - val_accuracy: 0.3888

Epoch 00020: val_loss improved from 1.59161 to 1.58902, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 21/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5271 - accuracy: 0.4167 - val_loss: 1.5833 - val_accuracy: 0.3899

Epoch 00021: val_loss improved from 1.58902 to 1.58327, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 22/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5187 - accuracy: 0.4225 - val_loss: 1.5797 - val_accuracy: 0.3916

Epoch 00022: val_loss improved from 1.58327 to 1.57966, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 23/100
84/84 [==============================] - 5s 65ms/step - loss: 1.5117 - accuracy: 0.4262 - val_loss: 1.5860 - val_accuracy: 0.3914

Epoch 00023: val_loss did not improve from 1.57966
Epoch 24/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5036 - accuracy: 0.4327 - val_loss: 1.5811 - val_accuracy: 0.3921

Epoch 00024: val_loss did not improve from 1.57966
Epoch 25/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4952 - accuracy: 0.4365 - val_loss: 1.5954 - val_accuracy: 0.3859

Epoch 00025: val_loss did not improve from 1.57966
Epoch 26/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4968 - accuracy: 0.4380 - val_loss: 1.6041 - val_accuracy: 0.3878

Epoch 00026: val_loss did not improve from 1.57966
Epoch 27/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4789 - accuracy: 0.4453 - val_loss: 1.6047 - val_accuracy: 0.3873

Epoch 00027: val_loss did not improve from 1.57966
Epoch 28/100
84/84 [==============================] - 5s 65ms/step - loss: 1.4722 - accuracy: 0.4547 - val_loss: 1.5972 - val_accuracy: 0.3913

Epoch 00028: val_loss did not improve from 1.57966
Epoch 29/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4627 - accuracy: 0.4620 - val_loss: 1.6021 - val_accuracy: 0.3949

Epoch 00029: val_loss did not improve from 1.57966
Epoch 30/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4529 - accuracy: 0.4660 - val_loss: 1.6068 - val_accuracy: 0.3930

Epoch 00030: val_loss did not improve from 1.57966
Epoch 31/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4428 - accuracy: 0.4739 - val_loss: 1.6246 - val_accuracy: 0.3851

Epoch 00031: val_loss did not improve from 1.57966
Epoch 32/100
84/84 [==============================] - 6s 65ms/step - loss: 1.4334 - accuracy: 0.4804 - val_loss: 1.6270 - val_accuracy: 0.3906

Epoch 00032: val_loss did not improve from 1.57966
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13584/13584 [==============================] - 53s 4ms/step - loss: 1.5683 - accuracy: 0.3894
Testing Loss = 1.568340, Testing Accuracy = 0.389429
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 43467.
Epoch 1/100
84/84 [==============================] - 6s 67ms/step - loss: 12.3852 - accuracy: 0.2047 - val_loss: 8.6459 - val_accuracy: 0.2094

Epoch 00001: val_loss improved from inf to 8.64587, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 2/100
84/84 [==============================] - 6s 66ms/step - loss: 6.7191 - accuracy: 0.2082 - val_loss: 5.2958 - val_accuracy: 0.2085

Epoch 00002: val_loss improved from 8.64587 to 5.29577, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 3/100
84/84 [==============================] - 6s 65ms/step - loss: 4.5194 - accuracy: 0.2210 - val_loss: 3.9055 - val_accuracy: 0.2431

Epoch 00003: val_loss improved from 5.29577 to 3.90549, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 4/100
84/84 [==============================] - 6s 66ms/step - loss: 3.4326 - accuracy: 0.2806 - val_loss: 3.1353 - val_accuracy: 0.2884

Epoch 00004: val_loss improved from 3.90549 to 3.13532, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 5/100
84/84 [==============================] - 6s 65ms/step - loss: 2.8528 - accuracy: 0.2971 - val_loss: 2.6633 - val_accuracy: 0.3100

Epoch 00005: val_loss improved from 3.13532 to 2.66330, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 6/100
84/84 [==============================] - 6s 65ms/step - loss: 2.4758 - accuracy: 0.3075 - val_loss: 2.3454 - val_accuracy: 0.3113

Epoch 00006: val_loss improved from 2.66330 to 2.34536, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 7/100
84/84 [==============================] - 5s 65ms/step - loss: 2.2168 - accuracy: 0.3157 - val_loss: 2.1216 - val_accuracy: 0.3210

Epoch 00007: val_loss improved from 2.34536 to 2.12162, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 8/100
84/84 [==============================] - 5s 65ms/step - loss: 2.0327 - accuracy: 0.3235 - val_loss: 1.9686 - val_accuracy: 0.3264

Epoch 00008: val_loss improved from 2.12162 to 1.96857, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 9/100
84/84 [==============================] - 5s 65ms/step - loss: 1.9051 - accuracy: 0.3326 - val_loss: 1.8594 - val_accuracy: 0.3340

Epoch 00009: val_loss improved from 1.96857 to 1.85942, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 10/100
84/84 [==============================] - 5s 65ms/step - loss: 1.8124 - accuracy: 0.3374 - val_loss: 1.7831 - val_accuracy: 0.3403

Epoch 00010: val_loss improved from 1.85942 to 1.78306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 11/100
84/84 [==============================] - 5s 65ms/step - loss: 1.7470 - accuracy: 0.3468 - val_loss: 1.7241 - val_accuracy: 0.3474

Epoch 00011: val_loss improved from 1.78306 to 1.72412, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 12/100
84/84 [==============================] - 6s 67ms/step - loss: 1.7009 - accuracy: 0.3531 - val_loss: 1.6896 - val_accuracy: 0.3501

Epoch 00012: val_loss improved from 1.72412 to 1.68960, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 13/100
84/84 [==============================] - 6s 65ms/step - loss: 1.6633 - accuracy: 0.3594 - val_loss: 1.6618 - val_accuracy: 0.3590

Epoch 00013: val_loss improved from 1.68960 to 1.66175, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 14/100
84/84 [==============================] - 5s 64ms/step - loss: 1.6370 - accuracy: 0.3653 - val_loss: 1.6402 - val_accuracy: 0.3642

Epoch 00014: val_loss improved from 1.66175 to 1.64020, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 15/100
84/84 [==============================] - 6s 65ms/step - loss: 1.6138 - accuracy: 0.3750 - val_loss: 1.6189 - val_accuracy: 0.3753

Epoch 00015: val_loss improved from 1.64020 to 1.61889, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 16/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5960 - accuracy: 0.3817 - val_loss: 1.6110 - val_accuracy: 0.3743

Epoch 00016: val_loss improved from 1.61889 to 1.61104, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 17/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5814 - accuracy: 0.3895 - val_loss: 1.6022 - val_accuracy: 0.3783

Epoch 00017: val_loss improved from 1.61104 to 1.60216, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 18/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5634 - accuracy: 0.3971 - val_loss: 1.5958 - val_accuracy: 0.3800

Epoch 00018: val_loss improved from 1.60216 to 1.59578, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 19/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5546 - accuracy: 0.4001 - val_loss: 1.5948 - val_accuracy: 0.3832

Epoch 00019: val_loss improved from 1.59578 to 1.59478, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 20/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5472 - accuracy: 0.4036 - val_loss: 1.5912 - val_accuracy: 0.3882

Epoch 00020: val_loss improved from 1.59478 to 1.59122, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 21/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5360 - accuracy: 0.4123 - val_loss: 1.5850 - val_accuracy: 0.3919

Epoch 00021: val_loss improved from 1.59122 to 1.58495, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 22/100
84/84 [==============================] - 6s 65ms/step - loss: 1.5272 - accuracy: 0.4167 - val_loss: 1.5885 - val_accuracy: 0.3890

Epoch 00022: val_loss did not improve from 1.58495
Epoch 23/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5205 - accuracy: 0.4178 - val_loss: 1.5881 - val_accuracy: 0.3897

Epoch 00023: val_loss did not improve from 1.58495
Epoch 24/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5144 - accuracy: 0.4241 - val_loss: 1.5874 - val_accuracy: 0.3901

Epoch 00024: val_loss did not improve from 1.58495
Epoch 25/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5065 - accuracy: 0.4295 - val_loss: 1.5923 - val_accuracy: 0.3919

Epoch 00025: val_loss did not improve from 1.58495
Epoch 26/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4954 - accuracy: 0.4354 - val_loss: 1.5930 - val_accuracy: 0.3902

Epoch 00026: val_loss did not improve from 1.58495
Epoch 27/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4906 - accuracy: 0.4435 - val_loss: 1.5980 - val_accuracy: 0.3908

Epoch 00027: val_loss did not improve from 1.58495
Epoch 28/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4812 - accuracy: 0.4498 - val_loss: 1.6029 - val_accuracy: 0.3876

Epoch 00028: val_loss did not improve from 1.58495
Epoch 29/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4724 - accuracy: 0.4564 - val_loss: 1.6115 - val_accuracy: 0.3904

Epoch 00029: val_loss did not improve from 1.58495
Epoch 30/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4632 - accuracy: 0.4622 - val_loss: 1.6142 - val_accuracy: 0.3916

Epoch 00030: val_loss did not improve from 1.58495
Epoch 31/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4538 - accuracy: 0.4677 - val_loss: 1.6134 - val_accuracy: 0.3917

Epoch 00031: val_loss did not improve from 1.58495
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13584/13584 [==============================] - 60s 4ms/step - loss: 1.5756 - accuracy: 0.3840
Testing Loss = 1.575573, Testing Accuracy = 0.383981
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 43467.
Epoch 1/100
84/84 [==============================] - 6s 67ms/step - loss: 12.4811 - accuracy: 0.1962 - val_loss: 8.7472 - val_accuracy: 0.2068

Epoch 00001: val_loss improved from inf to 8.74721, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 2/100
84/84 [==============================] - 6s 67ms/step - loss: 6.8104 - accuracy: 0.2080 - val_loss: 5.3710 - val_accuracy: 0.2102

Epoch 00002: val_loss improved from 8.74721 to 5.37102, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 3/100
84/84 [==============================] - 6s 66ms/step - loss: 4.5903 - accuracy: 0.2164 - val_loss: 3.9739 - val_accuracy: 0.2156

Epoch 00003: val_loss improved from 5.37102 to 3.97390, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 4/100
84/84 [==============================] - 6s 67ms/step - loss: 3.5038 - accuracy: 0.2600 - val_loss: 3.1669 - val_accuracy: 0.2743

Epoch 00004: val_loss improved from 3.97390 to 3.16686, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 5/100
84/84 [==============================] - 6s 66ms/step - loss: 2.8795 - accuracy: 0.2895 - val_loss: 2.6870 - val_accuracy: 0.2999

Epoch 00005: val_loss improved from 3.16686 to 2.68702, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 6/100
84/84 [==============================] - 6s 66ms/step - loss: 2.4909 - accuracy: 0.3049 - val_loss: 2.3606 - val_accuracy: 0.3098

Epoch 00006: val_loss improved from 2.68702 to 2.36060, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 7/100
84/84 [==============================] - 6s 66ms/step - loss: 2.2268 - accuracy: 0.3141 - val_loss: 2.1248 - val_accuracy: 0.3181

Epoch 00007: val_loss improved from 2.36060 to 2.12480, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 8/100
84/84 [==============================] - 6s 66ms/step - loss: 2.0387 - accuracy: 0.3220 - val_loss: 1.9645 - val_accuracy: 0.3325

Epoch 00008: val_loss improved from 2.12480 to 1.96453, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 9/100
84/84 [==============================] - 6s 66ms/step - loss: 1.9092 - accuracy: 0.3298 - val_loss: 1.8676 - val_accuracy: 0.3319

Epoch 00009: val_loss improved from 1.96453 to 1.86756, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 10/100
84/84 [==============================] - 6s 66ms/step - loss: 1.8143 - accuracy: 0.3359 - val_loss: 1.7847 - val_accuracy: 0.3443

Epoch 00010: val_loss improved from 1.86756 to 1.78475, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 11/100
84/84 [==============================] - 6s 66ms/step - loss: 1.7492 - accuracy: 0.3434 - val_loss: 1.7334 - val_accuracy: 0.3405

Epoch 00011: val_loss improved from 1.78475 to 1.73335, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 12/100
84/84 [==============================] - 6s 66ms/step - loss: 1.6980 - accuracy: 0.3520 - val_loss: 1.6868 - val_accuracy: 0.3520

Epoch 00012: val_loss improved from 1.73335 to 1.68683, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 13/100
84/84 [==============================] - 6s 66ms/step - loss: 1.6624 - accuracy: 0.3594 - val_loss: 1.6559 - val_accuracy: 0.3616

Epoch 00013: val_loss improved from 1.68683 to 1.65594, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 14/100
84/84 [==============================] - 6s 66ms/step - loss: 1.6315 - accuracy: 0.3694 - val_loss: 1.6392 - val_accuracy: 0.3641

Epoch 00014: val_loss improved from 1.65594 to 1.63918, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 15/100
84/84 [==============================] - 6s 66ms/step - loss: 1.6126 - accuracy: 0.3744 - val_loss: 1.6180 - val_accuracy: 0.3696

Epoch 00015: val_loss improved from 1.63918 to 1.61802, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 16/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5939 - accuracy: 0.3830 - val_loss: 1.6042 - val_accuracy: 0.3733

Epoch 00016: val_loss improved from 1.61802 to 1.60423, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 17/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5811 - accuracy: 0.3880 - val_loss: 1.5970 - val_accuracy: 0.3773

Epoch 00017: val_loss improved from 1.60423 to 1.59699, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 18/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5661 - accuracy: 0.3948 - val_loss: 1.5922 - val_accuracy: 0.3806

Epoch 00018: val_loss improved from 1.59699 to 1.59218, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 19/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5585 - accuracy: 0.3982 - val_loss: 1.5857 - val_accuracy: 0.3858

Epoch 00019: val_loss improved from 1.59218 to 1.58569, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 20/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5455 - accuracy: 0.4051 - val_loss: 1.5884 - val_accuracy: 0.3836

Epoch 00020: val_loss did not improve from 1.58569
Epoch 21/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5373 - accuracy: 0.4107 - val_loss: 1.5838 - val_accuracy: 0.3851

Epoch 00021: val_loss improved from 1.58569 to 1.58376, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 22/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5272 - accuracy: 0.4167 - val_loss: 1.5843 - val_accuracy: 0.3858

Epoch 00022: val_loss did not improve from 1.58376
Epoch 23/100
84/84 [==============================] - 6s 66ms/step - loss: 1.5225 - accuracy: 0.4182 - val_loss: 1.5843 - val_accuracy: 0.3860

Epoch 00023: val_loss did not improve from 1.58376
Epoch 24/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5136 - accuracy: 0.4219 - val_loss: 1.5825 - val_accuracy: 0.3864

Epoch 00024: val_loss improved from 1.58376 to 1.58246, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 25/100
84/84 [==============================] - 6s 67ms/step - loss: 1.5036 - accuracy: 0.4292 - val_loss: 1.5829 - val_accuracy: 0.3850

Epoch 00025: val_loss did not improve from 1.58246
Epoch 26/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4981 - accuracy: 0.4333 - val_loss: 1.5886 - val_accuracy: 0.3876

Epoch 00026: val_loss did not improve from 1.58246
Epoch 27/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4914 - accuracy: 0.4392 - val_loss: 1.5866 - val_accuracy: 0.3915

Epoch 00027: val_loss did not improve from 1.58246
Epoch 28/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4812 - accuracy: 0.4463 - val_loss: 1.5944 - val_accuracy: 0.3850

Epoch 00028: val_loss did not improve from 1.58246
Epoch 29/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4758 - accuracy: 0.4498 - val_loss: 1.5984 - val_accuracy: 0.3854

Epoch 00029: val_loss did not improve from 1.58246
Epoch 30/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4664 - accuracy: 0.4585 - val_loss: 1.6039 - val_accuracy: 0.3884

Epoch 00030: val_loss did not improve from 1.58246
Epoch 31/100
84/84 [==============================] - 6s 67ms/step - loss: 1.4618 - accuracy: 0.4590 - val_loss: 1.6060 - val_accuracy: 0.3902

Epoch 00031: val_loss did not improve from 1.58246
Epoch 32/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4448 - accuracy: 0.4716 - val_loss: 1.6080 - val_accuracy: 0.3909

Epoch 00032: val_loss did not improve from 1.58246
Epoch 33/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4376 - accuracy: 0.4768 - val_loss: 1.6216 - val_accuracy: 0.3894

Epoch 00033: val_loss did not improve from 1.58246
Epoch 34/100
84/84 [==============================] - 6s 66ms/step - loss: 1.4311 - accuracy: 0.4807 - val_loss: 1.6248 - val_accuracy: 0.3870

Epoch 00034: val_loss did not improve from 1.58246
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13584/13584 [==============================] - 62s 5ms/step - loss: 1.5713 - accuracy: 0.3849
Testing Loss = 1.571274, Testing Accuracy = 0.384938
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 83.10 +- 0.1434 %)
$W^-/W^-$ (auc = 84.13 +- 0.0965 %)
$Z/Z$ (auc = 76.45 +- 0.3076 %)
$W^+/W^-$ (auc = 72.12 +- 0.1877 %)
$W^+/Z$$ (auc = 69.09 +- 0.1682 %)
$W^-/Z$ (auc = 69.54 +- 0.1389 %)
The summarized testing accuracy = 38.51 +- 0.2171 %, with the loss = 1.5732 +- 0.003333


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-22 20:28:14.159237
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 9s 70ms/step - loss: 12.5373 - accuracy: 0.1962 - val_loss: 8.8425 - val_accuracy: 0.2094

Epoch 00001: val_loss improved from inf to 8.84249, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8987 - accuracy: 0.2038 - val_loss: 5.4355 - val_accuracy: 0.2092

Epoch 00002: val_loss improved from 8.84249 to 5.43549, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 3/100
83/83 [==============================] - 6s 67ms/step - loss: 4.6437 - accuracy: 0.2116 - val_loss: 4.0084 - val_accuracy: 0.2140

Epoch 00003: val_loss improved from 5.43549 to 4.00841, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5525 - accuracy: 0.2460 - val_loss: 3.1898 - val_accuracy: 0.2887

Epoch 00004: val_loss improved from 4.00841 to 3.18977, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8968 - accuracy: 0.2911 - val_loss: 2.6973 - val_accuracy: 0.3087

Epoch 00005: val_loss improved from 3.18977 to 2.69730, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5046 - accuracy: 0.3006 - val_loss: 2.3583 - val_accuracy: 0.3219

Epoch 00006: val_loss improved from 2.69730 to 2.35829, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2380 - accuracy: 0.3105 - val_loss: 2.1282 - val_accuracy: 0.3251

Epoch 00007: val_loss improved from 2.35829 to 2.12823, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0498 - accuracy: 0.3193 - val_loss: 1.9628 - val_accuracy: 0.3313

Epoch 00008: val_loss improved from 2.12823 to 1.96279, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9163 - accuracy: 0.3271 - val_loss: 1.8513 - val_accuracy: 0.3345

Epoch 00009: val_loss improved from 1.96279 to 1.85133, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8236 - accuracy: 0.3347 - val_loss: 1.7747 - val_accuracy: 0.3413

Epoch 00010: val_loss improved from 1.85133 to 1.77469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 11/100
83/83 [==============================] - 6s 70ms/step - loss: 1.7556 - accuracy: 0.3433 - val_loss: 1.7219 - val_accuracy: 0.3456

Epoch 00011: val_loss improved from 1.77469 to 1.72187, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7075 - accuracy: 0.3475 - val_loss: 1.6831 - val_accuracy: 0.3498

Epoch 00012: val_loss improved from 1.72187 to 1.68308, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6693 - accuracy: 0.3595 - val_loss: 1.6551 - val_accuracy: 0.3572

Epoch 00013: val_loss improved from 1.68308 to 1.65514, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6392 - accuracy: 0.3690 - val_loss: 1.6271 - val_accuracy: 0.3616

Epoch 00014: val_loss improved from 1.65514 to 1.62711, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6162 - accuracy: 0.3723 - val_loss: 1.6111 - val_accuracy: 0.3671

Epoch 00015: val_loss improved from 1.62711 to 1.61111, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5962 - accuracy: 0.3810 - val_loss: 1.5961 - val_accuracy: 0.3751

Epoch 00016: val_loss improved from 1.61111 to 1.59613, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5806 - accuracy: 0.3893 - val_loss: 1.5916 - val_accuracy: 0.3804

Epoch 00017: val_loss improved from 1.59613 to 1.59161, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5723 - accuracy: 0.3926 - val_loss: 1.5844 - val_accuracy: 0.3828

Epoch 00018: val_loss improved from 1.59161 to 1.58439, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5615 - accuracy: 0.3950 - val_loss: 1.5751 - val_accuracy: 0.3874

Epoch 00019: val_loss improved from 1.58439 to 1.57506, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5492 - accuracy: 0.4012 - val_loss: 1.5739 - val_accuracy: 0.3894

Epoch 00020: val_loss improved from 1.57506 to 1.57394, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5406 - accuracy: 0.4083 - val_loss: 1.5699 - val_accuracy: 0.3873

Epoch 00021: val_loss improved from 1.57394 to 1.56992, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5325 - accuracy: 0.4135 - val_loss: 1.5672 - val_accuracy: 0.3954

Epoch 00022: val_loss improved from 1.56992 to 1.56722, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/0
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5241 - accuracy: 0.4192 - val_loss: 1.5689 - val_accuracy: 0.3912

Epoch 00023: val_loss did not improve from 1.56722
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5202 - accuracy: 0.4231 - val_loss: 1.5706 - val_accuracy: 0.3911

Epoch 00024: val_loss did not improve from 1.56722
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5153 - accuracy: 0.4239 - val_loss: 1.5688 - val_accuracy: 0.3955

Epoch 00025: val_loss did not improve from 1.56722
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5065 - accuracy: 0.4307 - val_loss: 1.5714 - val_accuracy: 0.3923

Epoch 00026: val_loss did not improve from 1.56722
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5011 - accuracy: 0.4345 - val_loss: 1.5735 - val_accuracy: 0.3950

Epoch 00027: val_loss did not improve from 1.56722
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4928 - accuracy: 0.4418 - val_loss: 1.5778 - val_accuracy: 0.3924

Epoch 00028: val_loss did not improve from 1.56722
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4828 - accuracy: 0.4483 - val_loss: 1.5839 - val_accuracy: 0.3919

Epoch 00029: val_loss did not improve from 1.56722
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4776 - accuracy: 0.4542 - val_loss: 1.5920 - val_accuracy: 0.3912

Epoch 00030: val_loss did not improve from 1.56722
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4661 - accuracy: 0.4579 - val_loss: 1.5975 - val_accuracy: 0.3940

Epoch 00031: val_loss did not improve from 1.56722
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4562 - accuracy: 0.4673 - val_loss: 1.6139 - val_accuracy: 0.3936

Epoch 00032: val_loss did not improve from 1.56722
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.5722 - accuracy: 0.3909
Testing Loss = 1.572234, Testing Accuracy = 0.390890
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4927 - accuracy: 0.1972 - val_loss: 8.7857 - val_accuracy: 0.2097

Epoch 00001: val_loss improved from inf to 8.78573, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8606 - accuracy: 0.2072 - val_loss: 5.4182 - val_accuracy: 0.2088

Epoch 00002: val_loss improved from 8.78573 to 5.41816, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6294 - accuracy: 0.2180 - val_loss: 4.0016 - val_accuracy: 0.2317

Epoch 00003: val_loss improved from 5.41816 to 4.00163, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5134 - accuracy: 0.2786 - val_loss: 3.2213 - val_accuracy: 0.2725

Epoch 00004: val_loss improved from 4.00163 to 3.22129, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9097 - accuracy: 0.2923 - val_loss: 2.7115 - val_accuracy: 0.3098

Epoch 00005: val_loss improved from 3.22129 to 2.71148, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5189 - accuracy: 0.3039 - val_loss: 2.3749 - val_accuracy: 0.3222

Epoch 00006: val_loss improved from 2.71148 to 2.37490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 7/100
83/83 [==============================] - 6s 70ms/step - loss: 2.2514 - accuracy: 0.3114 - val_loss: 2.1364 - val_accuracy: 0.3264

Epoch 00007: val_loss improved from 2.37490 to 2.13639, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0600 - accuracy: 0.3187 - val_loss: 1.9754 - val_accuracy: 0.3294

Epoch 00008: val_loss improved from 2.13639 to 1.97545, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9249 - accuracy: 0.3249 - val_loss: 1.8625 - val_accuracy: 0.3343

Epoch 00009: val_loss improved from 1.97545 to 1.86249, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8318 - accuracy: 0.3320 - val_loss: 1.7850 - val_accuracy: 0.3378

Epoch 00010: val_loss improved from 1.86249 to 1.78500, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7629 - accuracy: 0.3393 - val_loss: 1.7311 - val_accuracy: 0.3409

Epoch 00011: val_loss improved from 1.78500 to 1.73109, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7166 - accuracy: 0.3410 - val_loss: 1.6905 - val_accuracy: 0.3439

Epoch 00012: val_loss improved from 1.73109 to 1.69051, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6802 - accuracy: 0.3504 - val_loss: 1.6613 - val_accuracy: 0.3483

Epoch 00013: val_loss improved from 1.69051 to 1.66131, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6520 - accuracy: 0.3570 - val_loss: 1.6442 - val_accuracy: 0.3573

Epoch 00014: val_loss improved from 1.66131 to 1.64417, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6299 - accuracy: 0.3635 - val_loss: 1.6259 - val_accuracy: 0.3638

Epoch 00015: val_loss improved from 1.64417 to 1.62586, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6109 - accuracy: 0.3715 - val_loss: 1.6115 - val_accuracy: 0.3629

Epoch 00016: val_loss improved from 1.62586 to 1.61154, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5951 - accuracy: 0.3779 - val_loss: 1.6010 - val_accuracy: 0.3688

Epoch 00017: val_loss improved from 1.61154 to 1.60101, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5831 - accuracy: 0.3847 - val_loss: 1.5920 - val_accuracy: 0.3762

Epoch 00018: val_loss improved from 1.60101 to 1.59195, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5727 - accuracy: 0.3924 - val_loss: 1.5847 - val_accuracy: 0.3763

Epoch 00019: val_loss improved from 1.59195 to 1.58475, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5609 - accuracy: 0.3977 - val_loss: 1.5792 - val_accuracy: 0.3785

Epoch 00020: val_loss improved from 1.58475 to 1.57917, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5531 - accuracy: 0.4046 - val_loss: 1.5762 - val_accuracy: 0.3869

Epoch 00021: val_loss improved from 1.57917 to 1.57615, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5461 - accuracy: 0.4056 - val_loss: 1.5767 - val_accuracy: 0.3817

Epoch 00022: val_loss did not improve from 1.57615
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5353 - accuracy: 0.4130 - val_loss: 1.5753 - val_accuracy: 0.3851

Epoch 00023: val_loss improved from 1.57615 to 1.57532, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/1
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5254 - accuracy: 0.4205 - val_loss: 1.5760 - val_accuracy: 0.3881

Epoch 00024: val_loss did not improve from 1.57532
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5188 - accuracy: 0.4263 - val_loss: 1.5772 - val_accuracy: 0.3880

Epoch 00025: val_loss did not improve from 1.57532
Epoch 26/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5119 - accuracy: 0.4286 - val_loss: 1.5825 - val_accuracy: 0.3901

Epoch 00026: val_loss did not improve from 1.57532
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5082 - accuracy: 0.4331 - val_loss: 1.5819 - val_accuracy: 0.3918

Epoch 00027: val_loss did not improve from 1.57532
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5003 - accuracy: 0.4377 - val_loss: 1.5869 - val_accuracy: 0.3895

Epoch 00028: val_loss did not improve from 1.57532
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4910 - accuracy: 0.4453 - val_loss: 1.5880 - val_accuracy: 0.3897

Epoch 00029: val_loss did not improve from 1.57532
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4860 - accuracy: 0.4487 - val_loss: 1.5958 - val_accuracy: 0.3910

Epoch 00030: val_loss did not improve from 1.57532
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4747 - accuracy: 0.4579 - val_loss: 1.6032 - val_accuracy: 0.3919

Epoch 00031: val_loss did not improve from 1.57532
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4659 - accuracy: 0.4627 - val_loss: 1.6069 - val_accuracy: 0.3905

Epoch 00032: val_loss did not improve from 1.57532
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4577 - accuracy: 0.4700 - val_loss: 1.6194 - val_accuracy: 0.3913

Epoch 00033: val_loss did not improve from 1.57532
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5776 - accuracy: 0.3938
Testing Loss = 1.577644, Testing Accuracy = 0.393793
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.5052 - accuracy: 0.1946 - val_loss: 8.7748 - val_accuracy: 0.2037

Epoch 00001: val_loss improved from inf to 8.77483, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8360 - accuracy: 0.2049 - val_loss: 5.3865 - val_accuracy: 0.2103

Epoch 00002: val_loss improved from 8.77483 to 5.38655, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.6079 - accuracy: 0.2116 - val_loss: 3.9842 - val_accuracy: 0.2130

Epoch 00003: val_loss improved from 5.38655 to 3.98417, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5253 - accuracy: 0.2568 - val_loss: 3.1818 - val_accuracy: 0.2870

Epoch 00004: val_loss improved from 3.98417 to 3.18180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8881 - accuracy: 0.2947 - val_loss: 2.6896 - val_accuracy: 0.3116

Epoch 00005: val_loss improved from 3.18180 to 2.68962, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5010 - accuracy: 0.3021 - val_loss: 2.3548 - val_accuracy: 0.3202

Epoch 00006: val_loss improved from 2.68962 to 2.35483, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.2340 - accuracy: 0.3090 - val_loss: 2.1248 - val_accuracy: 0.3239

Epoch 00007: val_loss improved from 2.35483 to 2.12477, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0472 - accuracy: 0.3176 - val_loss: 1.9629 - val_accuracy: 0.3300

Epoch 00008: val_loss improved from 2.12477 to 1.96288, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9133 - accuracy: 0.3283 - val_loss: 1.8507 - val_accuracy: 0.3332

Epoch 00009: val_loss improved from 1.96288 to 1.85072, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8211 - accuracy: 0.3330 - val_loss: 1.7749 - val_accuracy: 0.3391

Epoch 00010: val_loss improved from 1.85072 to 1.77486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7548 - accuracy: 0.3371 - val_loss: 1.7192 - val_accuracy: 0.3448

Epoch 00011: val_loss improved from 1.77486 to 1.71915, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7063 - accuracy: 0.3473 - val_loss: 1.6861 - val_accuracy: 0.3449

Epoch 00012: val_loss improved from 1.71915 to 1.68608, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6668 - accuracy: 0.3566 - val_loss: 1.6554 - val_accuracy: 0.3611

Epoch 00013: val_loss improved from 1.68608 to 1.65539, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6407 - accuracy: 0.3648 - val_loss: 1.6309 - val_accuracy: 0.3654

Epoch 00014: val_loss improved from 1.65539 to 1.63092, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6185 - accuracy: 0.3723 - val_loss: 1.6121 - val_accuracy: 0.3690

Epoch 00015: val_loss improved from 1.63092 to 1.61206, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5992 - accuracy: 0.3808 - val_loss: 1.5993 - val_accuracy: 0.3748

Epoch 00016: val_loss improved from 1.61206 to 1.59934, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5846 - accuracy: 0.3869 - val_loss: 1.5881 - val_accuracy: 0.3813

Epoch 00017: val_loss improved from 1.59934 to 1.58806, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5707 - accuracy: 0.3950 - val_loss: 1.5827 - val_accuracy: 0.3813

Epoch 00018: val_loss improved from 1.58806 to 1.58271, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5600 - accuracy: 0.3990 - val_loss: 1.5757 - val_accuracy: 0.3850

Epoch 00019: val_loss improved from 1.58271 to 1.57570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5469 - accuracy: 0.4072 - val_loss: 1.5739 - val_accuracy: 0.3872

Epoch 00020: val_loss improved from 1.57570 to 1.57392, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 21/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5402 - accuracy: 0.4111 - val_loss: 1.5768 - val_accuracy: 0.3873

Epoch 00021: val_loss did not improve from 1.57392
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5305 - accuracy: 0.4160 - val_loss: 1.5727 - val_accuracy: 0.3895

Epoch 00022: val_loss improved from 1.57392 to 1.57273, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5250 - accuracy: 0.4199 - val_loss: 1.5708 - val_accuracy: 0.3911

Epoch 00023: val_loss improved from 1.57273 to 1.57076, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/2
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5221 - accuracy: 0.4245 - val_loss: 1.5764 - val_accuracy: 0.3862

Epoch 00024: val_loss did not improve from 1.57076
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5100 - accuracy: 0.4306 - val_loss: 1.5719 - val_accuracy: 0.3899

Epoch 00025: val_loss did not improve from 1.57076
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5042 - accuracy: 0.4357 - val_loss: 1.5773 - val_accuracy: 0.3898

Epoch 00026: val_loss did not improve from 1.57076
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4954 - accuracy: 0.4393 - val_loss: 1.5820 - val_accuracy: 0.3898

Epoch 00027: val_loss did not improve from 1.57076
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4842 - accuracy: 0.4475 - val_loss: 1.5860 - val_accuracy: 0.3905

Epoch 00028: val_loss did not improve from 1.57076
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4769 - accuracy: 0.4539 - val_loss: 1.5913 - val_accuracy: 0.3909

Epoch 00029: val_loss did not improve from 1.57076
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4683 - accuracy: 0.4596 - val_loss: 1.5955 - val_accuracy: 0.3939

Epoch 00030: val_loss did not improve from 1.57076
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4614 - accuracy: 0.4650 - val_loss: 1.6073 - val_accuracy: 0.3933

Epoch 00031: val_loss did not improve from 1.57076
Epoch 32/100
83/83 [==============================] - 6s 70ms/step - loss: 1.4544 - accuracy: 0.4721 - val_loss: 1.6164 - val_accuracy: 0.3919

Epoch 00032: val_loss did not improve from 1.57076
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4413 - accuracy: 0.4814 - val_loss: 1.6267 - val_accuracy: 0.3901

Epoch 00033: val_loss did not improve from 1.57076
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5735 - accuracy: 0.3969
Testing Loss = 1.573541, Testing Accuracy = 0.396919
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.5227 - accuracy: 0.1979 - val_loss: 8.8103 - val_accuracy: 0.2084

Epoch 00001: val_loss improved from inf to 8.81027, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8720 - accuracy: 0.2058 - val_loss: 5.4186 - val_accuracy: 0.2114

Epoch 00002: val_loss improved from 8.81027 to 5.41859, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6340 - accuracy: 0.2092 - val_loss: 4.0054 - val_accuracy: 0.2137

Epoch 00003: val_loss improved from 5.41859 to 4.00536, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.5519 - accuracy: 0.2475 - val_loss: 3.1911 - val_accuracy: 0.2857

Epoch 00004: val_loss improved from 4.00536 to 3.19106, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8956 - accuracy: 0.2921 - val_loss: 2.6931 - val_accuracy: 0.3099

Epoch 00005: val_loss improved from 3.19106 to 2.69313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5037 - accuracy: 0.3041 - val_loss: 2.3581 - val_accuracy: 0.3181

Epoch 00006: val_loss improved from 2.69313 to 2.35812, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2348 - accuracy: 0.3117 - val_loss: 2.1208 - val_accuracy: 0.3316

Epoch 00007: val_loss improved from 2.35812 to 2.12077, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0470 - accuracy: 0.3201 - val_loss: 1.9588 - val_accuracy: 0.3282

Epoch 00008: val_loss improved from 2.12077 to 1.95880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9136 - accuracy: 0.3276 - val_loss: 1.8471 - val_accuracy: 0.3324

Epoch 00009: val_loss improved from 1.95880 to 1.84705, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8195 - accuracy: 0.3388 - val_loss: 1.7741 - val_accuracy: 0.3354

Epoch 00010: val_loss improved from 1.84705 to 1.77406, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7533 - accuracy: 0.3419 - val_loss: 1.7204 - val_accuracy: 0.3411

Epoch 00011: val_loss improved from 1.77406 to 1.72039, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7043 - accuracy: 0.3470 - val_loss: 1.6794 - val_accuracy: 0.3496

Epoch 00012: val_loss improved from 1.72039 to 1.67939, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6672 - accuracy: 0.3547 - val_loss: 1.6571 - val_accuracy: 0.3592

Epoch 00013: val_loss improved from 1.67939 to 1.65707, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6379 - accuracy: 0.3638 - val_loss: 1.6243 - val_accuracy: 0.3672

Epoch 00014: val_loss improved from 1.65707 to 1.62435, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6164 - accuracy: 0.3732 - val_loss: 1.6066 - val_accuracy: 0.3724

Epoch 00015: val_loss improved from 1.62435 to 1.60660, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 16/100
83/83 [==============================] - 6s 72ms/step - loss: 1.5957 - accuracy: 0.3821 - val_loss: 1.5923 - val_accuracy: 0.3794

Epoch 00016: val_loss improved from 1.60660 to 1.59230, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5792 - accuracy: 0.3895 - val_loss: 1.5837 - val_accuracy: 0.3844

Epoch 00017: val_loss improved from 1.59230 to 1.58372, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5659 - accuracy: 0.3955 - val_loss: 1.5807 - val_accuracy: 0.3842

Epoch 00018: val_loss improved from 1.58372 to 1.58067, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5593 - accuracy: 0.3994 - val_loss: 1.5709 - val_accuracy: 0.3868

Epoch 00019: val_loss improved from 1.58067 to 1.57089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5459 - accuracy: 0.4052 - val_loss: 1.5665 - val_accuracy: 0.3936

Epoch 00020: val_loss improved from 1.57089 to 1.56652, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5405 - accuracy: 0.4093 - val_loss: 1.5659 - val_accuracy: 0.3913

Epoch 00021: val_loss improved from 1.56652 to 1.56587, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5313 - accuracy: 0.4146 - val_loss: 1.5662 - val_accuracy: 0.3885

Epoch 00022: val_loss did not improve from 1.56587
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5264 - accuracy: 0.4160 - val_loss: 1.5656 - val_accuracy: 0.3924

Epoch 00023: val_loss improved from 1.56587 to 1.56562, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5165 - accuracy: 0.4221 - val_loss: 1.5655 - val_accuracy: 0.3916

Epoch 00024: val_loss improved from 1.56562 to 1.56554, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/3
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5120 - accuracy: 0.4273 - val_loss: 1.5662 - val_accuracy: 0.3937

Epoch 00025: val_loss did not improve from 1.56554
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5024 - accuracy: 0.4349 - val_loss: 1.5700 - val_accuracy: 0.3939

Epoch 00026: val_loss did not improve from 1.56554
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4968 - accuracy: 0.4374 - val_loss: 1.5729 - val_accuracy: 0.3931

Epoch 00027: val_loss did not improve from 1.56554
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4918 - accuracy: 0.4381 - val_loss: 1.5783 - val_accuracy: 0.3941

Epoch 00028: val_loss did not improve from 1.56554
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4787 - accuracy: 0.4505 - val_loss: 1.5836 - val_accuracy: 0.3952

Epoch 00029: val_loss did not improve from 1.56554
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4755 - accuracy: 0.4502 - val_loss: 1.5840 - val_accuracy: 0.3977

Epoch 00030: val_loss did not improve from 1.56554
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4690 - accuracy: 0.4576 - val_loss: 1.5884 - val_accuracy: 0.3929

Epoch 00031: val_loss did not improve from 1.56554
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4596 - accuracy: 0.4639 - val_loss: 1.5958 - val_accuracy: 0.3959

Epoch 00032: val_loss did not improve from 1.56554
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4509 - accuracy: 0.4697 - val_loss: 1.6042 - val_accuracy: 0.3952

Epoch 00033: val_loss did not improve from 1.56554
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5683 - accuracy: 0.3957
Testing Loss = 1.568257, Testing Accuracy = 0.395653
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 69ms/step - loss: 12.4247 - accuracy: 0.1980 - val_loss: 8.6878 - val_accuracy: 0.2040

Epoch 00001: val_loss improved from inf to 8.68782, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7675 - accuracy: 0.2073 - val_loss: 5.3400 - val_accuracy: 0.2113

Epoch 00002: val_loss improved from 8.68782 to 5.34000, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5735 - accuracy: 0.2131 - val_loss: 3.9639 - val_accuracy: 0.2279

Epoch 00003: val_loss improved from 5.34000 to 3.96388, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 4/100
83/83 [==============================] - 6s 69ms/step - loss: 3.4882 - accuracy: 0.2696 - val_loss: 3.1709 - val_accuracy: 0.2876

Epoch 00004: val_loss improved from 3.96388 to 3.17087, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 2.8844 - accuracy: 0.2956 - val_loss: 2.6874 - val_accuracy: 0.3072

Epoch 00005: val_loss improved from 3.17087 to 2.68736, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5008 - accuracy: 0.3064 - val_loss: 2.3591 - val_accuracy: 0.3203

Epoch 00006: val_loss improved from 2.68736 to 2.35914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2358 - accuracy: 0.3136 - val_loss: 2.1234 - val_accuracy: 0.3269

Epoch 00007: val_loss improved from 2.35914 to 2.12342, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 8/100
83/83 [==============================] - 6s 70ms/step - loss: 2.0486 - accuracy: 0.3206 - val_loss: 1.9648 - val_accuracy: 0.3360

Epoch 00008: val_loss improved from 2.12342 to 1.96481, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9175 - accuracy: 0.3293 - val_loss: 1.8542 - val_accuracy: 0.3345

Epoch 00009: val_loss improved from 1.96481 to 1.85422, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8240 - accuracy: 0.3341 - val_loss: 1.7783 - val_accuracy: 0.3413

Epoch 00010: val_loss improved from 1.85422 to 1.77833, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7573 - accuracy: 0.3425 - val_loss: 1.7246 - val_accuracy: 0.3437

Epoch 00011: val_loss improved from 1.77833 to 1.72455, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7087 - accuracy: 0.3474 - val_loss: 1.6857 - val_accuracy: 0.3507

Epoch 00012: val_loss improved from 1.72455 to 1.68570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6704 - accuracy: 0.3572 - val_loss: 1.6574 - val_accuracy: 0.3588

Epoch 00013: val_loss improved from 1.68570 to 1.65745, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6413 - accuracy: 0.3652 - val_loss: 1.6299 - val_accuracy: 0.3601

Epoch 00014: val_loss improved from 1.65745 to 1.62993, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6205 - accuracy: 0.3707 - val_loss: 1.6123 - val_accuracy: 0.3674

Epoch 00015: val_loss improved from 1.62993 to 1.61231, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 16/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6000 - accuracy: 0.3786 - val_loss: 1.5973 - val_accuracy: 0.3764

Epoch 00016: val_loss improved from 1.61231 to 1.59730, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5841 - accuracy: 0.3864 - val_loss: 1.5866 - val_accuracy: 0.3776

Epoch 00017: val_loss improved from 1.59730 to 1.58657, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5725 - accuracy: 0.3927 - val_loss: 1.5796 - val_accuracy: 0.3816

Epoch 00018: val_loss improved from 1.58657 to 1.57956, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5597 - accuracy: 0.3978 - val_loss: 1.5752 - val_accuracy: 0.3830

Epoch 00019: val_loss improved from 1.57956 to 1.57523, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5518 - accuracy: 0.4030 - val_loss: 1.5721 - val_accuracy: 0.3877

Epoch 00020: val_loss improved from 1.57523 to 1.57207, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5408 - accuracy: 0.4093 - val_loss: 1.5723 - val_accuracy: 0.3885

Epoch 00021: val_loss did not improve from 1.57207
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5341 - accuracy: 0.4129 - val_loss: 1.5710 - val_accuracy: 0.3844

Epoch 00022: val_loss improved from 1.57207 to 1.57097, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5283 - accuracy: 0.4190 - val_loss: 1.5657 - val_accuracy: 0.3958

Epoch 00023: val_loss improved from 1.57097 to 1.56572, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5214 - accuracy: 0.4208 - val_loss: 1.5652 - val_accuracy: 0.3916

Epoch 00024: val_loss improved from 1.56572 to 1.56517, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/4
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5149 - accuracy: 0.4243 - val_loss: 1.5684 - val_accuracy: 0.3934

Epoch 00025: val_loss did not improve from 1.56517
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5073 - accuracy: 0.4288 - val_loss: 1.5684 - val_accuracy: 0.3923

Epoch 00026: val_loss did not improve from 1.56517
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5068 - accuracy: 0.4312 - val_loss: 1.5706 - val_accuracy: 0.3916

Epoch 00027: val_loss did not improve from 1.56517
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4945 - accuracy: 0.4378 - val_loss: 1.5709 - val_accuracy: 0.3959

Epoch 00028: val_loss did not improve from 1.56517
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4900 - accuracy: 0.4429 - val_loss: 1.5736 - val_accuracy: 0.3948

Epoch 00029: val_loss did not improve from 1.56517
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4792 - accuracy: 0.4478 - val_loss: 1.5812 - val_accuracy: 0.3945

Epoch 00030: val_loss did not improve from 1.56517
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4754 - accuracy: 0.4520 - val_loss: 1.5880 - val_accuracy: 0.3946

Epoch 00031: val_loss did not improve from 1.56517
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4698 - accuracy: 0.4569 - val_loss: 1.5912 - val_accuracy: 0.3943

Epoch 00032: val_loss did not improve from 1.56517
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4599 - accuracy: 0.4650 - val_loss: 1.5957 - val_accuracy: 0.3944

Epoch 00033: val_loss did not improve from 1.56517
Epoch 34/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4505 - accuracy: 0.4716 - val_loss: 1.6054 - val_accuracy: 0.3933

Epoch 00034: val_loss did not improve from 1.56517
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.5696 - accuracy: 0.3930
Testing Loss = 1.569588, Testing Accuracy = 0.392974
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4846 - accuracy: 0.1936 - val_loss: 8.7526 - val_accuracy: 0.2091

Epoch 00001: val_loss improved from inf to 8.75262, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8201 - accuracy: 0.2065 - val_loss: 5.3787 - val_accuracy: 0.2100

Epoch 00002: val_loss improved from 8.75262 to 5.37870, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6025 - accuracy: 0.2151 - val_loss: 3.9807 - val_accuracy: 0.2290

Epoch 00003: val_loss improved from 5.37870 to 3.98070, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5035 - accuracy: 0.2725 - val_loss: 3.1835 - val_accuracy: 0.2912

Epoch 00004: val_loss improved from 3.98070 to 3.18352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8964 - accuracy: 0.2932 - val_loss: 2.7014 - val_accuracy: 0.3113

Epoch 00005: val_loss improved from 3.18352 to 2.70138, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5110 - accuracy: 0.3025 - val_loss: 2.3640 - val_accuracy: 0.3183

Epoch 00006: val_loss improved from 2.70138 to 2.36398, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2423 - accuracy: 0.3108 - val_loss: 2.1302 - val_accuracy: 0.3268

Epoch 00007: val_loss improved from 2.36398 to 2.13021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0552 - accuracy: 0.3184 - val_loss: 1.9678 - val_accuracy: 0.3292

Epoch 00008: val_loss improved from 2.13021 to 1.96778, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9207 - accuracy: 0.3245 - val_loss: 1.8570 - val_accuracy: 0.3338

Epoch 00009: val_loss improved from 1.96778 to 1.85698, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8287 - accuracy: 0.3295 - val_loss: 1.7806 - val_accuracy: 0.3365

Epoch 00010: val_loss improved from 1.85698 to 1.78060, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7600 - accuracy: 0.3392 - val_loss: 1.7259 - val_accuracy: 0.3406

Epoch 00011: val_loss improved from 1.78060 to 1.72594, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7106 - accuracy: 0.3479 - val_loss: 1.6861 - val_accuracy: 0.3488

Epoch 00012: val_loss improved from 1.72594 to 1.68609, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6757 - accuracy: 0.3543 - val_loss: 1.6610 - val_accuracy: 0.3541

Epoch 00013: val_loss improved from 1.68609 to 1.66100, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6466 - accuracy: 0.3620 - val_loss: 1.6423 - val_accuracy: 0.3588

Epoch 00014: val_loss improved from 1.66100 to 1.64230, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6232 - accuracy: 0.3694 - val_loss: 1.6196 - val_accuracy: 0.3648

Epoch 00015: val_loss improved from 1.64230 to 1.61962, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6048 - accuracy: 0.3745 - val_loss: 1.6073 - val_accuracy: 0.3661

Epoch 00016: val_loss improved from 1.61962 to 1.60735, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 17/100
83/83 [==============================] - 6s 70ms/step - loss: 1.5924 - accuracy: 0.3837 - val_loss: 1.5952 - val_accuracy: 0.3759

Epoch 00017: val_loss improved from 1.60735 to 1.59516, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5780 - accuracy: 0.3909 - val_loss: 1.5878 - val_accuracy: 0.3779

Epoch 00018: val_loss improved from 1.59516 to 1.58782, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5669 - accuracy: 0.3954 - val_loss: 1.5826 - val_accuracy: 0.3805

Epoch 00019: val_loss improved from 1.58782 to 1.58258, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5553 - accuracy: 0.4004 - val_loss: 1.5764 - val_accuracy: 0.3865

Epoch 00020: val_loss improved from 1.58258 to 1.57642, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5434 - accuracy: 0.4111 - val_loss: 1.5764 - val_accuracy: 0.3867

Epoch 00021: val_loss did not improve from 1.57642
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5359 - accuracy: 0.4127 - val_loss: 1.5731 - val_accuracy: 0.3890

Epoch 00022: val_loss improved from 1.57642 to 1.57309, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/5
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5268 - accuracy: 0.4214 - val_loss: 1.5753 - val_accuracy: 0.3904

Epoch 00023: val_loss did not improve from 1.57309
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5187 - accuracy: 0.4231 - val_loss: 1.5759 - val_accuracy: 0.3904

Epoch 00024: val_loss did not improve from 1.57309
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5161 - accuracy: 0.4281 - val_loss: 1.5748 - val_accuracy: 0.3888

Epoch 00025: val_loss did not improve from 1.57309
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5087 - accuracy: 0.4331 - val_loss: 1.5854 - val_accuracy: 0.3822

Epoch 00026: val_loss did not improve from 1.57309
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5060 - accuracy: 0.4350 - val_loss: 1.5808 - val_accuracy: 0.3919

Epoch 00027: val_loss did not improve from 1.57309
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4934 - accuracy: 0.4433 - val_loss: 1.5851 - val_accuracy: 0.3869

Epoch 00028: val_loss did not improve from 1.57309
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4852 - accuracy: 0.4502 - val_loss: 1.5925 - val_accuracy: 0.3853

Epoch 00029: val_loss did not improve from 1.57309
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.4767 - accuracy: 0.4557 - val_loss: 1.5938 - val_accuracy: 0.3891

Epoch 00030: val_loss did not improve from 1.57309
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4645 - accuracy: 0.4645 - val_loss: 1.6046 - val_accuracy: 0.3870

Epoch 00031: val_loss did not improve from 1.57309
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4585 - accuracy: 0.4695 - val_loss: 1.6121 - val_accuracy: 0.3886

Epoch 00032: val_loss did not improve from 1.57309
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.5762 - accuracy: 0.3919
Testing Loss = 1.576241, Testing Accuracy = 0.391858
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4684 - accuracy: 0.1979 - val_loss: 8.7391 - val_accuracy: 0.2104

Epoch 00001: val_loss improved from inf to 8.73907, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8080 - accuracy: 0.2078 - val_loss: 5.3689 - val_accuracy: 0.2112

Epoch 00002: val_loss improved from 8.73907 to 5.36888, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5896 - accuracy: 0.2151 - val_loss: 3.9718 - val_accuracy: 0.2359

Epoch 00003: val_loss improved from 5.36888 to 3.97183, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4897 - accuracy: 0.2747 - val_loss: 3.1748 - val_accuracy: 0.2964

Epoch 00004: val_loss improved from 3.97183 to 3.17478, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8840 - accuracy: 0.2970 - val_loss: 2.6878 - val_accuracy: 0.3163

Epoch 00005: val_loss improved from 3.17478 to 2.68783, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5031 - accuracy: 0.3040 - val_loss: 2.3580 - val_accuracy: 0.3191

Epoch 00006: val_loss improved from 2.68783 to 2.35803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2381 - accuracy: 0.3138 - val_loss: 2.1244 - val_accuracy: 0.3263

Epoch 00007: val_loss improved from 2.35803 to 2.12443, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0505 - accuracy: 0.3217 - val_loss: 1.9646 - val_accuracy: 0.3288

Epoch 00008: val_loss improved from 2.12443 to 1.96460, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9180 - accuracy: 0.3273 - val_loss: 1.8549 - val_accuracy: 0.3354

Epoch 00009: val_loss improved from 1.96460 to 1.85487, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8252 - accuracy: 0.3333 - val_loss: 1.7787 - val_accuracy: 0.3388

Epoch 00010: val_loss improved from 1.85487 to 1.77874, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7585 - accuracy: 0.3401 - val_loss: 1.7252 - val_accuracy: 0.3475

Epoch 00011: val_loss improved from 1.77874 to 1.72516, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7085 - accuracy: 0.3473 - val_loss: 1.6859 - val_accuracy: 0.3514

Epoch 00012: val_loss improved from 1.72516 to 1.68588, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6751 - accuracy: 0.3547 - val_loss: 1.6575 - val_accuracy: 0.3624

Epoch 00013: val_loss improved from 1.68588 to 1.65749, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6439 - accuracy: 0.3614 - val_loss: 1.6351 - val_accuracy: 0.3665

Epoch 00014: val_loss improved from 1.65749 to 1.63509, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6210 - accuracy: 0.3711 - val_loss: 1.6155 - val_accuracy: 0.3660

Epoch 00015: val_loss improved from 1.63509 to 1.61554, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6031 - accuracy: 0.3791 - val_loss: 1.6015 - val_accuracy: 0.3713

Epoch 00016: val_loss improved from 1.61554 to 1.60146, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5885 - accuracy: 0.3843 - val_loss: 1.5921 - val_accuracy: 0.3785

Epoch 00017: val_loss improved from 1.60146 to 1.59210, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5728 - accuracy: 0.3943 - val_loss: 1.5846 - val_accuracy: 0.3848

Epoch 00018: val_loss improved from 1.59210 to 1.58463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5613 - accuracy: 0.3966 - val_loss: 1.5802 - val_accuracy: 0.3857

Epoch 00019: val_loss improved from 1.58463 to 1.58022, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5517 - accuracy: 0.4046 - val_loss: 1.5753 - val_accuracy: 0.3872

Epoch 00020: val_loss improved from 1.58022 to 1.57529, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5453 - accuracy: 0.4080 - val_loss: 1.5726 - val_accuracy: 0.3851

Epoch 00021: val_loss improved from 1.57529 to 1.57258, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5348 - accuracy: 0.4136 - val_loss: 1.5715 - val_accuracy: 0.3886

Epoch 00022: val_loss improved from 1.57258 to 1.57150, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/6
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5292 - accuracy: 0.4178 - val_loss: 1.5741 - val_accuracy: 0.3866

Epoch 00023: val_loss did not improve from 1.57150
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5208 - accuracy: 0.4259 - val_loss: 1.5728 - val_accuracy: 0.3900

Epoch 00024: val_loss did not improve from 1.57150
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5132 - accuracy: 0.4292 - val_loss: 1.5729 - val_accuracy: 0.3906

Epoch 00025: val_loss did not improve from 1.57150
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5093 - accuracy: 0.4320 - val_loss: 1.5759 - val_accuracy: 0.3906

Epoch 00026: val_loss did not improve from 1.57150
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4992 - accuracy: 0.4395 - val_loss: 1.5772 - val_accuracy: 0.3916

Epoch 00027: val_loss did not improve from 1.57150
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4893 - accuracy: 0.4467 - val_loss: 1.5805 - val_accuracy: 0.3930

Epoch 00028: val_loss did not improve from 1.57150
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4809 - accuracy: 0.4505 - val_loss: 1.5852 - val_accuracy: 0.3918

Epoch 00029: val_loss did not improve from 1.57150
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4728 - accuracy: 0.4554 - val_loss: 1.5907 - val_accuracy: 0.3943

Epoch 00030: val_loss did not improve from 1.57150
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4673 - accuracy: 0.4577 - val_loss: 1.6021 - val_accuracy: 0.3909

Epoch 00031: val_loss did not improve from 1.57150
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4550 - accuracy: 0.4713 - val_loss: 1.6102 - val_accuracy: 0.3897

Epoch 00032: val_loss did not improve from 1.57150
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5748 - accuracy: 0.3890
Testing Loss = 1.574837, Testing Accuracy = 0.388955
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.5392 - accuracy: 0.1973 - val_loss: 8.8285 - val_accuracy: 0.2101

Epoch 00001: val_loss improved from inf to 8.82846, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8828 - accuracy: 0.2021 - val_loss: 5.4226 - val_accuracy: 0.2090

Epoch 00002: val_loss improved from 8.82846 to 5.42264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.6360 - accuracy: 0.2098 - val_loss: 4.0054 - val_accuracy: 0.2113

Epoch 00003: val_loss improved from 5.42264 to 4.00537, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.6006 - accuracy: 0.2182 - val_loss: 3.2452 - val_accuracy: 0.2282

Epoch 00004: val_loss improved from 4.00537 to 3.24522, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9196 - accuracy: 0.2737 - val_loss: 2.6916 - val_accuracy: 0.3008

Epoch 00005: val_loss improved from 3.24522 to 2.69157, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5031 - accuracy: 0.2961 - val_loss: 2.3554 - val_accuracy: 0.3132

Epoch 00006: val_loss improved from 2.69157 to 2.35536, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2327 - accuracy: 0.3065 - val_loss: 2.1198 - val_accuracy: 0.3189

Epoch 00007: val_loss improved from 2.35536 to 2.11983, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0444 - accuracy: 0.3184 - val_loss: 1.9571 - val_accuracy: 0.3286

Epoch 00008: val_loss improved from 2.11983 to 1.95711, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9116 - accuracy: 0.3258 - val_loss: 1.8498 - val_accuracy: 0.3326

Epoch 00009: val_loss improved from 1.95711 to 1.84984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8205 - accuracy: 0.3287 - val_loss: 1.7718 - val_accuracy: 0.3351

Epoch 00010: val_loss improved from 1.84984 to 1.77175, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7540 - accuracy: 0.3359 - val_loss: 1.7202 - val_accuracy: 0.3403

Epoch 00011: val_loss improved from 1.77175 to 1.72016, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7071 - accuracy: 0.3430 - val_loss: 1.6828 - val_accuracy: 0.3452

Epoch 00012: val_loss improved from 1.72016 to 1.68280, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6729 - accuracy: 0.3500 - val_loss: 1.6537 - val_accuracy: 0.3523

Epoch 00013: val_loss improved from 1.68280 to 1.65370, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6478 - accuracy: 0.3556 - val_loss: 1.6343 - val_accuracy: 0.3548

Epoch 00014: val_loss improved from 1.65370 to 1.63433, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6263 - accuracy: 0.3623 - val_loss: 1.6208 - val_accuracy: 0.3641

Epoch 00015: val_loss improved from 1.63433 to 1.62083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6070 - accuracy: 0.3723 - val_loss: 1.6016 - val_accuracy: 0.3683

Epoch 00016: val_loss improved from 1.62083 to 1.60156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5929 - accuracy: 0.3778 - val_loss: 1.5877 - val_accuracy: 0.3754

Epoch 00017: val_loss improved from 1.60156 to 1.58769, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5792 - accuracy: 0.3847 - val_loss: 1.5804 - val_accuracy: 0.3822

Epoch 00018: val_loss improved from 1.58769 to 1.58042, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5668 - accuracy: 0.3900 - val_loss: 1.5740 - val_accuracy: 0.3883

Epoch 00019: val_loss improved from 1.58042 to 1.57401, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5569 - accuracy: 0.3982 - val_loss: 1.5702 - val_accuracy: 0.3870

Epoch 00020: val_loss improved from 1.57401 to 1.57019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5476 - accuracy: 0.4062 - val_loss: 1.5690 - val_accuracy: 0.3930

Epoch 00021: val_loss improved from 1.57019 to 1.56903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5405 - accuracy: 0.4077 - val_loss: 1.5651 - val_accuracy: 0.3908

Epoch 00022: val_loss improved from 1.56903 to 1.56505, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5316 - accuracy: 0.4128 - val_loss: 1.5637 - val_accuracy: 0.3913

Epoch 00023: val_loss improved from 1.56505 to 1.56375, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5273 - accuracy: 0.4150 - val_loss: 1.5637 - val_accuracy: 0.3949

Epoch 00024: val_loss improved from 1.56375 to 1.56368, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/7
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5201 - accuracy: 0.4200 - val_loss: 1.5637 - val_accuracy: 0.3972

Epoch 00025: val_loss did not improve from 1.56368
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5107 - accuracy: 0.4270 - val_loss: 1.5657 - val_accuracy: 0.3968

Epoch 00026: val_loss did not improve from 1.56368
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5064 - accuracy: 0.4314 - val_loss: 1.5654 - val_accuracy: 0.3981

Epoch 00027: val_loss did not improve from 1.56368
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4993 - accuracy: 0.4362 - val_loss: 1.5739 - val_accuracy: 0.3970

Epoch 00028: val_loss did not improve from 1.56368
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4942 - accuracy: 0.4406 - val_loss: 1.5745 - val_accuracy: 0.3974

Epoch 00029: val_loss did not improve from 1.56368
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4821 - accuracy: 0.4459 - val_loss: 1.5778 - val_accuracy: 0.4003

Epoch 00030: val_loss did not improve from 1.56368
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4781 - accuracy: 0.4519 - val_loss: 1.5807 - val_accuracy: 0.3954

Epoch 00031: val_loss did not improve from 1.56368
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4737 - accuracy: 0.4542 - val_loss: 1.5811 - val_accuracy: 0.3996

Epoch 00032: val_loss did not improve from 1.56368
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4651 - accuracy: 0.4604 - val_loss: 1.5863 - val_accuracy: 0.3995

Epoch 00033: val_loss did not improve from 1.56368
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 65s 5ms/step - loss: 1.5682 - accuracy: 0.3925
Testing Loss = 1.568187, Testing Accuracy = 0.392453
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4240 - accuracy: 0.1980 - val_loss: 8.6929 - val_accuracy: 0.2082

Epoch 00001: val_loss improved from inf to 8.69287, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.7778 - accuracy: 0.2063 - val_loss: 5.3484 - val_accuracy: 0.2100

Epoch 00002: val_loss improved from 8.69287 to 5.34839, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5782 - accuracy: 0.2128 - val_loss: 3.9642 - val_accuracy: 0.2239

Epoch 00003: val_loss improved from 5.34839 to 3.96423, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4870 - accuracy: 0.2763 - val_loss: 3.1824 - val_accuracy: 0.2813

Epoch 00004: val_loss improved from 3.96423 to 3.18237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 2.8818 - accuracy: 0.2969 - val_loss: 2.6852 - val_accuracy: 0.3092

Epoch 00005: val_loss improved from 3.18237 to 2.68517, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5000 - accuracy: 0.3054 - val_loss: 2.3565 - val_accuracy: 0.3192

Epoch 00006: val_loss improved from 2.68517 to 2.35653, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2352 - accuracy: 0.3149 - val_loss: 2.1231 - val_accuracy: 0.3258

Epoch 00007: val_loss improved from 2.35653 to 2.12308, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0481 - accuracy: 0.3215 - val_loss: 1.9622 - val_accuracy: 0.3303

Epoch 00008: val_loss improved from 2.12308 to 1.96220, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9144 - accuracy: 0.3279 - val_loss: 1.8506 - val_accuracy: 0.3351

Epoch 00009: val_loss improved from 1.96220 to 1.85056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8237 - accuracy: 0.3321 - val_loss: 1.7737 - val_accuracy: 0.3392

Epoch 00010: val_loss improved from 1.85056 to 1.77371, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7578 - accuracy: 0.3413 - val_loss: 1.7219 - val_accuracy: 0.3426

Epoch 00011: val_loss improved from 1.77371 to 1.72186, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7070 - accuracy: 0.3485 - val_loss: 1.6804 - val_accuracy: 0.3488

Epoch 00012: val_loss improved from 1.72186 to 1.68035, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6712 - accuracy: 0.3544 - val_loss: 1.6518 - val_accuracy: 0.3573

Epoch 00013: val_loss improved from 1.68035 to 1.65185, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6425 - accuracy: 0.3617 - val_loss: 1.6289 - val_accuracy: 0.3646

Epoch 00014: val_loss improved from 1.65185 to 1.62891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6190 - accuracy: 0.3739 - val_loss: 1.6096 - val_accuracy: 0.3683

Epoch 00015: val_loss improved from 1.62891 to 1.60963, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5992 - accuracy: 0.3800 - val_loss: 1.5947 - val_accuracy: 0.3752

Epoch 00016: val_loss improved from 1.60963 to 1.59473, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5850 - accuracy: 0.3857 - val_loss: 1.5823 - val_accuracy: 0.3842

Epoch 00017: val_loss improved from 1.59473 to 1.58231, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5708 - accuracy: 0.3931 - val_loss: 1.5795 - val_accuracy: 0.3848

Epoch 00018: val_loss improved from 1.58231 to 1.57946, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5582 - accuracy: 0.3988 - val_loss: 1.5711 - val_accuracy: 0.3869

Epoch 00019: val_loss improved from 1.57946 to 1.57113, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5536 - accuracy: 0.3992 - val_loss: 1.5705 - val_accuracy: 0.3904

Epoch 00020: val_loss improved from 1.57113 to 1.57046, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5397 - accuracy: 0.4095 - val_loss: 1.5670 - val_accuracy: 0.3924

Epoch 00021: val_loss improved from 1.57046 to 1.56699, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5318 - accuracy: 0.4153 - val_loss: 1.5669 - val_accuracy: 0.3934

Epoch 00022: val_loss improved from 1.56699 to 1.56688, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5250 - accuracy: 0.4212 - val_loss: 1.5643 - val_accuracy: 0.3951

Epoch 00023: val_loss improved from 1.56688 to 1.56430, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/8
Epoch 24/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5169 - accuracy: 0.4240 - val_loss: 1.5653 - val_accuracy: 0.3980

Epoch 00024: val_loss did not improve from 1.56430
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5124 - accuracy: 0.4281 - val_loss: 1.5700 - val_accuracy: 0.3927

Epoch 00025: val_loss did not improve from 1.56430
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5032 - accuracy: 0.4343 - val_loss: 1.5695 - val_accuracy: 0.3947

Epoch 00026: val_loss did not improve from 1.56430
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4971 - accuracy: 0.4353 - val_loss: 1.5727 - val_accuracy: 0.3967

Epoch 00027: val_loss did not improve from 1.56430
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4909 - accuracy: 0.4413 - val_loss: 1.5765 - val_accuracy: 0.3936

Epoch 00028: val_loss did not improve from 1.56430
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4831 - accuracy: 0.4450 - val_loss: 1.5816 - val_accuracy: 0.3937

Epoch 00029: val_loss did not improve from 1.56430
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4749 - accuracy: 0.4523 - val_loss: 1.5942 - val_accuracy: 0.3911

Epoch 00030: val_loss did not improve from 1.56430
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4833 - accuracy: 0.4517 - val_loss: 1.5860 - val_accuracy: 0.3935

Epoch 00031: val_loss did not improve from 1.56430
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4753 - accuracy: 0.4518 - val_loss: 1.5894 - val_accuracy: 0.3967

Epoch 00032: val_loss did not improve from 1.56430
Epoch 33/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4696 - accuracy: 0.4579 - val_loss: 1.5879 - val_accuracy: 0.3971

Epoch 00033: val_loss did not improve from 1.56430
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.5728 - accuracy: 0.3913
Testing Loss = 1.572784, Testing Accuracy = 0.391262
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.4848 - accuracy: 0.1962 - val_loss: 8.7848 - val_accuracy: 0.2108

Epoch 00001: val_loss improved from inf to 8.78479, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.8490 - accuracy: 0.2073 - val_loss: 5.4011 - val_accuracy: 0.2138

Epoch 00002: val_loss improved from 8.78479 to 5.40108, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5859 - accuracy: 0.2350 - val_loss: 3.9494 - val_accuracy: 0.2637

Epoch 00003: val_loss improved from 5.40108 to 3.94941, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.4906 - accuracy: 0.2892 - val_loss: 3.1908 - val_accuracy: 0.2956

Epoch 00004: val_loss improved from 3.94941 to 3.19082, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.8995 - accuracy: 0.2997 - val_loss: 2.7007 - val_accuracy: 0.3119

Epoch 00005: val_loss improved from 3.19082 to 2.70070, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5153 - accuracy: 0.3091 - val_loss: 2.3720 - val_accuracy: 0.3176

Epoch 00006: val_loss improved from 2.70070 to 2.37202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.2461 - accuracy: 0.3173 - val_loss: 2.1359 - val_accuracy: 0.3262

Epoch 00007: val_loss improved from 2.37202 to 2.13585, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.0581 - accuracy: 0.3236 - val_loss: 1.9720 - val_accuracy: 0.3325

Epoch 00008: val_loss improved from 2.13585 to 1.97203, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9259 - accuracy: 0.3293 - val_loss: 1.8618 - val_accuracy: 0.3380

Epoch 00009: val_loss improved from 1.97203 to 1.86175, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8301 - accuracy: 0.3397 - val_loss: 1.7826 - val_accuracy: 0.3398

Epoch 00010: val_loss improved from 1.86175 to 1.78264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7620 - accuracy: 0.3420 - val_loss: 1.7273 - val_accuracy: 0.3461

Epoch 00011: val_loss improved from 1.78264 to 1.72734, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7108 - accuracy: 0.3500 - val_loss: 1.6889 - val_accuracy: 0.3468

Epoch 00012: val_loss improved from 1.72734 to 1.68892, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6752 - accuracy: 0.3564 - val_loss: 1.6668 - val_accuracy: 0.3569

Epoch 00013: val_loss improved from 1.68892 to 1.66684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6447 - accuracy: 0.3659 - val_loss: 1.6372 - val_accuracy: 0.3678

Epoch 00014: val_loss improved from 1.66684 to 1.63724, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6207 - accuracy: 0.3718 - val_loss: 1.6168 - val_accuracy: 0.3693

Epoch 00015: val_loss improved from 1.63724 to 1.61677, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6022 - accuracy: 0.3823 - val_loss: 1.6039 - val_accuracy: 0.3712

Epoch 00016: val_loss improved from 1.61677 to 1.60393, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5862 - accuracy: 0.3902 - val_loss: 1.5951 - val_accuracy: 0.3799

Epoch 00017: val_loss improved from 1.60393 to 1.59513, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5739 - accuracy: 0.3938 - val_loss: 1.5871 - val_accuracy: 0.3774

Epoch 00018: val_loss improved from 1.59513 to 1.58710, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5632 - accuracy: 0.3977 - val_loss: 1.5816 - val_accuracy: 0.3826

Epoch 00019: val_loss improved from 1.58710 to 1.58156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5536 - accuracy: 0.4034 - val_loss: 1.5775 - val_accuracy: 0.3853

Epoch 00020: val_loss improved from 1.58156 to 1.57746, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5481 - accuracy: 0.4044 - val_loss: 1.5766 - val_accuracy: 0.3842

Epoch 00021: val_loss improved from 1.57746 to 1.57661, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5361 - accuracy: 0.4135 - val_loss: 1.5737 - val_accuracy: 0.3863

Epoch 00022: val_loss improved from 1.57661 to 1.57365, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15/Try/9
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5248 - accuracy: 0.4208 - val_loss: 1.5822 - val_accuracy: 0.3846

Epoch 00023: val_loss did not improve from 1.57365
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5224 - accuracy: 0.4222 - val_loss: 1.5771 - val_accuracy: 0.3880

Epoch 00024: val_loss did not improve from 1.57365
Epoch 25/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5126 - accuracy: 0.4294 - val_loss: 1.5826 - val_accuracy: 0.3871

Epoch 00025: val_loss did not improve from 1.57365
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.5026 - accuracy: 0.4375 - val_loss: 1.5802 - val_accuracy: 0.3901

Epoch 00026: val_loss did not improve from 1.57365
Epoch 27/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4965 - accuracy: 0.4415 - val_loss: 1.5868 - val_accuracy: 0.3889

Epoch 00027: val_loss did not improve from 1.57365
Epoch 28/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4897 - accuracy: 0.4459 - val_loss: 1.5909 - val_accuracy: 0.3903

Epoch 00028: val_loss did not improve from 1.57365
Epoch 29/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4803 - accuracy: 0.4539 - val_loss: 1.5996 - val_accuracy: 0.3889

Epoch 00029: val_loss did not improve from 1.57365
Epoch 30/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4707 - accuracy: 0.4613 - val_loss: 1.6106 - val_accuracy: 0.3892

Epoch 00030: val_loss did not improve from 1.57365
Epoch 31/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4638 - accuracy: 0.4648 - val_loss: 1.6165 - val_accuracy: 0.3916

Epoch 00031: val_loss did not improve from 1.57365
Epoch 32/100
83/83 [==============================] - 6s 68ms/step - loss: 1.4537 - accuracy: 0.4716 - val_loss: 1.6326 - val_accuracy: 0.3857

Epoch 00032: val_loss did not improve from 1.57365
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 64s 5ms/step - loss: 1.5771 - accuracy: 0.3956
Testing Loss = 1.577116, Testing Accuracy = 0.395579
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 84.25 +- 0.0646 %)
$W^-/W^-$ (auc = 83.48 +- 0.1145 %)
$Z/Z$ (auc = 76.17 +- 0.3279 %)
$W^+/W^-$ (auc = 70.66 +- 0.2382 %)
$W^+/Z$$ (auc = 67.43 +- 0.1203 %)
$W^-/Z$ (auc = 68.96 +- 0.1042 %)
The summarized testing accuracy = 39.30 +- 0.2347 %, with the loss = 1.5730 +- 0.003325
