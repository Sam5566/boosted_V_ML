

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-12-19 12:19:14.184332
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
 - accuracy: 0.1990     82/Unknown - 201s 2s/step - loss: 12.4715 - accuracy: 0.1987
Epoch 1: val_loss improved from inf to 8.77115, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 227s 3s/step - loss: 12.4715 - accuracy: 0.1987 - val_loss: 8.7712 - val_accuracy: 0.2089
Epoch 2/100
82/82 [==============================] - ETA: 0s - loss: 6.8307 - accuracy: 0.2087
Epoch 2: val_loss improved from 8.77115 to 5.38901, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 211s 3s/step - loss: 6.8307 - accuracy: 0.2087 - val_loss: 5.3890 - val_accuracy: 0.2133
Epoch 3/100
82/82 [==============================] - ETA: 0s - loss: 4.6101 - accuracy: 0.2132
Epoch 3: val_loss improved from 5.38901 to 3.99478, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 215s 3s/step - loss: 4.6101 - accuracy: 0.2132 - val_loss: 3.9948 - val_accuracy: 0.2160
Epoch 4/100
82/82 [==============================] - ETA: 0s - loss: 3.5268 - accuracy: 0.2612
Epoch 4: val_loss improved from 3.99478 to 3.20638, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 126s 2s/step - loss: 3.5268 - accuracy: 0.2612 - val_loss: 3.2064 - val_accuracy: 0.2654
Epoch 5/100
82/82 [==============================] - ETA: 0s - loss: 2.9006 - accuracy: 0.2961
Epoch 5: val_loss improved from 3.20638 to 2.73493, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 110s 1s/step - loss: 2.9006 - accuracy: 0.2961 - val_loss: 2.7349 - val_accuracy: 0.2851
Epoch 6/100
82/82 [==============================] - ETA: 0s - loss: 2.5131 - accuracy: 0.3065
Epoch 6: val_loss improved from 2.73493 to 2.39443, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 111s 1s/step - loss: 2.5131 - accuracy: 0.3065 - val_loss: 2.3944 - val_accuracy: 0.3017
Epoch 7/100
82/82 [==============================] - ETA: 0s - loss: 2.2464 - accuracy: 0.3144
Epoch 7: val_loss improved from 2.39443 to 2.15544, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 109s 1s/step - loss: 2.2464 - accuracy: 0.3144 - val_loss: 2.1554 - val_accuracy: 0.3102
Epoch 8/100
82/82 [==============================] - ETA: 0s - loss: 2.0570 - accuracy: 0.3209
Epoch 8: val_loss improved from 2.15544 to 1.97782, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 110s 1s/step - loss: 2.0570 - accuracy: 0.3209 - val_loss: 1.9778 - val_accuracy: 0.3245
Epoch 9/100
82/82 [==============================] - ETA: 0s - loss: 1.9233 - accuracy: 0.3268
Epoch 9: val_loss improved from 1.97782 to 1.87268, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 111s 1s/step - loss: 1.9233 - accuracy: 0.3268 - val_loss: 1.8727 - val_accuracy: 0.3270
Epoch 10/100
82/82 [==============================] - ETA: 0s - loss: 1.8283 - accuracy: 0.3338
Epoch 10: val_loss improved from 1.87268 to 1.79992, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 108s 1s/step - loss: 1.8283 - accuracy: 0.3338 - val_loss: 1.7999 - val_accuracy: 0.3283
Epoch 11/100
82/82 [==============================] - ETA: 0s - loss: 1.7583 - accuracy: 0.3425
Epoch 11: val_loss improved from 1.79992 to 1.73737, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 106s 1s/step - loss: 1.7583 - accuracy: 0.3425 - val_loss: 1.7374 - val_accuracy: 0.3383
Epoch 12/100
82/82 [==============================] - ETA: 0s - loss: 1.7094 - accuracy: 0.3496
Epoch 12: val_loss improved from 1.73737 to 1.69668, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 101s 1s/step - loss: 1.7094 - accuracy: 0.3496 - val_loss: 1.6967 - val_accuracy: 0.3446
Epoch 13/100
82/82 [==============================] - ETA: 0s - loss: 1.6699 - accuracy: 0.3580
Epoch 13: val_loss improved from 1.69668 to 1.66885, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 101s 1s/step - loss: 1.6699 - accuracy: 0.3580 - val_loss: 1.6689 - val_accuracy: 0.3507
Epoch 14/100
82/82 [==============================] - ETA: 0s - loss: 1.6436 - accuracy: 0.3619
Epoch 14: val_loss improved from 1.66885 to 1.64505, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 100s 1s/step - loss: 1.6436 - accuracy: 0.3619 - val_loss: 1.6450 - val_accuracy: 0.3559
Epoch 15/100
82/82 [==============================] - ETA: 0s - loss: 1.6178 - accuracy: 0.3708
Epoch 15: val_loss improved from 1.64505 to 1.61440, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 100s 1s/step - loss: 1.6178 - accuracy: 0.3708 - val_loss: 1.6144 - val_accuracy: 0.3695
Epoch 16/100
82/82 [==============================] - ETA: 0s - loss: 1.5937 - accuracy: 0.3809
Epoch 16: val_loss improved from 1.61440 to 1.60820, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 99s 1s/step - loss: 1.5937 - accuracy: 0.3809 - val_loss: 1.6082 - val_accuracy: 0.3758
Epoch 17/100
82/82 [==============================] - ETA: 0s - loss: 1.5793 - accuracy: 0.3895
Epoch 17: val_loss improved from 1.60820 to 1.59283, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 98s 1s/step - loss: 1.5793 - accuracy: 0.3895 - val_loss: 1.5928 - val_accuracy: 0.3829
Epoch 18/100
82/82 [==============================] - ETA: 0s - loss: 1.5671 - accuracy: 0.3957
Epoch 18: val_loss improved from 1.59283 to 1.58253, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 99s 1s/step - loss: 1.5671 - accuracy: 0.3957 - val_loss: 1.5825 - val_accuracy: 0.3873
Epoch 19/100
82/82 [==============================] - ETA: 0s - loss: 1.5573 - accuracy: 0.3987
Epoch 19: val_loss improved from 1.58253 to 1.57858, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 98s 1s/step - loss: 1.5573 - accuracy: 0.3987 - val_loss: 1.5786 - val_accuracy: 0.3866
Epoch 20/100
82/82 [==============================] - ETA: 0s - loss: 1.5481 - accuracy: 0.4028
Epoch 20: val_loss improved from 1.57858 to 1.57530, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 97s 1s/step - loss: 1.5481 - accuracy: 0.4028 - val_loss: 1.5753 - val_accuracy: 0.3905
Epoch 21/100
82/82 [==============================] - ETA: 0s - loss: 1.5360 - accuracy: 0.4078
Epoch 21: val_loss did not improve from 1.57530
82/82 [==============================] - 93s 1s/step - loss: 1.5360 - accuracy: 0.4078 - val_loss: 1.5767 - val_accuracy: 0.3908
Epoch 22/100
82/82 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.4131
Epoch 22: val_loss improved from 1.57530 to 1.56429, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 129s 2s/step - loss: 1.5289 - accuracy: 0.4131 - val_loss: 1.5643 - val_accuracy: 0.3929
Epoch 23/100
82/82 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 0.4187
Epoch 23: val_loss did not improve from 1.56429
82/82 [==============================] - 135s 2s/step - loss: 1.5236 - accuracy: 0.4187 - val_loss: 1.5708 - val_accuracy: 0.3903
Epoch 24/100
82/82 [==============================] - ETA: 0s - loss: 1.5147 - accuracy: 0.4228
Epoch 24: val_loss did not improve from 1.56429
82/82 [==============================] - 94s 1s/step - loss: 1.5147 - accuracy: 0.4228 - val_loss: 1.5711 - val_accuracy: 0.3954
Epoch 25/100
82/82 [==============================] - ETA: 0s - loss: 1.5092 - accuracy: 0.4255
Epoch 25: val_loss did not improve from 1.56429
82/82 [==============================] - 93s 1s/step - loss: 1.5092 - accuracy: 0.4255 - val_loss: 1.5673 - val_accuracy: 0.3975
Epoch 26/100
82/82 [==============================] - ETA: 0s - loss: 1.5029 - accuracy: 0.4300
Epoch 26: val_loss improved from 1.56429 to 1.56352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/0
82/82 [==============================] - 95s 1s/step - loss: 1.5029 - accuracy: 0.4300 - val_loss: 1.5635 - val_accuracy: 0.3968
Epoch 27/100
82/82 [==============================] - ETA: 0s - loss: 1.4972 - accuracy: 0.4335
Epoch 27: val_loss did not improve from 1.56352
82/82 [==============================] - 93s 1s/step - loss: 1.4972 - accuracy: 0.4335 - val_loss: 1.5661 - val_accuracy: 0.3971
Epoch 28/100
82/82 [==============================] - ETA: 0s - loss: 1.4934 - accuracy: 0.4384
Epoch 28: val_loss did not improve from 1.56352
82/82 [==============================] - 95s 1s/step - loss: 1.4934 - accuracy: 0.4384 - val_loss: 1.5715 - val_accuracy: 0.3950
Epoch 29/100
82/82 [==============================] - ETA: 0s - loss: 1.4823 - accuracy: 0.4441
Epoch 29: val_loss did not improve from 1.56352
82/82 [==============================] - 92s 1s/step - loss: 1.4823 - accuracy: 0.4441 - val_loss: 1.5794 - val_accuracy: 0.3945
Epoch 30/100
82/82 [==============================] - ETA: 0s - loss: 1.4815 - accuracy: 0.4455
Epoch 30: val_loss did not improve from 1.56352
82/82 [==============================] - 94s 1s/step - loss: 1.4815 - accuracy: 0.4455 - val_loss: 1.5756 - val_accuracy: 0.3970
Epoch 31/100
82/82 [==============================] - ETA: 0s - loss: 1.4715 - accuracy: 0.4518
Epoch 31: val_loss did not improve from 1.56352
82/82 [==============================] - 94s 1s/step - loss: 1.4715 - accuracy: 0.4518 - val_loss: 1.5842 - val_accuracy: 0.3950
Epoch 32/100
82/82 [==============================] - ETA: 0s - loss: 1.4646 - accuracy: 0.4594
Epoch 32: val_loss did not improve from 1.56352
82/82 [==============================] - 93s 1s/step - loss: 1.4646 - accuracy: 0.4594 - val_loss: 1.5824 - val_accuracy: 0.4007
Epoch 33/100
82/82 [==============================] - ETA: 0s - loss: 1.4588 - accuracy: 0.4637
Epoch 33: val_loss did not improve from 1.56352
82/82 [==============================] - 94s 1s/step - loss: 1.4588 - accuracy: 0.4637 - val_loss: 1.5924 - val_accuracy: 0.3995
Epoch 34/100
82/82 [==============================] - ETA: 0s - loss: 1.4552 - accuracy: 0.4670
Epoch 34: val_loss did not improve from 1.56352
82/82 [==============================] - 93s 1s/step - loss: 1.4552 - accuracy: 0.4670 - val_loss: 1.5990 - val_accuracy: 0.3979
Epoch 35/100
82/82 [==============================] - ETA: 0s - loss: 1.4453 - accuracy: 0.4719
Epoch 35: val_loss did not improve from 1.56352
82/82 [==============================] - 94s 1s/step - loss: 1.4453 - accuracy: 0.4719 - val_loss: 1.6056 - val_accuracy: 0.3969
Epoch 36/100
82/82 [==============================] - ETA: 0s - loss: 1.4385 - accuracy: 0.4789
Epoch 36: val_loss did not improve from 1.56352
82/82 [==============================] - 93s 1s/step - loss: 1.4385 - accuracy: 0.4789 - val_loss: 1.6066 - val_accuracy: 0.4023
Epoch 36: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential (Sequential)     (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_2 (Dense)             multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda (Lambda)             (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization (BatchN  (None, 75, 75, 2)        8         [0m
[94m ormalization)                                                   [0m
[94m                                                                 [0m
[94m conv2d (Conv2D)             (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d (MaxPooling2D  (None, 37, 37, 32)       0         [0m
[94m )                                                               [0m
[94m                                                                 [0m
[94m conv2d_1 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_1 (MaxPooling  (None, 18, 18, 128)      0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_2 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_2 (MaxPooling  (None, 9, 9, 256)        0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m dropout (Dropout)           (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten (Flatten)           (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense (Dense)               (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_1 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_1 (Dense)             (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_2 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 128s 10ms/step - loss: 1.5694 - accuracy: 0.3993
Testing Loss = 1.569444, Testing Accuracy = 0.399319
The data set contains images
  13214/Unknown - 120s 9ms/step13216/13216 [==============================] - 120s 9ms/step
[[0.05941106751561165, 0.0655815601348877, 0.33279770612716675, 0.09483043104410172, 0.2200661450624466, 0.2273131161928177], [0.10327955335378647, 0.12580522894859314, 0.0736398845911026, 0.3854910135269165, 0.15257030725479126, 0.15921403467655182], [0.06282547861337662, 0.24261566996574402, 0.15734107792377472, 0.13553883135318756, 0.14271432161331177, 0.2589646875858307], [0.2791697382926941, 0.020729323849081993, 0.1646367609500885, 0.13934920728206635, 0.3098330497741699, 0.08628195524215698], [0.35545068979263306, 0.01525350846350193, 0.19271168112754822, 0.06494615972042084, 0.3063727915287018, 0.06526512652635574], [0.029763251543045044, 0.2751249372959137, 0.20671677589416504, 0.08997918665409088, 0.09690456837415695, 0.3015111982822418], [0.4003986120223999, 0.01607423834502697, 0.13386301696300507, 0.08678077161312103, 0.3013384938240051, 0.06154480203986168], [0.010750201530754566, 0.6659005880355835, 0.03070181794464588, 0.08504171669483185, 0.024660607799887657, 0.1829451322555542], [0.4738362729549408, 0.04678234085440636, 0.06010981276631355, 0.17468257248401642, 0.1787143051624298, 0.0658746212720871], [0.3536245822906494, 0.04227333143353462, 0.06639520823955536, 0.2458188533782959, 0.21237342059612274, 0.0795145332813263]]
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
74 - accuracy: 0.1978     82/Unknown - 90s 1s/step - loss: 12.4424 - accuracy: 0.1978
Epoch 1: val_loss improved from inf to 8.71944, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 99s 1s/step - loss: 12.4424 - accuracy: 0.1978 - val_loss: 8.7194 - val_accuracy: 0.2109
Epoch 2/100
82/82 [==============================] - ETA: 0s - loss: 6.7851 - accuracy: 0.2070
Epoch 2: val_loss improved from 8.71944 to 5.35608, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 100s 1s/step - loss: 6.7851 - accuracy: 0.2070 - val_loss: 5.3561 - val_accuracy: 0.2121
Epoch 3/100
82/82 [==============================] - ETA: 0s - loss: 4.5410 - accuracy: 0.2469
Epoch 3: val_loss improved from 5.35608 to 3.95644, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 101s 1s/step - loss: 4.5410 - accuracy: 0.2469 - val_loss: 3.9564 - val_accuracy: 0.2366
Epoch 4/100
82/82 [==============================] - ETA: 0s - loss: 3.4869 - accuracy: 0.2886
Epoch 4: val_loss improved from 3.95644 to 3.23682, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 102s 1s/step - loss: 3.4869 - accuracy: 0.2886 - val_loss: 3.2368 - val_accuracy: 0.2633
Epoch 5/100
82/82 [==============================] - ETA: 0s - loss: 2.9060 - accuracy: 0.3028
Epoch 5: val_loss improved from 3.23682 to 2.74718, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 98s 1s/step - loss: 2.9060 - accuracy: 0.3028 - val_loss: 2.7472 - val_accuracy: 0.2838
Epoch 6/100
82/82 [==============================] - ETA: 0s - loss: 2.5223 - accuracy: 0.3102
Epoch 6: val_loss improved from 2.74718 to 2.40284, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 98s 1s/step - loss: 2.5223 - accuracy: 0.3102 - val_loss: 2.4028 - val_accuracy: 0.3060
Epoch 7/100
82/82 [==============================] - ETA: 0s - loss: 2.2568 - accuracy: 0.3158
Epoch 7: val_loss improved from 2.40284 to 2.15767, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 98s 1s/step - loss: 2.2568 - accuracy: 0.3158 - val_loss: 2.1577 - val_accuracy: 0.3225
Epoch 8/100
82/82 [==============================] - ETA: 0s - loss: 2.0664 - accuracy: 0.3235
Epoch 8: val_loss improved from 2.15767 to 1.98719, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 97s 1s/step - loss: 2.0664 - accuracy: 0.3235 - val_loss: 1.9872 - val_accuracy: 0.3300
Epoch 9/100
82/82 [==============================] - ETA: 0s - loss: 1.9316 - accuracy: 0.3325
Epoch 9: val_loss improved from 1.98719 to 1.87664, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 99s 1s/step - loss: 1.9316 - accuracy: 0.3325 - val_loss: 1.8766 - val_accuracy: 0.3371
Epoch 10/100
82/82 [==============================] - ETA: 0s - loss: 1.8332 - accuracy: 0.3359
Epoch 10: val_loss improved from 1.87664 to 1.80333, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 152s 2s/step - loss: 1.8332 - accuracy: 0.3359 - val_loss: 1.8033 - val_accuracy: 0.3303
Epoch 11/100
82/82 [==============================] - ETA: 0s - loss: 1.7624 - accuracy: 0.3465
Epoch 11: val_loss improved from 1.80333 to 1.73672, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 210s 3s/step - loss: 1.7624 - accuracy: 0.3465 - val_loss: 1.7367 - val_accuracy: 0.3465
Epoch 12/100
82/82 [==============================] - ETA: 0s - loss: 1.7114 - accuracy: 0.3517
Epoch 12: val_loss improved from 1.73672 to 1.69643, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 208s 3s/step - loss: 1.7114 - accuracy: 0.3517 - val_loss: 1.6964 - val_accuracy: 0.3479
Epoch 13/100
82/82 [==============================] - ETA: 0s - loss: 1.6711 - accuracy: 0.3601
Epoch 13: val_loss improved from 1.69643 to 1.66779, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 208s 3s/step - loss: 1.6711 - accuracy: 0.3601 - val_loss: 1.6678 - val_accuracy: 0.3552
Epoch 14/100
82/82 [==============================] - ETA: 0s - loss: 1.6396 - accuracy: 0.3669
Epoch 14: val_loss improved from 1.66779 to 1.63240, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 213s 3s/step - loss: 1.6396 - accuracy: 0.3669 - val_loss: 1.6324 - val_accuracy: 0.3703
Epoch 15/100
82/82 [==============================] - ETA: 0s - loss: 1.6116 - accuracy: 0.3818
Epoch 15: val_loss improved from 1.63240 to 1.62149, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 208s 3s/step - loss: 1.6116 - accuracy: 0.3818 - val_loss: 1.6215 - val_accuracy: 0.3745
Epoch 16/100
82/82 [==============================] - ETA: 0s - loss: 1.5930 - accuracy: 0.3837
Epoch 16: val_loss improved from 1.62149 to 1.60139, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 210s 3s/step - loss: 1.5930 - accuracy: 0.3837 - val_loss: 1.6014 - val_accuracy: 0.3811
Epoch 17/100
82/82 [==============================] - ETA: 0s - loss: 1.5754 - accuracy: 0.3932
Epoch 17: val_loss improved from 1.60139 to 1.59650, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 211s 3s/step - loss: 1.5754 - accuracy: 0.3932 - val_loss: 1.5965 - val_accuracy: 0.3801
Epoch 18/100
82/82 [==============================] - ETA: 0s - loss: 1.5640 - accuracy: 0.3973
Epoch 18: val_loss improved from 1.59650 to 1.58069, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 210s 3s/step - loss: 1.5640 - accuracy: 0.3973 - val_loss: 1.5807 - val_accuracy: 0.3897
Epoch 19/100
82/82 [==============================] - ETA: 0s - loss: 1.5504 - accuracy: 0.4044
Epoch 19: val_loss did not improve from 1.58069
82/82 [==============================] - 207s 3s/step - loss: 1.5504 - accuracy: 0.4044 - val_loss: 1.5817 - val_accuracy: 0.3907
Epoch 20/100
82/82 [==============================] - ETA: 0s - loss: 1.5417 - accuracy: 0.4086
Epoch 20: val_loss improved from 1.58069 to 1.57381, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 215s 3s/step - loss: 1.5417 - accuracy: 0.4086 - val_loss: 1.5738 - val_accuracy: 0.3952
Epoch 21/100
82/82 [==============================] - ETA: 0s - loss: 1.5330 - accuracy: 0.4135
Epoch 21: val_loss did not improve from 1.57381
82/82 [==============================] - 206s 3s/step - loss: 1.5330 - accuracy: 0.4135 - val_loss: 1.5756 - val_accuracy: 0.3911
Epoch 22/100
82/82 [==============================] - ETA: 0s - loss: 1.5239 - accuracy: 0.4199
Epoch 22: val_loss improved from 1.57381 to 1.57037, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 144s 2s/step - loss: 1.5239 - accuracy: 0.4199 - val_loss: 1.5704 - val_accuracy: 0.3935
Epoch 23/100
82/82 [==============================] - ETA: 0s - loss: 1.5177 - accuracy: 0.4264
Epoch 23: val_loss did not improve from 1.57037
82/82 [==============================] - 99s 1s/step - loss: 1.5177 - accuracy: 0.4264 - val_loss: 1.5746 - val_accuracy: 0.3928
Epoch 24/100
82/82 [==============================] - ETA: 0s - loss: 1.5142 - accuracy: 0.4258
Epoch 24: val_loss improved from 1.57037 to 1.56962, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/1
82/82 [==============================] - 99s 1s/step - loss: 1.5142 - accuracy: 0.4258 - val_loss: 1.5696 - val_accuracy: 0.3965
Epoch 25/100
82/82 [==============================] - ETA: 0s - loss: 1.5044 - accuracy: 0.4306
Epoch 25: val_loss did not improve from 1.56962
82/82 [==============================] - 97s 1s/step - loss: 1.5044 - accuracy: 0.4306 - val_loss: 1.5721 - val_accuracy: 0.3978
Epoch 26/100
82/82 [==============================] - ETA: 0s - loss: 1.4970 - accuracy: 0.4349
Epoch 26: val_loss did not improve from 1.56962
82/82 [==============================] - 96s 1s/step - loss: 1.4970 - accuracy: 0.4349 - val_loss: 1.5714 - val_accuracy: 0.3957
Epoch 27/100
82/82 [==============================] - ETA: 0s - loss: 1.4915 - accuracy: 0.4383
Epoch 27: val_loss did not improve from 1.56962
82/82 [==============================] - 96s 1s/step - loss: 1.4915 - accuracy: 0.4383 - val_loss: 1.5769 - val_accuracy: 0.3971
Epoch 28/100
82/82 [==============================] - ETA: 0s - loss: 1.4868 - accuracy: 0.4432
Epoch 28: val_loss did not improve from 1.56962
82/82 [==============================] - 96s 1s/step - loss: 1.4868 - accuracy: 0.4432 - val_loss: 1.5847 - val_accuracy: 0.3951
Epoch 29/100
82/82 [==============================] - ETA: 0s - loss: 1.4819 - accuracy: 0.4491
Epoch 29: val_loss did not improve from 1.56962
82/82 [==============================] - 95s 1s/step - loss: 1.4819 - accuracy: 0.4491 - val_loss: 1.5842 - val_accuracy: 0.3939
Epoch 30/100
82/82 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.4512
Epoch 30: val_loss did not improve from 1.56962
82/82 [==============================] - 96s 1s/step - loss: 1.4750 - accuracy: 0.4512 - val_loss: 1.5960 - val_accuracy: 0.3913
Epoch 31/100
82/82 [==============================] - ETA: 0s - loss: 1.4694 - accuracy: 0.4547
Epoch 31: val_loss did not improve from 1.56962
82/82 [==============================] - 96s 1s/step - loss: 1.4694 - accuracy: 0.4547 - val_loss: 1.5971 - val_accuracy: 0.3930
Epoch 32/100
82/82 [==============================] - ETA: 0s - loss: 1.4629 - accuracy: 0.4611
Epoch 32: val_loss did not improve from 1.56962
82/82 [==============================] - 95s 1s/step - loss: 1.4629 - accuracy: 0.4611 - val_loss: 1.6035 - val_accuracy: 0.3932
Epoch 33/100
82/82 [==============================] - ETA: 0s - loss: 1.4691 - accuracy: 0.4577
Epoch 33: val_loss did not improve from 1.56962
82/82 [==============================] - 97s 1s/step - loss: 1.4691 - accuracy: 0.4577 - val_loss: 1.6215 - val_accuracy: 0.3825
Epoch 34/100
82/82 [==============================] - ETA: 0s - loss: 1.4478 - accuracy: 0.4729
Epoch 34: val_loss did not improve from 1.56962
82/82 [==============================] - 97s 1s/step - loss: 1.4478 - accuracy: 0.4729 - val_loss: 1.6052 - val_accuracy: 0.3945
Epoch 34: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_1 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_5 (Dense)             multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_1 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_1 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_3 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_3 (MaxPooling  (None, 37, 37, 32)       0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_4 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_4 (MaxPooling  (None, 18, 18, 128)      0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_5 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_5 (MaxPooling  (None, 9, 9, 256)        0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m dropout_3 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_1 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_3 (Dense)             (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_4 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_4 (Dense)             (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_5 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 133s 10ms/step - loss: 1.5737 - accuracy: 0.3974
Testing Loss = 1.573683, Testing Accuracy = 0.397352
The data set contains images
  13211/Unknown - 122s 9ms/step13216/13216 [==============================] - 122s 9ms/step
[[0.08189507573843002, 0.05911654606461525, 0.3399430811405182, 0.08565499633550644, 0.2359541356563568, 0.19743624329566956], [0.12462588399648666, 0.1050826907157898, 0.07078548520803452, 0.3862149119377136, 0.16352275013923645, 0.14976836740970612], [0.06406925618648529, 0.17580682039260864, 0.22238729894161224, 0.109736867249012, 0.15438556671142578, 0.2736142575740814], [0.3307080566883087, 0.03576229512691498, 0.0913587212562561, 0.21213744580745697, 0.24139516055583954, 0.0886383131146431], [0.4396625757217407, 0.015255517326295376, 0.1416938602924347, 0.06379768997430801, 0.28739216923713684, 0.0521981418132782], [0.033433590084314346, 0.22102852165699005, 0.2451896369457245, 0.08621573448181152, 0.1066926121711731, 0.3074398934841156], [0.335909903049469, 0.014200001955032349, 0.17353670299053192, 0.07521528005599976, 0.3351626396179199, 0.06597546488046646], [0.011355428956449032, 0.6743434071540833, 0.030153216794133186, 0.08858847618103027, 0.022966094315052032, 0.17259331047534943], [0.41545215249061584, 0.06492702662944794, 0.07064332067966461, 0.18384911119937897, 0.18233326077461243, 0.08279507607221603], [0.416830837726593, 0.03642119839787483, 0.04896138608455658, 0.24473688006401062, 0.18642480671405792, 0.06662489473819733]]
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
61 - accuracy: 0.1974     82/Unknown - 90s 1s/step - loss: 12.5214 - accuracy: 0.1974
Epoch 1: val_loss improved from inf to 8.83161, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 98s 1s/step - loss: 12.5214 - accuracy: 0.1974 - val_loss: 8.8316 - val_accuracy: 0.2106
Epoch 2/100
82/82 [==============================] - ETA: 0s - loss: 6.8855 - accuracy: 0.2060
Epoch 2: val_loss improved from 8.83161 to 5.43495, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 97s 1s/step - loss: 6.8855 - accuracy: 0.2060 - val_loss: 5.4349 - val_accuracy: 0.2105
Epoch 3/100
82/82 [==============================] - ETA: 0s - loss: 4.6243 - accuracy: 0.2263
Epoch 3: val_loss improved from 5.43495 to 3.99330, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 96s 1s/step - loss: 4.6243 - accuracy: 0.2263 - val_loss: 3.9933 - val_accuracy: 0.2448
Epoch 4/100
82/82 [==============================] - ETA: 0s - loss: 3.5070 - accuracy: 0.2853
Epoch 4: val_loss improved from 3.99330 to 3.22915, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 96s 1s/step - loss: 3.5070 - accuracy: 0.2853 - val_loss: 3.2291 - val_accuracy: 0.2663
Epoch 5/100
82/82 [==============================] - ETA: 0s - loss: 2.9127 - accuracy: 0.3007
Epoch 5: val_loss improved from 3.22915 to 2.74705, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 96s 1s/step - loss: 2.9127 - accuracy: 0.3007 - val_loss: 2.7471 - val_accuracy: 0.2816
Epoch 6/100
82/82 [==============================] - ETA: 0s - loss: 2.5241 - accuracy: 0.3067
Epoch 6: val_loss improved from 2.74705 to 2.40276, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 96s 1s/step - loss: 2.5241 - accuracy: 0.3067 - val_loss: 2.4028 - val_accuracy: 0.2981
Epoch 7/100
82/82 [==============================] - ETA: 0s - loss: 2.2544 - accuracy: 0.3141
Epoch 7: val_loss improved from 2.40276 to 2.15823, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 95s 1s/step - loss: 2.2544 - accuracy: 0.3141 - val_loss: 2.1582 - val_accuracy: 0.3131
Epoch 8/100
82/82 [==============================] - ETA: 0s - loss: 2.0645 - accuracy: 0.3215
Epoch 8: val_loss improved from 2.15823 to 1.98638, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 96s 1s/step - loss: 2.0645 - accuracy: 0.3215 - val_loss: 1.9864 - val_accuracy: 0.3275
Epoch 9/100
82/82 [==============================] - ETA: 0s - loss: 1.9308 - accuracy: 0.3233
Epoch 9: val_loss improved from 1.98638 to 1.87298, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 95s 1s/step - loss: 1.9308 - accuracy: 0.3233 - val_loss: 1.8730 - val_accuracy: 0.3321
Epoch 10/100
82/82 [==============================] - ETA: 0s - loss: 1.8325 - accuracy: 0.3316
Epoch 10: val_loss improved from 1.87298 to 1.79375, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 96s 1s/step - loss: 1.8325 - accuracy: 0.3316 - val_loss: 1.7937 - val_accuracy: 0.3360
Epoch 11/100
82/82 [==============================] - ETA: 0s - loss: 1.7641 - accuracy: 0.3356
Epoch 11: val_loss improved from 1.79375 to 1.74679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 98s 1s/step - loss: 1.7641 - accuracy: 0.3356 - val_loss: 1.7468 - val_accuracy: 0.3330
Epoch 12/100
82/82 [==============================] - ETA: 0s - loss: 1.7156 - accuracy: 0.3426
Epoch 12: val_loss improved from 1.74679 to 1.69311, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 97s 1s/step - loss: 1.7156 - accuracy: 0.3426 - val_loss: 1.6931 - val_accuracy: 0.3473
Epoch 13/100
82/82 [==============================] - ETA: 0s - loss: 1.6753 - accuracy: 0.3542
Epoch 13: val_loss improved from 1.69311 to 1.66813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 96s 1s/step - loss: 1.6753 - accuracy: 0.3542 - val_loss: 1.6681 - val_accuracy: 0.3508
Epoch 14/100
82/82 [==============================] - ETA: 0s - loss: 1.6489 - accuracy: 0.3602
Epoch 14: val_loss improved from 1.66813 to 1.63616, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 98s 1s/step - loss: 1.6489 - accuracy: 0.3602 - val_loss: 1.6362 - val_accuracy: 0.3635
Epoch 15/100
82/82 [==============================] - ETA: 0s - loss: 1.6246 - accuracy: 0.3674
Epoch 15: val_loss improved from 1.63616 to 1.62322, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 98s 1s/step - loss: 1.6246 - accuracy: 0.3674 - val_loss: 1.6232 - val_accuracy: 0.3692
Epoch 16/100
82/82 [==============================] - ETA: 0s - loss: 1.6016 - accuracy: 0.3782
Epoch 16: val_loss improved from 1.62322 to 1.60324, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 98s 1s/step - loss: 1.6016 - accuracy: 0.3782 - val_loss: 1.6032 - val_accuracy: 0.3771
Epoch 17/100
82/82 [==============================] - ETA: 0s - loss: 1.5836 - accuracy: 0.3846
Epoch 17: val_loss improved from 1.60324 to 1.59426, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 99s 1s/step - loss: 1.5836 - accuracy: 0.3846 - val_loss: 1.5943 - val_accuracy: 0.3810
Epoch 18/100
82/82 [==============================] - ETA: 0s - loss: 1.5711 - accuracy: 0.3905
Epoch 18: val_loss improved from 1.59426 to 1.59357, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 98s 1s/step - loss: 1.5711 - accuracy: 0.3905 - val_loss: 1.5936 - val_accuracy: 0.3824
Epoch 19/100
82/82 [==============================] - ETA: 0s - loss: 1.5622 - accuracy: 0.3967
Epoch 19: val_loss improved from 1.59357 to 1.58296, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 97s 1s/step - loss: 1.5622 - accuracy: 0.3967 - val_loss: 1.5830 - val_accuracy: 0.3900
Epoch 20/100
82/82 [==============================] - ETA: 0s - loss: 1.5501 - accuracy: 0.3997
Epoch 20: val_loss improved from 1.58296 to 1.57957, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 97s 1s/step - loss: 1.5501 - accuracy: 0.3997 - val_loss: 1.5796 - val_accuracy: 0.3890
Epoch 21/100
82/82 [==============================] - ETA: 0s - loss: 1.5409 - accuracy: 0.4073
Epoch 21: val_loss did not improve from 1.57957
82/82 [==============================] - 95s 1s/step - loss: 1.5409 - accuracy: 0.4073 - val_loss: 1.5805 - val_accuracy: 0.3858
Epoch 22/100
82/82 [==============================] - ETA: 0s - loss: 1.5380 - accuracy: 0.4098
Epoch 22: val_loss improved from 1.57957 to 1.57038, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/2
82/82 [==============================] - 97s 1s/step - loss: 1.5380 - accuracy: 0.4098 - val_loss: 1.5704 - val_accuracy: 0.3900
Epoch 23/100
82/82 [==============================] - ETA: 0s - loss: 1.5244 - accuracy: 0.4164
Epoch 23: val_loss did not improve from 1.57038
82/82 [==============================] - 96s 1s/step - loss: 1.5244 - accuracy: 0.4164 - val_loss: 1.5775 - val_accuracy: 0.3888
Epoch 24/100
82/82 [==============================] - ETA: 0s - loss: 1.5175 - accuracy: 0.4214
Epoch 24: val_loss did not improve from 1.57038
82/82 [==============================] - 96s 1s/step - loss: 1.5175 - accuracy: 0.4214 - val_loss: 1.5726 - val_accuracy: 0.3922
Epoch 25/100
82/82 [==============================] - ETA: 0s - loss: 1.5119 - accuracy: 0.4251
Epoch 25: val_loss did not improve from 1.57038
82/82 [==============================] - 94s 1s/step - loss: 1.5119 - accuracy: 0.4251 - val_loss: 1.5759 - val_accuracy: 0.3913
Epoch 26/100
82/82 [==============================] - ETA: 0s - loss: 1.5032 - accuracy: 0.4298
Epoch 26: val_loss did not improve from 1.57038
82/82 [==============================] - 93s 1s/step - loss: 1.5032 - accuracy: 0.4298 - val_loss: 1.5842 - val_accuracy: 0.3880
Epoch 27/100
82/82 [==============================] - ETA: 0s - loss: 1.5030 - accuracy: 0.4343
Epoch 27: val_loss did not improve from 1.57038
82/82 [==============================] - 92s 1s/step - loss: 1.5030 - accuracy: 0.4343 - val_loss: 1.5874 - val_accuracy: 0.3859
Epoch 28/100
82/82 [==============================] - ETA: 0s - loss: 1.4950 - accuracy: 0.4363
Epoch 28: val_loss did not improve from 1.57038
82/82 [==============================] - 93s 1s/step - loss: 1.4950 - accuracy: 0.4363 - val_loss: 1.5854 - val_accuracy: 0.3869
Epoch 29/100
82/82 [==============================] - ETA: 0s - loss: 1.4864 - accuracy: 0.4407
Epoch 29: val_loss did not improve from 1.57038
82/82 [==============================] - 94s 1s/step - loss: 1.4864 - accuracy: 0.4407 - val_loss: 1.5920 - val_accuracy: 0.3840
Epoch 30/100
82/82 [==============================] - ETA: 0s - loss: 1.4800 - accuracy: 0.4477
Epoch 30: val_loss did not improve from 1.57038
82/82 [==============================] - 93s 1s/step - loss: 1.4800 - accuracy: 0.4477 - val_loss: 1.5825 - val_accuracy: 0.3929
Epoch 31/100
82/82 [==============================] - ETA: 0s - loss: 1.4751 - accuracy: 0.4487
Epoch 31: val_loss did not improve from 1.57038
82/82 [==============================] - 92s 1s/step - loss: 1.4751 - accuracy: 0.4487 - val_loss: 1.6016 - val_accuracy: 0.3888
Epoch 32/100
82/82 [==============================] - ETA: 0s - loss: 1.4662 - accuracy: 0.4568
Epoch 32: val_loss did not improve from 1.57038
82/82 [==============================] - 94s 1s/step - loss: 1.4662 - accuracy: 0.4568 - val_loss: 1.6180 - val_accuracy: 0.3805
Epoch 32: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_2 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_8 (Dense)             multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_2 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_2 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_6 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_6 (MaxPooling  (None, 37, 37, 32)       0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_7 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_7 (MaxPooling  (None, 18, 18, 128)      0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_8 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_8 (MaxPooling  (None, 9, 9, 256)        0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m dropout_6 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_2 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_6 (Dense)             (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_7 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_7 (Dense)             (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_8 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 128s 10ms/step - loss: 1.5746 - accuracy: 0.3960
Testing Loss = 1.574646, Testing Accuracy = 0.395989
The data set contains images
  13212/Unknown - 120s 9ms/step13216/13216 [==============================] - 120s 9ms/step
[[0.07789267599582672, 0.06551282107830048, 0.340476393699646, 0.09177540987730026, 0.2222592979669571, 0.20208343863487244], [0.07982694357633591, 0.10765206813812256, 0.1334507018327713, 0.3147059977054596, 0.17455099523067474, 0.18981319665908813], [0.05928899720311165, 0.2936896085739136, 0.1324891597032547, 0.15097735822200775, 0.11172933876514435, 0.25182560086250305], [0.2885917127132416, 0.02676880545914173, 0.16659997403621674, 0.1458478569984436, 0.28125590085983276, 0.09093576669692993], [0.396124005317688, 0.01748746819794178, 0.1722632795572281, 0.07308797538280487, 0.27854567766189575, 0.062491558492183685], [0.035565782338380814, 0.32447415590286255, 0.17742130160331726, 0.09998609125614166, 0.08813018351793289, 0.2744225263595581], [0.4002264440059662, 0.0145716592669487, 0.13408051431179047, 0.09492099285125732, 0.2960912585258484, 0.060109131038188934], [0.0074209109880030155, 0.6803365349769592, 0.03360012173652649, 0.08119800686836243, 0.020410893484950066, 0.17703363299369812], [0.41167721152305603, 0.045617830008268356, 0.09930846840143204, 0.14969557523727417, 0.21216878294944763, 0.08153219521045685], [0.3560542166233063, 0.042148299515247345, 0.07090341299772263, 0.25267958641052246, 0.19889169931411743, 0.07932278513908386]]
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
46 - accuracy: 0.1997     82/Unknown - 93s 1s/step - loss: 12.4596 - accuracy: 0.1995
Epoch 1: val_loss improved from inf to 8.74550, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 102s 1s/step - loss: 12.4596 - accuracy: 0.1995 - val_loss: 8.7455 - val_accuracy: 0.2095
Epoch 2/100
82/82 [==============================] - ETA: 0s - loss: 6.8056 - accuracy: 0.2072
Epoch 2: val_loss improved from 8.74550 to 5.36568, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 103s 1s/step - loss: 6.8056 - accuracy: 0.2072 - val_loss: 5.3657 - val_accuracy: 0.2116
Epoch 3/100
82/82 [==============================] - ETA: 0s - loss: 4.5892 - accuracy: 0.2120
Epoch 3: val_loss improved from 5.36568 to 3.97767, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 101s 1s/step - loss: 4.5892 - accuracy: 0.2120 - val_loss: 3.9777 - val_accuracy: 0.2165
Epoch 4/100
82/82 [==============================] - ETA: 0s - loss: 3.5046 - accuracy: 0.2651
Epoch 4: val_loss improved from 3.97767 to 3.20631, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 101s 1s/step - loss: 3.5046 - accuracy: 0.2651 - val_loss: 3.2063 - val_accuracy: 0.2608
Epoch 5/100
82/82 [==============================] - ETA: 0s - loss: 2.8913 - accuracy: 0.2959
Epoch 5: val_loss improved from 3.20631 to 2.72672, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 100s 1s/step - loss: 2.8913 - accuracy: 0.2959 - val_loss: 2.7267 - val_accuracy: 0.2829
Epoch 6/100
82/82 [==============================] - ETA: 0s - loss: 2.5093 - accuracy: 0.3037
Epoch 6: val_loss improved from 2.72672 to 2.38891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 97s 1s/step - loss: 2.5093 - accuracy: 0.3037 - val_loss: 2.3889 - val_accuracy: 0.3005
Epoch 7/100
82/82 [==============================] - ETA: 0s - loss: 2.2416 - accuracy: 0.3113
Epoch 7: val_loss improved from 2.38891 to 2.14681, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 98s 1s/step - loss: 2.2416 - accuracy: 0.3113 - val_loss: 2.1468 - val_accuracy: 0.3164
Epoch 8/100
82/82 [==============================] - ETA: 0s - loss: 2.0525 - accuracy: 0.3190
Epoch 8: val_loss improved from 2.14681 to 1.97824, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 98s 1s/step - loss: 2.0525 - accuracy: 0.3190 - val_loss: 1.9782 - val_accuracy: 0.3229
Epoch 9/100
82/82 [==============================] - ETA: 0s - loss: 1.9213 - accuracy: 0.3256
Epoch 9: val_loss improved from 1.97824 to 1.86209, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 97s 1s/step - loss: 1.9213 - accuracy: 0.3256 - val_loss: 1.8621 - val_accuracy: 0.3317
Epoch 10/100
82/82 [==============================] - ETA: 0s - loss: 1.8252 - accuracy: 0.3318
Epoch 10: val_loss improved from 1.86209 to 1.78983, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 98s 1s/step - loss: 1.8252 - accuracy: 0.3318 - val_loss: 1.7898 - val_accuracy: 0.3322
Epoch 11/100
82/82 [==============================] - ETA: 0s - loss: 1.7575 - accuracy: 0.3405
Epoch 11: val_loss improved from 1.78983 to 1.73477, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 97s 1s/step - loss: 1.7575 - accuracy: 0.3405 - val_loss: 1.7348 - val_accuracy: 0.3371
Epoch 12/100
82/82 [==============================] - ETA: 0s - loss: 1.7061 - accuracy: 0.3507
Epoch 12: val_loss improved from 1.73477 to 1.69191, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 97s 1s/step - loss: 1.7061 - accuracy: 0.3507 - val_loss: 1.6919 - val_accuracy: 0.3456
Epoch 13/100
82/82 [==============================] - ETA: 0s - loss: 1.6694 - accuracy: 0.3539
Epoch 13: val_loss improved from 1.69191 to 1.66590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 99s 1s/step - loss: 1.6694 - accuracy: 0.3539 - val_loss: 1.6659 - val_accuracy: 0.3495
Epoch 14/100
82/82 [==============================] - ETA: 0s - loss: 1.6424 - accuracy: 0.3632
Epoch 14: val_loss improved from 1.66590 to 1.63903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 99s 1s/step - loss: 1.6424 - accuracy: 0.3632 - val_loss: 1.6390 - val_accuracy: 0.3591
Epoch 15/100
82/82 [==============================] - ETA: 0s - loss: 1.6147 - accuracy: 0.3748
Epoch 15: val_loss improved from 1.63903 to 1.61713, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 97s 1s/step - loss: 1.6147 - accuracy: 0.3748 - val_loss: 1.6171 - val_accuracy: 0.3707
Epoch 16/100
82/82 [==============================] - ETA: 0s - loss: 1.5966 - accuracy: 0.3794
Epoch 16: val_loss improved from 1.61713 to 1.60582, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 96s 1s/step - loss: 1.5966 - accuracy: 0.3794 - val_loss: 1.6058 - val_accuracy: 0.3747
Epoch 17/100
82/82 [==============================] - ETA: 0s - loss: 1.5811 - accuracy: 0.3890
Epoch 17: val_loss improved from 1.60582 to 1.60024, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 97s 1s/step - loss: 1.5811 - accuracy: 0.3890 - val_loss: 1.6002 - val_accuracy: 0.3758
Epoch 18/100
82/82 [==============================] - ETA: 0s - loss: 1.5672 - accuracy: 0.3951
Epoch 18: val_loss improved from 1.60024 to 1.58767, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 98s 1s/step - loss: 1.5672 - accuracy: 0.3951 - val_loss: 1.5877 - val_accuracy: 0.3826
Epoch 19/100
82/82 [==============================] - ETA: 0s - loss: 1.5549 - accuracy: 0.3997
Epoch 19: val_loss improved from 1.58767 to 1.57851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 98s 1s/step - loss: 1.5549 - accuracy: 0.3997 - val_loss: 1.5785 - val_accuracy: 0.3840
Epoch 20/100
82/82 [==============================] - ETA: 0s - loss: 1.5465 - accuracy: 0.4050
Epoch 20: val_loss did not improve from 1.57851
82/82 [==============================] - 95s 1s/step - loss: 1.5465 - accuracy: 0.4050 - val_loss: 1.5848 - val_accuracy: 0.3847
Epoch 21/100
82/82 [==============================] - ETA: 0s - loss: 1.5353 - accuracy: 0.4105
Epoch 21: val_loss did not improve from 1.57851
82/82 [==============================] - 94s 1s/step - loss: 1.5353 - accuracy: 0.4105 - val_loss: 1.5798 - val_accuracy: 0.3871
Epoch 22/100
82/82 [==============================] - ETA: 0s - loss: 1.5288 - accuracy: 0.4167
Epoch 22: val_loss improved from 1.57851 to 1.57599, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 96s 1s/step - loss: 1.5288 - accuracy: 0.4167 - val_loss: 1.5760 - val_accuracy: 0.3907
Epoch 23/100
82/82 [==============================] - ETA: 0s - loss: 1.5234 - accuracy: 0.4189
Epoch 23: val_loss improved from 1.57599 to 1.57468, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/3
82/82 [==============================] - 99s 1s/step - loss: 1.5234 - accuracy: 0.4189 - val_loss: 1.5747 - val_accuracy: 0.3914
Epoch 24/100
82/82 [==============================] - ETA: 0s - loss: 1.5137 - accuracy: 0.4243
Epoch 24: val_loss did not improve from 1.57468
82/82 [==============================] - 97s 1s/step - loss: 1.5137 - accuracy: 0.4243 - val_loss: 1.5770 - val_accuracy: 0.3924
Epoch 25/100
82/82 [==============================] - ETA: 0s - loss: 1.5064 - accuracy: 0.4305
Epoch 25: val_loss did not improve from 1.57468
82/82 [==============================] - 98s 1s/step - loss: 1.5064 - accuracy: 0.4305 - val_loss: 1.5767 - val_accuracy: 0.3905
Epoch 26/100
82/82 [==============================] - ETA: 0s - loss: 1.4990 - accuracy: 0.4363
Epoch 26: val_loss did not improve from 1.57468
82/82 [==============================] - 98s 1s/step - loss: 1.4990 - accuracy: 0.4363 - val_loss: 1.5781 - val_accuracy: 0.3925
Epoch 27/100
82/82 [==============================] - ETA: 0s - loss: 1.4942 - accuracy: 0.4400
Epoch 27: val_loss did not improve from 1.57468
82/82 [==============================] - 98s 1s/step - loss: 1.4942 - accuracy: 0.4400 - val_loss: 1.5880 - val_accuracy: 0.3885
Epoch 28/100
82/82 [==============================] - ETA: 0s - loss: 1.4875 - accuracy: 0.4431
Epoch 28: val_loss did not improve from 1.57468
82/82 [==============================] - 95s 1s/step - loss: 1.4875 - accuracy: 0.4431 - val_loss: 1.5918 - val_accuracy: 0.3868
Epoch 29/100
82/82 [==============================] - ETA: 0s - loss: 1.4787 - accuracy: 0.4485
Epoch 29: val_loss did not improve from 1.57468
82/82 [==============================] - 95s 1s/step - loss: 1.4787 - accuracy: 0.4485 - val_loss: 1.5883 - val_accuracy: 0.3908
Epoch 30/100
82/82 [==============================] - ETA: 0s - loss: 1.4702 - accuracy: 0.4542
Epoch 30: val_loss did not improve from 1.57468
82/82 [==============================] - 96s 1s/step - loss: 1.4702 - accuracy: 0.4542 - val_loss: 1.5984 - val_accuracy: 0.3876
Epoch 31/100
82/82 [==============================] - ETA: 0s - loss: 1.4645 - accuracy: 0.4573
Epoch 31: val_loss did not improve from 1.57468
82/82 [==============================] - 98s 1s/step - loss: 1.4645 - accuracy: 0.4573 - val_loss: 1.5981 - val_accuracy: 0.3938
Epoch 32/100
82/82 [==============================] - ETA: 0s - loss: 1.4597 - accuracy: 0.4673
Epoch 32: val_loss did not improve from 1.57468
82/82 [==============================] - 96s 1s/step - loss: 1.4597 - accuracy: 0.4673 - val_loss: 1.6141 - val_accuracy: 0.3868
Epoch 33/100
82/82 [==============================] - ETA: 0s - loss: 1.4495 - accuracy: 0.4710
Epoch 33: val_loss did not improve from 1.57468
82/82 [==============================] - 96s 1s/step - loss: 1.4495 - accuracy: 0.4710 - val_loss: 1.6211 - val_accuracy: 0.3874
Epoch 33: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_3 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_11 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_3 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_3 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_9 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_9 (MaxPooling  (None, 37, 37, 32)       0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_10 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_10 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_11 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_11 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_9 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_3 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_9 (Dense)             (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_10 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_10 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_11 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 127s 10ms/step - loss: 1.5787 - accuracy: 0.3904
Testing Loss = 1.578663, Testing Accuracy = 0.390390
The data set contains images
  13212/Unknown - 120s 9ms/step13216/13216 [==============================] - 120s 9ms/step
[[0.09643702208995819, 0.05839601159095764, 0.3214600086212158, 0.0953293889760971, 0.2477680891752243, 0.18060944974422455], [0.06795866042375565, 0.10975993424654007, 0.13250011205673218, 0.3038709759712219, 0.1724778711795807, 0.2134324461221695], [0.06270138919353485, 0.20566527545452118, 0.16334347426891327, 0.1530625820159912, 0.14158634841442108, 0.2736409604549408], [0.30830472707748413, 0.02885805442929268, 0.12725375592708588, 0.17623156309127808, 0.26966410875320435, 0.0896877646446228], [0.4442616403102875, 0.014409404247999191, 0.1434043049812317, 0.06742891669273376, 0.2783783972263336, 0.05211734026670456], [0.040015049278736115, 0.2785072326660156, 0.19262844324111938, 0.1044548824429512, 0.09816807508468628, 0.2862262427806854], [0.42705038189888, 0.013791268691420555, 0.12089806795120239, 0.09077199548482895, 0.29249194264411926, 0.05499633401632309], [0.0126730902120471, 0.657135009765625, 0.027357719838619232, 0.10166273266077042, 0.023777280002832413, 0.17739415168762207], [0.39600902795791626, 0.05162486061453819, 0.08825729787349701, 0.17448465526103973, 0.2056959718465805, 0.08392812311649323], [0.37839892506599426, 0.044130515307188034, 0.05797615647315979, 0.2568739652633667, 0.18798111379146576, 0.07463931292295456]]
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
17 - accuracy: 0.1979     82/Unknown - 90s 1s/step - loss: 12.5369 - accuracy: 0.1981
Epoch 1: val_loss improved from inf to 8.84595, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 99s 1s/step - loss: 12.5369 - accuracy: 0.1981 - val_loss: 8.8459 - val_accuracy: 0.2091
Epoch 2/100
82/82 [==============================] - ETA: 0s - loss: 6.8920 - accuracy: 0.2058
Epoch 2: val_loss improved from 8.84595 to 5.43472, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 97s 1s/step - loss: 6.8920 - accuracy: 0.2058 - val_loss: 5.4347 - val_accuracy: 0.2121
Epoch 3/100
82/82 [==============================] - ETA: 0s - loss: 4.6108 - accuracy: 0.2325
Epoch 3: val_loss improved from 5.43472 to 3.99252, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 98s 1s/step - loss: 4.6108 - accuracy: 0.2325 - val_loss: 3.9925 - val_accuracy: 0.2281
Epoch 4/100
82/82 [==============================] - ETA: 0s - loss: 3.5045 - accuracy: 0.2877
Epoch 4: val_loss improved from 3.99252 to 3.22964, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 99s 1s/step - loss: 3.5045 - accuracy: 0.2877 - val_loss: 3.2296 - val_accuracy: 0.2621
Epoch 5/100
82/82 [==============================] - ETA: 0s - loss: 2.9135 - accuracy: 0.3003
Epoch 5: val_loss improved from 3.22964 to 2.76009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 97s 1s/step - loss: 2.9135 - accuracy: 0.3003 - val_loss: 2.7601 - val_accuracy: 0.2727
Epoch 6/100
82/82 [==============================] - ETA: 0s - loss: 2.5241 - accuracy: 0.3113
Epoch 6: val_loss improved from 2.76009 to 2.40760, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 98s 1s/step - loss: 2.5241 - accuracy: 0.3113 - val_loss: 2.4076 - val_accuracy: 0.2948
Epoch 7/100
82/82 [==============================] - ETA: 0s - loss: 2.2561 - accuracy: 0.3180
Epoch 7: val_loss improved from 2.40760 to 2.16717, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 99s 1s/step - loss: 2.2561 - accuracy: 0.3180 - val_loss: 2.1672 - val_accuracy: 0.3096
Epoch 8/100
82/82 [==============================] - ETA: 0s - loss: 2.0665 - accuracy: 0.3210
Epoch 8: val_loss improved from 2.16717 to 1.99794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 97s 1s/step - loss: 2.0665 - accuracy: 0.3210 - val_loss: 1.9979 - val_accuracy: 0.3187
Epoch 9/100
82/82 [==============================] - ETA: 0s - loss: 1.9321 - accuracy: 0.3250
Epoch 9: val_loss improved from 1.99794 to 1.87549, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 99s 1s/step - loss: 1.9321 - accuracy: 0.3250 - val_loss: 1.8755 - val_accuracy: 0.3280
Epoch 10/100
82/82 [==============================] - ETA: 0s - loss: 1.8347 - accuracy: 0.3313
Epoch 10: val_loss improved from 1.87549 to 1.79671, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 100s 1s/step - loss: 1.8347 - accuracy: 0.3313 - val_loss: 1.7967 - val_accuracy: 0.3328
Epoch 11/100
82/82 [==============================] - ETA: 0s - loss: 1.7668 - accuracy: 0.3362
Epoch 11: val_loss improved from 1.79671 to 1.74973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 98s 1s/step - loss: 1.7668 - accuracy: 0.3362 - val_loss: 1.7497 - val_accuracy: 0.3299
Epoch 12/100
82/82 [==============================] - ETA: 0s - loss: 1.7146 - accuracy: 0.3455
Epoch 12: val_loss improved from 1.74973 to 1.70611, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 98s 1s/step - loss: 1.7146 - accuracy: 0.3455 - val_loss: 1.7061 - val_accuracy: 0.3395
Epoch 13/100
82/82 [==============================] - ETA: 0s - loss: 1.6761 - accuracy: 0.3539
Epoch 13: val_loss improved from 1.70611 to 1.67761, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 97s 1s/step - loss: 1.6761 - accuracy: 0.3539 - val_loss: 1.6776 - val_accuracy: 0.3444
Epoch 14/100
82/82 [==============================] - ETA: 0s - loss: 1.6487 - accuracy: 0.3613
Epoch 14: val_loss improved from 1.67761 to 1.65223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 98s 1s/step - loss: 1.6487 - accuracy: 0.3613 - val_loss: 1.6522 - val_accuracy: 0.3514
Epoch 15/100
82/82 [==============================] - ETA: 0s - loss: 1.6241 - accuracy: 0.3690
Epoch 15: val_loss improved from 1.65223 to 1.63616, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 97s 1s/step - loss: 1.6241 - accuracy: 0.3690 - val_loss: 1.6362 - val_accuracy: 0.3548
Epoch 16/100
82/82 [==============================] - ETA: 0s - loss: 1.6037 - accuracy: 0.3753
Epoch 16: val_loss improved from 1.63616 to 1.60943, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 96s 1s/step - loss: 1.6037 - accuracy: 0.3753 - val_loss: 1.6094 - val_accuracy: 0.3728
Epoch 17/100
82/82 [==============================] - ETA: 0s - loss: 1.5848 - accuracy: 0.3848
Epoch 17: val_loss improved from 1.60943 to 1.59562, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 96s 1s/step - loss: 1.5848 - accuracy: 0.3848 - val_loss: 1.5956 - val_accuracy: 0.3801
Epoch 18/100
82/82 [==============================] - ETA: 0s - loss: 1.5741 - accuracy: 0.3894
Epoch 18: val_loss improved from 1.59562 to 1.59168, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 96s 1s/step - loss: 1.5741 - accuracy: 0.3894 - val_loss: 1.5917 - val_accuracy: 0.3800
Epoch 19/100
82/82 [==============================] - ETA: 0s - loss: 1.5626 - accuracy: 0.3965
Epoch 19: val_loss improved from 1.59168 to 1.58135, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 97s 1s/step - loss: 1.5626 - accuracy: 0.3965 - val_loss: 1.5813 - val_accuracy: 0.3847
Epoch 20/100
82/82 [==============================] - ETA: 0s - loss: 1.5505 - accuracy: 0.4009
Epoch 20: val_loss improved from 1.58135 to 1.57453, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 96s 1s/step - loss: 1.5505 - accuracy: 0.4009 - val_loss: 1.5745 - val_accuracy: 0.3894
Epoch 21/100
82/82 [==============================] - ETA: 0s - loss: 1.5431 - accuracy: 0.4072
Epoch 21: val_loss improved from 1.57453 to 1.57192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 97s 1s/step - loss: 1.5431 - accuracy: 0.4072 - val_loss: 1.5719 - val_accuracy: 0.3902
Epoch 22/100
82/82 [==============================] - ETA: 0s - loss: 1.5364 - accuracy: 0.4103
Epoch 22: val_loss did not improve from 1.57192
82/82 [==============================] - 96s 1s/step - loss: 1.5364 - accuracy: 0.4103 - val_loss: 1.5804 - val_accuracy: 0.3836
Epoch 23/100
82/82 [==============================] - ETA: 0s - loss: 1.5298 - accuracy: 0.4125
Epoch 23: val_loss improved from 1.57192 to 1.56568, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 98s 1s/step - loss: 1.5298 - accuracy: 0.4125 - val_loss: 1.5657 - val_accuracy: 0.3932
Epoch 24/100
82/82 [==============================] - ETA: 0s - loss: 1.5205 - accuracy: 0.4210
Epoch 24: val_loss did not improve from 1.56568
82/82 [==============================] - 96s 1s/step - loss: 1.5205 - accuracy: 0.4210 - val_loss: 1.5688 - val_accuracy: 0.3922
Epoch 25/100
82/82 [==============================] - ETA: 0s - loss: 1.5129 - accuracy: 0.4258
Epoch 25: val_loss improved from 1.56568 to 1.56396, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/4
82/82 [==============================] - 97s 1s/step - loss: 1.5129 - accuracy: 0.4258 - val_loss: 1.5640 - val_accuracy: 0.3967
Epoch 26/100
82/82 [==============================] - ETA: 0s - loss: 1.5060 - accuracy: 0.4271
Epoch 26: val_loss did not improve from 1.56396
82/82 [==============================] - 96s 1s/step - loss: 1.5060 - accuracy: 0.4271 - val_loss: 1.5770 - val_accuracy: 0.3898
Epoch 27/100
82/82 [==============================] - ETA: 0s - loss: 1.5043 - accuracy: 0.4311
Epoch 27: val_loss did not improve from 1.56396
82/82 [==============================] - 96s 1s/step - loss: 1.5043 - accuracy: 0.4311 - val_loss: 1.5662 - val_accuracy: 0.3987
Epoch 28/100
82/82 [==============================] - ETA: 0s - loss: 1.4968 - accuracy: 0.4358
Epoch 28: val_loss did not improve from 1.56396
82/82 [==============================] - 96s 1s/step - loss: 1.4968 - accuracy: 0.4358 - val_loss: 1.5711 - val_accuracy: 0.3975
Epoch 29/100
82/82 [==============================] - ETA: 0s - loss: 1.4888 - accuracy: 0.4421
Epoch 29: val_loss did not improve from 1.56396
82/82 [==============================] - 95s 1s/step - loss: 1.4888 - accuracy: 0.4421 - val_loss: 1.5737 - val_accuracy: 0.3957
Epoch 30/100
82/82 [==============================] - ETA: 0s - loss: 1.4828 - accuracy: 0.4448
Epoch 30: val_loss did not improve from 1.56396
82/82 [==============================] - 94s 1s/step - loss: 1.4828 - accuracy: 0.4448 - val_loss: 1.5753 - val_accuracy: 0.3962
Epoch 31/100
82/82 [==============================] - ETA: 0s - loss: 1.4771 - accuracy: 0.4497
Epoch 31: val_loss did not improve from 1.56396
82/82 [==============================] - 96s 1s/step - loss: 1.4771 - accuracy: 0.4497 - val_loss: 1.5949 - val_accuracy: 0.3845
Epoch 32/100
82/82 [==============================] - ETA: 0s - loss: 1.4718 - accuracy: 0.4533
Epoch 32: val_loss did not improve from 1.56396
82/82 [==============================] - 97s 1s/step - loss: 1.4718 - accuracy: 0.4533 - val_loss: 1.5812 - val_accuracy: 0.4021
Epoch 33/100
82/82 [==============================] - ETA: 0s - loss: 1.4635 - accuracy: 0.4577
Epoch 33: val_loss did not improve from 1.56396
82/82 [==============================] - 94s 1s/step - loss: 1.4635 - accuracy: 0.4577 - val_loss: 1.5876 - val_accuracy: 0.3960
Epoch 34/100
82/82 [==============================] - ETA: 0s - loss: 1.4599 - accuracy: 0.4632
Epoch 34: val_loss did not improve from 1.56396
82/82 [==============================] - 95s 1s/step - loss: 1.4599 - accuracy: 0.4632 - val_loss: 1.5960 - val_accuracy: 0.3994
Epoch 35/100
82/82 [==============================] - ETA: 0s - loss: 1.4496 - accuracy: 0.4720
Epoch 35: val_loss did not improve from 1.56396
82/82 [==============================] - 95s 1s/step - loss: 1.4496 - accuracy: 0.4720 - val_loss: 1.6033 - val_accuracy: 0.3966
Epoch 35: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_4 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_14 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_4 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_4 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_12 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_12 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_13 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_13 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_14 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_14 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_12 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_4 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_12 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_13 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_13 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_14 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 127s 10ms/step - loss: 1.5683 - accuracy: 0.3986
Testing Loss = 1.568271, Testing Accuracy = 0.398562
The data set contains images
  13215/Unknown - 119s 9ms/step13216/13216 [==============================] - 119s 9ms/step
[[0.05979522317647934, 0.04883772134780884, 0.4084155261516571, 0.07082691043615341, 0.21820245683193207, 0.19392220675945282], [0.07934875786304474, 0.09900747984647751, 0.11833811551332474, 0.3409680128097534, 0.17527183890342712, 0.18706585466861725], [0.04266943782567978, 0.16945390403270721, 0.2485145777463913, 0.10107052326202393, 0.1473538726568222, 0.2909376919269562], [0.31596633791923523, 0.02763954922556877, 0.12996555864810944, 0.16900692880153656, 0.2697256803512573, 0.08769594877958298], [0.46306267380714417, 0.018373889848589897, 0.12232814729213715, 0.0764852985739708, 0.262237548828125, 0.0575125589966774], [0.039142102003097534, 0.32502856850624084, 0.16984277963638306, 0.10053879022598267, 0.09077993035316467, 0.27466779947280884], [0.36695989966392517, 0.013326693326234818, 0.15430165827274323, 0.08429726958274841, 0.31726282835006714, 0.06385168433189392], [0.010111222043633461, 0.638532280921936, 0.03908967971801758, 0.084092877805233, 0.025842854753136635, 0.2023310661315918], [0.43497639894485474, 0.05672730132937431, 0.06942611932754517, 0.17693442106246948, 0.1848120093345642, 0.07712369412183762], [0.3590538501739502, 0.04299302026629448, 0.06486798077821732, 0.2503823935985565, 0.202775776386261, 0.07992690801620483]]
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
31 - accuracy: 0.1971     82/Unknown - 91s 1s/step - loss: 12.5283 - accuracy: 0.1968
Epoch 1: val_loss improved from inf to 8.83373, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 100s 1s/step - loss: 12.5283 - accuracy: 0.1968 - val_loss: 8.8337 - val_accuracy: 0.2093
Epoch 2/100
82/82 [==============================] - ETA: 0s - loss: 6.8852 - accuracy: 0.2043
Epoch 2: val_loss improved from 8.83373 to 5.43250, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 101s 1s/step - loss: 6.8852 - accuracy: 0.2043 - val_loss: 5.4325 - val_accuracy: 0.2102
Epoch 3/100
82/82 [==============================] - ETA: 0s - loss: 4.6325 - accuracy: 0.2178
Epoch 3: val_loss improved from 5.43250 to 4.00686, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 100s 1s/step - loss: 4.6325 - accuracy: 0.2178 - val_loss: 4.0069 - val_accuracy: 0.2315
Epoch 4/100
82/82 [==============================] - ETA: 0s - loss: 3.5149 - accuracy: 0.2801
Epoch 4: val_loss improved from 4.00686 to 3.22969, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 101s 1s/step - loss: 3.5149 - accuracy: 0.2801 - val_loss: 3.2297 - val_accuracy: 0.2652
Epoch 5/100
82/82 [==============================] - ETA: 0s - loss: 2.9143 - accuracy: 0.3004
Epoch 5: val_loss improved from 3.22969 to 2.74517, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 102s 1s/step - loss: 2.9143 - accuracy: 0.3004 - val_loss: 2.7452 - val_accuracy: 0.2809
Epoch 6/100
82/82 [==============================] - ETA: 0s - loss: 2.5243 - accuracy: 0.3054
Epoch 6: val_loss improved from 2.74517 to 2.40100, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 100s 1s/step - loss: 2.5243 - accuracy: 0.3054 - val_loss: 2.4010 - val_accuracy: 0.3004
Epoch 7/100
82/82 [==============================] - ETA: 0s - loss: 2.2570 - accuracy: 0.3135
Epoch 7: val_loss improved from 2.40100 to 2.16289, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 100s 1s/step - loss: 2.2570 - accuracy: 0.3135 - val_loss: 2.1629 - val_accuracy: 0.3147
Epoch 8/100
82/82 [==============================] - ETA: 0s - loss: 2.0665 - accuracy: 0.3205
Epoch 8: val_loss improved from 2.16289 to 1.98956, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 100s 1s/step - loss: 2.0665 - accuracy: 0.3205 - val_loss: 1.9896 - val_accuracy: 0.3277
Epoch 9/100
82/82 [==============================] - ETA: 0s - loss: 1.9309 - accuracy: 0.3241
Epoch 9: val_loss improved from 1.98956 to 1.87935, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 98s 1s/step - loss: 1.9309 - accuracy: 0.3241 - val_loss: 1.8793 - val_accuracy: 0.3269
Epoch 10/100
82/82 [==============================] - ETA: 0s - loss: 1.8368 - accuracy: 0.3296
Epoch 10: val_loss improved from 1.87935 to 1.79274, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 97s 1s/step - loss: 1.8368 - accuracy: 0.3296 - val_loss: 1.7927 - val_accuracy: 0.3386
Epoch 11/100
82/82 [==============================] - ETA: 0s - loss: 1.7660 - accuracy: 0.3357
Epoch 11: val_loss improved from 1.79274 to 1.74661, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 98s 1s/step - loss: 1.7660 - accuracy: 0.3357 - val_loss: 1.7466 - val_accuracy: 0.3322
Epoch 12/100
82/82 [==============================] - ETA: 0s - loss: 1.7154 - accuracy: 0.3431
Epoch 12: val_loss improved from 1.74661 to 1.69659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 99s 1s/step - loss: 1.7154 - accuracy: 0.3431 - val_loss: 1.6966 - val_accuracy: 0.3474
Epoch 13/100
82/82 [==============================] - ETA: 0s - loss: 1.6791 - accuracy: 0.3500
Epoch 13: val_loss improved from 1.69659 to 1.66338, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 99s 1s/step - loss: 1.6791 - accuracy: 0.3500 - val_loss: 1.6634 - val_accuracy: 0.3505
Epoch 14/100
82/82 [==============================] - ETA: 0s - loss: 1.6490 - accuracy: 0.3593
Epoch 14: val_loss improved from 1.66338 to 1.63461, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 101s 1s/step - loss: 1.6490 - accuracy: 0.3593 - val_loss: 1.6346 - val_accuracy: 0.3594
Epoch 15/100
82/82 [==============================] - ETA: 0s - loss: 1.6256 - accuracy: 0.3640
Epoch 15: val_loss improved from 1.63461 to 1.62223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 99s 1s/step - loss: 1.6256 - accuracy: 0.3640 - val_loss: 1.6222 - val_accuracy: 0.3714
Epoch 16/100
82/82 [==============================] - ETA: 0s - loss: 1.6026 - accuracy: 0.3742
Epoch 16: val_loss improved from 1.62223 to 1.60852, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 97s 1s/step - loss: 1.6026 - accuracy: 0.3742 - val_loss: 1.6085 - val_accuracy: 0.3761
Epoch 17/100
82/82 [==============================] - ETA: 0s - loss: 1.5881 - accuracy: 0.3846
Epoch 17: val_loss improved from 1.60852 to 1.59673, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 96s 1s/step - loss: 1.5881 - accuracy: 0.3846 - val_loss: 1.5967 - val_accuracy: 0.3789
Epoch 18/100
82/82 [==============================] - ETA: 0s - loss: 1.5742 - accuracy: 0.3864
Epoch 18: val_loss improved from 1.59673 to 1.59112, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 96s 1s/step - loss: 1.5742 - accuracy: 0.3864 - val_loss: 1.5911 - val_accuracy: 0.3837
Epoch 19/100
82/82 [==============================] - ETA: 0s - loss: 1.5634 - accuracy: 0.3936
Epoch 19: val_loss improved from 1.59112 to 1.58162, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 96s 1s/step - loss: 1.5634 - accuracy: 0.3936 - val_loss: 1.5816 - val_accuracy: 0.3890
Epoch 20/100
82/82 [==============================] - ETA: 0s - loss: 1.5520 - accuracy: 0.4004
Epoch 20: val_loss improved from 1.58162 to 1.57975, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 94s 1s/step - loss: 1.5520 - accuracy: 0.4004 - val_loss: 1.5798 - val_accuracy: 0.3882
Epoch 21/100
82/82 [==============================] - ETA: 0s - loss: 1.5457 - accuracy: 0.4036
Epoch 21: val_loss did not improve from 1.57975
82/82 [==============================] - 92s 1s/step - loss: 1.5457 - accuracy: 0.4036 - val_loss: 1.5808 - val_accuracy: 0.3880
Epoch 22/100
82/82 [==============================] - ETA: 0s - loss: 1.5363 - accuracy: 0.4095
Epoch 22: val_loss improved from 1.57975 to 1.57192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/5
82/82 [==============================] - 92s 1s/step - loss: 1.5363 - accuracy: 0.4095 - val_loss: 1.5719 - val_accuracy: 0.3944
Epoch 23/100
82/82 [==============================] - ETA: 0s - loss: 1.5285 - accuracy: 0.4161
Epoch 23: val_loss did not improve from 1.57192
82/82 [==============================] - 90s 1s/step - loss: 1.5285 - accuracy: 0.4161 - val_loss: 1.5745 - val_accuracy: 0.3929
Epoch 24/100
82/82 [==============================] - ETA: 0s - loss: 1.5199 - accuracy: 0.4209
Epoch 24: val_loss did not improve from 1.57192
82/82 [==============================] - 91s 1s/step - loss: 1.5199 - accuracy: 0.4209 - val_loss: 1.5750 - val_accuracy: 0.3947
Epoch 25/100
82/82 [==============================] - ETA: 0s - loss: 1.5137 - accuracy: 0.4238
Epoch 25: val_loss did not improve from 1.57192
82/82 [==============================] - 91s 1s/step - loss: 1.5137 - accuracy: 0.4238 - val_loss: 1.5744 - val_accuracy: 0.3931
Epoch 26/100
82/82 [==============================] - ETA: 0s - loss: 1.5087 - accuracy: 0.4254
Epoch 26: val_loss did not improve from 1.57192
82/82 [==============================] - 92s 1s/step - loss: 1.5087 - accuracy: 0.4254 - val_loss: 1.5794 - val_accuracy: 0.3909
Epoch 27/100
82/82 [==============================] - ETA: 0s - loss: 1.5018 - accuracy: 0.4293
Epoch 27: val_loss did not improve from 1.57192
82/82 [==============================] - 91s 1s/step - loss: 1.5018 - accuracy: 0.4293 - val_loss: 1.5817 - val_accuracy: 0.3935
Epoch 28/100
82/82 [==============================] - ETA: 0s - loss: 1.4943 - accuracy: 0.4381
Epoch 28: val_loss did not improve from 1.57192
82/82 [==============================] - 91s 1s/step - loss: 1.4943 - accuracy: 0.4381 - val_loss: 1.5766 - val_accuracy: 0.3985
Epoch 29/100
82/82 [==============================] - ETA: 0s - loss: 1.4902 - accuracy: 0.4389
Epoch 29: val_loss did not improve from 1.57192
82/82 [==============================] - 93s 1s/step - loss: 1.4902 - accuracy: 0.4389 - val_loss: 1.5831 - val_accuracy: 0.3939
Epoch 30/100
82/82 [==============================] - ETA: 0s - loss: 1.4823 - accuracy: 0.4443
Epoch 30: val_loss did not improve from 1.57192
82/82 [==============================] - 95s 1s/step - loss: 1.4823 - accuracy: 0.4443 - val_loss: 1.5788 - val_accuracy: 0.3946
Epoch 31/100
82/82 [==============================] - ETA: 0s - loss: 1.4748 - accuracy: 0.4509
Epoch 31: val_loss did not improve from 1.57192
82/82 [==============================] - 93s 1s/step - loss: 1.4748 - accuracy: 0.4509 - val_loss: 1.5845 - val_accuracy: 0.3975
Epoch 32/100
82/82 [==============================] - ETA: 0s - loss: 1.4694 - accuracy: 0.4554
Epoch 32: val_loss did not improve from 1.57192
82/82 [==============================] - 95s 1s/step - loss: 1.4694 - accuracy: 0.4554 - val_loss: 1.5905 - val_accuracy: 0.3945
Epoch 32: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_5 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_17 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_5 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_5 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_15 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_15 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_16 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_16 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_17 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_17 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_15 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_5 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_15 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_16 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_16 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_17 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 131s 10ms/step - loss: 1.5741 - accuracy: 0.3970
Testing Loss = 1.574093, Testing Accuracy = 0.396973
The data set contains images
  13212/Unknown - 124s 9ms/step13216/13216 [==============================] - 124s 9ms/step
[[0.07839148491621017, 0.06509392708539963, 0.3561640679836273, 0.08217629790306091, 0.22153739631175995, 0.1966368705034256], [0.08778698742389679, 0.1413881778717041, 0.11964840441942215, 0.2914200723171234, 0.16024135053157806, 0.1995149850845337], [0.08878275752067566, 0.27445873618125916, 0.11502785980701447, 0.1661936193704605, 0.12801972031593323, 0.2275172621011734], [0.34419307112693787, 0.03031427599489689, 0.12113277614116669, 0.1684107780456543, 0.25149232149124146, 0.08445681631565094], [0.3959959149360657, 0.019933022558689117, 0.16512948274612427, 0.07921425253152847, 0.2754913866519928, 0.06423595547676086], [0.051636479794979095, 0.33102139830589294, 0.1530768722295761, 0.1143285259604454, 0.0939551293849945, 0.25598159432411194], [0.4017074406147003, 0.016291679814457893, 0.14569008350372314, 0.0857214629650116, 0.2891339361667633, 0.06145544722676277], [0.01047745905816555, 0.6418237090110779, 0.04517441242933273, 0.07197840511798859, 0.025497054681181908, 0.20504888892173767], [0.3961713910102844, 0.055401891469955444, 0.09156490862369537, 0.17280715703964233, 0.2007501870393753, 0.0833045244216919], [0.32269492745399475, 0.047458089888095856, 0.061691273003816605, 0.2956855297088623, 0.18975037336349487, 0.08271975815296173]]
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
02 - accuracy: 0.2006     82/Unknown - 88s 1s/step - loss: 12.5255 - accuracy: 0.2006
Epoch 1: val_loss improved from inf to 8.83294, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 96s 1s/step - loss: 12.5255 - accuracy: 0.2006 - val_loss: 8.8329 - val_accuracy: 0.2097
Epoch 2/100
82/82 [==============================] - ETA: 0s - loss: 6.8803 - accuracy: 0.2065
Epoch 2: val_loss improved from 8.83294 to 5.42595, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 95s 1s/step - loss: 6.8803 - accuracy: 0.2065 - val_loss: 5.4260 - val_accuracy: 0.2132
Epoch 3/100
82/82 [==============================] - ETA: 0s - loss: 4.6354 - accuracy: 0.2106
Epoch 3: val_loss improved from 5.42595 to 4.00929, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 97s 1s/step - loss: 4.6354 - accuracy: 0.2106 - val_loss: 4.0093 - val_accuracy: 0.2142
Epoch 4/100
82/82 [==============================] - ETA: 0s - loss: 3.5301 - accuracy: 0.2640
Epoch 4: val_loss improved from 4.00929 to 3.21182, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 96s 1s/step - loss: 3.5301 - accuracy: 0.2640 - val_loss: 3.2118 - val_accuracy: 0.2698
Epoch 5/100
82/82 [==============================] - ETA: 0s - loss: 2.9028 - accuracy: 0.2919
Epoch 5: val_loss improved from 3.21182 to 2.75302, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 97s 1s/step - loss: 2.9028 - accuracy: 0.2919 - val_loss: 2.7530 - val_accuracy: 0.2654
Epoch 6/100
82/82 [==============================] - ETA: 0s - loss: 2.5125 - accuracy: 0.3020
Epoch 6: val_loss improved from 2.75302 to 2.39009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 96s 1s/step - loss: 2.5125 - accuracy: 0.3020 - val_loss: 2.3901 - val_accuracy: 0.2993
Epoch 7/100
82/82 [==============================] - ETA: 0s - loss: 2.2431 - accuracy: 0.3137
Epoch 7: val_loss improved from 2.39009 to 2.14862, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 94s 1s/step - loss: 2.2431 - accuracy: 0.3137 - val_loss: 2.1486 - val_accuracy: 0.3168
Epoch 8/100
82/82 [==============================] - ETA: 0s - loss: 2.0544 - accuracy: 0.3178
Epoch 8: val_loss improved from 2.14862 to 1.97861, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 95s 1s/step - loss: 2.0544 - accuracy: 0.3178 - val_loss: 1.9786 - val_accuracy: 0.3255
Epoch 9/100
82/82 [==============================] - ETA: 0s - loss: 1.9209 - accuracy: 0.3251
Epoch 9: val_loss improved from 1.97861 to 1.86127, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 94s 1s/step - loss: 1.9209 - accuracy: 0.3251 - val_loss: 1.8613 - val_accuracy: 0.3356
Epoch 10/100
82/82 [==============================] - ETA: 0s - loss: 1.8227 - accuracy: 0.3350
Epoch 10: val_loss improved from 1.86127 to 1.79113, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 93s 1s/step - loss: 1.8227 - accuracy: 0.3350 - val_loss: 1.7911 - val_accuracy: 0.3280
Epoch 11/100
82/82 [==============================] - ETA: 0s - loss: 1.7555 - accuracy: 0.3417
Epoch 11: val_loss improved from 1.79113 to 1.72351, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 93s 1s/step - loss: 1.7555 - accuracy: 0.3417 - val_loss: 1.7235 - val_accuracy: 0.3485
Epoch 12/100
82/82 [==============================] - ETA: 0s - loss: 1.7039 - accuracy: 0.3499
Epoch 12: val_loss improved from 1.72351 to 1.68231, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 95s 1s/step - loss: 1.7039 - accuracy: 0.3499 - val_loss: 1.6823 - val_accuracy: 0.3532
Epoch 13/100
82/82 [==============================] - ETA: 0s - loss: 1.6670 - accuracy: 0.3569
Epoch 13: val_loss improved from 1.68231 to 1.65364, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 93s 1s/step - loss: 1.6670 - accuracy: 0.3569 - val_loss: 1.6536 - val_accuracy: 0.3594
Epoch 14/100
82/82 [==============================] - ETA: 0s - loss: 1.6367 - accuracy: 0.3661
Epoch 14: val_loss improved from 1.65364 to 1.62600, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 93s 1s/step - loss: 1.6367 - accuracy: 0.3661 - val_loss: 1.6260 - val_accuracy: 0.3687
Epoch 15/100
82/82 [==============================] - ETA: 0s - loss: 1.6104 - accuracy: 0.3747
Epoch 15: val_loss improved from 1.62600 to 1.61044, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 95s 1s/step - loss: 1.6104 - accuracy: 0.3747 - val_loss: 1.6104 - val_accuracy: 0.3755
Epoch 16/100
82/82 [==============================] - ETA: 0s - loss: 1.5922 - accuracy: 0.3822
Epoch 16: val_loss improved from 1.61044 to 1.60064, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 94s 1s/step - loss: 1.5922 - accuracy: 0.3822 - val_loss: 1.6006 - val_accuracy: 0.3773
Epoch 17/100
82/82 [==============================] - ETA: 0s - loss: 1.5762 - accuracy: 0.3879
Epoch 17: val_loss improved from 1.60064 to 1.58689, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 93s 1s/step - loss: 1.5762 - accuracy: 0.3879 - val_loss: 1.5869 - val_accuracy: 0.3807
Epoch 18/100
82/82 [==============================] - ETA: 0s - loss: 1.5660 - accuracy: 0.3930
Epoch 18: val_loss improved from 1.58689 to 1.58087, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 95s 1s/step - loss: 1.5660 - accuracy: 0.3930 - val_loss: 1.5809 - val_accuracy: 0.3827
Epoch 19/100
82/82 [==============================] - ETA: 0s - loss: 1.5525 - accuracy: 0.4000
Epoch 19: val_loss improved from 1.58087 to 1.57421, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 94s 1s/step - loss: 1.5525 - accuracy: 0.4000 - val_loss: 1.5742 - val_accuracy: 0.3874
Epoch 20/100
82/82 [==============================] - ETA: 0s - loss: 1.5470 - accuracy: 0.4047
Epoch 20: val_loss improved from 1.57421 to 1.57127, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 94s 1s/step - loss: 1.5470 - accuracy: 0.4047 - val_loss: 1.5713 - val_accuracy: 0.3875
Epoch 21/100
82/82 [==============================] - ETA: 0s - loss: 1.5357 - accuracy: 0.4094
Epoch 21: val_loss did not improve from 1.57127
82/82 [==============================] - 91s 1s/step - loss: 1.5357 - accuracy: 0.4094 - val_loss: 1.5735 - val_accuracy: 0.3845
Epoch 22/100
82/82 [==============================] - ETA: 0s - loss: 1.5294 - accuracy: 0.4141
Epoch 22: val_loss improved from 1.57127 to 1.56845, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 93s 1s/step - loss: 1.5294 - accuracy: 0.4141 - val_loss: 1.5685 - val_accuracy: 0.3891
Epoch 23/100
82/82 [==============================] - ETA: 0s - loss: 1.5203 - accuracy: 0.4200
Epoch 23: val_loss improved from 1.56845 to 1.56390, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/6
82/82 [==============================] - 95s 1s/step - loss: 1.5203 - accuracy: 0.4200 - val_loss: 1.5639 - val_accuracy: 0.3919
Epoch 24/100
82/82 [==============================] - ETA: 0s - loss: 1.5178 - accuracy: 0.4198
Epoch 24: val_loss did not improve from 1.56390
82/82 [==============================] - 92s 1s/step - loss: 1.5178 - accuracy: 0.4198 - val_loss: 1.5663 - val_accuracy: 0.3908
Epoch 25/100
82/82 [==============================] - ETA: 0s - loss: 1.5099 - accuracy: 0.4253
Epoch 25: val_loss did not improve from 1.56390
82/82 [==============================] - 91s 1s/step - loss: 1.5099 - accuracy: 0.4253 - val_loss: 1.5741 - val_accuracy: 0.3866
Epoch 26/100
82/82 [==============================] - ETA: 0s - loss: 1.5022 - accuracy: 0.4316
Epoch 26: val_loss did not improve from 1.56390
82/82 [==============================] - 91s 1s/step - loss: 1.5022 - accuracy: 0.4316 - val_loss: 1.5720 - val_accuracy: 0.3922
Epoch 27/100
82/82 [==============================] - ETA: 0s - loss: 1.4960 - accuracy: 0.4350
Epoch 27: val_loss did not improve from 1.56390
82/82 [==============================] - 93s 1s/step - loss: 1.4960 - accuracy: 0.4350 - val_loss: 1.5684 - val_accuracy: 0.3919
Epoch 28/100
82/82 [==============================] - ETA: 0s - loss: 1.4896 - accuracy: 0.4404
Epoch 28: val_loss did not improve from 1.56390
82/82 [==============================] - 91s 1s/step - loss: 1.4896 - accuracy: 0.4404 - val_loss: 1.5710 - val_accuracy: 0.3928
Epoch 29/100
82/82 [==============================] - ETA: 0s - loss: 1.4826 - accuracy: 0.4462
Epoch 29: val_loss did not improve from 1.56390
82/82 [==============================] - 93s 1s/step - loss: 1.4826 - accuracy: 0.4462 - val_loss: 1.5783 - val_accuracy: 0.3928
Epoch 30/100
82/82 [==============================] - ETA: 0s - loss: 1.4781 - accuracy: 0.4487
Epoch 30: val_loss did not improve from 1.56390
82/82 [==============================] - 91s 1s/step - loss: 1.4781 - accuracy: 0.4487 - val_loss: 1.5949 - val_accuracy: 0.3862
Epoch 31/100
82/82 [==============================] - ETA: 0s - loss: 1.4720 - accuracy: 0.4522
Epoch 31: val_loss did not improve from 1.56390
82/82 [==============================] - 90s 1s/step - loss: 1.4720 - accuracy: 0.4522 - val_loss: 1.5896 - val_accuracy: 0.3938
Epoch 32/100
82/82 [==============================] - ETA: 0s - loss: 1.4643 - accuracy: 0.4587
Epoch 32: val_loss did not improve from 1.56390
82/82 [==============================] - 91s 1s/step - loss: 1.4643 - accuracy: 0.4587 - val_loss: 1.5886 - val_accuracy: 0.3946
Epoch 33/100
82/82 [==============================] - ETA: 0s - loss: 1.4567 - accuracy: 0.4633
Epoch 33: val_loss did not improve from 1.56390
82/82 [==============================] - 93s 1s/step - loss: 1.4567 - accuracy: 0.4633 - val_loss: 1.6006 - val_accuracy: 0.3923
Epoch 33: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_6 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_20 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_6 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_6 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_18 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_18 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_19 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_19 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_20 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_20 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_18 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_6 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_18 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_19 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_19 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_20 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 130s 10ms/step - loss: 1.5693 - accuracy: 0.3941
Testing Loss = 1.569281, Testing Accuracy = 0.394098
The data set contains images
  13213/Unknown - 125s 9ms/step13216/13216 [==============================] - 125s 9ms/step
[[0.05609290674328804, 0.041437748819589615, 0.4285423755645752, 0.06605342775583267, 0.2201131284236908, 0.18776042759418488], [0.07411118596792221, 0.09529299288988113, 0.1471652239561081, 0.2860981523990631, 0.18933816254138947, 0.20799431204795837], [0.06514012068510056, 0.2071705460548401, 0.1770169734954834, 0.14017319679260254, 0.15047208964824677, 0.26002708077430725], [0.2652645409107208, 0.03802354633808136, 0.13786698877811432, 0.18594740331172943, 0.2680850923061371, 0.10481244325637817], [0.3924819231033325, 0.01596231199800968, 0.16700564324855804, 0.07128015160560608, 0.2934110760688782, 0.05985887348651886], [0.039778079837560654, 0.2778884172439575, 0.19797933101654053, 0.10290868580341339, 0.1023937314748764, 0.2790517508983612], [0.37982842326164246, 0.01606057584285736, 0.14343836903572083, 0.09238418191671371, 0.3055988848209381, 0.0626896470785141], [0.007983214221894741, 0.7236860990524292, 0.02436903305351734, 0.08098260313272476, 0.018091747537255287, 0.1448872834444046], [0.3972732424736023, 0.06371767073869705, 0.07930266112089157, 0.18108265101909637, 0.1949312537908554, 0.0836925134062767], [0.3764817714691162, 0.03704734891653061, 0.06540916860103607, 0.24107567965984344, 0.20998093485832214, 0.0700051486492157]]
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
71 - accuracy: 0.1971     82/Unknown - 86s 1s/step - loss: 12.6126 - accuracy: 0.1970
Epoch 1: val_loss improved from inf to 8.94053, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 94s 1s/step - loss: 12.6126 - accuracy: 0.1970 - val_loss: 8.9405 - val_accuracy: 0.2132
Epoch 2/100
82/82 [==============================] - ETA: 0s - loss: 6.9718 - accuracy: 0.2042
Epoch 2: val_loss improved from 8.94053 to 5.49527, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 93s 1s/step - loss: 6.9718 - accuracy: 0.2042 - val_loss: 5.4953 - val_accuracy: 0.2138
Epoch 3/100
82/82 [==============================] - ETA: 0s - loss: 4.6892 - accuracy: 0.2095
Epoch 3: val_loss improved from 5.49527 to 4.05038, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 93s 1s/step - loss: 4.6892 - accuracy: 0.2095 - val_loss: 4.0504 - val_accuracy: 0.2136
Epoch 4/100
82/82 [==============================] - ETA: 0s - loss: 3.5717 - accuracy: 0.2567
Epoch 4: val_loss improved from 4.05038 to 3.23933, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 93s 1s/step - loss: 3.5717 - accuracy: 0.2567 - val_loss: 3.2393 - val_accuracy: 0.2578
Epoch 5/100
82/82 [==============================] - ETA: 0s - loss: 2.9203 - accuracy: 0.2958
Epoch 5: val_loss improved from 3.23933 to 2.75199, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 94s 1s/step - loss: 2.9203 - accuracy: 0.2958 - val_loss: 2.7520 - val_accuracy: 0.2749
Epoch 6/100
82/82 [==============================] - ETA: 0s - loss: 2.5250 - accuracy: 0.3048
Epoch 6: val_loss improved from 2.75199 to 2.40204, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 93s 1s/step - loss: 2.5250 - accuracy: 0.3048 - val_loss: 2.4020 - val_accuracy: 0.2975
Epoch 7/100
82/82 [==============================] - ETA: 0s - loss: 2.2521 - accuracy: 0.3131
Epoch 7: val_loss improved from 2.40204 to 2.16472, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 93s 1s/step - loss: 2.2521 - accuracy: 0.3131 - val_loss: 2.1647 - val_accuracy: 0.3078
Epoch 8/100
82/82 [==============================] - ETA: 0s - loss: 2.0609 - accuracy: 0.3221
Epoch 8: val_loss improved from 2.16472 to 1.98621, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 93s 1s/step - loss: 2.0609 - accuracy: 0.3221 - val_loss: 1.9862 - val_accuracy: 0.3216
Epoch 9/100
82/82 [==============================] - ETA: 0s - loss: 1.9266 - accuracy: 0.3241
Epoch 9: val_loss improved from 1.98621 to 1.86947, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 93s 1s/step - loss: 1.9266 - accuracy: 0.3241 - val_loss: 1.8695 - val_accuracy: 0.3311
Epoch 10/100
82/82 [==============================] - ETA: 0s - loss: 1.8305 - accuracy: 0.3302
Epoch 10: val_loss improved from 1.86947 to 1.79315, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 92s 1s/step - loss: 1.8305 - accuracy: 0.3302 - val_loss: 1.7932 - val_accuracy: 0.3325
Epoch 11/100
82/82 [==============================] - ETA: 0s - loss: 1.7618 - accuracy: 0.3369
Epoch 11: val_loss improved from 1.79315 to 1.74130, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 92s 1s/step - loss: 1.7618 - accuracy: 0.3369 - val_loss: 1.7413 - val_accuracy: 0.3335
Epoch 12/100
82/82 [==============================] - ETA: 0s - loss: 1.7107 - accuracy: 0.3429
Epoch 12: val_loss improved from 1.74130 to 1.68975, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 93s 1s/step - loss: 1.7107 - accuracy: 0.3429 - val_loss: 1.6897 - val_accuracy: 0.3463
Epoch 13/100
82/82 [==============================] - ETA: 0s - loss: 1.6753 - accuracy: 0.3515
Epoch 13: val_loss improved from 1.68975 to 1.66179, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 93s 1s/step - loss: 1.6753 - accuracy: 0.3515 - val_loss: 1.6618 - val_accuracy: 0.3490
Epoch 14/100
82/82 [==============================] - ETA: 0s - loss: 1.6468 - accuracy: 0.3589
Epoch 14: val_loss improved from 1.66179 to 1.63618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 92s 1s/step - loss: 1.6468 - accuracy: 0.3589 - val_loss: 1.6362 - val_accuracy: 0.3619
Epoch 15/100
82/82 [==============================] - ETA: 0s - loss: 1.6216 - accuracy: 0.3686
Epoch 15: val_loss improved from 1.63618 to 1.62054, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 93s 1s/step - loss: 1.6216 - accuracy: 0.3686 - val_loss: 1.6205 - val_accuracy: 0.3671
Epoch 16/100
82/82 [==============================] - ETA: 0s - loss: 1.6008 - accuracy: 0.3782
Epoch 16: val_loss improved from 1.62054 to 1.60206, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 94s 1s/step - loss: 1.6008 - accuracy: 0.3782 - val_loss: 1.6021 - val_accuracy: 0.3751
Epoch 17/100
82/82 [==============================] - ETA: 0s - loss: 1.5834 - accuracy: 0.3829
Epoch 17: val_loss improved from 1.60206 to 1.59313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 92s 1s/step - loss: 1.5834 - accuracy: 0.3829 - val_loss: 1.5931 - val_accuracy: 0.3806
Epoch 18/100
82/82 [==============================] - ETA: 0s - loss: 1.5704 - accuracy: 0.3913
Epoch 18: val_loss improved from 1.59313 to 1.58837, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 94s 1s/step - loss: 1.5704 - accuracy: 0.3913 - val_loss: 1.5884 - val_accuracy: 0.3805
Epoch 19/100
82/82 [==============================] - ETA: 0s - loss: 1.5592 - accuracy: 0.3967
Epoch 19: val_loss improved from 1.58837 to 1.57809, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 97s 1s/step - loss: 1.5592 - accuracy: 0.3967 - val_loss: 1.5781 - val_accuracy: 0.3868
Epoch 20/100
82/82 [==============================] - ETA: 0s - loss: 1.5505 - accuracy: 0.4011
Epoch 20: val_loss improved from 1.57809 to 1.57324, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 97s 1s/step - loss: 1.5505 - accuracy: 0.4011 - val_loss: 1.5732 - val_accuracy: 0.3890
Epoch 21/100
82/82 [==============================] - ETA: 0s - loss: 1.5436 - accuracy: 0.4017
Epoch 21: val_loss improved from 1.57324 to 1.57111, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 95s 1s/step - loss: 1.5436 - accuracy: 0.4017 - val_loss: 1.5711 - val_accuracy: 0.3905
Epoch 22/100
82/82 [==============================] - ETA: 0s - loss: 1.5363 - accuracy: 0.4101
Epoch 22: val_loss improved from 1.57111 to 1.57086, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 97s 1s/step - loss: 1.5363 - accuracy: 0.4101 - val_loss: 1.5709 - val_accuracy: 0.3876
Epoch 23/100
82/82 [==============================] - ETA: 0s - loss: 1.5270 - accuracy: 0.4157
Epoch 23: val_loss improved from 1.57086 to 1.56707, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 96s 1s/step - loss: 1.5270 - accuracy: 0.4157 - val_loss: 1.5671 - val_accuracy: 0.3916
Epoch 24/100
82/82 [==============================] - ETA: 0s - loss: 1.5196 - accuracy: 0.4172
Epoch 24: val_loss improved from 1.56707 to 1.56570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/7
82/82 [==============================] - 94s 1s/step - loss: 1.5196 - accuracy: 0.4172 - val_loss: 1.5657 - val_accuracy: 0.3903
Epoch 25/100
82/82 [==============================] - ETA: 0s - loss: 1.5135 - accuracy: 0.4228
Epoch 25: val_loss did not improve from 1.56570
82/82 [==============================] - 94s 1s/step - loss: 1.5135 - accuracy: 0.4228 - val_loss: 1.5720 - val_accuracy: 0.3878
Epoch 26/100
82/82 [==============================] - ETA: 0s - loss: 1.5096 - accuracy: 0.4271
Epoch 26: val_loss did not improve from 1.56570
82/82 [==============================] - 95s 1s/step - loss: 1.5096 - accuracy: 0.4271 - val_loss: 1.5717 - val_accuracy: 0.3893
Epoch 27/100
82/82 [==============================] - ETA: 0s - loss: 1.5029 - accuracy: 0.4284
Epoch 27: val_loss did not improve from 1.56570
82/82 [==============================] - 96s 1s/step - loss: 1.5029 - accuracy: 0.4284 - val_loss: 1.5716 - val_accuracy: 0.3897
Epoch 28/100
82/82 [==============================] - ETA: 0s - loss: 1.4956 - accuracy: 0.4331
Epoch 28: val_loss did not improve from 1.56570
82/82 [==============================] - 95s 1s/step - loss: 1.4956 - accuracy: 0.4331 - val_loss: 1.5824 - val_accuracy: 0.3875
Epoch 29/100
82/82 [==============================] - ETA: 0s - loss: 1.4941 - accuracy: 0.4350
Epoch 29: val_loss did not improve from 1.56570
82/82 [==============================] - 94s 1s/step - loss: 1.4941 - accuracy: 0.4350 - val_loss: 1.5761 - val_accuracy: 0.3877
Epoch 30/100
82/82 [==============================] - ETA: 0s - loss: 1.4841 - accuracy: 0.4411
Epoch 30: val_loss did not improve from 1.56570
82/82 [==============================] - 94s 1s/step - loss: 1.4841 - accuracy: 0.4411 - val_loss: 1.5766 - val_accuracy: 0.3912
Epoch 31/100
82/82 [==============================] - ETA: 0s - loss: 1.4796 - accuracy: 0.4498
Epoch 31: val_loss did not improve from 1.56570
82/82 [==============================] - 96s 1s/step - loss: 1.4796 - accuracy: 0.4498 - val_loss: 1.5851 - val_accuracy: 0.3921
Epoch 32/100
82/82 [==============================] - ETA: 0s - loss: 1.4703 - accuracy: 0.4512
Epoch 32: val_loss did not improve from 1.56570
82/82 [==============================] - 95s 1s/step - loss: 1.4703 - accuracy: 0.4512 - val_loss: 1.5876 - val_accuracy: 0.3938
Epoch 33/100
82/82 [==============================] - ETA: 0s - loss: 1.4674 - accuracy: 0.4546
Epoch 33: val_loss did not improve from 1.56570
82/82 [==============================] - 95s 1s/step - loss: 1.4674 - accuracy: 0.4546 - val_loss: 1.5860 - val_accuracy: 0.3941
Epoch 34/100
82/82 [==============================] - ETA: 0s - loss: 1.4572 - accuracy: 0.4630
Epoch 34: val_loss did not improve from 1.56570
82/82 [==============================] - 96s 1s/step - loss: 1.4572 - accuracy: 0.4630 - val_loss: 1.5945 - val_accuracy: 0.3936
Epoch 34: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_7 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_23 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_7 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_7 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_21 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_21 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_22 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_22 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_23 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_23 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_21 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_7 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_21 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_22 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_22 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_23 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 131s 10ms/step - loss: 1.5688 - accuracy: 0.3970
Testing Loss = 1.568799, Testing Accuracy = 0.397049
The data set contains images
  13212/Unknown - 121s 9ms/step13216/13216 [==============================] - 121s 9ms/step
[[0.05231968313455582, 0.06379532068967819, 0.40031522512435913, 0.07108201831579208, 0.19908589124679565, 0.2134018987417221], [0.10259834676980972, 0.11911269277334213, 0.09908143430948257, 0.34391313791275024, 0.16543138027191162, 0.1698630303144455], [0.0527416355907917, 0.23083533346652985, 0.18835152685642242, 0.1172851100564003, 0.1291234791278839, 0.28166282176971436], [0.3219190239906311, 0.03834916651248932, 0.12326101213693619, 0.17186453938484192, 0.2517249286174774, 0.09288132935762405], [0.39874714612960815, 0.017562825232744217, 0.16449128091335297, 0.06963852047920227, 0.28771159052848816, 0.06184869632124901], [0.03360740840435028, 0.21891102194786072, 0.2512981593608856, 0.08690442889928818, 0.10910876840353012, 0.30017027258872986], [0.41724589467048645, 0.017418861389160156, 0.12236164510250092, 0.09419423341751099, 0.2878706157207489, 0.060908734798431396], [0.009747270494699478, 0.6303150057792664, 0.03976694867014885, 0.0828474760055542, 0.02592681162059307, 0.21139656007289886], [0.424284428358078, 0.05717557296156883, 0.07441993057727814, 0.17412041127681732, 0.19149254262447357, 0.07850709557533264], [0.35833126306533813, 0.047510094940662384, 0.05512118339538574, 0.27775901556015015, 0.18551208078861237, 0.07576639205217361]]
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
92 - accuracy: 0.1969     82/Unknown - 88s 1s/step - loss: 12.5246 - accuracy: 0.1968
Epoch 1: val_loss improved from inf to 8.84696, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 96s 1s/step - loss: 12.5246 - accuracy: 0.1968 - val_loss: 8.8470 - val_accuracy: 0.2104
Epoch 2/100
82/82 [==============================] - ETA: 0s - loss: 6.8964 - accuracy: 0.2058
Epoch 2: val_loss improved from 8.84696 to 5.44203, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 96s 1s/step - loss: 6.8964 - accuracy: 0.2058 - val_loss: 5.4420 - val_accuracy: 0.2135
Epoch 3/100
82/82 [==============================] - ETA: 0s - loss: 4.6198 - accuracy: 0.2317
Epoch 3: val_loss improved from 5.44203 to 3.99521, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 95s 1s/step - loss: 4.6198 - accuracy: 0.2317 - val_loss: 3.9952 - val_accuracy: 0.2342
Epoch 4/100
82/82 [==============================] - ETA: 0s - loss: 3.5110 - accuracy: 0.2862
Epoch 4: val_loss improved from 3.99521 to 3.23457, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 97s 1s/step - loss: 3.5110 - accuracy: 0.2862 - val_loss: 3.2346 - val_accuracy: 0.2580
Epoch 5/100
82/82 [==============================] - ETA: 0s - loss: 2.9173 - accuracy: 0.2992
Epoch 5: val_loss improved from 3.23457 to 2.76082, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 96s 1s/step - loss: 2.9173 - accuracy: 0.2992 - val_loss: 2.7608 - val_accuracy: 0.2762
Epoch 6/100
82/82 [==============================] - ETA: 0s - loss: 2.5277 - accuracy: 0.3082
Epoch 6: val_loss improved from 2.76082 to 2.40708, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 94s 1s/step - loss: 2.5277 - accuracy: 0.3082 - val_loss: 2.4071 - val_accuracy: 0.3020
Epoch 7/100
82/82 [==============================] - ETA: 0s - loss: 2.2576 - accuracy: 0.3157
Epoch 7: val_loss improved from 2.40708 to 2.15717, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 94s 1s/step - loss: 2.2576 - accuracy: 0.3157 - val_loss: 2.1572 - val_accuracy: 0.3216
Epoch 8/100
82/82 [==============================] - ETA: 0s - loss: 2.0667 - accuracy: 0.3238
Epoch 8: val_loss improved from 2.15717 to 1.99162, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 94s 1s/step - loss: 2.0667 - accuracy: 0.3238 - val_loss: 1.9916 - val_accuracy: 0.3279
Epoch 9/100
82/82 [==============================] - ETA: 0s - loss: 1.9319 - accuracy: 0.3303
Epoch 9: val_loss improved from 1.99162 to 1.87872, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 93s 1s/step - loss: 1.9319 - accuracy: 0.3303 - val_loss: 1.8787 - val_accuracy: 0.3292
Epoch 10/100
82/82 [==============================] - ETA: 0s - loss: 1.8355 - accuracy: 0.3323
Epoch 10: val_loss improved from 1.87872 to 1.80104, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 94s 1s/step - loss: 1.8355 - accuracy: 0.3323 - val_loss: 1.8010 - val_accuracy: 0.3332
Epoch 11/100
82/82 [==============================] - ETA: 0s - loss: 1.7653 - accuracy: 0.3399
Epoch 11: val_loss improved from 1.80104 to 1.74529, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 94s 1s/step - loss: 1.7653 - accuracy: 0.3399 - val_loss: 1.7453 - val_accuracy: 0.3351
Epoch 12/100
82/82 [==============================] - ETA: 0s - loss: 1.7168 - accuracy: 0.3430
Epoch 12: val_loss improved from 1.74529 to 1.70520, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 94s 1s/step - loss: 1.7168 - accuracy: 0.3430 - val_loss: 1.7052 - val_accuracy: 0.3399
Epoch 13/100
82/82 [==============================] - ETA: 0s - loss: 1.6768 - accuracy: 0.3540
Epoch 13: val_loss improved from 1.70520 to 1.66890, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 95s 1s/step - loss: 1.6768 - accuracy: 0.3540 - val_loss: 1.6689 - val_accuracy: 0.3495
Epoch 14/100
82/82 [==============================] - ETA: 0s - loss: 1.6472 - accuracy: 0.3614
Epoch 14: val_loss improved from 1.66890 to 1.64316, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 94s 1s/step - loss: 1.6472 - accuracy: 0.3614 - val_loss: 1.6432 - val_accuracy: 0.3592
Epoch 15/100
82/82 [==============================] - ETA: 0s - loss: 1.6227 - accuracy: 0.3673
Epoch 15: val_loss improved from 1.64316 to 1.62135, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 95s 1s/step - loss: 1.6227 - accuracy: 0.3673 - val_loss: 1.6214 - val_accuracy: 0.3691
Epoch 16/100
82/82 [==============================] - ETA: 0s - loss: 1.6035 - accuracy: 0.3769
Epoch 16: val_loss improved from 1.62135 to 1.61048, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 97s 1s/step - loss: 1.6035 - accuracy: 0.3769 - val_loss: 1.6105 - val_accuracy: 0.3749
Epoch 17/100
82/82 [==============================] - ETA: 0s - loss: 1.5864 - accuracy: 0.3848
Epoch 17: val_loss improved from 1.61048 to 1.59997, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 97s 1s/step - loss: 1.5864 - accuracy: 0.3848 - val_loss: 1.6000 - val_accuracy: 0.3793
Epoch 18/100
82/82 [==============================] - ETA: 0s - loss: 1.5724 - accuracy: 0.3911
Epoch 18: val_loss improved from 1.59997 to 1.58908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 94s 1s/step - loss: 1.5724 - accuracy: 0.3911 - val_loss: 1.5891 - val_accuracy: 0.3813
Epoch 19/100
82/82 [==============================] - ETA: 0s - loss: 1.5621 - accuracy: 0.3981
Epoch 19: val_loss improved from 1.58908 to 1.58455, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 96s 1s/step - loss: 1.5621 - accuracy: 0.3981 - val_loss: 1.5845 - val_accuracy: 0.3832
Epoch 20/100
82/82 [==============================] - ETA: 0s - loss: 1.5531 - accuracy: 0.4023
Epoch 20: val_loss improved from 1.58455 to 1.57690, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 96s 1s/step - loss: 1.5531 - accuracy: 0.4023 - val_loss: 1.5769 - val_accuracy: 0.3874
Epoch 21/100
82/82 [==============================] - ETA: 0s - loss: 1.5422 - accuracy: 0.4071
Epoch 21: val_loss did not improve from 1.57690
82/82 [==============================] - 94s 1s/step - loss: 1.5422 - accuracy: 0.4071 - val_loss: 1.5790 - val_accuracy: 0.3856
Epoch 22/100
82/82 [==============================] - ETA: 0s - loss: 1.5355 - accuracy: 0.4088
Epoch 22: val_loss did not improve from 1.57690
82/82 [==============================] - 92s 1s/step - loss: 1.5355 - accuracy: 0.4088 - val_loss: 1.5801 - val_accuracy: 0.3854
Epoch 23/100
82/82 [==============================] - ETA: 0s - loss: 1.5282 - accuracy: 0.4115
Epoch 23: val_loss improved from 1.57690 to 1.57650, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 94s 1s/step - loss: 1.5282 - accuracy: 0.4115 - val_loss: 1.5765 - val_accuracy: 0.3881
Epoch 24/100
82/82 [==============================] - ETA: 0s - loss: 1.5192 - accuracy: 0.4205
Epoch 24: val_loss improved from 1.57650 to 1.57046, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/8
82/82 [==============================] - 95s 1s/step - loss: 1.5192 - accuracy: 0.4205 - val_loss: 1.5705 - val_accuracy: 0.3926
Epoch 25/100
82/82 [==============================] - ETA: 0s - loss: 1.5154 - accuracy: 0.4254
Epoch 25: val_loss did not improve from 1.57046
82/82 [==============================] - 93s 1s/step - loss: 1.5154 - accuracy: 0.4254 - val_loss: 1.5710 - val_accuracy: 0.3912
Epoch 26/100
82/82 [==============================] - ETA: 0s - loss: 1.5058 - accuracy: 0.4287
Epoch 26: val_loss did not improve from 1.57046
82/82 [==============================] - 92s 1s/step - loss: 1.5058 - accuracy: 0.4287 - val_loss: 1.5724 - val_accuracy: 0.3903
Epoch 27/100
82/82 [==============================] - ETA: 0s - loss: 1.4996 - accuracy: 0.4347
Epoch 27: val_loss did not improve from 1.57046
82/82 [==============================] - 93s 1s/step - loss: 1.4996 - accuracy: 0.4347 - val_loss: 1.5722 - val_accuracy: 0.3912
Epoch 28/100
82/82 [==============================] - ETA: 0s - loss: 1.4941 - accuracy: 0.4374
Epoch 28: val_loss did not improve from 1.57046
82/82 [==============================] - 93s 1s/step - loss: 1.4941 - accuracy: 0.4374 - val_loss: 1.5730 - val_accuracy: 0.3937
Epoch 29/100
82/82 [==============================] - ETA: 0s - loss: 1.4887 - accuracy: 0.4414
Epoch 29: val_loss did not improve from 1.57046
82/82 [==============================] - 93s 1s/step - loss: 1.4887 - accuracy: 0.4414 - val_loss: 1.5818 - val_accuracy: 0.3938
Epoch 30/100
82/82 [==============================] - ETA: 0s - loss: 1.4850 - accuracy: 0.4431
Epoch 30: val_loss did not improve from 1.57046
82/82 [==============================] - 93s 1s/step - loss: 1.4850 - accuracy: 0.4431 - val_loss: 1.5954 - val_accuracy: 0.3881
Epoch 31/100
82/82 [==============================] - ETA: 0s - loss: 1.4781 - accuracy: 0.4490
Epoch 31: val_loss did not improve from 1.57046
82/82 [==============================] - 93s 1s/step - loss: 1.4781 - accuracy: 0.4490 - val_loss: 1.5828 - val_accuracy: 0.3938
Epoch 32/100
82/82 [==============================] - ETA: 0s - loss: 1.4718 - accuracy: 0.4565
Epoch 32: val_loss did not improve from 1.57046
82/82 [==============================] - 94s 1s/step - loss: 1.4718 - accuracy: 0.4565 - val_loss: 1.5994 - val_accuracy: 0.3874
Epoch 33/100
82/82 [==============================] - ETA: 0s - loss: 1.4635 - accuracy: 0.4606
Epoch 33: val_loss did not improve from 1.57046
82/82 [==============================] - 94s 1s/step - loss: 1.4635 - accuracy: 0.4606 - val_loss: 1.5949 - val_accuracy: 0.3945
Epoch 34/100
82/82 [==============================] - ETA: 0s - loss: 1.4570 - accuracy: 0.4650
Epoch 34: val_loss did not improve from 1.57046
82/82 [==============================] - 95s 1s/step - loss: 1.4570 - accuracy: 0.4650 - val_loss: 1.6121 - val_accuracy: 0.3907
Epoch 34: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_8 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_26 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_8 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_8 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_24 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_24 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_25 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_25 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_26 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_26 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_24 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_8 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_24 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_25 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_25 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_26 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 128s 10ms/step - loss: 1.5702 - accuracy: 0.3967
Testing Loss = 1.570153, Testing Accuracy = 0.396670
The data set contains images
  13212/Unknown - 128s 10ms/step13216/13216 [==============================] - 128s 10ms/step
[[0.052760474383831024, 0.05374738946557045, 0.43045052886009216, 0.06275390088558197, 0.20111440122127533, 0.19917328655719757], [0.09665770828723907, 0.11718528717756271, 0.10254166275262833, 0.3355070948600769, 0.17138928174972534, 0.17671895027160645], [0.05208977684378624, 0.2030123770236969, 0.21975596249103546, 0.10325747728347778, 0.13809999823570251, 0.2837844491004944], [0.3547298014163971, 0.022727442905306816, 0.12314148992300034, 0.14093732833862305, 0.28164440393447876, 0.07681948691606522], [0.38204994797706604, 0.01328168623149395, 0.17876853048801422, 0.062237877398729324, 0.3049580454826355, 0.05870389938354492], [0.033420488238334656, 0.2944401204586029, 0.19299668073654175, 0.08923366665840149, 0.09044324606657028, 0.29946577548980713], [0.3720363974571228, 0.01747368462383747, 0.14060112833976746, 0.09907365590333939, 0.3011172413825989, 0.06969792395830154], [0.008607329800724983, 0.6794549226760864, 0.0310163926333189, 0.07266237586736679, 0.020308244973421097, 0.1879507452249527], [0.38950464129447937, 0.06253307312726974, 0.08038204908370972, 0.18727797269821167, 0.1929764449596405, 0.0873258039355278], [0.2912183105945587, 0.051777664572000504, 0.05527503788471222, 0.3313034474849701, 0.18703006207942963, 0.08339544385671616]]
The data set contains images
The data set contains images
Number of training datasets: 42286.
Epoch 1/100
90 - accuracy: 0.1986     82/Unknown - 89s 1s/step - loss: 12.5546 - accuracy: 0.1985
Epoch 1: val_loss improved from inf to 8.88774, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 97s 1s/step - loss: 12.5546 - accuracy: 0.1985 - val_loss: 8.8877 - val_accuracy: 0.2100
Epoch 2/100
82/82 [==============================] - ETA: 0s - loss: 6.9332 - accuracy: 0.2055
Epoch 2: val_loss improved from 8.88774 to 5.46849, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 100s 1s/step - loss: 6.9332 - accuracy: 0.2055 - val_loss: 5.4685 - val_accuracy: 0.2113
Epoch 3/100
82/82 [==============================] - ETA: 0s - loss: 4.6522 - accuracy: 0.2249
Epoch 3: val_loss improved from 5.46849 to 4.03482, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 100s 1s/step - loss: 4.6522 - accuracy: 0.2249 - val_loss: 4.0348 - val_accuracy: 0.2294
Epoch 4/100
82/82 [==============================] - ETA: 0s - loss: 3.5214 - accuracy: 0.2857
Epoch 4: val_loss improved from 4.03482 to 3.24020, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 99s 1s/step - loss: 3.5214 - accuracy: 0.2857 - val_loss: 3.2402 - val_accuracy: 0.2682
Epoch 5/100
82/82 [==============================] - ETA: 0s - loss: 2.9212 - accuracy: 0.2989
Epoch 5: val_loss improved from 3.24020 to 2.75030, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 99s 1s/step - loss: 2.9212 - accuracy: 0.2989 - val_loss: 2.7503 - val_accuracy: 0.2863
Epoch 6/100
82/82 [==============================] - ETA: 0s - loss: 2.5289 - accuracy: 0.3101
Epoch 6: val_loss improved from 2.75030 to 2.40421, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 97s 1s/step - loss: 2.5289 - accuracy: 0.3101 - val_loss: 2.4042 - val_accuracy: 0.3062
Epoch 7/100
82/82 [==============================] - ETA: 0s - loss: 2.2562 - accuracy: 0.3182
Epoch 7: val_loss improved from 2.40421 to 2.15865, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 95s 1s/step - loss: 2.2562 - accuracy: 0.3182 - val_loss: 2.1587 - val_accuracy: 0.3189
Epoch 8/100
82/82 [==============================] - ETA: 0s - loss: 2.0669 - accuracy: 0.3195
Epoch 8: val_loss improved from 2.15865 to 1.99474, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 93s 1s/step - loss: 2.0669 - accuracy: 0.3195 - val_loss: 1.9947 - val_accuracy: 0.3262
Epoch 9/100
82/82 [==============================] - ETA: 0s - loss: 1.9344 - accuracy: 0.3237
Epoch 9: val_loss improved from 1.99474 to 1.87889, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 93s 1s/step - loss: 1.9344 - accuracy: 0.3237 - val_loss: 1.8789 - val_accuracy: 0.3293
Epoch 10/100
82/82 [==============================] - ETA: 0s - loss: 1.8340 - accuracy: 0.3355
Epoch 10: val_loss improved from 1.87889 to 1.79853, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 94s 1s/step - loss: 1.8340 - accuracy: 0.3355 - val_loss: 1.7985 - val_accuracy: 0.3313
Epoch 11/100
82/82 [==============================] - ETA: 0s - loss: 1.7641 - accuracy: 0.3397
Epoch 11: val_loss improved from 1.79853 to 1.74007, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 95s 1s/step - loss: 1.7641 - accuracy: 0.3397 - val_loss: 1.7401 - val_accuracy: 0.3425
Epoch 12/100
82/82 [==============================] - ETA: 0s - loss: 1.7122 - accuracy: 0.3468
Epoch 12: val_loss improved from 1.74007 to 1.70156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 95s 1s/step - loss: 1.7122 - accuracy: 0.3468 - val_loss: 1.7016 - val_accuracy: 0.3448
Epoch 13/100
82/82 [==============================] - ETA: 0s - loss: 1.6767 - accuracy: 0.3555
Epoch 13: val_loss improved from 1.70156 to 1.66450, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 93s 1s/step - loss: 1.6767 - accuracy: 0.3555 - val_loss: 1.6645 - val_accuracy: 0.3559
Epoch 14/100
82/82 [==============================] - ETA: 0s - loss: 1.6465 - accuracy: 0.3606
Epoch 14: val_loss improved from 1.66450 to 1.64530, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 95s 1s/step - loss: 1.6465 - accuracy: 0.3606 - val_loss: 1.6453 - val_accuracy: 0.3566
Epoch 15/100
82/82 [==============================] - ETA: 0s - loss: 1.6223 - accuracy: 0.3699
Epoch 15: val_loss improved from 1.64530 to 1.62320, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 94s 1s/step - loss: 1.6223 - accuracy: 0.3699 - val_loss: 1.6232 - val_accuracy: 0.3662
Epoch 16/100
82/82 [==============================] - ETA: 0s - loss: 1.6019 - accuracy: 0.3762
Epoch 16: val_loss improved from 1.62320 to 1.60740, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 95s 1s/step - loss: 1.6019 - accuracy: 0.3762 - val_loss: 1.6074 - val_accuracy: 0.3738
Epoch 17/100
82/82 [==============================] - ETA: 0s - loss: 1.5845 - accuracy: 0.3870
Epoch 17: val_loss improved from 1.60740 to 1.59868, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 94s 1s/step - loss: 1.5845 - accuracy: 0.3870 - val_loss: 1.5987 - val_accuracy: 0.3788
Epoch 18/100
82/82 [==============================] - ETA: 0s - loss: 1.5732 - accuracy: 0.3908
Epoch 18: val_loss improved from 1.59868 to 1.58936, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 94s 1s/step - loss: 1.5732 - accuracy: 0.3908 - val_loss: 1.5894 - val_accuracy: 0.3849
Epoch 19/100
82/82 [==============================] - ETA: 0s - loss: 1.5620 - accuracy: 0.3951
Epoch 19: val_loss improved from 1.58936 to 1.58789, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 95s 1s/step - loss: 1.5620 - accuracy: 0.3951 - val_loss: 1.5879 - val_accuracy: 0.3820
Epoch 20/100
82/82 [==============================] - ETA: 0s - loss: 1.5522 - accuracy: 0.4021
Epoch 20: val_loss improved from 1.58789 to 1.58294, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 95s 1s/step - loss: 1.5522 - accuracy: 0.4021 - val_loss: 1.5829 - val_accuracy: 0.3852
Epoch 21/100
82/82 [==============================] - ETA: 0s - loss: 1.5401 - accuracy: 0.4078
Epoch 21: val_loss improved from 1.58294 to 1.58099, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 93s 1s/step - loss: 1.5401 - accuracy: 0.4078 - val_loss: 1.5810 - val_accuracy: 0.3882
Epoch 22/100
82/82 [==============================] - ETA: 0s - loss: 1.5347 - accuracy: 0.4131
Epoch 22: val_loss improved from 1.58099 to 1.57518, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.23/Try/9
82/82 [==============================] - 94s 1s/step - loss: 1.5347 - accuracy: 0.4131 - val_loss: 1.5752 - val_accuracy: 0.3884
Epoch 23/100
82/82 [==============================] - ETA: 0s - loss: 1.5256 - accuracy: 0.4158
Epoch 23: val_loss did not improve from 1.57518
82/82 [==============================] - 92s 1s/step - loss: 1.5256 - accuracy: 0.4158 - val_loss: 1.5772 - val_accuracy: 0.3892
Epoch 24/100
82/82 [==============================] - ETA: 0s - loss: 1.5202 - accuracy: 0.4216
Epoch 24: val_loss did not improve from 1.57518
82/82 [==============================] - 92s 1s/step - loss: 1.5202 - accuracy: 0.4216 - val_loss: 1.5797 - val_accuracy: 0.3909
Epoch 25/100
82/82 [==============================] - ETA: 0s - loss: 1.5119 - accuracy: 0.4254
Epoch 25: val_loss did not improve from 1.57518
82/82 [==============================] - 91s 1s/step - loss: 1.5119 - accuracy: 0.4254 - val_loss: 1.5815 - val_accuracy: 0.3875
Epoch 26/100
82/82 [==============================] - ETA: 0s - loss: 1.5055 - accuracy: 0.4324
Epoch 26: val_loss did not improve from 1.57518
82/82 [==============================] - 93s 1s/step - loss: 1.5055 - accuracy: 0.4324 - val_loss: 1.5846 - val_accuracy: 0.3906
Epoch 27/100
82/82 [==============================] - ETA: 0s - loss: 1.4990 - accuracy: 0.4341
Epoch 27: val_loss did not improve from 1.57518
82/82 [==============================] - 92s 1s/step - loss: 1.4990 - accuracy: 0.4341 - val_loss: 1.5804 - val_accuracy: 0.3907
Epoch 28/100
82/82 [==============================] - ETA: 0s - loss: 1.4909 - accuracy: 0.4428
Epoch 28: val_loss did not improve from 1.57518
82/82 [==============================] - 92s 1s/step - loss: 1.4909 - accuracy: 0.4428 - val_loss: 1.5846 - val_accuracy: 0.3893
Epoch 29/100
82/82 [==============================] - ETA: 0s - loss: 1.4840 - accuracy: 0.4460
Epoch 29: val_loss did not improve from 1.57518
82/82 [==============================] - 92s 1s/step - loss: 1.4840 - accuracy: 0.4460 - val_loss: 1.5868 - val_accuracy: 0.3921
Epoch 30/100
82/82 [==============================] - ETA: 0s - loss: 1.4755 - accuracy: 0.4533
Epoch 30: val_loss did not improve from 1.57518
82/82 [==============================] - 92s 1s/step - loss: 1.4755 - accuracy: 0.4533 - val_loss: 1.5941 - val_accuracy: 0.3939
Epoch 31/100
82/82 [==============================] - ETA: 0s - loss: 1.4683 - accuracy: 0.4556
Epoch 31: val_loss did not improve from 1.57518
82/82 [==============================] - 93s 1s/step - loss: 1.4683 - accuracy: 0.4556 - val_loss: 1.6017 - val_accuracy: 0.3908
Epoch 32/100
82/82 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 0.4617
Epoch 32: val_loss did not improve from 1.57518
82/82 [==============================] - 93s 1s/step - loss: 1.4617 - accuracy: 0.4617 - val_loss: 1.6019 - val_accuracy: 0.3919
Epoch 32: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_9 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_29 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_9 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_9 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_27 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_27 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_28 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_28 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_29 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_29 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_27 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_9 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_27 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_28 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_28 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_29 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13215/13215 [==============================] - 129s 10ms/step - loss: 1.5769 - accuracy: 0.3908
Testing Loss = 1.576928, Testing Accuracy = 0.390844
The data set contains images
  13213/Unknown - 125s 9ms/step13216/13216 [==============================] - 125s 9ms/step
[[0.06875064969062805, 0.05797586590051651, 0.3732408285140991, 0.08023905754089355, 0.22014319896697998, 0.19965030252933502], [0.07230868190526962, 0.11360044777393341, 0.15283682942390442, 0.2728845179080963, 0.17468246817588806, 0.21368706226348877], [0.08003778755664825, 0.2862372398376465, 0.11810997873544693, 0.16049087047576904, 0.11786306649446487, 0.23726113140583038], [0.270671546459198, 0.02885287255048752, 0.15126949548721313, 0.16850750148296356, 0.2880533039569855, 0.0926453024148941], [0.38435718417167664, 0.013774322345852852, 0.1784273236989975, 0.06282676756381989, 0.30329516530036926, 0.057319220155477524], [0.036260269582271576, 0.31847065687179565, 0.1750863641500473, 0.09903835505247116, 0.08576439321041107, 0.2853800058364868], [0.406453937292099, 0.016834784299135208, 0.1308218240737915, 0.09302663058042526, 0.2924274504184723, 0.06043531373143196], [0.011734701693058014, 0.6048282980918884, 0.05758356302976608, 0.0746084600687027, 0.029111623764038086, 0.22213336825370789], [0.4552765488624573, 0.043537113815546036, 0.07707203179597855, 0.16203495860099792, 0.19006246328353882, 0.0720168724656105], [0.3110058009624481, 0.0482950322329998, 0.0598883330821991, 0.3063663840293884, 0.18988223373889923, 0.0845622643828392]]
N of classes 6
$W^+/W^+$ (auc = 84.50 +- 0.0904 %)
$W^-/W^-$ (auc = 83.65 +- 0.1041 %)
$Z/Z$ (auc = 77.08 +- 0.3501 %)
$W^+/W^-$ (auc = 70.96 +- 0.2553 %)
$W^+/Z$ (auc = 67.50 +- 0.1700 %)
$W^-/Z$ (auc = 68.85 +- 0.1058 %)
N of classes 6
$W^+/W^+$ (acc = 40.46 +- 0.7892 %
$W^-/W^-$ (acc = 46.58 +- 0.6433 %
$Z/Z$ (acc = 46.50 +- 0.9328 %
$W^+/W^-$ (acc = 34.16 +- 1.0628 %
$W^+/Z$ (acc = 30.55 +- 0.6727 %
$W^-/Z$ (acc = 31.75 +- 0.5571 %
The summarized testing accuracy = 39.57 +- 0.2878 %, with the loss = 1.5724 +- 0.003505
