

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2023-02-14 11:05:13.695475
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.792, val acc= 18.35% |
Epoch 1: val_loss improved from inf to 1.7920, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.663, val acc= 27.53% |
Epoch 2: val_loss improved from 1.7920 to 1.6631, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.636, val acc= 30.58% |
Epoch 3: val_loss improved from 1.6631 to 1.6364, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.587, val acc= 31.65% |
Epoch 4: val_loss improved from 1.6364 to 1.5872, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.618, val acc= 31.95% |
Epoch   5: val_loss did not improve from 1.5872. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.551, val acc= 32.20% |
Epoch 6: val_loss improved from 1.5872 to 1.5505, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.593, val acc= 32.64% |
Epoch   7: val_loss did not improve from 1.5505. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.505, val acc= 32.97% |
Epoch 8: val_loss improved from 1.5505 to 1.5048, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.530, val acc= 34.10% |
Epoch   9: val_loss did not improve from 1.5048. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.497, val acc= 34.70% |
Epoch 10: val_loss improved from 1.5048 to 1.4973, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.518, val acc= 35.57% |
Epoch  11: val_loss did not improve from 1.4973. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.458, val acc= 35.69% |
Epoch 12: val_loss improved from 1.4973 to 1.4575, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.563, val acc= 36.58% |
Epoch  13: val_loss did not improve from 1.4575. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.429, val acc= 37.61% |
Epoch 14: val_loss improved from 1.4575 to 1.4290, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.525, val acc= 37.69% |
Epoch  15: val_loss did not improve from 1.4290. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.538, val acc= 38.75% |
Epoch  16: val_loss did not improve from 1.4290. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.519, val acc= 38.37% |
Epoch  17: val_loss did not improve from 1.4290. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.472, val acc= 38.62% |
Epoch  18: val_loss did not improve from 1.4290. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.470, val acc= 38.65% |
Epoch  19: val_loss did not improve from 1.4290. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.550, val acc= 38.99% |
Epoch  20: val_loss did not improve from 1.4290. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.608, val acc= 38.72% |
Epoch  21: val_loss did not improve from 1.4290. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.584, val acc= 39.46% |
Epoch  22: val_loss did not improve from 1.4290. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.534, val acc= 39.29% |
Epoch  23: val_loss did not improve from 1.4290. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.536, val acc= 39.38% |
Epoch  24: val_loss did not improve from 1.4290. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 3.124, test acc= 37.30% |
Finished Training
N of classes 6
$W^+/W^+$ (auc = 82.61 +- 0.0000 %)
$W^-/W^-$ (auc = 81.72 +- 0.0000 %)
$Z/Z$ (auc = 72.97 +- 0.0000 %)
$W^+/W^-$ (auc = 66.73 +- 0.0000 %)
$W^+/Z$ (auc = 67.39 +- 0.0000 %)
$W^-/Z$ (auc = 66.89 +- 0.0000 %)
N of classes 6
$W^+/W^+$ (acc = 43.89 +- 0.0000 %
$W^-/W^-$ (acc = 43.52 +- 0.0000 %
$Z/Z$ (acc = 39.58 +- 0.0000 %
$W^+/W^-$ (acc = 32.60 +- 0.0000 %
$W^+/Z$ (acc = 28.03 +- 0.0000 %
$W^-/Z$ (acc = 27.28 +- 0.0000 %
The summarized testing accuracy = 37.30 +- 0.0000 %, with the loss = 3.1245 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2023-02-20 00:59:35.627881
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.553, val acc= 34.14% |
Epoch 1: val_loss improved from inf to 1.5527, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.356, val acc= 39.06% |
Epoch 2: val_loss improved from 1.5527 to 1.3565, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.374, val acc= 40.57% |
Epoch   3: val_loss did not improve from 1.3565. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.391, val acc= 41.14% |
Epoch   4: val_loss did not improve from 1.3565. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.393, val acc= 42.05% |
Epoch   5: val_loss did not improve from 1.3565. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.281, val acc= 42.64% |
Epoch 6: val_loss improved from 1.3565 to 1.2807, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.441, val acc= 42.38% |
Epoch   7: val_loss did not improve from 1.2807. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.476, val acc= 41.35% |
Epoch   8: val_loss did not improve from 1.2807. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.530, val acc= 39.49% |
Epoch   9: val_loss did not improve from 1.2807. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.754, val acc= 38.80% |
Epoch  10: val_loss did not improve from 1.2807. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.168, val acc= 38.79% |
Epoch  11: val_loss did not improve from 1.2807. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2807. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2807. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2807. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.2807. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.2807. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.338, test acc= 42.72% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.511, val acc= 33.21% |
Epoch 1: val_loss improved from inf to 1.5111, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/1
VALIDATION:   kappa = 1.05000     | val loss= 1.431, val acc= 37.31% |
Epoch 2: val_loss improved from 1.5111 to 1.4315, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/1
VALIDATION:   kappa = 1.05000     | val loss= 1.420, val acc= 40.37% |
Epoch 3: val_loss improved from 1.4315 to 1.4202, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/1
VALIDATION:   kappa = 1.05000     | val loss= 1.329, val acc= 42.00% |
Epoch 4: val_loss improved from 1.4202 to 1.3291, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/1
VALIDATION:   kappa = 1.05000     | val loss= 1.347, val acc= 42.08% |
Epoch   5: val_loss did not improve from 1.3291. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.322, val acc= 41.57% |
Epoch 6: val_loss improved from 1.3291 to 1.3218, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/1
VALIDATION:   kappa = 1.05000     | val loss= 1.408, val acc= 41.45% |
Epoch   7: val_loss did not improve from 1.3218. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.478, val acc= 40.79% |
Epoch   8: val_loss did not improve from 1.3218. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.557, val acc= 40.21% |
Epoch   9: val_loss did not improve from 1.3218. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.717, val acc= 39.13% |
Epoch  10: val_loss did not improve from 1.3218. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  11: val_loss did not improve from 1.3218. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.3218. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.3218. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.3218. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.3218. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.3218. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.440, test acc= 41.53% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.527, val acc= 32.46% |
Epoch 1: val_loss improved from inf to 1.5269, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/2
VALIDATION:   kappa = 1.05000     | val loss= 1.415, val acc= 37.70% |
Epoch 2: val_loss improved from 1.5269 to 1.4155, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/2
VALIDATION:   kappa = 1.05000     | val loss= 1.370, val acc= 40.34% |
Epoch 3: val_loss improved from 1.4155 to 1.3704, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/2
VALIDATION:   kappa = 1.05000     | val loss= 1.313, val acc= 41.11% |
Epoch 4: val_loss improved from 1.3704 to 1.3134, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/2
VALIDATION:   kappa = 1.05000     | val loss= 1.367, val acc= 41.99% |
Epoch   5: val_loss did not improve from 1.3134. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.300, val acc= 41.64% |
Epoch 6: val_loss improved from 1.3134 to 1.2999, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/2
VALIDATION:   kappa = 1.05000     | val loss= 1.310, val acc= 41.04% |
Epoch   7: val_loss did not improve from 1.2999. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.342, val acc= 40.51% |
Epoch   8: val_loss did not improve from 1.2999. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.456, val acc= 39.53% |
Epoch   9: val_loss did not improve from 1.2999. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.739, val acc= 39.08% |
Epoch  10: val_loss did not improve from 1.2999. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  11: val_loss did not improve from 1.2999. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2999. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2999. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2999. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.2999. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.2999. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.365, test acc= 41.92% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.579, val acc= 32.65% |
Epoch 1: val_loss improved from inf to 1.5795, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/3
VALIDATION:   kappa = 1.05000     | val loss= 1.413, val acc= 37.85% |
Epoch 2: val_loss improved from 1.5795 to 1.4125, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/3
VALIDATION:   kappa = 1.05000     | val loss= 1.416, val acc= 40.33% |
Epoch   3: val_loss did not improve from 1.4125. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.301, val acc= 41.88% |
Epoch 4: val_loss improved from 1.4125 to 1.3011, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/3
VALIDATION:   kappa = 1.05000     | val loss= 1.267, val acc= 42.24% |
Epoch 5: val_loss improved from 1.3011 to 1.2669, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/3
VALIDATION:   kappa = 1.05000     | val loss= 1.393, val acc= 41.65% |
Epoch   6: val_loss did not improve from 1.2669. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.284, val acc= 42.42% |
Epoch   7: val_loss did not improve from 1.2669. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.378, val acc= 41.88% |
Epoch   8: val_loss did not improve from 1.2669. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.633, val acc= 40.45% |
Epoch   9: val_loss did not improve from 1.2669. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.781, val acc= 39.61% |
Epoch  10: val_loss did not improve from 1.2669. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.154, val acc= 39.58% |
Epoch  11: val_loss did not improve from 1.2669. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.174, val acc= 38.40% |
Epoch  12: val_loss did not improve from 1.2669. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2669. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2669. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.2669. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.384, test acc= 42.64% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.514, val acc= 32.71% |
Epoch 1: val_loss improved from inf to 1.5138, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/4
VALIDATION:   kappa = 1.05000     | val loss= 1.403, val acc= 37.86% |
Epoch 2: val_loss improved from 1.5138 to 1.4028, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/4
VALIDATION:   kappa = 1.05000     | val loss= 1.330, val acc= 39.45% |
Epoch 3: val_loss improved from 1.4028 to 1.3295, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/4
VALIDATION:   kappa = 1.05000     | val loss= 1.280, val acc= 41.58% |
Epoch 4: val_loss improved from 1.3295 to 1.2798, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/4
VALIDATION:   kappa = 1.05000     | val loss= 1.301, val acc= 42.17% |
Epoch   5: val_loss did not improve from 1.2798. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.335, val acc= 42.02% |
Epoch   6: val_loss did not improve from 1.2798. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.298, val acc= 42.37% |
Epoch   7: val_loss did not improve from 1.2798. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.359, val acc= 41.33% |
Epoch   8: val_loss did not improve from 1.2798. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.446, val acc= 40.29% |
Epoch   9: val_loss did not improve from 1.2798. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.672, val acc= 39.74% |
Epoch  10: val_loss did not improve from 1.2798. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  11: val_loss did not improve from 1.2798. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2798. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2798. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2798. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.166, test acc= 41.72% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.566, val acc= 31.54% |
Epoch 1: val_loss improved from inf to 1.5657, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/5
VALIDATION:   kappa = 1.05000     | val loss= 1.474, val acc= 37.15% |
Epoch 2: val_loss improved from 1.5657 to 1.4738, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/5
VALIDATION:   kappa = 1.05000     | val loss= 1.378, val acc= 40.26% |
Epoch 3: val_loss improved from 1.4738 to 1.3775, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/5
VALIDATION:   kappa = 1.05000     | val loss= 1.425, val acc= 40.43% |
Epoch   4: val_loss did not improve from 1.3775. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.347, val acc= 42.16% |
Epoch 5: val_loss improved from 1.3775 to 1.3475, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/5
VALIDATION:   kappa = 1.05000     | val loss= 1.347, val acc= 41.93% |
Epoch 6: val_loss improved from 1.3475 to 1.3466, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/5
VALIDATION:   kappa = 1.05000     | val loss= 1.505, val acc= 41.12% |
Epoch   7: val_loss did not improve from 1.3466. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.481, val acc= 39.74% |
Epoch   8: val_loss did not improve from 1.3466. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.877, val acc= 39.12% |
Epoch   9: val_loss did not improve from 1.3466. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.953, val acc= 38.72% |
Epoch  10: val_loss did not improve from 1.3466. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  11: val_loss did not improve from 1.3466. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.3466. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.3466. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.3466. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.3466. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.3466. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.051, test acc= 42.13% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.594, val acc= 31.64% |
Epoch 1: val_loss improved from inf to 1.5938, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/6
VALIDATION:   kappa = 1.05000     | val loss= 1.442, val acc= 37.01% |
Epoch 2: val_loss improved from 1.5938 to 1.4423, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/6
VALIDATION:   kappa = 1.05000     | val loss= 1.350, val acc= 40.24% |
Epoch 3: val_loss improved from 1.4423 to 1.3503, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/6
VALIDATION:   kappa = 1.05000     | val loss= 1.362, val acc= 41.19% |
Epoch   4: val_loss did not improve from 1.3503. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.294, val acc= 42.36% |
Epoch 5: val_loss improved from 1.3503 to 1.2936, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/6
VALIDATION:   kappa = 1.05000     | val loss= 1.285, val acc= 42.57% |
Epoch 6: val_loss improved from 1.2936 to 1.2852, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/6
VALIDATION:   kappa = 1.05000     | val loss= 1.307, val acc= 41.20% |
Epoch   7: val_loss did not improve from 1.2852. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.430, val acc= 41.78% |
Epoch   8: val_loss did not improve from 1.2852. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.379, val acc= 40.27% |
Epoch   9: val_loss did not improve from 1.2852. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.621, val acc= 39.82% |
Epoch  10: val_loss did not improve from 1.2852. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.940, val acc= 38.36% |
Epoch  11: val_loss did not improve from 1.2852. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2852. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2852. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2852. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.2852. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.2852. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.099, test acc= 42.90% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.534, val acc= 32.79% |
Epoch 1: val_loss improved from inf to 1.5344, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/7
VALIDATION:   kappa = 1.05000     | val loss= 1.405, val acc= 37.53% |
Epoch 2: val_loss improved from 1.5344 to 1.4048, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/7
VALIDATION:   kappa = 1.05000     | val loss= 1.374, val acc= 39.28% |
Epoch 3: val_loss improved from 1.4048 to 1.3742, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/7
VALIDATION:   kappa = 1.05000     | val loss= 1.321, val acc= 41.47% |
Epoch 4: val_loss improved from 1.3742 to 1.3209, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/7
VALIDATION:   kappa = 1.05000     | val loss= 1.319, val acc= 42.73% |
Epoch 5: val_loss improved from 1.3209 to 1.3188, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/7
VALIDATION:   kappa = 1.05000     | val loss= 1.349, val acc= 41.70% |
Epoch   6: val_loss did not improve from 1.3188. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.399, val acc= 41.74% |
Epoch   7: val_loss did not improve from 1.3188. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.469, val acc= 40.91% |
Epoch   8: val_loss did not improve from 1.3188. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.513, val acc= 40.38% |
Epoch   9: val_loss did not improve from 1.3188. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.783, val acc= 38.86% |
Epoch  10: val_loss did not improve from 1.3188. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  11: val_loss did not improve from 1.3188. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.3188. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.3188. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.3188. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.3188. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.039, test acc= 42.96% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.516, val acc= 33.04% |
Epoch 1: val_loss improved from inf to 1.5159, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.453, val acc= 37.05% |
Epoch 2: val_loss improved from 1.5159 to 1.4534, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.409, val acc= 40.68% |
Epoch 3: val_loss improved from 1.4534 to 1.4086, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.420, val acc= 41.17% |
Epoch   4: val_loss did not improve from 1.4086. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.376, val acc= 42.26% |
Epoch 5: val_loss improved from 1.4086 to 1.3763, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.323, val acc= 42.51% |
Epoch 6: val_loss improved from 1.3763 to 1.3227, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.304, val acc= 41.93% |
Epoch 7: val_loss improved from 1.3227 to 1.3039, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.295, val acc= 41.68% |
Epoch 8: val_loss improved from 1.3039 to 1.2948, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.521, val acc= 40.38% |
Epoch   9: val_loss did not improve from 1.2948. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.537, val acc= 39.32% |
Epoch  10: val_loss did not improve from 1.2948. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  11: val_loss did not improve from 1.2948. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2948. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2948. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2948. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.2948. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.2948. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  17: val_loss did not improve from 1.2948. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  18: val_loss did not improve from 1.2948. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.021, test acc= 41.04% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.563, val acc= 31.65% |
Epoch 1: val_loss improved from inf to 1.5635, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/9
VALIDATION:   kappa = 1.05000     | val loss= 1.445, val acc= 36.98% |
Epoch 2: val_loss improved from 1.5635 to 1.4453, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/9
VALIDATION:   kappa = 1.05000     | val loss= 1.382, val acc= 38.79% |
Epoch 3: val_loss improved from 1.4453 to 1.3821, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/9
VALIDATION:   kappa = 1.05000     | val loss= 1.355, val acc= 41.26% |
Epoch 4: val_loss improved from 1.3821 to 1.3546, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/9
VALIDATION:   kappa = 1.05000     | val loss= 1.365, val acc= 40.89% |
Epoch   5: val_loss did not improve from 1.3546. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.343, val acc= 41.95% |
Epoch 6: val_loss improved from 1.3546 to 1.3428, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/9
VALIDATION:   kappa = 1.05000     | val loss= 1.298, val acc= 41.69% |
Epoch 7: val_loss improved from 1.3428 to 1.2977, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/9
VALIDATION:   kappa = 1.05000     | val loss= 1.282, val acc= 41.91% |
Epoch 8: val_loss improved from 1.2977 to 1.2819, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/9
VALIDATION:   kappa = 1.05000     | val loss= 1.396, val acc= 39.49% |
Epoch   9: val_loss did not improve from 1.2819. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.596, val acc= 39.59% |
Epoch  10: val_loss did not improve from 1.2819. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.755, val acc= 39.08% |
Epoch  11: val_loss did not improve from 1.2819. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2819. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2819. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2819. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.2819. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.2819. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  17: val_loss did not improve from 1.2819. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  18: val_loss did not improve from 1.2819. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.022, test acc= 41.84% |
Finished Training
N of classes 6
$W^+/W^+$ (auc = 84.46 +- 0.4947 %)
$W^-/W^-$ (auc = 83.59 +- 0.6200 %)
$Z/Z$ (auc = 80.23 +- 0.5522 %)
$W^+/W^-$ (auc = 71.82 +- 0.6066 %)
$W^+/Z$ (auc = 69.74 +- 0.4844 %)
$W^-/Z$ (auc = 69.83 +- 0.3424 %)
N of classes 6
$W^+/W^+$ (acc = 50.74 +- 2.3993 %
$W^-/W^-$ (acc = 50.52 +- 2.1612 %
$Z/Z$ (acc = 43.78 +- 2.9944 %
$W^+/W^-$ (acc = 37.35 +- 1.8558 %
$W^+/Z$ (acc = 32.54 +- 0.9804 %
$W^-/Z$ (acc = 32.53 +- 1.1971 %
The summarized testing accuracy = 42.14 +- 0.6121 %, with the loss = 0.1924 +- 0.161251


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2023-02-23 00:46:16.309856
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.564, val acc= 32.18% |
Epoch 1: val_loss improved from inf to 1.5644, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.458, val acc= 37.75% |
Epoch 2: val_loss improved from 1.5644 to 1.4580, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.406, val acc= 40.23% |
Epoch 3: val_loss improved from 1.4580 to 1.4059, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.359, val acc= 41.37% |
Epoch 4: val_loss improved from 1.4059 to 1.3590, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.342, val acc= 42.33% |
Epoch 5: val_loss improved from 1.3590 to 1.3418, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.374, val acc= 41.94% |
Epoch   6: val_loss did not improve from 1.3418. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.348, val acc= 41.99% |
Epoch   7: val_loss did not improve from 1.3418. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.515, val acc= 41.09% |
Epoch   8: val_loss did not improve from 1.3418. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.552, val acc= 40.30% |
Epoch   9: val_loss did not improve from 1.3418. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.096, val acc= 38.24% |
Epoch  10: val_loss did not improve from 1.3418. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.594, val acc= 38.29% |
Epoch  11: val_loss did not improve from 1.3418. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.3418. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.3418. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.3418. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.3418. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.562, test acc= 42.55% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.550, val acc= 32.62% |
Epoch 1: val_loss improved from inf to 1.5495, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/1
VALIDATION:   kappa = 1.05000     | val loss= 1.475, val acc= 35.65% |
Epoch 2: val_loss improved from 1.5495 to 1.4752, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/1
VALIDATION:   kappa = 1.05000     | val loss= 1.349, val acc= 38.81% |
Epoch 3: val_loss improved from 1.4752 to 1.3492, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/1
VALIDATION:   kappa = 1.05000     | val loss= 1.391, val acc= 40.72% |
Epoch   4: val_loss did not improve from 1.3492. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.334, val acc= 42.02% |
Epoch 5: val_loss improved from 1.3492 to 1.3341, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/1
VALIDATION:   kappa = 1.05000     | val loss= 1.290, val acc= 41.81% |
Epoch 6: val_loss improved from 1.3341 to 1.2901, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/1
VALIDATION:   kappa = 1.05000     | val loss= 1.265, val acc= 41.81% |
Epoch 7: val_loss improved from 1.2901 to 1.2645, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/1
VALIDATION:   kappa = 1.05000     | val loss= 1.328, val acc= 39.57% |
Epoch   8: val_loss did not improve from 1.2645. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.468, val acc= 38.67% |
Epoch   9: val_loss did not improve from 1.2645. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.696, val acc= 39.44% |
Epoch  10: val_loss did not improve from 1.2645. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.054, val acc= 38.61% |
Epoch  11: val_loss did not improve from 1.2645. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2645. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2645. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2645. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.2645. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.2645. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  17: val_loss did not improve from 1.2645. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.538, test acc= 41.90% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.504, val acc= 32.19% |
Epoch 1: val_loss improved from inf to 1.5044, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/2
VALIDATION:   kappa = 1.05000     | val loss= 1.507, val acc= 36.63% |
Epoch   2: val_loss did not improve from 1.5044. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.344, val acc= 40.04% |
Epoch 3: val_loss improved from 1.5044 to 1.3439, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/2
VALIDATION:   kappa = 1.05000     | val loss= 1.369, val acc= 40.83% |
Epoch   4: val_loss did not improve from 1.3439. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.350, val acc= 41.20% |
Epoch   5: val_loss did not improve from 1.3439. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.346, val acc= 42.22% |
Epoch   6: val_loss did not improve from 1.3439. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.405, val acc= 40.96% |
Epoch   7: val_loss did not improve from 1.3439. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.400, val acc= 40.82% |
Epoch   8: val_loss did not improve from 1.3439. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.577, val acc= 40.16% |
Epoch   9: val_loss did not improve from 1.3439. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.841, val acc= 39.14% |
Epoch  10: val_loss did not improve from 1.3439. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.878, val acc= 37.88% |
Epoch  11: val_loss did not improve from 1.3439. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.3439. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.3439. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.193, test acc= 40.05% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.540, val acc= 32.66% |
Epoch 1: val_loss improved from inf to 1.5401, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/3
VALIDATION:   kappa = 1.05000     | val loss= 1.499, val acc= 35.62% |
Epoch 2: val_loss improved from 1.5401 to 1.4986, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/3
VALIDATION:   kappa = 1.05000     | val loss= 1.385, val acc= 39.94% |
Epoch 3: val_loss improved from 1.4986 to 1.3855, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/3
VALIDATION:   kappa = 1.05000     | val loss= 1.324, val acc= 41.23% |
Epoch 4: val_loss improved from 1.3855 to 1.3244, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/3
VALIDATION:   kappa = 1.05000     | val loss= 1.313, val acc= 41.96% |
Epoch 5: val_loss improved from 1.3244 to 1.3135, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/3
VALIDATION:   kappa = 1.05000     | val loss= 1.278, val acc= 42.29% |
Epoch 6: val_loss improved from 1.3135 to 1.2778, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/3
VALIDATION:   kappa = 1.05000     | val loss= 1.388, val acc= 41.83% |
Epoch   7: val_loss did not improve from 1.2778. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.427, val acc= 41.63% |
Epoch   8: val_loss did not improve from 1.2778. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.611, val acc= 40.24% |
Epoch   9: val_loss did not improve from 1.2778. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.759, val acc= 39.28% |
Epoch  10: val_loss did not improve from 1.2778. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.116, val acc= 38.73% |
Epoch  11: val_loss did not improve from 1.2778. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2778. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2778. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2778. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.2778. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.2778. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.295, test acc= 42.56% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.537, val acc= 33.31% |
Epoch 1: val_loss improved from inf to 1.5366, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/4
VALIDATION:   kappa = 1.05000     | val loss= 1.448, val acc= 38.08% |
Epoch 2: val_loss improved from 1.5366 to 1.4481, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/4
VALIDATION:   kappa = 1.05000     | val loss= 1.353, val acc= 40.84% |
Epoch 3: val_loss improved from 1.4481 to 1.3533, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/4
VALIDATION:   kappa = 1.05000     | val loss= 1.287, val acc= 41.67% |
Epoch 4: val_loss improved from 1.3533 to 1.2870, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/4
VALIDATION:   kappa = 1.05000     | val loss= 1.369, val acc= 42.37% |
Epoch   5: val_loss did not improve from 1.2870. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.306, val acc= 42.23% |
Epoch   6: val_loss did not improve from 1.2870. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.475, val acc= 40.93% |
Epoch   7: val_loss did not improve from 1.2870. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.517, val acc= 39.93% |
Epoch   8: val_loss did not improve from 1.2870. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.717, val acc= 40.07% |
Epoch   9: val_loss did not improve from 1.2870. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.925, val acc= 38.33% |
Epoch  10: val_loss did not improve from 1.2870. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  11: val_loss did not improve from 1.2870. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2870. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2870. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2870. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.510, test acc= 42.12% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.557, val acc= 32.70% |
Epoch 1: val_loss improved from inf to 1.5566, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/5
VALIDATION:   kappa = 1.05000     | val loss= 1.421, val acc= 38.61% |
Epoch 2: val_loss improved from 1.5566 to 1.4205, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/5
VALIDATION:   kappa = 1.05000     | val loss= 1.365, val acc= 41.13% |
Epoch 3: val_loss improved from 1.4205 to 1.3648, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/5
VALIDATION:   kappa = 1.05000     | val loss= 1.277, val acc= 42.04% |
Epoch 4: val_loss improved from 1.3648 to 1.2768, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/5
VALIDATION:   kappa = 1.05000     | val loss= 1.312, val acc= 42.54% |
Epoch   5: val_loss did not improve from 1.2768. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.339, val acc= 42.43% |
Epoch   6: val_loss did not improve from 1.2768. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.345, val acc= 42.11% |
Epoch   7: val_loss did not improve from 1.2768. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.574, val acc= 41.42% |
Epoch   8: val_loss did not improve from 1.2768. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.482, val acc= 40.55% |
Epoch   9: val_loss did not improve from 1.2768. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.714, val acc= 39.52% |
Epoch  10: val_loss did not improve from 1.2768. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.243, val acc= 37.57% |
Epoch  11: val_loss did not improve from 1.2768. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2768. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2768. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2768. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.417, test acc= 42.03% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.519, val acc= 31.67% |
Epoch 1: val_loss improved from inf to 1.5194, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/6
VALIDATION:   kappa = 1.05000     | val loss= 1.506, val acc= 36.30% |
Epoch 2: val_loss improved from 1.5194 to 1.5059, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/6
VALIDATION:   kappa = 1.05000     | val loss= 1.381, val acc= 38.89% |
Epoch 3: val_loss improved from 1.5059 to 1.3815, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/6
VALIDATION:   kappa = 1.05000     | val loss= 1.284, val acc= 40.64% |
Epoch 4: val_loss improved from 1.3815 to 1.2841, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/6
VALIDATION:   kappa = 1.05000     | val loss= 1.282, val acc= 41.42% |
Epoch 5: val_loss improved from 1.2841 to 1.2819, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/6
VALIDATION:   kappa = 1.05000     | val loss= 1.314, val acc= 41.26% |
Epoch   6: val_loss did not improve from 1.2819. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.387, val acc= 41.20% |
Epoch   7: val_loss did not improve from 1.2819. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.364, val acc= 39.98% |
Epoch   8: val_loss did not improve from 1.2819. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.844, val acc= 38.84% |
Epoch   9: val_loss did not improve from 1.2819. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.989, val acc= 38.14% |
Epoch  10: val_loss did not improve from 1.2819. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  11: val_loss did not improve from 1.2819. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2819. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2819. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2819. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.2819. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.148, test acc= 42.12% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.523, val acc= 31.65% |
Epoch 1: val_loss improved from inf to 1.5231, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/7
VALIDATION:   kappa = 1.05000     | val loss= 1.479, val acc= 34.21% |
Epoch 2: val_loss improved from 1.5231 to 1.4787, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/7
VALIDATION:   kappa = 1.05000     | val loss= 1.422, val acc= 38.49% |
Epoch 3: val_loss improved from 1.4787 to 1.4223, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/7
VALIDATION:   kappa = 1.05000     | val loss= 1.329, val acc= 40.87% |
Epoch 4: val_loss improved from 1.4223 to 1.3286, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/7
VALIDATION:   kappa = 1.05000     | val loss= 1.291, val acc= 41.79% |
Epoch 5: val_loss improved from 1.3286 to 1.2909, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/7
VALIDATION:   kappa = 1.05000     | val loss= 1.347, val acc= 41.88% |
Epoch   6: val_loss did not improve from 1.2909. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.285, val acc= 41.12% |
Epoch 7: val_loss improved from 1.2909 to 1.2853, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/7
VALIDATION:   kappa = 1.05000     | val loss= 1.402, val acc= 40.38% |
Epoch   8: val_loss did not improve from 1.2853. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.575, val acc= 39.99% |
Epoch   9: val_loss did not improve from 1.2853. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.793, val acc= 38.45% |
Epoch  10: val_loss did not improve from 1.2853. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  11: val_loss did not improve from 1.2853. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2853. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2853. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2853. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.2853. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.2853. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  17: val_loss did not improve from 1.2853. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.107, test acc= 41.01% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.516, val acc= 32.90% |
Epoch 1: val_loss improved from inf to 1.5158, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.408, val acc= 38.65% |
Epoch 2: val_loss improved from 1.5158 to 1.4081, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.358, val acc= 40.70% |
Epoch 3: val_loss improved from 1.4081 to 1.3584, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.318, val acc= 41.83% |
Epoch 4: val_loss improved from 1.3584 to 1.3175, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.317, val acc= 42.78% |
Epoch 5: val_loss improved from 1.3175 to 1.3166, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.307, val acc= 42.64% |
Epoch 6: val_loss improved from 1.3166 to 1.3073, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/8
VALIDATION:   kappa = 1.05000     | val loss= 1.331, val acc= 42.35% |
Epoch   7: val_loss did not improve from 1.3073. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.324, val acc= 41.48% |
Epoch   8: val_loss did not improve from 1.3073. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.643, val acc= 40.18% |
Epoch   9: val_loss did not improve from 1.3073. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.640, val acc= 39.30% |
Epoch  10: val_loss did not improve from 1.3073. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.029, val acc= 38.40% |
Epoch  11: val_loss did not improve from 1.3073. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.3073. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.3073. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.3073. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.3073. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.3073. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.352, test acc= 43.07% |
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.478, val acc= 33.33% |
Epoch 1: val_loss improved from inf to 1.4780, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/9
VALIDATION:   kappa = 1.05000     | val loss= 1.492, val acc= 37.54% |
Epoch   2: val_loss did not improve from 1.4780. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.314, val acc= 39.98% |
Epoch 3: val_loss improved from 1.4780 to 1.3139, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/9
VALIDATION:   kappa = 1.05000     | val loss= 1.326, val acc= 41.47% |
Epoch   4: val_loss did not improve from 1.3139. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.354, val acc= 41.36% |
Epoch   5: val_loss did not improve from 1.3139. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.260, val acc= 41.79% |
Epoch 6: val_loss improved from 1.3139 to 1.2600, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/9
VALIDATION:   kappa = 1.05000     | val loss= 1.202, val acc= 42.02% |
Epoch 7: val_loss improved from 1.2600 to 1.2020, saving model to/home/samhuang/ML/best_model/best_model_senary_P_CNN2_kappa0.2301_fiximag/Try/9
VALIDATION:   kappa = 1.05000     | val loss= 1.309, val acc= 41.18% |
Epoch   8: val_loss did not improve from 1.2020. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.282, val acc= 40.36% |
Epoch   9: val_loss did not improve from 1.2020. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.345, val acc= 39.36% |
Epoch  10: val_loss did not improve from 1.2020. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.855, val acc= 38.77% |
Epoch  11: val_loss did not improve from 1.2020. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  12: val_loss did not improve from 1.2020. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  13: val_loss did not improve from 1.2020. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  14: val_loss did not improve from 1.2020. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  15: val_loss did not improve from 1.2020. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  16: val_loss did not improve from 1.2020. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.74% |
Epoch  17: val_loss did not improve from 1.2020. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 0.287, test acc= 41.82% |
Finished Training
[1.5784084  1.53619686 1.48974829 1.41655675 1.42180303 1.31517062
 1.23372771 1.11445885 0.99750723 0.8588869         nan        nan
        nan        nan        nan        nan        nan] <class 'numpy.ndarray'>
N of classes 6
$W^+/W^+$ (auc = 84.46 +- 0.3875 %)
$W^-/W^-$ (auc = 83.45 +- 0.4594 %)
$Z/Z$ (auc = 80.06 +- 0.9335 %)
$W^+/W^-$ (auc = 71.52 +- 0.6536 %)
$W^+/Z$ (auc = 69.76 +- 0.5055 %)
$W^-/Z$ (auc = 69.59 +- 0.5933 %)
N of classes 6
$W^+/W^+$ (acc = 48.53 +- 3.2441 %)
$W^-/W^-$ (acc = 50.46 +- 2.1152 %)
$Z/Z$ (acc = 43.11 +- 1.5405 %)
$W^+/W^-$ (acc = 38.13 +- 1.0059 %)
$W^+/Z$ (acc = 31.80 +- 2.0196 %)
$W^-/Z$ (acc = 32.54 +- 1.4173 %)
The summarized testing accuracy = 41.93 +- 0.8092 %, with the loss = 0.3407 +- 0.155121
Best performance is derived from Model #8, whose loss = 0.3519 and acc = 43.07 %
