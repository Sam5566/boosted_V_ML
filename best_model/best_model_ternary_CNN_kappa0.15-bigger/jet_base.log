

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-02 09:57:39.238178
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 209s 200ms/step - loss: 1.3254 - accuracy: 0.4633 - val_loss: 1.0004 - val_accuracy: 0.4779

Epoch 00001: val_loss improved from inf to 1.00042, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 2/100
937/937 [==============================] - 202s 215ms/step - loss: 1.0020 - accuracy: 0.4767 - val_loss: 0.9788 - val_accuracy: 0.4913

Epoch 00002: val_loss improved from 1.00042 to 0.97884, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 3/100
937/937 [==============================] - 215s 229ms/step - loss: 0.9945 - accuracy: 0.4825 - val_loss: 0.9860 - val_accuracy: 0.4874

Epoch 00003: val_loss did not improve from 0.97884
Epoch 4/100
937/937 [==============================] - 169s 180ms/step - loss: 0.9898 - accuracy: 0.4848 - val_loss: 0.9888 - val_accuracy: 0.4842

Epoch 00004: val_loss did not improve from 0.97884
Epoch 5/100
937/937 [==============================] - 168s 179ms/step - loss: 0.9875 - accuracy: 0.4865 - val_loss: 0.9777 - val_accuracy: 0.4908

Epoch 00005: val_loss improved from 0.97884 to 0.97772, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 6/100
937/937 [==============================] - 177s 189ms/step - loss: 0.9845 - accuracy: 0.4894 - val_loss: 0.9822 - val_accuracy: 0.4887

Epoch 00006: val_loss did not improve from 0.97772
Epoch 7/100
937/937 [==============================] - 181s 193ms/step - loss: 0.9830 - accuracy: 0.4889 - val_loss: 0.9685 - val_accuracy: 0.4974

Epoch 00007: val_loss improved from 0.97772 to 0.96845, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 8/100
937/937 [==============================] - 147s 157ms/step - loss: 0.9814 - accuracy: 0.4900 - val_loss: 0.9795 - val_accuracy: 0.4912

Epoch 00008: val_loss did not improve from 0.96845
Epoch 9/100
937/937 [==============================] - 146s 155ms/step - loss: 0.9793 - accuracy: 0.4919 - val_loss: 0.9679 - val_accuracy: 0.4988

Epoch 00009: val_loss improved from 0.96845 to 0.96786, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 10/100
937/937 [==============================] - 146s 156ms/step - loss: 0.9779 - accuracy: 0.4931 - val_loss: 0.9729 - val_accuracy: 0.4959

Epoch 00010: val_loss did not improve from 0.96786
Epoch 11/100
937/937 [==============================] - 161s 172ms/step - loss: 0.9762 - accuracy: 0.4937 - val_loss: 0.9861 - val_accuracy: 0.4885

Epoch 00011: val_loss did not improve from 0.96786
Epoch 12/100
937/937 [==============================] - 118s 126ms/step - loss: 0.9751 - accuracy: 0.4953 - val_loss: 0.9770 - val_accuracy: 0.4933

Epoch 00012: val_loss did not improve from 0.96786
Epoch 13/100
937/937 [==============================] - 102s 109ms/step - loss: 0.9734 - accuracy: 0.4964 - val_loss: 0.9778 - val_accuracy: 0.4934

Epoch 00013: val_loss did not improve from 0.96786
Epoch 14/100
937/937 [==============================] - 105s 112ms/step - loss: 0.9724 - accuracy: 0.4959 - val_loss: 0.9620 - val_accuracy: 0.5010

Epoch 00014: val_loss improved from 0.96786 to 0.96198, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 15/100
937/937 [==============================] - 105s 112ms/step - loss: 0.9713 - accuracy: 0.4972 - val_loss: 0.9886 - val_accuracy: 0.4865

Epoch 00015: val_loss did not improve from 0.96198
Epoch 16/100
937/937 [==============================] - 106s 113ms/step - loss: 0.9701 - accuracy: 0.4980 - val_loss: 0.9647 - val_accuracy: 0.4994

Epoch 00016: val_loss did not improve from 0.96198
Epoch 17/100
937/937 [==============================] - 120s 128ms/step - loss: 0.9688 - accuracy: 0.4990 - val_loss: 0.9711 - val_accuracy: 0.4976

Epoch 00017: val_loss did not improve from 0.96198
Epoch 18/100
937/937 [==============================] - 186s 199ms/step - loss: 0.9685 - accuracy: 0.4997 - val_loss: 0.9624 - val_accuracy: 0.5018

Epoch 00018: val_loss did not improve from 0.96198
Epoch 19/100
937/937 [==============================] - 192s 205ms/step - loss: 0.9668 - accuracy: 0.5017 - val_loss: 0.9663 - val_accuracy: 0.4999

Epoch 00019: val_loss did not improve from 0.96198
Epoch 20/100
937/937 [==============================] - 197s 210ms/step - loss: 0.9675 - accuracy: 0.4997 - val_loss: 0.9638 - val_accuracy: 0.5014

Epoch 00020: val_loss did not improve from 0.96198
Epoch 21/100
937/937 [==============================] - 190s 203ms/step - loss: 0.9653 - accuracy: 0.5017 - val_loss: 0.9675 - val_accuracy: 0.4992

Epoch 00021: val_loss did not improve from 0.96198
Epoch 22/100
937/937 [==============================] - 187s 199ms/step - loss: 0.9651 - accuracy: 0.5014 - val_loss: 0.9757 - val_accuracy: 0.4940

Epoch 00022: val_loss did not improve from 0.96198
Epoch 23/100
937/937 [==============================] - 185s 197ms/step - loss: 0.9651 - accuracy: 0.5014 - val_loss: 0.9804 - val_accuracy: 0.4923

Epoch 00023: val_loss did not improve from 0.96198
Epoch 24/100
937/937 [==============================] - 188s 200ms/step - loss: 0.9635 - accuracy: 0.5036 - val_loss: 0.9840 - val_accuracy: 0.4907

Epoch 00024: val_loss did not improve from 0.96198
Epoch 00024: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 483s 3ms/step - loss: 0.9929 - accuracy: 0.6549
Testing Loss = 0.992861, Testing Accuracy = 0.654933
The data set contains images
N of classes 3
$W^+$ (auc = 79.77 +- 0.0000 %)
$W^-$ (auc = 50.84 +- 0.0000 %)
$Z$ (auc = 81.55 +- 0.0000 %)
The summarized testing accuracy = 65.49 +- 0.0000 %, with the loss = 0.9929 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-02 11:32:15.021563
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 66s 67ms/step - loss: 3.0631 - accuracy: 0.5970 - val_loss: 0.9826 - val_accuracy: 0.6458

Epoch 00001: val_loss improved from inf to 0.98260, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 2/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8947 - accuracy: 0.6457 - val_loss: 0.8473 - val_accuracy: 0.6517

Epoch 00002: val_loss improved from 0.98260 to 0.84733, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8463 - accuracy: 0.6518 - val_loss: 0.8308 - val_accuracy: 0.6557

Epoch 00003: val_loss improved from 0.84733 to 0.83083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 4/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8334 - accuracy: 0.6562 - val_loss: 0.8184 - val_accuracy: 0.6614

Epoch 00004: val_loss improved from 0.83083 to 0.81838, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 5/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8233 - accuracy: 0.6618 - val_loss: 0.8069 - val_accuracy: 0.6692

Epoch 00005: val_loss improved from 0.81838 to 0.80694, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8147 - accuracy: 0.6663 - val_loss: 0.8039 - val_accuracy: 0.6689

Epoch 00006: val_loss improved from 0.80694 to 0.80386, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 7/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8087 - accuracy: 0.6692 - val_loss: 0.7995 - val_accuracy: 0.6708

Epoch 00007: val_loss improved from 0.80386 to 0.79954, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 8/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8045 - accuracy: 0.6710 - val_loss: 0.7978 - val_accuracy: 0.6710

Epoch 00008: val_loss improved from 0.79954 to 0.79781, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 9/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8011 - accuracy: 0.6724 - val_loss: 0.7938 - val_accuracy: 0.6737

Epoch 00009: val_loss improved from 0.79781 to 0.79381, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7975 - accuracy: 0.6746 - val_loss: 0.7880 - val_accuracy: 0.6772

Epoch 00010: val_loss improved from 0.79381 to 0.78803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 11/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7951 - accuracy: 0.6757 - val_loss: 0.7859 - val_accuracy: 0.6777

Epoch 00011: val_loss improved from 0.78803 to 0.78587, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7928 - accuracy: 0.6767 - val_loss: 0.7826 - val_accuracy: 0.6798

Epoch 00012: val_loss improved from 0.78587 to 0.78257, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 13/100
937/937 [==============================] - 101s 108ms/step - loss: 0.7904 - accuracy: 0.6777 - val_loss: 0.7856 - val_accuracy: 0.6768

Epoch 00013: val_loss did not improve from 0.78257
Epoch 14/100
937/937 [==============================] - 73s 78ms/step - loss: 0.7885 - accuracy: 0.6791 - val_loss: 0.7836 - val_accuracy: 0.6776

Epoch 00014: val_loss did not improve from 0.78257
Epoch 15/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7869 - accuracy: 0.6798 - val_loss: 0.7836 - val_accuracy: 0.6780

Epoch 00015: val_loss did not improve from 0.78257
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7852 - accuracy: 0.6804 - val_loss: 0.7799 - val_accuracy: 0.6811

Epoch 00016: val_loss improved from 0.78257 to 0.77988, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 17/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7832 - accuracy: 0.6817 - val_loss: 0.7801 - val_accuracy: 0.6793

Epoch 00017: val_loss did not improve from 0.77988
Epoch 18/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7814 - accuracy: 0.6825 - val_loss: 0.7793 - val_accuracy: 0.6806

Epoch 00018: val_loss improved from 0.77988 to 0.77927, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7800 - accuracy: 0.6833 - val_loss: 0.7804 - val_accuracy: 0.6796

Epoch 00019: val_loss did not improve from 0.77927
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7790 - accuracy: 0.6841 - val_loss: 0.7819 - val_accuracy: 0.6786

Epoch 00020: val_loss did not improve from 0.77927
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7775 - accuracy: 0.6847 - val_loss: 0.7812 - val_accuracy: 0.6785

Epoch 00021: val_loss did not improve from 0.77927
Epoch 22/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7760 - accuracy: 0.6855 - val_loss: 0.7777 - val_accuracy: 0.6815

Epoch 00022: val_loss improved from 0.77927 to 0.77765, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 23/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7744 - accuracy: 0.6870 - val_loss: 0.7773 - val_accuracy: 0.6816

Epoch 00023: val_loss improved from 0.77765 to 0.77730, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 24/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7730 - accuracy: 0.6868 - val_loss: 0.7800 - val_accuracy: 0.6797

Epoch 00024: val_loss did not improve from 0.77730
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7714 - accuracy: 0.6884 - val_loss: 0.7840 - val_accuracy: 0.6784

Epoch 00025: val_loss did not improve from 0.77730
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7701 - accuracy: 0.6895 - val_loss: 0.7837 - val_accuracy: 0.6779

Epoch 00026: val_loss did not improve from 0.77730
Epoch 27/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7685 - accuracy: 0.6907 - val_loss: 0.7816 - val_accuracy: 0.6795

Epoch 00027: val_loss did not improve from 0.77730
Epoch 28/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7674 - accuracy: 0.6913 - val_loss: 0.7777 - val_accuracy: 0.6824

Epoch 00028: val_loss did not improve from 0.77730
Epoch 29/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7658 - accuracy: 0.6922 - val_loss: 0.7811 - val_accuracy: 0.6801

Epoch 00029: val_loss did not improve from 0.77730
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7650 - accuracy: 0.6932 - val_loss: 0.7778 - val_accuracy: 0.6817

Epoch 00030: val_loss did not improve from 0.77730
Epoch 31/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7632 - accuracy: 0.6944 - val_loss: 0.7854 - val_accuracy: 0.6786

Epoch 00031: val_loss did not improve from 0.77730
Epoch 32/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7616 - accuracy: 0.6958 - val_loss: 0.7854 - val_accuracy: 0.6787

Epoch 00032: val_loss did not improve from 0.77730
Epoch 33/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7603 - accuracy: 0.6961 - val_loss: 0.7907 - val_accuracy: 0.6761

Epoch 00033: val_loss did not improve from 0.77730
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 652s 4ms/step - loss: 0.7138 - accuracy: 0.7207
Testing Loss = 0.713783, Testing Accuracy = 0.720700
The data set contains images
N of classes 3
$W^+$ (auc = 83.97 +- 0.0000 %)
$W^-$ (auc = 84.69 +- 0.0000 %)
$Z$ (auc = 83.86 +- 0.0000 %)
The summarized testing accuracy = 72.07 +- 0.0000 %, with the loss = 0.7138 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-02 19:24:30.333949
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 94s 79ms/step - loss: 3.0621 - accuracy: 0.5996 - val_loss: 0.9809 - val_accuracy: 0.6475

Epoch 00001: val_loss improved from inf to 0.98094, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 2/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8953 - accuracy: 0.6441 - val_loss: 0.8447 - val_accuracy: 0.6544

Epoch 00002: val_loss improved from 0.98094 to 0.84470, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8474 - accuracy: 0.6506 - val_loss: 0.8271 - val_accuracy: 0.6590

Epoch 00003: val_loss improved from 0.84470 to 0.82712, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 4/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8346 - accuracy: 0.6551 - val_loss: 0.8284 - val_accuracy: 0.6560

Epoch 00004: val_loss did not improve from 0.82712
Epoch 5/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8258 - accuracy: 0.6594 - val_loss: 0.8306 - val_accuracy: 0.6533

Epoch 00005: val_loss did not improve from 0.82712
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8171 - accuracy: 0.6640 - val_loss: 0.8230 - val_accuracy: 0.6578

Epoch 00006: val_loss improved from 0.82712 to 0.82297, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8114 - accuracy: 0.6664 - val_loss: 0.8171 - val_accuracy: 0.6605

Epoch 00007: val_loss improved from 0.82297 to 0.81710, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 8/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8058 - accuracy: 0.6696 - val_loss: 0.8120 - val_accuracy: 0.6631

Epoch 00008: val_loss improved from 0.81710 to 0.81197, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 9/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8014 - accuracy: 0.6715 - val_loss: 0.8099 - val_accuracy: 0.6630

Epoch 00009: val_loss improved from 0.81197 to 0.80989, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 10/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7980 - accuracy: 0.6732 - val_loss: 0.8130 - val_accuracy: 0.6617

Epoch 00010: val_loss did not improve from 0.80989
Epoch 11/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7959 - accuracy: 0.6746 - val_loss: 0.8236 - val_accuracy: 0.6543

Epoch 00011: val_loss did not improve from 0.80989
Epoch 12/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7929 - accuracy: 0.6759 - val_loss: 0.8094 - val_accuracy: 0.6627

Epoch 00012: val_loss improved from 0.80989 to 0.80937, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 13/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7908 - accuracy: 0.6762 - val_loss: 0.8183 - val_accuracy: 0.6566

Epoch 00013: val_loss did not improve from 0.80937
Epoch 14/100
937/937 [==============================] - 68s 73ms/step - loss: 0.7893 - accuracy: 0.6774 - val_loss: 0.8076 - val_accuracy: 0.6632

Epoch 00014: val_loss improved from 0.80937 to 0.80761, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 15/100
937/937 [==============================] - 73s 78ms/step - loss: 0.7874 - accuracy: 0.6786 - val_loss: 0.8049 - val_accuracy: 0.6658

Epoch 00015: val_loss improved from 0.80761 to 0.80489, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 16/100
937/937 [==============================] - 68s 73ms/step - loss: 0.7853 - accuracy: 0.6797 - val_loss: 0.8064 - val_accuracy: 0.6641

Epoch 00016: val_loss did not improve from 0.80489
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7837 - accuracy: 0.6803 - val_loss: 0.7983 - val_accuracy: 0.6696

Epoch 00017: val_loss improved from 0.80489 to 0.79826, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 18/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7827 - accuracy: 0.6811 - val_loss: 0.7988 - val_accuracy: 0.6674

Epoch 00018: val_loss did not improve from 0.79826
Epoch 19/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7813 - accuracy: 0.6818 - val_loss: 0.7999 - val_accuracy: 0.6678

Epoch 00019: val_loss did not improve from 0.79826
Epoch 20/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7803 - accuracy: 0.6821 - val_loss: 0.8034 - val_accuracy: 0.6650

Epoch 00020: val_loss did not improve from 0.79826
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7787 - accuracy: 0.6833 - val_loss: 0.7991 - val_accuracy: 0.6677

Epoch 00021: val_loss did not improve from 0.79826
Epoch 22/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7773 - accuracy: 0.6837 - val_loss: 0.8001 - val_accuracy: 0.6662

Epoch 00022: val_loss did not improve from 0.79826
Epoch 23/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7755 - accuracy: 0.6851 - val_loss: 0.7944 - val_accuracy: 0.6697

Epoch 00023: val_loss improved from 0.79826 to 0.79437, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 24/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7742 - accuracy: 0.6856 - val_loss: 0.8011 - val_accuracy: 0.6664

Epoch 00024: val_loss did not improve from 0.79437
Epoch 25/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7733 - accuracy: 0.6866 - val_loss: 0.7934 - val_accuracy: 0.6717

Epoch 00025: val_loss improved from 0.79437 to 0.79338, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 26/100
937/937 [==============================] - 67s 71ms/step - loss: 0.7722 - accuracy: 0.6874 - val_loss: 0.7953 - val_accuracy: 0.6705

Epoch 00026: val_loss did not improve from 0.79338
Epoch 27/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7706 - accuracy: 0.6882 - val_loss: 0.7931 - val_accuracy: 0.6712

Epoch 00027: val_loss improved from 0.79338 to 0.79313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 28/100
937/937 [==============================] - 67s 72ms/step - loss: 0.7694 - accuracy: 0.6887 - val_loss: 0.7948 - val_accuracy: 0.6699

Epoch 00028: val_loss did not improve from 0.79313
Epoch 29/100
937/937 [==============================] - 66s 71ms/step - loss: 0.7679 - accuracy: 0.6902 - val_loss: 0.7995 - val_accuracy: 0.6678

Epoch 00029: val_loss did not improve from 0.79313
Epoch 30/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7663 - accuracy: 0.6916 - val_loss: 0.7954 - val_accuracy: 0.6703

Epoch 00030: val_loss did not improve from 0.79313
Epoch 31/100
937/937 [==============================] - 67s 71ms/step - loss: 0.7653 - accuracy: 0.6916 - val_loss: 0.7919 - val_accuracy: 0.6717

Epoch 00031: val_loss improved from 0.79313 to 0.79185, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 32/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7636 - accuracy: 0.6934 - val_loss: 0.7953 - val_accuracy: 0.6703

Epoch 00032: val_loss did not improve from 0.79185
Epoch 33/100
937/937 [==============================] - 66s 71ms/step - loss: 0.7627 - accuracy: 0.6940 - val_loss: 0.7990 - val_accuracy: 0.6690

Epoch 00033: val_loss did not improve from 0.79185
Epoch 34/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7611 - accuracy: 0.6946 - val_loss: 0.7897 - val_accuracy: 0.6745

Epoch 00034: val_loss improved from 0.79185 to 0.78965, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 35/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7594 - accuracy: 0.6959 - val_loss: 0.7966 - val_accuracy: 0.6699

Epoch 00035: val_loss did not improve from 0.78965
Epoch 36/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7578 - accuracy: 0.6971 - val_loss: 0.7907 - val_accuracy: 0.6740

Epoch 00036: val_loss did not improve from 0.78965
Epoch 37/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7561 - accuracy: 0.6984 - val_loss: 0.7928 - val_accuracy: 0.6729

Epoch 00037: val_loss did not improve from 0.78965
Epoch 38/100
937/937 [==============================] - 248s 265ms/step - loss: 0.7553 - accuracy: 0.6990 - val_loss: 0.8012 - val_accuracy: 0.6682

Epoch 00038: val_loss did not improve from 0.78965
Epoch 39/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7529 - accuracy: 0.7014 - val_loss: 0.7910 - val_accuracy: 0.6751

Epoch 00039: val_loss did not improve from 0.78965
Epoch 40/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7517 - accuracy: 0.7017 - val_loss: 0.7951 - val_accuracy: 0.6728

Epoch 00040: val_loss did not improve from 0.78965
Epoch 41/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7498 - accuracy: 0.7033 - val_loss: 0.7982 - val_accuracy: 0.6711

Epoch 00041: val_loss did not improve from 0.78965
Epoch 42/100
937/937 [==============================] - 66s 71ms/step - loss: 0.7484 - accuracy: 0.7045 - val_loss: 0.7963 - val_accuracy: 0.6727

Epoch 00042: val_loss did not improve from 0.78965
Epoch 43/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7465 - accuracy: 0.7058 - val_loss: 0.8001 - val_accuracy: 0.6709

Epoch 00043: val_loss did not improve from 0.78965
Epoch 44/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7427 - accuracy: 0.7089 - val_loss: 0.8030 - val_accuracy: 0.6698

Epoch 00044: val_loss did not improve from 0.78965
Epoch 00044: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 658s 4ms/step - loss: 0.7865 - accuracy: 0.6771
Testing Loss = 0.786455, Testing Accuracy = 0.677140
The data set contains images
N of classes 3
$W^+$ (auc = 85.43 +- 0.0000 %)
$W^-$ (auc = 85.38 +- 0.0000 %)
$Z$ (auc = 83.39 +- 0.0000 %)
The summarized testing accuracy = 67.71 +- 0.0000 %, with the loss = 0.7865 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-02 20:37:55.390777
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 70s 70ms/step - loss: 3.0298 - accuracy: 0.5936 - val_loss: 0.9724 - val_accuracy: 0.6488

Epoch 00001: val_loss improved from inf to 0.97242, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 2/100
937/937 [==============================] - 66s 70ms/step - loss: 0.8919 - accuracy: 0.6448 - val_loss: 0.8422 - val_accuracy: 0.6549

Epoch 00002: val_loss improved from 0.97242 to 0.84217, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 3/100
937/937 [==============================] - 66s 71ms/step - loss: 0.8456 - accuracy: 0.6505 - val_loss: 0.8328 - val_accuracy: 0.6543

Epoch 00003: val_loss improved from 0.84217 to 0.83282, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 4/100
937/937 [==============================] - 66s 70ms/step - loss: 0.8314 - accuracy: 0.6562 - val_loss: 0.8269 - val_accuracy: 0.6560

Epoch 00004: val_loss improved from 0.83282 to 0.82693, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 5/100
937/937 [==============================] - 65s 70ms/step - loss: 0.8210 - accuracy: 0.6622 - val_loss: 0.8218 - val_accuracy: 0.6589

Epoch 00005: val_loss improved from 0.82693 to 0.82182, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 6/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8128 - accuracy: 0.6661 - val_loss: 0.8209 - val_accuracy: 0.6584

Epoch 00006: val_loss improved from 0.82182 to 0.82093, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 7/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8074 - accuracy: 0.6689 - val_loss: 0.8214 - val_accuracy: 0.6567

Epoch 00007: val_loss did not improve from 0.82093
Epoch 8/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8028 - accuracy: 0.6712 - val_loss: 0.8135 - val_accuracy: 0.6617

Epoch 00008: val_loss improved from 0.82093 to 0.81347, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 9/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7987 - accuracy: 0.6728 - val_loss: 0.8092 - val_accuracy: 0.6639

Epoch 00009: val_loss improved from 0.81347 to 0.80915, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 10/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7964 - accuracy: 0.6740 - val_loss: 0.8062 - val_accuracy: 0.6654

Epoch 00010: val_loss improved from 0.80915 to 0.80617, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 11/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7935 - accuracy: 0.6752 - val_loss: 0.8052 - val_accuracy: 0.6660

Epoch 00011: val_loss improved from 0.80617 to 0.80525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 12/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7913 - accuracy: 0.6761 - val_loss: 0.8072 - val_accuracy: 0.6635

Epoch 00012: val_loss did not improve from 0.80525
Epoch 13/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7895 - accuracy: 0.6772 - val_loss: 0.8074 - val_accuracy: 0.6638

Epoch 00013: val_loss did not improve from 0.80525
Epoch 14/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7875 - accuracy: 0.6782 - val_loss: 0.8043 - val_accuracy: 0.6650

Epoch 00014: val_loss improved from 0.80525 to 0.80428, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 15/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7863 - accuracy: 0.6792 - val_loss: 0.8002 - val_accuracy: 0.6670

Epoch 00015: val_loss improved from 0.80428 to 0.80023, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 16/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7846 - accuracy: 0.6796 - val_loss: 0.8059 - val_accuracy: 0.6642

Epoch 00016: val_loss did not improve from 0.80023
Epoch 17/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7832 - accuracy: 0.6803 - val_loss: 0.7947 - val_accuracy: 0.6705

Epoch 00017: val_loss improved from 0.80023 to 0.79466, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 18/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7809 - accuracy: 0.6812 - val_loss: 0.7966 - val_accuracy: 0.6689

Epoch 00018: val_loss did not improve from 0.79466
Epoch 19/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7802 - accuracy: 0.6819 - val_loss: 0.7965 - val_accuracy: 0.6703

Epoch 00019: val_loss did not improve from 0.79466
Epoch 20/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7785 - accuracy: 0.6831 - val_loss: 0.7968 - val_accuracy: 0.6693

Epoch 00020: val_loss did not improve from 0.79466
Epoch 21/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7773 - accuracy: 0.6839 - val_loss: 0.7912 - val_accuracy: 0.6716

Epoch 00021: val_loss improved from 0.79466 to 0.79120, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 22/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7762 - accuracy: 0.6838 - val_loss: 0.7989 - val_accuracy: 0.6681

Epoch 00022: val_loss did not improve from 0.79120
Epoch 23/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7744 - accuracy: 0.6859 - val_loss: 0.7967 - val_accuracy: 0.6693

Epoch 00023: val_loss did not improve from 0.79120
Epoch 24/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7736 - accuracy: 0.6865 - val_loss: 0.7933 - val_accuracy: 0.6705

Epoch 00024: val_loss did not improve from 0.79120
Epoch 25/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7719 - accuracy: 0.6873 - val_loss: 0.7939 - val_accuracy: 0.6712

Epoch 00025: val_loss did not improve from 0.79120
Epoch 26/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7710 - accuracy: 0.6882 - val_loss: 0.7959 - val_accuracy: 0.6703

Epoch 00026: val_loss did not improve from 0.79120
Epoch 27/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7687 - accuracy: 0.6896 - val_loss: 0.7882 - val_accuracy: 0.6745

Epoch 00027: val_loss improved from 0.79120 to 0.78823, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 28/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7682 - accuracy: 0.6896 - val_loss: 0.7889 - val_accuracy: 0.6736

Epoch 00028: val_loss did not improve from 0.78823
Epoch 29/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7670 - accuracy: 0.6903 - val_loss: 0.7880 - val_accuracy: 0.6748

Epoch 00029: val_loss improved from 0.78823 to 0.78799, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 30/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7656 - accuracy: 0.6915 - val_loss: 0.7877 - val_accuracy: 0.6748

Epoch 00030: val_loss improved from 0.78799 to 0.78772, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 31/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7637 - accuracy: 0.6927 - val_loss: 0.7903 - val_accuracy: 0.6736

Epoch 00031: val_loss did not improve from 0.78772
Epoch 32/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7630 - accuracy: 0.6929 - val_loss: 0.7891 - val_accuracy: 0.6754

Epoch 00032: val_loss did not improve from 0.78772
Epoch 33/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7618 - accuracy: 0.6946 - val_loss: 0.7901 - val_accuracy: 0.6740

Epoch 00033: val_loss did not improve from 0.78772
Epoch 34/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7595 - accuracy: 0.6961 - val_loss: 0.7908 - val_accuracy: 0.6741

Epoch 00034: val_loss did not improve from 0.78772
Epoch 35/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7587 - accuracy: 0.6968 - val_loss: 0.7893 - val_accuracy: 0.6744

Epoch 00035: val_loss did not improve from 0.78772
Epoch 36/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7568 - accuracy: 0.6986 - val_loss: 0.7931 - val_accuracy: 0.6726

Epoch 00036: val_loss did not improve from 0.78772
Epoch 37/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7551 - accuracy: 0.6991 - val_loss: 0.7962 - val_accuracy: 0.6712

Epoch 00037: val_loss did not improve from 0.78772
Epoch 38/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7529 - accuracy: 0.7012 - val_loss: 0.7974 - val_accuracy: 0.6725

Epoch 00038: val_loss did not improve from 0.78772
Epoch 39/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7515 - accuracy: 0.7019 - val_loss: 0.7940 - val_accuracy: 0.6740

Epoch 00039: val_loss did not improve from 0.78772
Epoch 40/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7492 - accuracy: 0.7037 - val_loss: 0.7954 - val_accuracy: 0.6727

Epoch 00040: val_loss did not improve from 0.78772
Epoch 00040: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 658s 4ms/step - loss: 0.7844 - accuracy: 0.6779
Testing Loss = 0.784389, Testing Accuracy = 0.677927
The data set contains images
N of classes 3
$W^+$ (auc = 85.42 +- 0.0000 %)
$W^-$ (auc = 85.38 +- 0.0000 %)
$Z$ (auc = 83.43 +- 0.0000 %)
The summarized testing accuracy = 67.79 +- 0.0000 %, with the loss = 0.7844 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-05 23:35:17.529261
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 480s 410ms/step - loss: 3.0792 - accuracy: 0.5913 - val_loss: 0.9783 - val_accuracy: 0.6494

Epoch 00001: val_loss improved from inf to 0.97835, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 2/100
937/937 [==============================] - 334s 356ms/step - loss: 0.8942 - accuracy: 0.6454 - val_loss: 0.8430 - val_accuracy: 0.6533

Epoch 00002: val_loss improved from 0.97835 to 0.84303, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 3/100
937/937 [==============================] - 327s 349ms/step - loss: 0.8459 - accuracy: 0.6510 - val_loss: 0.8311 - val_accuracy: 0.6556

Epoch 00003: val_loss improved from 0.84303 to 0.83115, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 4/100
937/937 [==============================] - 299s 319ms/step - loss: 0.8339 - accuracy: 0.6545 - val_loss: 0.8293 - val_accuracy: 0.6547

Epoch 00004: val_loss improved from 0.83115 to 0.82926, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 5/100
937/937 [==============================] - 323s 345ms/step - loss: 0.8252 - accuracy: 0.6595 - val_loss: 0.8245 - val_accuracy: 0.6542

Epoch 00005: val_loss improved from 0.82926 to 0.82453, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 6/100
937/937 [==============================] - 326s 348ms/step - loss: 0.8174 - accuracy: 0.6638 - val_loss: 0.8230 - val_accuracy: 0.6554

Epoch 00006: val_loss improved from 0.82453 to 0.82295, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 7/100
937/937 [==============================] - 314s 335ms/step - loss: 0.8101 - accuracy: 0.6674 - val_loss: 0.8127 - val_accuracy: 0.6623

Epoch 00007: val_loss improved from 0.82295 to 0.81271, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 8/100
937/937 [==============================] - 154s 164ms/step - loss: 0.8052 - accuracy: 0.6698 - val_loss: 0.8134 - val_accuracy: 0.6616

Epoch 00008: val_loss did not improve from 0.81271
Epoch 9/100
937/937 [==============================] - 74s 79ms/step - loss: 0.8017 - accuracy: 0.6712 - val_loss: 0.8144 - val_accuracy: 0.6600

Epoch 00009: val_loss did not improve from 0.81271
Epoch 10/100
937/937 [==============================] - 71s 76ms/step - loss: 0.7983 - accuracy: 0.6733 - val_loss: 0.8160 - val_accuracy: 0.6591

Epoch 00010: val_loss did not improve from 0.81271
Epoch 11/100
937/937 [==============================] - 69s 74ms/step - loss: 0.7955 - accuracy: 0.6745 - val_loss: 0.8145 - val_accuracy: 0.6593

Epoch 00011: val_loss did not improve from 0.81271
Epoch 12/100
937/937 [==============================] - 69s 74ms/step - loss: 0.7935 - accuracy: 0.6751 - val_loss: 0.8138 - val_accuracy: 0.6600

Epoch 00012: val_loss did not improve from 0.81271
Epoch 13/100
937/937 [==============================] - 71s 75ms/step - loss: 0.7911 - accuracy: 0.6769 - val_loss: 0.8028 - val_accuracy: 0.6666

Epoch 00013: val_loss improved from 0.81271 to 0.80278, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 14/100
937/937 [==============================] - 70s 74ms/step - loss: 0.7892 - accuracy: 0.6773 - val_loss: 0.8059 - val_accuracy: 0.6645

Epoch 00014: val_loss did not improve from 0.80278
Epoch 15/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7875 - accuracy: 0.6778 - val_loss: 0.8054 - val_accuracy: 0.6648

Epoch 00015: val_loss did not improve from 0.80278
Epoch 16/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7863 - accuracy: 0.6791 - val_loss: 0.8081 - val_accuracy: 0.6626

Epoch 00016: val_loss did not improve from 0.80278
Epoch 17/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7844 - accuracy: 0.6798 - val_loss: 0.7998 - val_accuracy: 0.6672

Epoch 00017: val_loss improved from 0.80278 to 0.79977, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 18/100
937/937 [==============================] - 110s 117ms/step - loss: 0.7838 - accuracy: 0.6804 - val_loss: 0.8049 - val_accuracy: 0.6634

Epoch 00018: val_loss did not improve from 0.79977
Epoch 19/100
937/937 [==============================] - 77s 82ms/step - loss: 0.7818 - accuracy: 0.6816 - val_loss: 0.8096 - val_accuracy: 0.6617

Epoch 00019: val_loss did not improve from 0.79977
Epoch 20/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7806 - accuracy: 0.6822 - val_loss: 0.8051 - val_accuracy: 0.6637

Epoch 00020: val_loss did not improve from 0.79977
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7793 - accuracy: 0.6828 - val_loss: 0.7992 - val_accuracy: 0.6667

Epoch 00021: val_loss improved from 0.79977 to 0.79925, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 22/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7774 - accuracy: 0.6839 - val_loss: 0.7961 - val_accuracy: 0.6695

Epoch 00022: val_loss improved from 0.79925 to 0.79614, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 23/100
937/937 [==============================] - 115s 123ms/step - loss: 0.7762 - accuracy: 0.6847 - val_loss: 0.7964 - val_accuracy: 0.6693

Epoch 00023: val_loss did not improve from 0.79614
Epoch 24/100
937/937 [==============================] - 125s 134ms/step - loss: 0.7753 - accuracy: 0.6853 - val_loss: 0.7963 - val_accuracy: 0.6695

Epoch 00024: val_loss did not improve from 0.79614
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7743 - accuracy: 0.6861 - val_loss: 0.8087 - val_accuracy: 0.6613

Epoch 00025: val_loss did not improve from 0.79614
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7727 - accuracy: 0.6870 - val_loss: 0.7945 - val_accuracy: 0.6714

Epoch 00026: val_loss improved from 0.79614 to 0.79451, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7718 - accuracy: 0.6876 - val_loss: 0.7998 - val_accuracy: 0.6677

Epoch 00027: val_loss did not improve from 0.79451
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7703 - accuracy: 0.6884 - val_loss: 0.7915 - val_accuracy: 0.6731

Epoch 00028: val_loss improved from 0.79451 to 0.79149, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/0
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7692 - accuracy: 0.6896 - val_loss: 0.7971 - val_accuracy: 0.6687

Epoch 00029: val_loss did not improve from 0.79149
Epoch 30/100
937/937 [==============================] - 138s 147ms/step - loss: 0.7681 - accuracy: 0.6902 - val_loss: 0.7968 - val_accuracy: 0.6702

Epoch 00030: val_loss did not improve from 0.79149
Epoch 31/100
937/937 [==============================] - 199s 212ms/step - loss: 0.7662 - accuracy: 0.6921 - val_loss: 0.7970 - val_accuracy: 0.6699

Epoch 00031: val_loss did not improve from 0.79149
Epoch 32/100
937/937 [==============================] - 201s 215ms/step - loss: 0.7648 - accuracy: 0.6930 - val_loss: 0.7973 - val_accuracy: 0.6698

Epoch 00032: val_loss did not improve from 0.79149
Epoch 33/100
937/937 [==============================] - 258s 276ms/step - loss: 0.7639 - accuracy: 0.6928 - val_loss: 0.7964 - val_accuracy: 0.6704

Epoch 00033: val_loss did not improve from 0.79149
Epoch 34/100
937/937 [==============================] - 227s 243ms/step - loss: 0.7625 - accuracy: 0.6940 - val_loss: 0.7993 - val_accuracy: 0.6691

Epoch 00034: val_loss did not improve from 0.79149
Epoch 35/100
937/937 [==============================] - 282s 301ms/step - loss: 0.7609 - accuracy: 0.6955 - val_loss: 0.7948 - val_accuracy: 0.6725

Epoch 00035: val_loss did not improve from 0.79149
Epoch 36/100
937/937 [==============================] - 282s 300ms/step - loss: 0.7595 - accuracy: 0.6967 - val_loss: 0.7949 - val_accuracy: 0.6719

Epoch 00036: val_loss did not improve from 0.79149
Epoch 37/100
937/937 [==============================] - 308s 329ms/step - loss: 0.7582 - accuracy: 0.6973 - val_loss: 0.7983 - val_accuracy: 0.6714

Epoch 00037: val_loss did not improve from 0.79149
Epoch 38/100
937/937 [==============================] - 266s 284ms/step - loss: 0.7562 - accuracy: 0.6989 - val_loss: 0.7917 - val_accuracy: 0.6750

Epoch 00038: val_loss did not improve from 0.79149
Epoch 00038: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 703s 5ms/step - loss: 0.7876 - accuracy: 0.6761
Testing Loss = 0.787555, Testing Accuracy = 0.676067
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 65s 68ms/step - loss: 3.0532 - accuracy: 0.5900 - val_loss: 0.9773 - val_accuracy: 0.6498

Epoch 00001: val_loss improved from inf to 0.97732, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8939 - accuracy: 0.6444 - val_loss: 0.8472 - val_accuracy: 0.6510

Epoch 00002: val_loss improved from 0.97732 to 0.84724, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 3/100
937/937 [==============================] - 66s 71ms/step - loss: 0.8466 - accuracy: 0.6499 - val_loss: 0.8301 - val_accuracy: 0.6564

Epoch 00003: val_loss improved from 0.84724 to 0.83008, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 4/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8343 - accuracy: 0.6543 - val_loss: 0.8252 - val_accuracy: 0.6570

Epoch 00004: val_loss improved from 0.83008 to 0.82522, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 5/100
937/937 [==============================] - 67s 71ms/step - loss: 0.8255 - accuracy: 0.6584 - val_loss: 0.8358 - val_accuracy: 0.6475

Epoch 00005: val_loss did not improve from 0.82522
Epoch 6/100
937/937 [==============================] - 66s 71ms/step - loss: 0.8173 - accuracy: 0.6630 - val_loss: 0.8203 - val_accuracy: 0.6582

Epoch 00006: val_loss improved from 0.82522 to 0.82031, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 7/100
937/937 [==============================] - 68s 72ms/step - loss: 0.8107 - accuracy: 0.6660 - val_loss: 0.8163 - val_accuracy: 0.6594

Epoch 00007: val_loss improved from 0.82031 to 0.81626, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 8/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8060 - accuracy: 0.6682 - val_loss: 0.8087 - val_accuracy: 0.6646

Epoch 00008: val_loss improved from 0.81626 to 0.80875, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 9/100
937/937 [==============================] - 65s 70ms/step - loss: 0.8018 - accuracy: 0.6706 - val_loss: 0.8066 - val_accuracy: 0.6646

Epoch 00009: val_loss improved from 0.80875 to 0.80663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 10/100
937/937 [==============================] - 66s 71ms/step - loss: 0.7983 - accuracy: 0.6724 - val_loss: 0.8091 - val_accuracy: 0.6633

Epoch 00010: val_loss did not improve from 0.80663
Epoch 11/100
937/937 [==============================] - 67s 71ms/step - loss: 0.7953 - accuracy: 0.6734 - val_loss: 0.8071 - val_accuracy: 0.6645

Epoch 00011: val_loss did not improve from 0.80663
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7941 - accuracy: 0.6743 - val_loss: 0.8125 - val_accuracy: 0.6609

Epoch 00012: val_loss did not improve from 0.80663
Epoch 13/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7916 - accuracy: 0.6754 - val_loss: 0.8104 - val_accuracy: 0.6610

Epoch 00013: val_loss did not improve from 0.80663
Epoch 14/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7896 - accuracy: 0.6763 - val_loss: 0.8066 - val_accuracy: 0.6641

Epoch 00014: val_loss improved from 0.80663 to 0.80661, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 15/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7888 - accuracy: 0.6766 - val_loss: 0.8026 - val_accuracy: 0.6666

Epoch 00015: val_loss improved from 0.80661 to 0.80261, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 16/100
937/937 [==============================] - 67s 71ms/step - loss: 0.7866 - accuracy: 0.6782 - val_loss: 0.8012 - val_accuracy: 0.6660

Epoch 00016: val_loss improved from 0.80261 to 0.80119, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 17/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7855 - accuracy: 0.6787 - val_loss: 0.8041 - val_accuracy: 0.6645

Epoch 00017: val_loss did not improve from 0.80119
Epoch 18/100
937/937 [==============================] - 66s 70ms/step - loss: 0.7836 - accuracy: 0.6796 - val_loss: 0.7997 - val_accuracy: 0.6678

Epoch 00018: val_loss improved from 0.80119 to 0.79973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 19/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7819 - accuracy: 0.6807 - val_loss: 0.7985 - val_accuracy: 0.6685

Epoch 00019: val_loss improved from 0.79973 to 0.79851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 20/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7811 - accuracy: 0.6805 - val_loss: 0.7954 - val_accuracy: 0.6696

Epoch 00020: val_loss improved from 0.79851 to 0.79544, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 21/100
937/937 [==============================] - 66s 71ms/step - loss: 0.7797 - accuracy: 0.6819 - val_loss: 0.7983 - val_accuracy: 0.6677

Epoch 00021: val_loss did not improve from 0.79544
Epoch 22/100
937/937 [==============================] - 67s 71ms/step - loss: 0.7782 - accuracy: 0.6833 - val_loss: 0.7970 - val_accuracy: 0.6688

Epoch 00022: val_loss did not improve from 0.79544
Epoch 23/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7776 - accuracy: 0.6838 - val_loss: 0.7892 - val_accuracy: 0.6734

Epoch 00023: val_loss improved from 0.79544 to 0.78919, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 24/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7761 - accuracy: 0.6842 - val_loss: 0.7985 - val_accuracy: 0.6685

Epoch 00024: val_loss did not improve from 0.78919
Epoch 25/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7752 - accuracy: 0.6856 - val_loss: 0.7921 - val_accuracy: 0.6715

Epoch 00025: val_loss did not improve from 0.78919
Epoch 26/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7732 - accuracy: 0.6863 - val_loss: 0.7930 - val_accuracy: 0.6712

Epoch 00026: val_loss did not improve from 0.78919
Epoch 27/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7724 - accuracy: 0.6865 - val_loss: 0.7954 - val_accuracy: 0.6699

Epoch 00027: val_loss did not improve from 0.78919
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7713 - accuracy: 0.6872 - val_loss: 0.7927 - val_accuracy: 0.6717

Epoch 00028: val_loss did not improve from 0.78919
Epoch 29/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7700 - accuracy: 0.6884 - val_loss: 0.7977 - val_accuracy: 0.6678

Epoch 00029: val_loss did not improve from 0.78919
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7684 - accuracy: 0.6894 - val_loss: 0.7912 - val_accuracy: 0.6734

Epoch 00030: val_loss did not improve from 0.78919
Epoch 31/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7673 - accuracy: 0.6901 - val_loss: 0.7909 - val_accuracy: 0.6730

Epoch 00031: val_loss did not improve from 0.78919
Epoch 32/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7668 - accuracy: 0.6902 - val_loss: 0.7930 - val_accuracy: 0.6719

Epoch 00032: val_loss did not improve from 0.78919
Epoch 33/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7650 - accuracy: 0.6917 - val_loss: 0.7881 - val_accuracy: 0.6748

Epoch 00033: val_loss improved from 0.78919 to 0.78812, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/1
Epoch 34/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7639 - accuracy: 0.6925 - val_loss: 0.7900 - val_accuracy: 0.6731

Epoch 00034: val_loss did not improve from 0.78812
Epoch 35/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7627 - accuracy: 0.6937 - val_loss: 0.7958 - val_accuracy: 0.6706

Epoch 00035: val_loss did not improve from 0.78812
Epoch 36/100
937/937 [==============================] - 67s 71ms/step - loss: 0.7614 - accuracy: 0.6946 - val_loss: 0.7916 - val_accuracy: 0.6732

Epoch 00036: val_loss did not improve from 0.78812
Epoch 37/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7594 - accuracy: 0.6954 - val_loss: 0.7940 - val_accuracy: 0.6717

Epoch 00037: val_loss did not improve from 0.78812
Epoch 38/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7574 - accuracy: 0.6973 - val_loss: 0.7884 - val_accuracy: 0.6751

Epoch 00038: val_loss did not improve from 0.78812
Epoch 39/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7571 - accuracy: 0.6976 - val_loss: 0.7985 - val_accuracy: 0.6705

Epoch 00039: val_loss did not improve from 0.78812
Epoch 40/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7547 - accuracy: 0.6997 - val_loss: 0.7932 - val_accuracy: 0.6726

Epoch 00040: val_loss did not improve from 0.78812
Epoch 41/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7528 - accuracy: 0.7011 - val_loss: 0.7949 - val_accuracy: 0.6731

Epoch 00041: val_loss did not improve from 0.78812
Epoch 42/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7515 - accuracy: 0.7016 - val_loss: 0.7970 - val_accuracy: 0.6709

Epoch 00042: val_loss did not improve from 0.78812
Epoch 43/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7499 - accuracy: 0.7033 - val_loss: 0.7953 - val_accuracy: 0.6727

Epoch 00043: val_loss did not improve from 0.78812
Epoch 00043: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 712s 5ms/step - loss: 0.7848 - accuracy: 0.6782
Testing Loss = 0.784750, Testing Accuracy = 0.678193
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 187s 198ms/step - loss: 3.0727 - accuracy: 0.5902 - val_loss: 0.9762 - val_accuracy: 0.6487

Epoch 00001: val_loss improved from inf to 0.97617, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 2/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8926 - accuracy: 0.6448 - val_loss: 0.8434 - val_accuracy: 0.6536

Epoch 00002: val_loss improved from 0.97617 to 0.84336, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 3/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8454 - accuracy: 0.6512 - val_loss: 0.8327 - val_accuracy: 0.6557

Epoch 00003: val_loss improved from 0.84336 to 0.83269, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 4/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8329 - accuracy: 0.6549 - val_loss: 0.8320 - val_accuracy: 0.6529

Epoch 00004: val_loss improved from 0.83269 to 0.83201, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 5/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8235 - accuracy: 0.6599 - val_loss: 0.8262 - val_accuracy: 0.6538

Epoch 00005: val_loss improved from 0.83201 to 0.82622, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8164 - accuracy: 0.6642 - val_loss: 0.8260 - val_accuracy: 0.6531

Epoch 00006: val_loss improved from 0.82622 to 0.82598, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 7/100
937/937 [==============================] - 65s 70ms/step - loss: 0.8095 - accuracy: 0.6677 - val_loss: 0.8190 - val_accuracy: 0.6577

Epoch 00007: val_loss improved from 0.82598 to 0.81898, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 8/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8048 - accuracy: 0.6696 - val_loss: 0.8169 - val_accuracy: 0.6598

Epoch 00008: val_loss improved from 0.81898 to 0.81690, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 9/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8001 - accuracy: 0.6718 - val_loss: 0.8162 - val_accuracy: 0.6589

Epoch 00009: val_loss improved from 0.81690 to 0.81620, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 10/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7972 - accuracy: 0.6736 - val_loss: 0.8148 - val_accuracy: 0.6598

Epoch 00010: val_loss improved from 0.81620 to 0.81476, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 11/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7946 - accuracy: 0.6744 - val_loss: 0.8126 - val_accuracy: 0.6598

Epoch 00011: val_loss improved from 0.81476 to 0.81260, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7916 - accuracy: 0.6756 - val_loss: 0.8126 - val_accuracy: 0.6595

Epoch 00012: val_loss did not improve from 0.81260
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7898 - accuracy: 0.6772 - val_loss: 0.8065 - val_accuracy: 0.6638

Epoch 00013: val_loss improved from 0.81260 to 0.80648, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 14/100
937/937 [==============================] - 65s 70ms/step - loss: 0.7877 - accuracy: 0.6782 - val_loss: 0.8057 - val_accuracy: 0.6642

Epoch 00014: val_loss improved from 0.80648 to 0.80566, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 15/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7865 - accuracy: 0.6787 - val_loss: 0.8056 - val_accuracy: 0.6629

Epoch 00015: val_loss improved from 0.80566 to 0.80559, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7846 - accuracy: 0.6796 - val_loss: 0.8006 - val_accuracy: 0.6674

Epoch 00016: val_loss improved from 0.80559 to 0.80056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 17/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7825 - accuracy: 0.6805 - val_loss: 0.7983 - val_accuracy: 0.6687

Epoch 00017: val_loss improved from 0.80056 to 0.79834, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 18/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7813 - accuracy: 0.6814 - val_loss: 0.7987 - val_accuracy: 0.6676

Epoch 00018: val_loss did not improve from 0.79834
Epoch 19/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7797 - accuracy: 0.6821 - val_loss: 0.8008 - val_accuracy: 0.6667

Epoch 00019: val_loss did not improve from 0.79834
Epoch 20/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7785 - accuracy: 0.6828 - val_loss: 0.7947 - val_accuracy: 0.6699

Epoch 00020: val_loss improved from 0.79834 to 0.79471, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7773 - accuracy: 0.6838 - val_loss: 0.8007 - val_accuracy: 0.6663

Epoch 00021: val_loss did not improve from 0.79471
Epoch 22/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7760 - accuracy: 0.6846 - val_loss: 0.7969 - val_accuracy: 0.6683

Epoch 00022: val_loss did not improve from 0.79471
Epoch 23/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7750 - accuracy: 0.6853 - val_loss: 0.7925 - val_accuracy: 0.6714

Epoch 00023: val_loss improved from 0.79471 to 0.79246, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 24/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7733 - accuracy: 0.6861 - val_loss: 0.7942 - val_accuracy: 0.6709

Epoch 00024: val_loss did not improve from 0.79246
Epoch 25/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7726 - accuracy: 0.6869 - val_loss: 0.7913 - val_accuracy: 0.6728

Epoch 00025: val_loss improved from 0.79246 to 0.79128, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 26/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7709 - accuracy: 0.6876 - val_loss: 0.7899 - val_accuracy: 0.6742

Epoch 00026: val_loss improved from 0.79128 to 0.78987, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 27/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7698 - accuracy: 0.6883 - val_loss: 0.7964 - val_accuracy: 0.6692

Epoch 00027: val_loss did not improve from 0.78987
Epoch 28/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7688 - accuracy: 0.6897 - val_loss: 0.7944 - val_accuracy: 0.6710

Epoch 00028: val_loss did not improve from 0.78987
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7676 - accuracy: 0.6903 - val_loss: 0.7945 - val_accuracy: 0.6715

Epoch 00029: val_loss did not improve from 0.78987
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7662 - accuracy: 0.6913 - val_loss: 0.7947 - val_accuracy: 0.6713

Epoch 00030: val_loss did not improve from 0.78987
Epoch 31/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7646 - accuracy: 0.6921 - val_loss: 0.7901 - val_accuracy: 0.6740

Epoch 00031: val_loss did not improve from 0.78987
Epoch 32/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7635 - accuracy: 0.6935 - val_loss: 0.7885 - val_accuracy: 0.6745

Epoch 00032: val_loss improved from 0.78987 to 0.78847, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/2
Epoch 33/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7628 - accuracy: 0.6938 - val_loss: 0.7944 - val_accuracy: 0.6707

Epoch 00033: val_loss did not improve from 0.78847
Epoch 34/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7614 - accuracy: 0.6947 - val_loss: 0.7980 - val_accuracy: 0.6698

Epoch 00034: val_loss did not improve from 0.78847
Epoch 35/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7601 - accuracy: 0.6955 - val_loss: 0.7945 - val_accuracy: 0.6719

Epoch 00035: val_loss did not improve from 0.78847
Epoch 36/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7587 - accuracy: 0.6966 - val_loss: 0.7964 - val_accuracy: 0.6717

Epoch 00036: val_loss did not improve from 0.78847
Epoch 37/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7562 - accuracy: 0.6985 - val_loss: 0.7917 - val_accuracy: 0.6736

Epoch 00037: val_loss did not improve from 0.78847
Epoch 38/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7552 - accuracy: 0.6989 - val_loss: 0.7947 - val_accuracy: 0.6727

Epoch 00038: val_loss did not improve from 0.78847
Epoch 39/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7529 - accuracy: 0.7010 - val_loss: 0.8005 - val_accuracy: 0.6699

Epoch 00039: val_loss did not improve from 0.78847
Epoch 40/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7513 - accuracy: 0.7020 - val_loss: 0.8023 - val_accuracy: 0.6689

Epoch 00040: val_loss did not improve from 0.78847
Epoch 41/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7498 - accuracy: 0.7038 - val_loss: 0.7992 - val_accuracy: 0.6710

Epoch 00041: val_loss did not improve from 0.78847
Epoch 42/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7473 - accuracy: 0.7047 - val_loss: 0.8004 - val_accuracy: 0.6711

Epoch 00042: val_loss did not improve from 0.78847
Epoch 00042: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 664s 4ms/step - loss: 0.7853 - accuracy: 0.6768
Testing Loss = 0.785346, Testing Accuracy = 0.676753
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 65s 69ms/step - loss: 3.0392 - accuracy: 0.5898 - val_loss: 0.9747 - val_accuracy: 0.6479

Epoch 00001: val_loss improved from inf to 0.97466, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8926 - accuracy: 0.6446 - val_loss: 0.8458 - val_accuracy: 0.6512

Epoch 00002: val_loss improved from 0.97466 to 0.84577, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8459 - accuracy: 0.6501 - val_loss: 0.8265 - val_accuracy: 0.6572

Epoch 00003: val_loss improved from 0.84577 to 0.82651, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 4/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8337 - accuracy: 0.6543 - val_loss: 0.8239 - val_accuracy: 0.6568

Epoch 00004: val_loss improved from 0.82651 to 0.82389, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 5/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8254 - accuracy: 0.6580 - val_loss: 0.8263 - val_accuracy: 0.6543

Epoch 00005: val_loss did not improve from 0.82389
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8180 - accuracy: 0.6621 - val_loss: 0.8159 - val_accuracy: 0.6604

Epoch 00006: val_loss improved from 0.82389 to 0.81587, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8116 - accuracy: 0.6655 - val_loss: 0.8163 - val_accuracy: 0.6610

Epoch 00007: val_loss did not improve from 0.81587
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8060 - accuracy: 0.6683 - val_loss: 0.8153 - val_accuracy: 0.6599

Epoch 00008: val_loss improved from 0.81587 to 0.81527, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 9/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8026 - accuracy: 0.6704 - val_loss: 0.8179 - val_accuracy: 0.6581

Epoch 00009: val_loss did not improve from 0.81527
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7992 - accuracy: 0.6723 - val_loss: 0.8124 - val_accuracy: 0.6609

Epoch 00010: val_loss improved from 0.81527 to 0.81238, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7962 - accuracy: 0.6735 - val_loss: 0.8111 - val_accuracy: 0.6616

Epoch 00011: val_loss improved from 0.81238 to 0.81115, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7940 - accuracy: 0.6743 - val_loss: 0.8051 - val_accuracy: 0.6657

Epoch 00012: val_loss improved from 0.81115 to 0.80506, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7923 - accuracy: 0.6760 - val_loss: 0.8108 - val_accuracy: 0.6608

Epoch 00013: val_loss did not improve from 0.80506
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7902 - accuracy: 0.6763 - val_loss: 0.8090 - val_accuracy: 0.6624

Epoch 00014: val_loss did not improve from 0.80506
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7887 - accuracy: 0.6768 - val_loss: 0.8048 - val_accuracy: 0.6651

Epoch 00015: val_loss improved from 0.80506 to 0.80485, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7871 - accuracy: 0.6780 - val_loss: 0.7970 - val_accuracy: 0.6709

Epoch 00016: val_loss improved from 0.80485 to 0.79698, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7854 - accuracy: 0.6786 - val_loss: 0.8027 - val_accuracy: 0.6666

Epoch 00017: val_loss did not improve from 0.79698
Epoch 18/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7847 - accuracy: 0.6795 - val_loss: 0.7999 - val_accuracy: 0.6684

Epoch 00018: val_loss did not improve from 0.79698
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7825 - accuracy: 0.6808 - val_loss: 0.7958 - val_accuracy: 0.6706

Epoch 00019: val_loss improved from 0.79698 to 0.79576, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7811 - accuracy: 0.6810 - val_loss: 0.7908 - val_accuracy: 0.6730

Epoch 00020: val_loss improved from 0.79576 to 0.79083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7799 - accuracy: 0.6819 - val_loss: 0.7949 - val_accuracy: 0.6710

Epoch 00021: val_loss did not improve from 0.79083
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7791 - accuracy: 0.6828 - val_loss: 0.7988 - val_accuracy: 0.6683

Epoch 00022: val_loss did not improve from 0.79083
Epoch 23/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7779 - accuracy: 0.6831 - val_loss: 0.7929 - val_accuracy: 0.6721

Epoch 00023: val_loss did not improve from 0.79083
Epoch 24/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7770 - accuracy: 0.6837 - val_loss: 0.7950 - val_accuracy: 0.6704

Epoch 00024: val_loss did not improve from 0.79083
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7755 - accuracy: 0.6846 - val_loss: 0.7893 - val_accuracy: 0.6740

Epoch 00025: val_loss improved from 0.79083 to 0.78927, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7740 - accuracy: 0.6859 - val_loss: 0.7933 - val_accuracy: 0.6714

Epoch 00026: val_loss did not improve from 0.78927
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7729 - accuracy: 0.6860 - val_loss: 0.7915 - val_accuracy: 0.6722

Epoch 00027: val_loss did not improve from 0.78927
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7715 - accuracy: 0.6873 - val_loss: 0.7959 - val_accuracy: 0.6714

Epoch 00028: val_loss did not improve from 0.78927
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7704 - accuracy: 0.6880 - val_loss: 0.7928 - val_accuracy: 0.6710

Epoch 00029: val_loss did not improve from 0.78927
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7694 - accuracy: 0.6888 - val_loss: 0.7919 - val_accuracy: 0.6721

Epoch 00030: val_loss did not improve from 0.78927
Epoch 31/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7679 - accuracy: 0.6898 - val_loss: 0.7883 - val_accuracy: 0.6742

Epoch 00031: val_loss improved from 0.78927 to 0.78830, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 32/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7665 - accuracy: 0.6911 - val_loss: 0.7877 - val_accuracy: 0.6756

Epoch 00032: val_loss improved from 0.78830 to 0.78775, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/3
Epoch 33/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7652 - accuracy: 0.6920 - val_loss: 0.7886 - val_accuracy: 0.6753

Epoch 00033: val_loss did not improve from 0.78775
Epoch 34/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7643 - accuracy: 0.6925 - val_loss: 0.7884 - val_accuracy: 0.6748

Epoch 00034: val_loss did not improve from 0.78775
Epoch 35/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7628 - accuracy: 0.6931 - val_loss: 0.7912 - val_accuracy: 0.6739

Epoch 00035: val_loss did not improve from 0.78775
Epoch 36/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7608 - accuracy: 0.6948 - val_loss: 0.7906 - val_accuracy: 0.6748

Epoch 00036: val_loss did not improve from 0.78775
Epoch 37/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7597 - accuracy: 0.6958 - val_loss: 0.7889 - val_accuracy: 0.6757

Epoch 00037: val_loss did not improve from 0.78775
Epoch 38/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7585 - accuracy: 0.6965 - val_loss: 0.7927 - val_accuracy: 0.6738

Epoch 00038: val_loss did not improve from 0.78775
Epoch 39/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7572 - accuracy: 0.6977 - val_loss: 0.7927 - val_accuracy: 0.6739

Epoch 00039: val_loss did not improve from 0.78775
Epoch 40/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7551 - accuracy: 0.6995 - val_loss: 0.7947 - val_accuracy: 0.6734

Epoch 00040: val_loss did not improve from 0.78775
Epoch 41/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7537 - accuracy: 0.7007 - val_loss: 0.7903 - val_accuracy: 0.6755

Epoch 00041: val_loss did not improve from 0.78775
Epoch 42/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7513 - accuracy: 0.7017 - val_loss: 0.7960 - val_accuracy: 0.6732

Epoch 00042: val_loss did not improve from 0.78775
Epoch 00042: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 667s 4ms/step - loss: 0.7843 - accuracy: 0.6776
Testing Loss = 0.784315, Testing Accuracy = 0.677567
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 74s 78ms/step - loss: 3.0422 - accuracy: 0.6007 - val_loss: 0.9832 - val_accuracy: 0.6481

Epoch 00001: val_loss improved from inf to 0.98320, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8974 - accuracy: 0.6448 - val_loss: 0.8517 - val_accuracy: 0.6506

Epoch 00002: val_loss improved from 0.98320 to 0.85173, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8485 - accuracy: 0.6503 - val_loss: 0.8346 - val_accuracy: 0.6547

Epoch 00003: val_loss improved from 0.85173 to 0.83465, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 4/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8361 - accuracy: 0.6550 - val_loss: 0.8284 - val_accuracy: 0.6553

Epoch 00004: val_loss improved from 0.83465 to 0.82838, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 5/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8272 - accuracy: 0.6587 - val_loss: 0.8251 - val_accuracy: 0.6550

Epoch 00005: val_loss improved from 0.82838 to 0.82507, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8209 - accuracy: 0.6615 - val_loss: 0.8226 - val_accuracy: 0.6559

Epoch 00006: val_loss improved from 0.82507 to 0.82261, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 7/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8142 - accuracy: 0.6645 - val_loss: 0.8200 - val_accuracy: 0.6561

Epoch 00007: val_loss improved from 0.82261 to 0.82004, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8091 - accuracy: 0.6672 - val_loss: 0.8215 - val_accuracy: 0.6544

Epoch 00008: val_loss did not improve from 0.82004
Epoch 9/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8041 - accuracy: 0.6698 - val_loss: 0.8138 - val_accuracy: 0.6598

Epoch 00009: val_loss improved from 0.82004 to 0.81376, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8006 - accuracy: 0.6716 - val_loss: 0.8152 - val_accuracy: 0.6589

Epoch 00010: val_loss did not improve from 0.81376
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7973 - accuracy: 0.6735 - val_loss: 0.8181 - val_accuracy: 0.6561

Epoch 00011: val_loss did not improve from 0.81376
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7946 - accuracy: 0.6746 - val_loss: 0.8146 - val_accuracy: 0.6591

Epoch 00012: val_loss did not improve from 0.81376
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7922 - accuracy: 0.6760 - val_loss: 0.8059 - val_accuracy: 0.6638

Epoch 00013: val_loss improved from 0.81376 to 0.80586, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7903 - accuracy: 0.6766 - val_loss: 0.8147 - val_accuracy: 0.6570

Epoch 00014: val_loss did not improve from 0.80586
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7883 - accuracy: 0.6784 - val_loss: 0.8027 - val_accuracy: 0.6651

Epoch 00015: val_loss improved from 0.80586 to 0.80267, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7861 - accuracy: 0.6800 - val_loss: 0.8033 - val_accuracy: 0.6652

Epoch 00016: val_loss did not improve from 0.80267
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7844 - accuracy: 0.6801 - val_loss: 0.8024 - val_accuracy: 0.6648

Epoch 00017: val_loss improved from 0.80267 to 0.80244, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 18/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7829 - accuracy: 0.6810 - val_loss: 0.8036 - val_accuracy: 0.6635

Epoch 00018: val_loss did not improve from 0.80244
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7809 - accuracy: 0.6823 - val_loss: 0.8053 - val_accuracy: 0.6633

Epoch 00019: val_loss did not improve from 0.80244
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7801 - accuracy: 0.6826 - val_loss: 0.8076 - val_accuracy: 0.6626

Epoch 00020: val_loss did not improve from 0.80244
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7778 - accuracy: 0.6840 - val_loss: 0.8007 - val_accuracy: 0.6660

Epoch 00021: val_loss improved from 0.80244 to 0.80069, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7768 - accuracy: 0.6847 - val_loss: 0.8014 - val_accuracy: 0.6661

Epoch 00022: val_loss did not improve from 0.80069
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7757 - accuracy: 0.6854 - val_loss: 0.8007 - val_accuracy: 0.6664

Epoch 00023: val_loss improved from 0.80069 to 0.80067, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 24/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7745 - accuracy: 0.6862 - val_loss: 0.7980 - val_accuracy: 0.6691

Epoch 00024: val_loss improved from 0.80067 to 0.79800, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7728 - accuracy: 0.6871 - val_loss: 0.7959 - val_accuracy: 0.6692

Epoch 00025: val_loss improved from 0.79800 to 0.79590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7707 - accuracy: 0.6887 - val_loss: 0.7912 - val_accuracy: 0.6728

Epoch 00026: val_loss improved from 0.79590 to 0.79123, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/4
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7701 - accuracy: 0.6887 - val_loss: 0.8018 - val_accuracy: 0.6670

Epoch 00027: val_loss did not improve from 0.79123
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7680 - accuracy: 0.6905 - val_loss: 0.7965 - val_accuracy: 0.6692

Epoch 00028: val_loss did not improve from 0.79123
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7670 - accuracy: 0.6911 - val_loss: 0.7934 - val_accuracy: 0.6717

Epoch 00029: val_loss did not improve from 0.79123
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7652 - accuracy: 0.6925 - val_loss: 0.7934 - val_accuracy: 0.6717

Epoch 00030: val_loss did not improve from 0.79123
Epoch 31/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7644 - accuracy: 0.6935 - val_loss: 0.7925 - val_accuracy: 0.6725

Epoch 00031: val_loss did not improve from 0.79123
Epoch 32/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7621 - accuracy: 0.6947 - val_loss: 0.7931 - val_accuracy: 0.6729

Epoch 00032: val_loss did not improve from 0.79123
Epoch 33/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7601 - accuracy: 0.6961 - val_loss: 0.7949 - val_accuracy: 0.6715

Epoch 00033: val_loss did not improve from 0.79123
Epoch 34/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7586 - accuracy: 0.6973 - val_loss: 0.7944 - val_accuracy: 0.6720

Epoch 00034: val_loss did not improve from 0.79123
Epoch 35/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7575 - accuracy: 0.6986 - val_loss: 0.8018 - val_accuracy: 0.6676

Epoch 00035: val_loss did not improve from 0.79123
Epoch 36/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7548 - accuracy: 0.7005 - val_loss: 0.7963 - val_accuracy: 0.6712

Epoch 00036: val_loss did not improve from 0.79123
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 671s 4ms/step - loss: 0.7879 - accuracy: 0.6755
Testing Loss = 0.787947, Testing Accuracy = 0.675507
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 65s 68ms/step - loss: 3.0394 - accuracy: 0.5994 - val_loss: 0.9787 - val_accuracy: 0.6483

Epoch 00001: val_loss improved from inf to 0.97874, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8946 - accuracy: 0.6447 - val_loss: 0.8446 - val_accuracy: 0.6537

Epoch 00002: val_loss improved from 0.97874 to 0.84455, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 3/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8475 - accuracy: 0.6505 - val_loss: 0.8332 - val_accuracy: 0.6547

Epoch 00003: val_loss improved from 0.84455 to 0.83319, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 4/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8347 - accuracy: 0.6549 - val_loss: 0.8275 - val_accuracy: 0.6563

Epoch 00004: val_loss improved from 0.83319 to 0.82752, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 5/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8262 - accuracy: 0.6587 - val_loss: 0.8290 - val_accuracy: 0.6535

Epoch 00005: val_loss did not improve from 0.82752
Epoch 6/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8183 - accuracy: 0.6618 - val_loss: 0.8272 - val_accuracy: 0.6534

Epoch 00006: val_loss improved from 0.82752 to 0.82718, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 7/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8119 - accuracy: 0.6655 - val_loss: 0.8212 - val_accuracy: 0.6557

Epoch 00007: val_loss improved from 0.82718 to 0.82125, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 8/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8066 - accuracy: 0.6683 - val_loss: 0.8204 - val_accuracy: 0.6573

Epoch 00008: val_loss improved from 0.82125 to 0.82037, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 9/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8025 - accuracy: 0.6705 - val_loss: 0.8251 - val_accuracy: 0.6545

Epoch 00009: val_loss did not improve from 0.82037
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7986 - accuracy: 0.6720 - val_loss: 0.8159 - val_accuracy: 0.6584

Epoch 00010: val_loss improved from 0.82037 to 0.81594, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7954 - accuracy: 0.6744 - val_loss: 0.8173 - val_accuracy: 0.6575

Epoch 00011: val_loss did not improve from 0.81594
Epoch 12/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7928 - accuracy: 0.6754 - val_loss: 0.8095 - val_accuracy: 0.6624

Epoch 00012: val_loss improved from 0.81594 to 0.80951, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7905 - accuracy: 0.6761 - val_loss: 0.8103 - val_accuracy: 0.6619

Epoch 00013: val_loss did not improve from 0.80951
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7891 - accuracy: 0.6779 - val_loss: 0.8031 - val_accuracy: 0.6661

Epoch 00014: val_loss improved from 0.80951 to 0.80307, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 15/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7870 - accuracy: 0.6784 - val_loss: 0.7998 - val_accuracy: 0.6672

Epoch 00015: val_loss improved from 0.80307 to 0.79982, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7851 - accuracy: 0.6795 - val_loss: 0.8040 - val_accuracy: 0.6648

Epoch 00016: val_loss did not improve from 0.79982
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7828 - accuracy: 0.6807 - val_loss: 0.7977 - val_accuracy: 0.6690

Epoch 00017: val_loss improved from 0.79982 to 0.79768, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 18/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7820 - accuracy: 0.6811 - val_loss: 0.7969 - val_accuracy: 0.6695

Epoch 00018: val_loss improved from 0.79768 to 0.79685, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7803 - accuracy: 0.6826 - val_loss: 0.7991 - val_accuracy: 0.6671

Epoch 00019: val_loss did not improve from 0.79685
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7786 - accuracy: 0.6830 - val_loss: 0.7965 - val_accuracy: 0.6692

Epoch 00020: val_loss improved from 0.79685 to 0.79651, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 21/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7777 - accuracy: 0.6843 - val_loss: 0.7914 - val_accuracy: 0.6724

Epoch 00021: val_loss improved from 0.79651 to 0.79142, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7760 - accuracy: 0.6847 - val_loss: 0.7959 - val_accuracy: 0.6692

Epoch 00022: val_loss did not improve from 0.79142
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7745 - accuracy: 0.6859 - val_loss: 0.7971 - val_accuracy: 0.6684

Epoch 00023: val_loss did not improve from 0.79142
Epoch 24/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7740 - accuracy: 0.6865 - val_loss: 0.7900 - val_accuracy: 0.6731

Epoch 00024: val_loss improved from 0.79142 to 0.78997, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7730 - accuracy: 0.6865 - val_loss: 0.7929 - val_accuracy: 0.6705

Epoch 00025: val_loss did not improve from 0.78997
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7707 - accuracy: 0.6886 - val_loss: 0.7887 - val_accuracy: 0.6737

Epoch 00026: val_loss improved from 0.78997 to 0.78875, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/5
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7702 - accuracy: 0.6887 - val_loss: 0.7934 - val_accuracy: 0.6710

Epoch 00027: val_loss did not improve from 0.78875
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7687 - accuracy: 0.6895 - val_loss: 0.7923 - val_accuracy: 0.6711

Epoch 00028: val_loss did not improve from 0.78875
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7676 - accuracy: 0.6907 - val_loss: 0.7936 - val_accuracy: 0.6713

Epoch 00029: val_loss did not improve from 0.78875
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7656 - accuracy: 0.6915 - val_loss: 0.7904 - val_accuracy: 0.6738

Epoch 00030: val_loss did not improve from 0.78875
Epoch 31/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7648 - accuracy: 0.6925 - val_loss: 0.7909 - val_accuracy: 0.6730

Epoch 00031: val_loss did not improve from 0.78875
Epoch 32/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7632 - accuracy: 0.6938 - val_loss: 0.7911 - val_accuracy: 0.6730

Epoch 00032: val_loss did not improve from 0.78875
Epoch 33/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7618 - accuracy: 0.6947 - val_loss: 0.8015 - val_accuracy: 0.6678

Epoch 00033: val_loss did not improve from 0.78875
Epoch 34/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7603 - accuracy: 0.6954 - val_loss: 0.7972 - val_accuracy: 0.6699

Epoch 00034: val_loss did not improve from 0.78875
Epoch 35/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7585 - accuracy: 0.6972 - val_loss: 0.7949 - val_accuracy: 0.6715

Epoch 00035: val_loss did not improve from 0.78875
Epoch 36/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7568 - accuracy: 0.6981 - val_loss: 0.7947 - val_accuracy: 0.6725

Epoch 00036: val_loss did not improve from 0.78875
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 663s 4ms/step - loss: 0.7855 - accuracy: 0.6773
Testing Loss = 0.785472, Testing Accuracy = 0.677273
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 66s 69ms/step - loss: 3.0652 - accuracy: 0.5884 - val_loss: 0.9754 - val_accuracy: 0.6486

Epoch 00001: val_loss improved from inf to 0.97540, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 2/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8929 - accuracy: 0.6453 - val_loss: 0.8416 - val_accuracy: 0.6548

Epoch 00002: val_loss improved from 0.97540 to 0.84164, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 3/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8467 - accuracy: 0.6509 - val_loss: 0.8296 - val_accuracy: 0.6567

Epoch 00003: val_loss improved from 0.84164 to 0.82962, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 4/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8338 - accuracy: 0.6550 - val_loss: 0.8280 - val_accuracy: 0.6559

Epoch 00004: val_loss improved from 0.82962 to 0.82802, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 5/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8259 - accuracy: 0.6586 - val_loss: 0.8328 - val_accuracy: 0.6499

Epoch 00005: val_loss did not improve from 0.82802
Epoch 6/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8175 - accuracy: 0.6630 - val_loss: 0.8190 - val_accuracy: 0.6594

Epoch 00006: val_loss improved from 0.82802 to 0.81905, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8111 - accuracy: 0.6666 - val_loss: 0.8175 - val_accuracy: 0.6592

Epoch 00007: val_loss improved from 0.81905 to 0.81747, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8058 - accuracy: 0.6691 - val_loss: 0.8174 - val_accuracy: 0.6581

Epoch 00008: val_loss improved from 0.81747 to 0.81743, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 9/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8012 - accuracy: 0.6721 - val_loss: 0.8141 - val_accuracy: 0.6606

Epoch 00009: val_loss improved from 0.81743 to 0.81411, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7983 - accuracy: 0.6733 - val_loss: 0.8176 - val_accuracy: 0.6577

Epoch 00010: val_loss did not improve from 0.81411
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7951 - accuracy: 0.6746 - val_loss: 0.8090 - val_accuracy: 0.6637

Epoch 00011: val_loss improved from 0.81411 to 0.80902, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 12/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7933 - accuracy: 0.6755 - val_loss: 0.8168 - val_accuracy: 0.6573

Epoch 00012: val_loss did not improve from 0.80902
Epoch 13/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7911 - accuracy: 0.6767 - val_loss: 0.8029 - val_accuracy: 0.6668

Epoch 00013: val_loss improved from 0.80902 to 0.80287, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7889 - accuracy: 0.6772 - val_loss: 0.8047 - val_accuracy: 0.6651

Epoch 00014: val_loss did not improve from 0.80287
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7873 - accuracy: 0.6781 - val_loss: 0.8102 - val_accuracy: 0.6619

Epoch 00015: val_loss did not improve from 0.80287
Epoch 16/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7862 - accuracy: 0.6785 - val_loss: 0.8046 - val_accuracy: 0.6648

Epoch 00016: val_loss did not improve from 0.80287
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7842 - accuracy: 0.6802 - val_loss: 0.8007 - val_accuracy: 0.6672

Epoch 00017: val_loss improved from 0.80287 to 0.80067, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 18/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7824 - accuracy: 0.6809 - val_loss: 0.7972 - val_accuracy: 0.6693

Epoch 00018: val_loss improved from 0.80067 to 0.79720, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 19/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7811 - accuracy: 0.6817 - val_loss: 0.7989 - val_accuracy: 0.6676

Epoch 00019: val_loss did not improve from 0.79720
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7789 - accuracy: 0.6829 - val_loss: 0.7968 - val_accuracy: 0.6686

Epoch 00020: val_loss improved from 0.79720 to 0.79679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 21/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7786 - accuracy: 0.6832 - val_loss: 0.7959 - val_accuracy: 0.6703

Epoch 00021: val_loss improved from 0.79679 to 0.79589, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 22/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7767 - accuracy: 0.6844 - val_loss: 0.7922 - val_accuracy: 0.6733

Epoch 00022: val_loss improved from 0.79589 to 0.79218, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 23/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7759 - accuracy: 0.6845 - val_loss: 0.7987 - val_accuracy: 0.6683

Epoch 00023: val_loss did not improve from 0.79218
Epoch 24/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7737 - accuracy: 0.6862 - val_loss: 0.7983 - val_accuracy: 0.6681

Epoch 00024: val_loss did not improve from 0.79218
Epoch 25/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7731 - accuracy: 0.6862 - val_loss: 0.7938 - val_accuracy: 0.6711

Epoch 00025: val_loss did not improve from 0.79218
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7713 - accuracy: 0.6880 - val_loss: 0.7941 - val_accuracy: 0.6713

Epoch 00026: val_loss did not improve from 0.79218
Epoch 27/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7702 - accuracy: 0.6888 - val_loss: 0.7956 - val_accuracy: 0.6709

Epoch 00027: val_loss did not improve from 0.79218
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7691 - accuracy: 0.6894 - val_loss: 0.7956 - val_accuracy: 0.6697

Epoch 00028: val_loss did not improve from 0.79218
Epoch 29/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7678 - accuracy: 0.6900 - val_loss: 0.7945 - val_accuracy: 0.6703

Epoch 00029: val_loss did not improve from 0.79218
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7663 - accuracy: 0.6912 - val_loss: 0.7874 - val_accuracy: 0.6753

Epoch 00030: val_loss improved from 0.79218 to 0.78736, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/6
Epoch 31/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7646 - accuracy: 0.6921 - val_loss: 0.7932 - val_accuracy: 0.6718

Epoch 00031: val_loss did not improve from 0.78736
Epoch 32/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7632 - accuracy: 0.6935 - val_loss: 0.7953 - val_accuracy: 0.6714

Epoch 00032: val_loss did not improve from 0.78736
Epoch 33/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7624 - accuracy: 0.6942 - val_loss: 0.7955 - val_accuracy: 0.6716

Epoch 00033: val_loss did not improve from 0.78736
Epoch 34/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7602 - accuracy: 0.6957 - val_loss: 0.7942 - val_accuracy: 0.6724

Epoch 00034: val_loss did not improve from 0.78736
Epoch 35/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7595 - accuracy: 0.6961 - val_loss: 0.7957 - val_accuracy: 0.6718

Epoch 00035: val_loss did not improve from 0.78736
Epoch 36/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7579 - accuracy: 0.6973 - val_loss: 0.7956 - val_accuracy: 0.6722

Epoch 00036: val_loss did not improve from 0.78736
Epoch 37/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7556 - accuracy: 0.6997 - val_loss: 0.7963 - val_accuracy: 0.6722

Epoch 00037: val_loss did not improve from 0.78736
Epoch 38/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7543 - accuracy: 0.7000 - val_loss: 0.7949 - val_accuracy: 0.6720

Epoch 00038: val_loss did not improve from 0.78736
Epoch 39/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7528 - accuracy: 0.7011 - val_loss: 0.7990 - val_accuracy: 0.6704

Epoch 00039: val_loss did not improve from 0.78736
Epoch 40/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7510 - accuracy: 0.7025 - val_loss: 0.7992 - val_accuracy: 0.6713

Epoch 00040: val_loss did not improve from 0.78736
Epoch 00040: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 669s 4ms/step - loss: 0.7841 - accuracy: 0.6778
Testing Loss = 0.784147, Testing Accuracy = 0.677820
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 66s 70ms/step - loss: 3.0352 - accuracy: 0.5963 - val_loss: 0.9781 - val_accuracy: 0.6477

Epoch 00001: val_loss improved from inf to 0.97806, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 2/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8953 - accuracy: 0.6448 - val_loss: 0.8450 - val_accuracy: 0.6533

Epoch 00002: val_loss improved from 0.97806 to 0.84505, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 3/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8476 - accuracy: 0.6508 - val_loss: 0.8312 - val_accuracy: 0.6558

Epoch 00003: val_loss improved from 0.84505 to 0.83123, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 4/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8348 - accuracy: 0.6547 - val_loss: 0.8337 - val_accuracy: 0.6501

Epoch 00004: val_loss did not improve from 0.83123
Epoch 5/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8254 - accuracy: 0.6593 - val_loss: 0.8207 - val_accuracy: 0.6583

Epoch 00005: val_loss improved from 0.83123 to 0.82073, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8167 - accuracy: 0.6645 - val_loss: 0.8168 - val_accuracy: 0.6602

Epoch 00006: val_loss improved from 0.82073 to 0.81684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 7/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8100 - accuracy: 0.6671 - val_loss: 0.8133 - val_accuracy: 0.6624

Epoch 00007: val_loss improved from 0.81684 to 0.81326, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 8/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8059 - accuracy: 0.6694 - val_loss: 0.8171 - val_accuracy: 0.6592

Epoch 00008: val_loss did not improve from 0.81326
Epoch 9/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8018 - accuracy: 0.6713 - val_loss: 0.8201 - val_accuracy: 0.6569

Epoch 00009: val_loss did not improve from 0.81326
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7988 - accuracy: 0.6735 - val_loss: 0.8182 - val_accuracy: 0.6584

Epoch 00010: val_loss did not improve from 0.81326
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7958 - accuracy: 0.6742 - val_loss: 0.8216 - val_accuracy: 0.6553

Epoch 00011: val_loss did not improve from 0.81326
Epoch 12/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7931 - accuracy: 0.6760 - val_loss: 0.8062 - val_accuracy: 0.6652

Epoch 00012: val_loss improved from 0.81326 to 0.80622, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 13/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7908 - accuracy: 0.6766 - val_loss: 0.8165 - val_accuracy: 0.6590

Epoch 00013: val_loss did not improve from 0.80622
Epoch 14/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7888 - accuracy: 0.6779 - val_loss: 0.8174 - val_accuracy: 0.6577

Epoch 00014: val_loss did not improve from 0.80622
Epoch 15/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7876 - accuracy: 0.6786 - val_loss: 0.8113 - val_accuracy: 0.6609

Epoch 00015: val_loss did not improve from 0.80622
Epoch 16/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7857 - accuracy: 0.6791 - val_loss: 0.8150 - val_accuracy: 0.6587

Epoch 00016: val_loss did not improve from 0.80622
Epoch 17/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7837 - accuracy: 0.6809 - val_loss: 0.8020 - val_accuracy: 0.6659

Epoch 00017: val_loss improved from 0.80622 to 0.80200, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 18/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7828 - accuracy: 0.6811 - val_loss: 0.8061 - val_accuracy: 0.6631

Epoch 00018: val_loss did not improve from 0.80200
Epoch 19/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7809 - accuracy: 0.6819 - val_loss: 0.8090 - val_accuracy: 0.6621

Epoch 00019: val_loss did not improve from 0.80200
Epoch 20/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7804 - accuracy: 0.6825 - val_loss: 0.8098 - val_accuracy: 0.6609

Epoch 00020: val_loss did not improve from 0.80200
Epoch 21/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7783 - accuracy: 0.6837 - val_loss: 0.8070 - val_accuracy: 0.6637

Epoch 00021: val_loss did not improve from 0.80200
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7768 - accuracy: 0.6843 - val_loss: 0.7966 - val_accuracy: 0.6698

Epoch 00022: val_loss improved from 0.80200 to 0.79658, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 23/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7761 - accuracy: 0.6850 - val_loss: 0.7999 - val_accuracy: 0.6670

Epoch 00023: val_loss did not improve from 0.79658
Epoch 24/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7743 - accuracy: 0.6858 - val_loss: 0.8013 - val_accuracy: 0.6664

Epoch 00024: val_loss did not improve from 0.79658
Epoch 25/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7731 - accuracy: 0.6871 - val_loss: 0.7966 - val_accuracy: 0.6704

Epoch 00025: val_loss improved from 0.79658 to 0.79656, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7724 - accuracy: 0.6874 - val_loss: 0.7976 - val_accuracy: 0.6676

Epoch 00026: val_loss did not improve from 0.79656
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7711 - accuracy: 0.6881 - val_loss: 0.7978 - val_accuracy: 0.6687

Epoch 00027: val_loss did not improve from 0.79656
Epoch 28/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7695 - accuracy: 0.6889 - val_loss: 0.7999 - val_accuracy: 0.6677

Epoch 00028: val_loss did not improve from 0.79656
Epoch 29/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7686 - accuracy: 0.6901 - val_loss: 0.7962 - val_accuracy: 0.6703

Epoch 00029: val_loss improved from 0.79656 to 0.79618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7673 - accuracy: 0.6912 - val_loss: 0.7933 - val_accuracy: 0.6719

Epoch 00030: val_loss improved from 0.79618 to 0.79328, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 31/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7653 - accuracy: 0.6923 - val_loss: 0.7973 - val_accuracy: 0.6691

Epoch 00031: val_loss did not improve from 0.79328
Epoch 32/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7647 - accuracy: 0.6928 - val_loss: 0.7953 - val_accuracy: 0.6706

Epoch 00032: val_loss did not improve from 0.79328
Epoch 33/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7630 - accuracy: 0.6941 - val_loss: 0.7977 - val_accuracy: 0.6699

Epoch 00033: val_loss did not improve from 0.79328
Epoch 34/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7621 - accuracy: 0.6948 - val_loss: 0.7911 - val_accuracy: 0.6738

Epoch 00034: val_loss improved from 0.79328 to 0.79105, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/7
Epoch 35/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7603 - accuracy: 0.6957 - val_loss: 0.7960 - val_accuracy: 0.6708

Epoch 00035: val_loss did not improve from 0.79105
Epoch 36/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7594 - accuracy: 0.6967 - val_loss: 0.7957 - val_accuracy: 0.6707

Epoch 00036: val_loss did not improve from 0.79105
Epoch 37/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7569 - accuracy: 0.6987 - val_loss: 0.8030 - val_accuracy: 0.6680

Epoch 00037: val_loss did not improve from 0.79105
Epoch 38/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7547 - accuracy: 0.6997 - val_loss: 0.8027 - val_accuracy: 0.6677

Epoch 00038: val_loss did not improve from 0.79105
Epoch 39/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7539 - accuracy: 0.7003 - val_loss: 0.8014 - val_accuracy: 0.6699

Epoch 00039: val_loss did not improve from 0.79105
Epoch 40/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7520 - accuracy: 0.7021 - val_loss: 0.8020 - val_accuracy: 0.6702

Epoch 00040: val_loss did not improve from 0.79105
Epoch 41/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7509 - accuracy: 0.7031 - val_loss: 0.7954 - val_accuracy: 0.6738

Epoch 00041: val_loss did not improve from 0.79105
Epoch 42/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7478 - accuracy: 0.7054 - val_loss: 0.8029 - val_accuracy: 0.6704

Epoch 00042: val_loss did not improve from 0.79105
Epoch 43/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7469 - accuracy: 0.7063 - val_loss: 0.7985 - val_accuracy: 0.6732

Epoch 00043: val_loss did not improve from 0.79105
Epoch 44/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7445 - accuracy: 0.7080 - val_loss: 0.8088 - val_accuracy: 0.6678

Epoch 00044: val_loss did not improve from 0.79105
Epoch 00044: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 671s 4ms/step - loss: 0.7873 - accuracy: 0.6768
Testing Loss = 0.787345, Testing Accuracy = 0.676767
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 64s 68ms/step - loss: 3.0241 - accuracy: 0.6009 - val_loss: 0.9782 - val_accuracy: 0.6481

Epoch 00001: val_loss improved from inf to 0.97822, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 2/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8948 - accuracy: 0.6453 - val_loss: 0.8460 - val_accuracy: 0.6542

Epoch 00002: val_loss improved from 0.97822 to 0.84601, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8480 - accuracy: 0.6513 - val_loss: 0.8346 - val_accuracy: 0.6553

Epoch 00003: val_loss improved from 0.84601 to 0.83462, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 4/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8355 - accuracy: 0.6548 - val_loss: 0.8277 - val_accuracy: 0.6571

Epoch 00004: val_loss improved from 0.83462 to 0.82765, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 5/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8265 - accuracy: 0.6592 - val_loss: 0.8241 - val_accuracy: 0.6574

Epoch 00005: val_loss improved from 0.82765 to 0.82410, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8187 - accuracy: 0.6626 - val_loss: 0.8328 - val_accuracy: 0.6501

Epoch 00006: val_loss did not improve from 0.82410
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8125 - accuracy: 0.6663 - val_loss: 0.8225 - val_accuracy: 0.6564

Epoch 00007: val_loss improved from 0.82410 to 0.82254, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8068 - accuracy: 0.6694 - val_loss: 0.8134 - val_accuracy: 0.6618

Epoch 00008: val_loss improved from 0.82254 to 0.81341, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 9/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8020 - accuracy: 0.6718 - val_loss: 0.8119 - val_accuracy: 0.6626

Epoch 00009: val_loss improved from 0.81341 to 0.81192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7986 - accuracy: 0.6734 - val_loss: 0.8168 - val_accuracy: 0.6585

Epoch 00010: val_loss did not improve from 0.81192
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7957 - accuracy: 0.6747 - val_loss: 0.8139 - val_accuracy: 0.6599

Epoch 00011: val_loss did not improve from 0.81192
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7927 - accuracy: 0.6762 - val_loss: 0.8112 - val_accuracy: 0.6613

Epoch 00012: val_loss improved from 0.81192 to 0.81117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7901 - accuracy: 0.6775 - val_loss: 0.8088 - val_accuracy: 0.6620

Epoch 00013: val_loss improved from 0.81117 to 0.80877, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7879 - accuracy: 0.6784 - val_loss: 0.8057 - val_accuracy: 0.6645

Epoch 00014: val_loss improved from 0.80877 to 0.80575, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 15/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7859 - accuracy: 0.6797 - val_loss: 0.8079 - val_accuracy: 0.6619

Epoch 00015: val_loss did not improve from 0.80575
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7841 - accuracy: 0.6805 - val_loss: 0.8045 - val_accuracy: 0.6642

Epoch 00016: val_loss improved from 0.80575 to 0.80448, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7819 - accuracy: 0.6815 - val_loss: 0.8013 - val_accuracy: 0.6664

Epoch 00017: val_loss improved from 0.80448 to 0.80129, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 18/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7811 - accuracy: 0.6820 - val_loss: 0.8052 - val_accuracy: 0.6640

Epoch 00018: val_loss did not improve from 0.80129
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7794 - accuracy: 0.6830 - val_loss: 0.8008 - val_accuracy: 0.6668

Epoch 00019: val_loss improved from 0.80129 to 0.80083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 20/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7775 - accuracy: 0.6843 - val_loss: 0.8033 - val_accuracy: 0.6648

Epoch 00020: val_loss did not improve from 0.80083
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7766 - accuracy: 0.6852 - val_loss: 0.8082 - val_accuracy: 0.6620

Epoch 00021: val_loss did not improve from 0.80083
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7756 - accuracy: 0.6857 - val_loss: 0.7978 - val_accuracy: 0.6688

Epoch 00022: val_loss improved from 0.80083 to 0.79780, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7735 - accuracy: 0.6873 - val_loss: 0.8006 - val_accuracy: 0.6669

Epoch 00023: val_loss did not improve from 0.79780
Epoch 24/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7714 - accuracy: 0.6878 - val_loss: 0.8046 - val_accuracy: 0.6647

Epoch 00024: val_loss did not improve from 0.79780
Epoch 25/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7707 - accuracy: 0.6882 - val_loss: 0.7965 - val_accuracy: 0.6704

Epoch 00025: val_loss improved from 0.79780 to 0.79653, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/8
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7684 - accuracy: 0.6899 - val_loss: 0.7996 - val_accuracy: 0.6682

Epoch 00026: val_loss did not improve from 0.79653
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7671 - accuracy: 0.6910 - val_loss: 0.7973 - val_accuracy: 0.6702

Epoch 00027: val_loss did not improve from 0.79653
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7658 - accuracy: 0.6918 - val_loss: 0.7985 - val_accuracy: 0.6684

Epoch 00028: val_loss did not improve from 0.79653
Epoch 29/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7638 - accuracy: 0.6938 - val_loss: 0.7975 - val_accuracy: 0.6698

Epoch 00029: val_loss did not improve from 0.79653
Epoch 30/100
937/937 [==============================] - 89s 95ms/step - loss: 0.7626 - accuracy: 0.6941 - val_loss: 0.8006 - val_accuracy: 0.6680

Epoch 00030: val_loss did not improve from 0.79653
Epoch 31/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7610 - accuracy: 0.6958 - val_loss: 0.8003 - val_accuracy: 0.6689

Epoch 00031: val_loss did not improve from 0.79653
Epoch 32/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7597 - accuracy: 0.6968 - val_loss: 0.7979 - val_accuracy: 0.6712

Epoch 00032: val_loss did not improve from 0.79653
Epoch 33/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7567 - accuracy: 0.6987 - val_loss: 0.8012 - val_accuracy: 0.6697

Epoch 00033: val_loss did not improve from 0.79653
Epoch 34/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7556 - accuracy: 0.6995 - val_loss: 0.7995 - val_accuracy: 0.6711

Epoch 00034: val_loss did not improve from 0.79653
Epoch 35/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7536 - accuracy: 0.7016 - val_loss: 0.8039 - val_accuracy: 0.6680

Epoch 00035: val_loss did not improve from 0.79653
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 679s 5ms/step - loss: 0.7933 - accuracy: 0.6721
Testing Loss = 0.793344, Testing Accuracy = 0.672120
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 480000.
Epoch 1/100
937/937 [==============================] - 65s 68ms/step - loss: 3.0813 - accuracy: 0.5906 - val_loss: 0.9801 - val_accuracy: 0.6484

Epoch 00001: val_loss improved from inf to 0.98007, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8943 - accuracy: 0.6451 - val_loss: 0.8437 - val_accuracy: 0.6535

Epoch 00002: val_loss improved from 0.98007 to 0.84375, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8462 - accuracy: 0.6503 - val_loss: 0.8386 - val_accuracy: 0.6522

Epoch 00003: val_loss improved from 0.84375 to 0.83856, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 4/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8341 - accuracy: 0.6547 - val_loss: 0.8293 - val_accuracy: 0.6539

Epoch 00004: val_loss improved from 0.83856 to 0.82933, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 5/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8249 - accuracy: 0.6587 - val_loss: 0.8247 - val_accuracy: 0.6548

Epoch 00005: val_loss improved from 0.82933 to 0.82474, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 6/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8179 - accuracy: 0.6625 - val_loss: 0.8313 - val_accuracy: 0.6499

Epoch 00006: val_loss did not improve from 0.82474
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8110 - accuracy: 0.6663 - val_loss: 0.8239 - val_accuracy: 0.6548

Epoch 00007: val_loss improved from 0.82474 to 0.82393, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8059 - accuracy: 0.6692 - val_loss: 0.8258 - val_accuracy: 0.6533

Epoch 00008: val_loss did not improve from 0.82393
Epoch 9/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8018 - accuracy: 0.6710 - val_loss: 0.8173 - val_accuracy: 0.6593

Epoch 00009: val_loss improved from 0.82393 to 0.81730, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7981 - accuracy: 0.6729 - val_loss: 0.8189 - val_accuracy: 0.6571

Epoch 00010: val_loss did not improve from 0.81730
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7952 - accuracy: 0.6745 - val_loss: 0.8112 - val_accuracy: 0.6611

Epoch 00011: val_loss improved from 0.81730 to 0.81117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 12/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7925 - accuracy: 0.6754 - val_loss: 0.8126 - val_accuracy: 0.6601

Epoch 00012: val_loss did not improve from 0.81117
Epoch 13/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7897 - accuracy: 0.6773 - val_loss: 0.8112 - val_accuracy: 0.6606

Epoch 00013: val_loss did not improve from 0.81117
Epoch 14/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7885 - accuracy: 0.6780 - val_loss: 0.8035 - val_accuracy: 0.6660

Epoch 00014: val_loss improved from 0.81117 to 0.80346, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7862 - accuracy: 0.6794 - val_loss: 0.8091 - val_accuracy: 0.6625

Epoch 00015: val_loss did not improve from 0.80346
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7848 - accuracy: 0.6802 - val_loss: 0.8033 - val_accuracy: 0.6669

Epoch 00016: val_loss improved from 0.80346 to 0.80335, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7831 - accuracy: 0.6812 - val_loss: 0.8004 - val_accuracy: 0.6678

Epoch 00017: val_loss improved from 0.80335 to 0.80039, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 18/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7820 - accuracy: 0.6813 - val_loss: 0.8017 - val_accuracy: 0.6666

Epoch 00018: val_loss did not improve from 0.80039
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7800 - accuracy: 0.6828 - val_loss: 0.8002 - val_accuracy: 0.6667

Epoch 00019: val_loss improved from 0.80039 to 0.80021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7788 - accuracy: 0.6831 - val_loss: 0.8028 - val_accuracy: 0.6650

Epoch 00020: val_loss did not improve from 0.80021
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7781 - accuracy: 0.6839 - val_loss: 0.7965 - val_accuracy: 0.6698

Epoch 00021: val_loss improved from 0.80021 to 0.79646, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 22/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7761 - accuracy: 0.6846 - val_loss: 0.7965 - val_accuracy: 0.6683

Epoch 00022: val_loss did not improve from 0.79646
Epoch 23/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7748 - accuracy: 0.6857 - val_loss: 0.7944 - val_accuracy: 0.6705

Epoch 00023: val_loss improved from 0.79646 to 0.79443, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 24/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7732 - accuracy: 0.6866 - val_loss: 0.7903 - val_accuracy: 0.6728

Epoch 00024: val_loss improved from 0.79443 to 0.79026, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7722 - accuracy: 0.6868 - val_loss: 0.7944 - val_accuracy: 0.6698

Epoch 00025: val_loss did not improve from 0.79026
Epoch 26/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7714 - accuracy: 0.6882 - val_loss: 0.7944 - val_accuracy: 0.6702

Epoch 00026: val_loss did not improve from 0.79026
Epoch 27/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7696 - accuracy: 0.6896 - val_loss: 0.7917 - val_accuracy: 0.6723

Epoch 00027: val_loss did not improve from 0.79026
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7680 - accuracy: 0.6904 - val_loss: 0.7893 - val_accuracy: 0.6732

Epoch 00028: val_loss improved from 0.79026 to 0.78931, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 29/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7671 - accuracy: 0.6910 - val_loss: 0.7933 - val_accuracy: 0.6714

Epoch 00029: val_loss did not improve from 0.78931
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7661 - accuracy: 0.6915 - val_loss: 0.7897 - val_accuracy: 0.6738

Epoch 00030: val_loss did not improve from 0.78931
Epoch 31/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7646 - accuracy: 0.6926 - val_loss: 0.7929 - val_accuracy: 0.6717

Epoch 00031: val_loss did not improve from 0.78931
Epoch 32/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7632 - accuracy: 0.6935 - val_loss: 0.7889 - val_accuracy: 0.6743

Epoch 00032: val_loss improved from 0.78931 to 0.78889, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 33/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7613 - accuracy: 0.6947 - val_loss: 0.7863 - val_accuracy: 0.6759

Epoch 00033: val_loss improved from 0.78889 to 0.78629, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-bigger/Try/9
Epoch 34/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7600 - accuracy: 0.6951 - val_loss: 0.7887 - val_accuracy: 0.6745

Epoch 00034: val_loss did not improve from 0.78629
Epoch 35/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7590 - accuracy: 0.6964 - val_loss: 0.7922 - val_accuracy: 0.6729

Epoch 00035: val_loss did not improve from 0.78629
Epoch 36/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7576 - accuracy: 0.6975 - val_loss: 0.7924 - val_accuracy: 0.6739

Epoch 00036: val_loss did not improve from 0.78629
Epoch 37/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7554 - accuracy: 0.6991 - val_loss: 0.7869 - val_accuracy: 0.6767

Epoch 00037: val_loss did not improve from 0.78629
Epoch 38/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7541 - accuracy: 0.7002 - val_loss: 0.7950 - val_accuracy: 0.6723

Epoch 00038: val_loss did not improve from 0.78629
Epoch 39/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7523 - accuracy: 0.7015 - val_loss: 0.7920 - val_accuracy: 0.6743

Epoch 00039: val_loss did not improve from 0.78629
Epoch 40/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7502 - accuracy: 0.7028 - val_loss: 0.7941 - val_accuracy: 0.6733

Epoch 00040: val_loss did not improve from 0.78629
Epoch 41/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7488 - accuracy: 0.7039 - val_loss: 0.7957 - val_accuracy: 0.6732

Epoch 00041: val_loss did not improve from 0.78629
Epoch 42/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7468 - accuracy: 0.7052 - val_loss: 0.7990 - val_accuracy: 0.6722

Epoch 00042: val_loss did not improve from 0.78629
Epoch 43/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7457 - accuracy: 0.7059 - val_loss: 0.8046 - val_accuracy: 0.6690

Epoch 00043: val_loss did not improve from 0.78629
Epoch 00043: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 673s 4ms/step - loss: 0.7828 - accuracy: 0.6790
Testing Loss = 0.782801, Testing Accuracy = 0.679013
The data set contains images
N of classes 3
$W^+$ (auc = 85.44 +- 0.0261 %)
$W^-$ (auc = 85.35 +- 0.0336 %)
$Z$ (auc = 83.45 +- 0.0714 %)
The summarized testing accuracy = 67.67 +- 0.1809 %, with the loss = 0.7863 +- 0.002825
