

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2023-01-29 19:29:41.399206
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.767, val acc= 27.24% |
Epoch 1: val_loss improved from inf to 1.7666, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.790, val acc= 29.74% |
Epoch   2: val_loss did not improve from 1.7666. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.719, val acc= 31.76% |
Epoch 3: val_loss improved from 1.7666 to 1.7188, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.691, val acc= 34.06% |
Epoch 4: val_loss improved from 1.7188 to 1.6910, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.607, val acc= 36.93% |
Epoch 5: val_loss improved from 1.6910 to 1.6073, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.609, val acc= 38.36% |
Epoch   6: val_loss did not improve from 1.6073. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.609, val acc= 38.48% |
Epoch   7: val_loss did not improve from 1.6073. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.563, val acc= 39.60% |
Epoch 8: val_loss improved from 1.6073 to 1.5628, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.469, val acc= 39.34% |
Epoch 9: val_loss improved from 1.5628 to 1.4688, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.620, val acc= 38.20% |
Epoch  10: val_loss did not improve from 1.4688. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.647, val acc= 38.98% |
Epoch  11: val_loss did not improve from 1.4688. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.554, val acc= 38.55% |
Epoch  12: val_loss did not improve from 1.4688. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.733, val acc= 36.15% |
Epoch  13: val_loss did not improve from 1.4688. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.909, val acc= 36.82% |
Epoch  14: val_loss did not improve from 1.4688. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.433, val acc= 37.23% |
Epoch  15: val_loss did not improve from 1.4688. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.801, val acc= 35.81% |
Epoch  16: val_loss did not improve from 1.4688. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.23% |
Epoch  17: val_loss did not improve from 1.4688. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.23% |
Epoch  18: val_loss did not improve from 1.4688. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.23% |
Epoch  19: val_loss did not improve from 1.4688. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 1.629, test acc= 39.96% |
Finished Training
N of classes 6
$W^+/W^+$ (auc = 83.14 +- 0.0000 %)
$W^-/W^-$ (auc = 82.27 +- 0.0000 %)
$Z/Z$ (auc = 77.78 +- 0.0000 %)
$W^+/W^-$ (auc = 70.55 +- 0.0000 %)
$W^+/Z$ (auc = 67.58 +- 0.0000 %)
$W^-/Z$ (auc = 69.03 +- 0.0000 %)
N of classes 6
$W^+/W^+$ (acc = 47.69 +- 0.0000 %
$W^-/W^-$ (acc = 42.72 +- 0.0000 %
$Z/Z$ (acc = 41.93 +- 0.0000 %
$W^+/W^-$ (acc = 36.12 +- 0.0000 %
$W^+/Z$ (acc = 30.91 +- 0.0000 %
$W^-/Z$ (acc = 29.79 +- 0.0000 %
The summarized testing accuracy = 39.96 +- 0.0000 %, with the loss = 1.6292 +- 0.000000
Finished Training


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2023-01-29 23:45:33.392000
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.767, val acc= 24.44% |
Epoch 1: val_loss improved from inf to 1.7669, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.764, val acc= 29.05% |
Epoch 2: val_loss improved from 1.7669 to 1.7644, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.809, val acc= 31.02% |
Epoch   3: val_loss did not improve from 1.7644. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.714, val acc= 32.64% |
Epoch 4: val_loss improved from 1.7644 to 1.7139, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.711, val acc= 32.63% |
Epoch 5: val_loss improved from 1.7139 to 1.7113, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.601, val acc= 34.53% |
Epoch 6: val_loss improved from 1.7113 to 1.6005, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.551, val acc= 36.37% |
Epoch 7: val_loss improved from 1.6005 to 1.5513, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.600, val acc= 36.82% |
Epoch   8: val_loss did not improve from 1.5513. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.559, val acc= 38.24% |
Epoch   9: val_loss did not improve from 1.5513. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.616, val acc= 38.50% |
Epoch  10: val_loss did not improve from 1.5513. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.585, val acc= 38.63% |
Epoch  11: val_loss did not improve from 1.5513. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.600, val acc= 38.62% |
Epoch  12: val_loss did not improve from 1.5513. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.731, val acc= 37.78% |
Epoch  13: val_loss did not improve from 1.5513. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.638, val acc= 38.38% |
Epoch  14: val_loss did not improve from 1.5513. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.903, val acc= 38.17% |
Epoch  15: val_loss did not improve from 1.5513. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.922, val acc= 37.70% |
Epoch  16: val_loss did not improve from 1.5513. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.743, val acc= 38.56% |
Epoch  17: val_loss did not improve from 1.5513. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 1.187, test acc= 36.62% |
Finished Training
N of classes 6
$W^+/W^+$ (auc = 82.52 +- 0.0000 %)
$W^-/W^-$ (auc = 81.22 +- 0.0000 %)
$Z/Z$ (auc = 72.00 +- 0.0000 %)
$W^+/W^-$ (auc = 67.79 +- 0.0000 %)
$W^+/Z$ (auc = 65.53 +- 0.0000 %)
$W^-/Z$ (auc = 66.71 +- 0.0000 %)
N of classes 6
$W^+/W^+$ (acc = 43.78 +- 0.0000 %
$W^-/W^-$ (acc = 48.00 +- 0.0000 %
$Z/Z$ (acc = 33.33 +- 0.0000 %
$W^+/W^-$ (acc = 37.45 +- 0.0000 %
$W^+/Z$ (acc = 26.31 +- 0.0000 %
$W^-/Z$ (acc = 26.48 +- 0.0000 %
The summarized testing accuracy = 36.62 +- 0.0000 %, with the loss = 1.1870 +- 0.000000
Finished Training


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2023-01-30 11:03:17.906588
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.695, val acc= 28.80% |
Epoch 1: val_loss improved from inf to 1.6950, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.722, val acc= 31.40% |
Epoch   2: val_loss did not improve from 1.6950. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.754, val acc= 33.16% |
Epoch   3: val_loss did not improve from 1.6950. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.686, val acc= 34.84% |
Epoch 4: val_loss improved from 1.6950 to 1.6857, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.610, val acc= 38.40% |
Epoch 5: val_loss improved from 1.6857 to 1.6096, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.648, val acc= 39.92% |
Epoch   6: val_loss did not improve from 1.6096. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.548, val acc= 40.17% |
Epoch 7: val_loss improved from 1.6096 to 1.5482, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.533, val acc= 39.44% |
Epoch 8: val_loss improved from 1.5482 to 1.5331, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.536, val acc= 39.81% |
Epoch   9: val_loss did not improve from 1.5331. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.603, val acc= 39.74% |
Epoch  10: val_loss did not improve from 1.5331. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.657, val acc= 39.47% |
Epoch  11: val_loss did not improve from 1.5331. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.210, val acc= 36.90% |
Epoch  12: val_loss did not improve from 1.5331. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.038, val acc= 37.62% |
Epoch  13: val_loss did not improve from 1.5331. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.320, val acc= 37.42% |
Epoch  14: val_loss did not improve from 1.5331. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 3.224, val acc= 36.63% |
Epoch  15: val_loss did not improve from 1.5331. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.688, val acc= 36.69% |
Epoch  16: val_loss did not improve from 1.5331. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.23% |
Epoch  17: val_loss did not improve from 1.5331. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.23% |
Epoch  18: val_loss did not improve from 1.5331. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 1.359, test acc= 40.14% |
Finished Training
N of classes 6
$W^+/W^+$ (auc = 83.26 +- 0.0000 %)
$W^-/W^-$ (auc = 83.03 +- 0.0000 %)
$Z/Z$ (auc = 78.43 +- 0.0000 %)
$W^+/W^-$ (auc = 70.72 +- 0.0000 %)
$W^+/Z$ (auc = 67.89 +- 0.0000 %)
$W^-/Z$ (auc = 69.25 +- 0.0000 %)
N of classes 6
$W^+/W^+$ (acc = 48.06 +- 0.0000 %
$W^-/W^-$ (acc = 42.85 +- 0.0000 %
$Z/Z$ (acc = 46.81 +- 0.0000 %
$W^+/W^-$ (acc = 32.59 +- 0.0000 %
$W^+/Z$ (acc = 32.86 +- 0.0000 %
$W^-/Z$ (acc = 31.54 +- 0.0000 %
The summarized testing accuracy = 40.14 +- 0.0000 %, with the loss = 1.3588 +- 0.000000
Finished Training


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2023-01-30 12:34:19.432507
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
CNN2_torch(
  (h2ptjl): Sequential(
    (0): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Conv2d(2, 32, kernel_size=(6, 6), stride=(1, 1), padding=same)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(32, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(128, 128, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Sequential(
      (0): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), padding=same)
        )
      )
      (1): ResidualBlock(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
          (1): ReLU(inplace=True)
          (2): Conv2d(256, 256, kernel_size=(6, 6), stride=(1, 1), padding=same)
        )
        (shortcut): Sequential()
      )
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Dropout(p=0.1, inplace=False)
  )
  (linear1): Linear(in_features=20736, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=32, bias=True)
  (linear3): Linear(in_features=512, out_features=128, bias=True)
  (linear4): Linear(in_features=128, out_features=32, bias=True)
  (_output): Linear(in_features=32, out_features=6, bias=True)
)
Send the model to cuda
VALIDATION:   kappa = 1.05000     | val loss= 1.696, val acc= 30.70% |
Epoch 1: val_loss improved from inf to 1.6956, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.614, val acc= 32.98% |
Epoch 2: val_loss improved from 1.6956 to 1.6139, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.613, val acc= 36.35% |
Epoch 3: val_loss improved from 1.6139 to 1.6135, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.511, val acc= 39.13% |
Epoch 4: val_loss improved from 1.6135 to 1.5111, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.493, val acc= 40.44% |
Epoch 5: val_loss improved from 1.5111 to 1.4930, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.491, val acc= 40.38% |
Epoch 6: val_loss improved from 1.4930 to 1.4908, saving model to/home/samhuang/ML/best_model/best_model_senary_CNN2_kappa0.23_fiximag/Try/0
VALIDATION:   kappa = 1.05000     | val loss= 1.536, val acc= 39.53% |
Epoch   7: val_loss did not improve from 1.4908. Performance did not improve for  1 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.505, val acc= 39.72% |
Epoch   8: val_loss did not improve from 1.4908. Performance did not improve for  2 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.638, val acc= 39.86% |
Epoch   9: val_loss did not improve from 1.4908. Performance did not improve for  3 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 1.870, val acc= 37.57% |
Epoch  10: val_loss did not improve from 1.4908. Performance did not improve for  4 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.433, val acc= 37.72% |
Epoch  11: val_loss did not improve from 1.4908. Performance did not improve for  5 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.456, val acc= 37.12% |
Epoch  12: val_loss did not improve from 1.4908. Performance did not improve for  6 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= 2.880, val acc= 37.43% |
Epoch  13: val_loss did not improve from 1.4908. Performance did not improve for  7 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.23% |
Epoch  14: val_loss did not improve from 1.4908. Performance did not improve for  8 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.23% |
Epoch  15: val_loss did not improve from 1.4908. Performance did not improve for  9 epoch(s)
VALIDATION:   kappa = 1.05000     | val loss= nan, val acc= 16.23% |
Epoch  16: val_loss did not improve from 1.4908. Performance did not improve for 10 epoch(s)
dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
TEST:   kappa = 1.05000     | test loss= 1.239, test acc= 40.30% |
Finished Training
N of classes 6
$W^+/W^+$ (auc = 84.26 +- 0.0000 %)
$W^-/W^-$ (auc = 82.77 +- 0.0000 %)
$Z/Z$ (auc = 79.08 +- 0.0000 %)
$W^+/W^-$ (auc = 70.01 +- 0.0000 %)
$W^+/Z$ (auc = 67.84 +- 0.0000 %)
$W^-/Z$ (auc = 69.51 +- 0.0000 %)
N of classes 6
$W^+/W^+$ (acc = 43.73 +- 0.0000 %
$W^-/W^-$ (acc = 49.65 +- 0.0000 %
$Z/Z$ (acc = 45.00 +- 0.0000 %
$W^+/W^-$ (acc = 34.01 +- 0.0000 %
$W^+/Z$ (acc = 30.23 +- 0.0000 %
$W^-/Z$ (acc = 33.13 +- 0.0000 %
The summarized testing accuracy = 40.30 +- 0.0000 %, with the loss = 1.2393 +- 0.000000
Finished Training
