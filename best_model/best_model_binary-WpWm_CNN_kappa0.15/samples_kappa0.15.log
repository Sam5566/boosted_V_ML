

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-21 20:45:22.141269
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
456/456 [==============================] - 66s 129ms/step - loss: 4.7877 - accuracy: 0.7792 - val_loss: 1.5560 - val_accuracy: 0.8510

Epoch 00001: val_loss improved from inf to 1.55599, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 2/500
456/456 [==============================] - 31s 69ms/step - loss: 0.9028 - accuracy: 0.8528 - val_loss: 0.5567 - val_accuracy: 0.8519

Epoch 00002: val_loss improved from 1.55599 to 0.55674, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 3/500
456/456 [==============================] - 31s 68ms/step - loss: 0.4524 - accuracy: 0.8567 - val_loss: 0.3975 - val_accuracy: 0.8544

Epoch 00003: val_loss improved from 0.55674 to 0.39747, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 4/500
456/456 [==============================] - 31s 68ms/step - loss: 0.3751 - accuracy: 0.8583 - val_loss: 0.3653 - val_accuracy: 0.8553

Epoch 00004: val_loss improved from 0.39747 to 0.36532, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 5/500
456/456 [==============================] - 31s 68ms/step - loss: 0.3565 - accuracy: 0.8593 - val_loss: 0.3519 - val_accuracy: 0.8581

Epoch 00005: val_loss improved from 0.36532 to 0.35190, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 6/500
456/456 [==============================] - 31s 69ms/step - loss: 0.3492 - accuracy: 0.8601 - val_loss: 0.3518 - val_accuracy: 0.8567

Epoch 00006: val_loss improved from 0.35190 to 0.35182, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 7/500
456/456 [==============================] - 32s 70ms/step - loss: 0.3458 - accuracy: 0.8605 - val_loss: 0.3465 - val_accuracy: 0.8582

Epoch 00007: val_loss improved from 0.35182 to 0.34651, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 8/500
456/456 [==============================] - 31s 68ms/step - loss: 0.3437 - accuracy: 0.8614 - val_loss: 0.3474 - val_accuracy: 0.8574

Epoch 00008: val_loss did not improve from 0.34651
Epoch 9/500
456/456 [==============================] - 32s 69ms/step - loss: 0.3427 - accuracy: 0.8611 - val_loss: 0.3447 - val_accuracy: 0.8586

Epoch 00009: val_loss improved from 0.34651 to 0.34469, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 10/500
456/456 [==============================] - 31s 68ms/step - loss: 0.3411 - accuracy: 0.8621 - val_loss: 0.3475 - val_accuracy: 0.8564

Epoch 00010: val_loss did not improve from 0.34469
Epoch 11/500
456/456 [==============================] - 31s 69ms/step - loss: 0.3407 - accuracy: 0.8617 - val_loss: 0.3427 - val_accuracy: 0.8594

Epoch 00011: val_loss improved from 0.34469 to 0.34269, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 12/500
456/456 [==============================] - 31s 68ms/step - loss: 0.3392 - accuracy: 0.8628 - val_loss: 0.3429 - val_accuracy: 0.8589

Epoch 00012: val_loss did not improve from 0.34269
Epoch 13/500
456/456 [==============================] - 32s 70ms/step - loss: 0.3386 - accuracy: 0.8624 - val_loss: 0.3402 - val_accuracy: 0.8606

Epoch 00013: val_loss improved from 0.34269 to 0.34016, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 14/500
456/456 [==============================] - 31s 68ms/step - loss: 0.3378 - accuracy: 0.8633 - val_loss: 0.3391 - val_accuracy: 0.8612

Epoch 00014: val_loss improved from 0.34016 to 0.33908, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 15/500
456/456 [==============================] - 31s 69ms/step - loss: 0.3369 - accuracy: 0.8637 - val_loss: 0.3397 - val_accuracy: 0.8601

Epoch 00015: val_loss did not improve from 0.33908
Epoch 16/500
456/456 [==============================] - 32s 70ms/step - loss: 0.3360 - accuracy: 0.8641 - val_loss: 0.3403 - val_accuracy: 0.8602

Epoch 00016: val_loss did not improve from 0.33908
Epoch 17/500
456/456 [==============================] - 32s 69ms/step - loss: 0.3351 - accuracy: 0.8647 - val_loss: 0.3398 - val_accuracy: 0.8606

Epoch 00017: val_loss did not improve from 0.33908
Epoch 18/500
456/456 [==============================] - 32s 70ms/step - loss: 0.3344 - accuracy: 0.8647 - val_loss: 0.3412 - val_accuracy: 0.8600

Epoch 00018: val_loss did not improve from 0.33908
Epoch 19/500
456/456 [==============================] - 33s 69ms/step - loss: 0.3342 - accuracy: 0.8647 - val_loss: 0.3399 - val_accuracy: 0.8607

Epoch 00019: val_loss did not improve from 0.33908
Epoch 20/500
456/456 [==============================] - 31s 69ms/step - loss: 0.3333 - accuracy: 0.8655 - val_loss: 0.3412 - val_accuracy: 0.8598

Epoch 00020: val_loss did not improve from 0.33908
Epoch 21/500
456/456 [==============================] - 33s 69ms/step - loss: 0.3319 - accuracy: 0.8662 - val_loss: 0.3394 - val_accuracy: 0.8600

Epoch 00021: val_loss did not improve from 0.33908
Epoch 22/500
456/456 [==============================] - 32s 69ms/step - loss: 0.3313 - accuracy: 0.8671 - val_loss: 0.3417 - val_accuracy: 0.8595

Epoch 00022: val_loss did not improve from 0.33908
Epoch 23/500
456/456 [==============================] - 33s 68ms/step - loss: 0.3311 - accuracy: 0.8669 - val_loss: 0.3398 - val_accuracy: 0.8601

Epoch 00023: val_loss did not improve from 0.33908
Epoch 24/500
456/456 [==============================] - 31s 68ms/step - loss: 0.3299 - accuracy: 0.8679 - val_loss: 0.3416 - val_accuracy: 0.8598

Epoch 00024: val_loss did not improve from 0.33908
Epoch 00024: early stopping
The data set contains images
72962/72962 [==============================] - 296s 4ms/step - loss: 0.3501 - accuracy: 0.8554
Testing Loss = 0.350088, Testing Accuracy = 0.855377
The data set contains images
[[0.9170941710472107, 0.0829007625579834, 4.988243745174259e-06], [0.007335643749684095, 0.992664098739624, 1.957928503770745e-07], [0.41100165247917175, 0.5889747142791748, 2.3582530047860928e-05], [0.48017269372940063, 0.5198044776916504, 2.2782674932386726e-05], [0.7211742401123047, 0.2788084149360657, 1.7403053789166734e-05], [0.1238144189119339, 0.8761767148971558, 8.855004125507548e-06], [0.026005292311310768, 0.9739935398101807, 1.1771268191296258e-06], [0.2382434904575348, 0.7617398500442505, 1.6664054783177562e-05], [0.028083093464374542, 0.9719155430793762, 1.3417267155091395e-06], [0.8923116326332092, 0.10768087953329086, 7.549733254563762e-06]]
[[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0]]
3


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-22 20:49:55.351281
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-22 20:52:00.586945
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-22 20:52:46.643270
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-22 20:53:35.378072
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-22 20:53:54.100686
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-22 21:14:10.029189
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-22 21:15:18.235442
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-23 00:16:39.788206
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 19:16:17.173410
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
228/228 [==============================] - 21s 67ms/step - loss: 6.8552 - accuracy: 0.7476 - val_loss: 3.0942 - val_accuracy: 0.7657

Epoch 00001: val_loss improved from inf to 3.09420, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 2/500
228/228 [==============================] - 15s 65ms/step - loss: 1.9720 - accuracy: 0.8347 - val_loss: 1.3153 - val_accuracy: 0.8365

Epoch 00002: val_loss improved from 3.09420 to 1.31525, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 3/500
228/228 [==============================] - 15s 66ms/step - loss: 0.9457 - accuracy: 0.8404 - val_loss: 0.6896 - val_accuracy: 0.8434

Epoch 00003: val_loss improved from 1.31525 to 0.68960, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 4/500
228/228 [==============================] - 15s 65ms/step - loss: 0.5677 - accuracy: 0.8425 - val_loss: 0.4705 - val_accuracy: 0.8466

Epoch 00004: val_loss improved from 0.68960 to 0.47047, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 5/500
228/228 [==============================] - 15s 65ms/step - loss: 0.4335 - accuracy: 0.8446 - val_loss: 0.3971 - val_accuracy: 0.8466

Epoch 00005: val_loss improved from 0.47047 to 0.39714, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 6/500
228/228 [==============================] - 15s 65ms/step - loss: 0.3900 - accuracy: 0.8455 - val_loss: 0.3737 - val_accuracy: 0.8476

Epoch 00006: val_loss improved from 0.39714 to 0.37373, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 7/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3751 - accuracy: 0.8460 - val_loss: 0.3664 - val_accuracy: 0.8489

Epoch 00007: val_loss improved from 0.37373 to 0.36636, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 8/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3700 - accuracy: 0.8463 - val_loss: 0.3671 - val_accuracy: 0.8468

Epoch 00008: val_loss did not improve from 0.36636
Epoch 9/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3681 - accuracy: 0.8466 - val_loss: 0.3685 - val_accuracy: 0.8453

Epoch 00009: val_loss did not improve from 0.36636
Epoch 10/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3674 - accuracy: 0.8465 - val_loss: 0.3664 - val_accuracy: 0.8455

Epoch 00010: val_loss did not improve from 0.36636
Epoch 11/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3654 - accuracy: 0.8473 - val_loss: 0.3654 - val_accuracy: 0.8460

Epoch 00011: val_loss improved from 0.36636 to 0.36539, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 12/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3642 - accuracy: 0.8484 - val_loss: 0.3645 - val_accuracy: 0.8465

Epoch 00012: val_loss improved from 0.36539 to 0.36453, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 13/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3633 - accuracy: 0.8494 - val_loss: 0.3633 - val_accuracy: 0.8474

Epoch 00013: val_loss improved from 0.36453 to 0.36329, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 14/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3621 - accuracy: 0.8497 - val_loss: 0.3649 - val_accuracy: 0.8464

Epoch 00014: val_loss did not improve from 0.36329
Epoch 15/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3611 - accuracy: 0.8501 - val_loss: 0.3632 - val_accuracy: 0.8473

Epoch 00015: val_loss improved from 0.36329 to 0.36316, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 16/500
228/228 [==============================] - 15s 65ms/step - loss: 0.3594 - accuracy: 0.8517 - val_loss: 0.3650 - val_accuracy: 0.8466

Epoch 00016: val_loss did not improve from 0.36316
Epoch 17/500
228/228 [==============================] - 15s 65ms/step - loss: 0.3597 - accuracy: 0.8517 - val_loss: 0.3644 - val_accuracy: 0.8473

Epoch 00017: val_loss did not improve from 0.36316
Epoch 18/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3574 - accuracy: 0.8529 - val_loss: 0.3640 - val_accuracy: 0.8468

Epoch 00018: val_loss did not improve from 0.36316
Epoch 19/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3563 - accuracy: 0.8541 - val_loss: 0.3678 - val_accuracy: 0.8460

Epoch 00019: val_loss did not improve from 0.36316
Epoch 20/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3551 - accuracy: 0.8547 - val_loss: 0.3683 - val_accuracy: 0.8453

Epoch 00020: val_loss did not improve from 0.36316
Epoch 21/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3524 - accuracy: 0.8567 - val_loss: 0.3659 - val_accuracy: 0.8473

Epoch 00021: val_loss did not improve from 0.36316
Epoch 22/500
228/228 [==============================] - 15s 67ms/step - loss: 0.3493 - accuracy: 0.8588 - val_loss: 0.3670 - val_accuracy: 0.8481

Epoch 00022: val_loss did not improve from 0.36316
Epoch 23/500
228/228 [==============================] - 15s 66ms/step - loss: 0.3465 - accuracy: 0.8615 - val_loss: 0.3726 - val_accuracy: 0.8461

Epoch 00023: val_loss did not improve from 0.36316
Epoch 24/500
228/228 [==============================] - 17s 73ms/step - loss: 0.3444 - accuracy: 0.8633 - val_loss: 0.3760 - val_accuracy: 0.8437

Epoch 00024: val_loss did not improve from 0.36316
Epoch 25/500
228/228 [==============================] - 15s 67ms/step - loss: 0.3400 - accuracy: 0.8667 - val_loss: 0.3795 - val_accuracy: 0.8434

Epoch 00025: val_loss did not improve from 0.36316
Epoch 26/500
228/228 [==============================] - 16s 68ms/step - loss: 0.3341 - accuracy: 0.8715 - val_loss: 0.3867 - val_accuracy: 0.8457

Epoch 00026: val_loss did not improve from 0.36316
Epoch 27/500
228/228 [==============================] - 16s 68ms/step - loss: 0.3292 - accuracy: 0.8758 - val_loss: 0.3938 - val_accuracy: 0.8433

Epoch 00027: val_loss did not improve from 0.36316
Epoch 28/500
228/228 [==============================] - 16s 69ms/step - loss: 0.3212 - accuracy: 0.8801 - val_loss: 0.4089 - val_accuracy: 0.8405

Epoch 00028: val_loss did not improve from 0.36316
Epoch 29/500
228/228 [==============================] - 16s 68ms/step - loss: 0.3128 - accuracy: 0.8872 - val_loss: 0.4167 - val_accuracy: 0.8385

Epoch 00029: val_loss did not improve from 0.36316
Epoch 30/500
228/228 [==============================] - 15s 65ms/step - loss: 0.3044 - accuracy: 0.8933 - val_loss: 0.4227 - val_accuracy: 0.8367

Epoch 00030: val_loss did not improve from 0.36316
Epoch 31/500
228/228 [==============================] - 15s 66ms/step - loss: 0.2943 - accuracy: 0.8991 - val_loss: 0.4293 - val_accuracy: 0.8329

Epoch 00031: val_loss did not improve from 0.36316
Epoch 32/500
228/228 [==============================] - 15s 66ms/step - loss: 0.2902 - accuracy: 0.9016 - val_loss: 0.4391 - val_accuracy: 0.8323

Epoch 00032: val_loss did not improve from 0.36316
Epoch 33/500
228/228 [==============================] - 15s 66ms/step - loss: 0.2790 - accuracy: 0.9078 - val_loss: 0.4462 - val_accuracy: 0.8349

Epoch 00033: val_loss did not improve from 0.36316
Epoch 34/500
228/228 [==============================] - 15s 66ms/step - loss: 0.2673 - accuracy: 0.9140 - val_loss: 0.4719 - val_accuracy: 0.8250

Epoch 00034: val_loss did not improve from 0.36316
Epoch 35/500
228/228 [==============================] - 15s 66ms/step - loss: 0.2631 - accuracy: 0.9157 - val_loss: 0.4833 - val_accuracy: 0.8198

Epoch 00035: val_loss did not improve from 0.36316
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_binary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQBhQJm\nBBkAUwCpAk7pAgAAAKkAqQHaAXhyAwAAAHIDAAAA+hsvaG9tZS9zYW1odWFuZy9NTC9tb2RlbHMu\ncHnaCDxsYW1iZGE+1AAAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
36541/36541 [==============================] - 102s 3ms/step - loss: 0.4815 - accuracy: 0.8201
Testing Loss = 0.481479, Testing Accuracy = 0.820065
The data set contains images
[[0.9807606935501099, 0.019239341840147972], [0.9942153096199036, 0.005784681532531977], [0.03126583248376846, 0.9687341451644897], [0.9994921684265137, 0.0005078301765024662], [0.013382483273744583, 0.9866175055503845], [0.8301413059234619, 0.16985872387886047], [0.8561705946922302, 0.1438293606042862], [0.8360048532485962, 0.16399511694908142], [0.8020946383476257, 0.19790536165237427], [0.9489210247993469, 0.05107894167304039]]
[[1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]]
2
$W^+$ (auc = 0.89)
$W^-$ (auc = 0.89)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-11 15:20:19.606751
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
864/864 [==============================] - 110s 100ms/step - loss: 2.7640 - accuracy: 0.7818 - val_loss: 0.5425 - val_accuracy: 0.8236

Epoch 00001: val_loss improved from inf to 0.54247, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 2/500
864/864 [==============================] - 59s 69ms/step - loss: 0.4377 - accuracy: 0.8227 - val_loss: 0.3994 - val_accuracy: 0.8253

Epoch 00002: val_loss improved from 0.54247 to 0.39944, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 3/500
864/864 [==============================] - 59s 69ms/step - loss: 0.4017 - accuracy: 0.8250 - val_loss: 0.3953 - val_accuracy: 0.8254

Epoch 00003: val_loss improved from 0.39944 to 0.39531, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 4/500
864/864 [==============================] - 61s 70ms/step - loss: 0.3982 - accuracy: 0.8257 - val_loss: 0.3938 - val_accuracy: 0.8261

Epoch 00004: val_loss improved from 0.39531 to 0.39382, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 5/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3963 - accuracy: 0.8269 - val_loss: 0.3929 - val_accuracy: 0.8260

Epoch 00005: val_loss improved from 0.39382 to 0.39293, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 6/500
864/864 [==============================] - 59s 69ms/step - loss: 0.3946 - accuracy: 0.8274 - val_loss: 0.3911 - val_accuracy: 0.8277

Epoch 00006: val_loss improved from 0.39293 to 0.39112, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 7/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3933 - accuracy: 0.8279 - val_loss: 0.3929 - val_accuracy: 0.8260

Epoch 00007: val_loss did not improve from 0.39112
Epoch 8/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3919 - accuracy: 0.8286 - val_loss: 0.3908 - val_accuracy: 0.8269

Epoch 00008: val_loss improved from 0.39112 to 0.39081, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 9/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3907 - accuracy: 0.8290 - val_loss: 0.3908 - val_accuracy: 0.8272

Epoch 00009: val_loss improved from 0.39081 to 0.39080, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 10/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3895 - accuracy: 0.8296 - val_loss: 0.3904 - val_accuracy: 0.8271

Epoch 00010: val_loss improved from 0.39080 to 0.39037, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 11/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3888 - accuracy: 0.8301 - val_loss: 0.3897 - val_accuracy: 0.8283

Epoch 00011: val_loss improved from 0.39037 to 0.38974, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 12/500
864/864 [==============================] - 59s 69ms/step - loss: 0.3877 - accuracy: 0.8305 - val_loss: 0.3898 - val_accuracy: 0.8272

Epoch 00012: val_loss did not improve from 0.38974
Epoch 13/500
864/864 [==============================] - 59s 69ms/step - loss: 0.3870 - accuracy: 0.8310 - val_loss: 0.3894 - val_accuracy: 0.8277

Epoch 00013: val_loss improved from 0.38974 to 0.38943, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 14/500
864/864 [==============================] - 59s 69ms/step - loss: 0.3863 - accuracy: 0.8313 - val_loss: 0.3907 - val_accuracy: 0.8273

Epoch 00014: val_loss did not improve from 0.38943
Epoch 15/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3851 - accuracy: 0.8320 - val_loss: 0.3887 - val_accuracy: 0.8282

Epoch 00015: val_loss improved from 0.38943 to 0.38875, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 16/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3844 - accuracy: 0.8326 - val_loss: 0.3890 - val_accuracy: 0.8283

Epoch 00016: val_loss did not improve from 0.38875
Epoch 17/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3837 - accuracy: 0.8329 - val_loss: 0.3875 - val_accuracy: 0.8291

Epoch 00017: val_loss improved from 0.38875 to 0.38753, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 18/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3827 - accuracy: 0.8334 - val_loss: 0.3882 - val_accuracy: 0.8286

Epoch 00018: val_loss did not improve from 0.38753
Epoch 19/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3819 - accuracy: 0.8340 - val_loss: 0.3882 - val_accuracy: 0.8284

Epoch 00019: val_loss did not improve from 0.38753
Epoch 20/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3807 - accuracy: 0.8354 - val_loss: 0.3881 - val_accuracy: 0.8294

Epoch 00020: val_loss did not improve from 0.38753
Epoch 21/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3803 - accuracy: 0.8356 - val_loss: 0.3872 - val_accuracy: 0.8304

Epoch 00021: val_loss improved from 0.38753 to 0.38721, saving model to best_model_binary-WpWm_CNN_kappa0.15/
Epoch 22/500
864/864 [==============================] - 61s 70ms/step - loss: 0.3788 - accuracy: 0.8364 - val_loss: 0.3879 - val_accuracy: 0.8300

Epoch 00022: val_loss did not improve from 0.38721
Epoch 23/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3778 - accuracy: 0.8374 - val_loss: 0.3889 - val_accuracy: 0.8297

Epoch 00023: val_loss did not improve from 0.38721
Epoch 24/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3769 - accuracy: 0.8383 - val_loss: 0.3910 - val_accuracy: 0.8287

Epoch 00024: val_loss did not improve from 0.38721
Epoch 25/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3754 - accuracy: 0.8390 - val_loss: 0.3900 - val_accuracy: 0.8301

Epoch 00025: val_loss did not improve from 0.38721
Epoch 26/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3741 - accuracy: 0.8400 - val_loss: 0.3913 - val_accuracy: 0.8299

Epoch 00026: val_loss did not improve from 0.38721
Epoch 27/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3721 - accuracy: 0.8420 - val_loss: 0.3925 - val_accuracy: 0.8295

Epoch 00027: val_loss did not improve from 0.38721
Epoch 28/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3704 - accuracy: 0.8438 - val_loss: 0.3944 - val_accuracy: 0.8286

Epoch 00028: val_loss did not improve from 0.38721
Epoch 29/500
864/864 [==============================] - 59s 69ms/step - loss: 0.3685 - accuracy: 0.8451 - val_loss: 0.3963 - val_accuracy: 0.8289

Epoch 00029: val_loss did not improve from 0.38721
Epoch 30/500
864/864 [==============================] - 61s 70ms/step - loss: 0.3662 - accuracy: 0.8469 - val_loss: 0.3991 - val_accuracy: 0.8285

Epoch 00030: val_loss did not improve from 0.38721
Epoch 31/500
864/864 [==============================] - 59s 69ms/step - loss: 0.3637 - accuracy: 0.8490 - val_loss: 0.4029 - val_accuracy: 0.8269

Epoch 00031: val_loss did not improve from 0.38721
Epoch 32/500
864/864 [==============================] - 61s 70ms/step - loss: 0.3608 - accuracy: 0.8516 - val_loss: 0.4062 - val_accuracy: 0.8265

Epoch 00032: val_loss did not improve from 0.38721
Epoch 33/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3577 - accuracy: 0.8536 - val_loss: 0.4087 - val_accuracy: 0.8255

Epoch 00033: val_loss did not improve from 0.38721
Epoch 34/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3536 - accuracy: 0.8569 - val_loss: 0.4119 - val_accuracy: 0.8258

Epoch 00034: val_loss did not improve from 0.38721
Epoch 35/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3498 - accuracy: 0.8592 - val_loss: 0.4204 - val_accuracy: 0.8241

Epoch 00035: val_loss did not improve from 0.38721
Epoch 36/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3459 - accuracy: 0.8619 - val_loss: 0.4225 - val_accuracy: 0.8238

Epoch 00036: val_loss did not improve from 0.38721
Epoch 37/500
864/864 [==============================] - 60s 70ms/step - loss: 0.3406 - accuracy: 0.8653 - val_loss: 0.4275 - val_accuracy: 0.8217

Epoch 00037: val_loss did not improve from 0.38721
Epoch 38/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3369 - accuracy: 0.8687 - val_loss: 0.4306 - val_accuracy: 0.8217

Epoch 00038: val_loss did not improve from 0.38721
Epoch 39/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3310 - accuracy: 0.8721 - val_loss: 0.4372 - val_accuracy: 0.8206

Epoch 00039: val_loss did not improve from 0.38721
Epoch 40/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3261 - accuracy: 0.8753 - val_loss: 0.4446 - val_accuracy: 0.8207

Epoch 00040: val_loss did not improve from 0.38721
Epoch 41/500
864/864 [==============================] - 60s 69ms/step - loss: 0.3200 - accuracy: 0.8789 - val_loss: 0.4494 - val_accuracy: 0.8201

Epoch 00041: val_loss did not improve from 0.38721
Epoch 00041: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_binary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQBhQJm\nBBkAUwCpAk7pAgAAAKkAqQHaAXhyAwAAAHIDAAAA+hsvaG9tZS9zYW1odWFuZy9NTC9tb2RlbHMu\ncHnaCDxsYW1iZGE+1AAAAPMAAAAA\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
138240/138240 [==============================] - 583s 4ms/step - loss: 0.4495 - accuracy: 0.8216
Testing Loss = 0.449539, Testing Accuracy = 0.821629
The data set contains images
[[0.5216518044471741, 0.47834813594818115], [0.5211700797080994, 0.47882992029190063], [0.08740637451410294, 0.9125936031341553], [0.023363780230283737, 0.9766362309455872], [0.5473854541778564, 0.45261454582214355], [0.25658994913101196, 0.743410050868988], [0.8894559741020203, 0.11054398864507675], [0.5536330938339233, 0.44636690616607666], [0.18403106927871704, 0.815968930721283], [0.18403106927871704, 0.815968930721283]]
[[1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0]]
2
$W^+$ (auc = 0.90)
$W^-$ (auc = 0.90)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-12 19:12:20.725393
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
248/248 [==============================] - 25s 77ms/step - loss: 1.8194 - accuracy: 0.7211 - val_loss: 0.6816 - val_accuracy: 0.7455

Epoch 00001: val_loss improved from inf to 0.68162, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 2/500
248/248 [==============================] - 17s 67ms/step - loss: 0.4651 - accuracy: 0.8217 - val_loss: 0.4576 - val_accuracy: 0.8223

Epoch 00002: val_loss improved from 0.68162 to 0.45763, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 3/500
248/248 [==============================] - 17s 67ms/step - loss: 0.4241 - accuracy: 0.8238 - val_loss: 0.4083 - val_accuracy: 0.8280

Epoch 00003: val_loss improved from 0.45763 to 0.40826, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 4/500
248/248 [==============================] - 17s 67ms/step - loss: 0.4153 - accuracy: 0.8244 - val_loss: 0.3976 - val_accuracy: 0.8306

Epoch 00004: val_loss improved from 0.40826 to 0.39756, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 5/500
248/248 [==============================] - 17s 67ms/step - loss: 0.4118 - accuracy: 0.8263 - val_loss: 0.3938 - val_accuracy: 0.8312

Epoch 00005: val_loss improved from 0.39756 to 0.39382, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 6/500
248/248 [==============================] - 17s 67ms/step - loss: 0.4083 - accuracy: 0.8268 - val_loss: 0.3925 - val_accuracy: 0.8322

Epoch 00006: val_loss improved from 0.39382 to 0.39254, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 7/500
248/248 [==============================] - 17s 67ms/step - loss: 0.4065 - accuracy: 0.8275 - val_loss: 0.3927 - val_accuracy: 0.8311

Epoch 00007: val_loss did not improve from 0.39254
Epoch 8/500
248/248 [==============================] - 17s 67ms/step - loss: 0.4042 - accuracy: 0.8291 - val_loss: 0.3930 - val_accuracy: 0.8314

Epoch 00008: val_loss did not improve from 0.39254
Epoch 9/500
248/248 [==============================] - 17s 67ms/step - loss: 0.4024 - accuracy: 0.8299 - val_loss: 0.3918 - val_accuracy: 0.8317

Epoch 00009: val_loss improved from 0.39254 to 0.39176, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 10/500
248/248 [==============================] - 17s 67ms/step - loss: 0.4021 - accuracy: 0.8303 - val_loss: 0.3932 - val_accuracy: 0.8318

Epoch 00010: val_loss did not improve from 0.39176
Epoch 11/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3999 - accuracy: 0.8317 - val_loss: 0.3960 - val_accuracy: 0.8306

Epoch 00011: val_loss did not improve from 0.39176
Epoch 12/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3988 - accuracy: 0.8326 - val_loss: 0.3959 - val_accuracy: 0.8315

Epoch 00012: val_loss did not improve from 0.39176
Epoch 13/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3983 - accuracy: 0.8331 - val_loss: 0.3988 - val_accuracy: 0.8289

Epoch 00013: val_loss did not improve from 0.39176
Epoch 14/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3961 - accuracy: 0.8358 - val_loss: 0.4036 - val_accuracy: 0.8272

Epoch 00014: val_loss did not improve from 0.39176
Epoch 15/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3946 - accuracy: 0.8367 - val_loss: 0.4032 - val_accuracy: 0.8290

Epoch 00015: val_loss did not improve from 0.39176
Epoch 16/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3922 - accuracy: 0.8397 - val_loss: 0.4070 - val_accuracy: 0.8283

Epoch 00016: val_loss did not improve from 0.39176
Epoch 17/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3902 - accuracy: 0.8429 - val_loss: 0.4189 - val_accuracy: 0.8233

Epoch 00017: val_loss did not improve from 0.39176
Epoch 18/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3872 - accuracy: 0.8465 - val_loss: 0.4233 - val_accuracy: 0.8210

Epoch 00018: val_loss did not improve from 0.39176
Epoch 19/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3811 - accuracy: 0.8510 - val_loss: 0.4274 - val_accuracy: 0.8211

Epoch 00019: val_loss did not improve from 0.39176
Epoch 20/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3732 - accuracy: 0.8573 - val_loss: 0.4383 - val_accuracy: 0.8179

Epoch 00020: val_loss did not improve from 0.39176
Epoch 21/500
248/248 [==============================] - 17s 68ms/step - loss: 0.3669 - accuracy: 0.8623 - val_loss: 0.4535 - val_accuracy: 0.8181

Epoch 00021: val_loss did not improve from 0.39176
Epoch 22/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3682 - accuracy: 0.8632 - val_loss: 0.4700 - val_accuracy: 0.8101

Epoch 00022: val_loss did not improve from 0.39176
Epoch 23/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3713 - accuracy: 0.8605 - val_loss: 0.4981 - val_accuracy: 0.7982

Epoch 00023: val_loss did not improve from 0.39176
Epoch 24/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3617 - accuracy: 0.8673 - val_loss: 0.5173 - val_accuracy: 0.7976

Epoch 00024: val_loss did not improve from 0.39176
Epoch 25/500
248/248 [==============================] - 17s 68ms/step - loss: 0.3587 - accuracy: 0.8692 - val_loss: 0.4640 - val_accuracy: 0.8081

Epoch 00025: val_loss did not improve from 0.39176
Epoch 26/500
248/248 [==============================] - 17s 68ms/step - loss: 0.3529 - accuracy: 0.8742 - val_loss: 0.5027 - val_accuracy: 0.7858

Epoch 00026: val_loss did not improve from 0.39176
Epoch 27/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3368 - accuracy: 0.8821 - val_loss: 0.5144 - val_accuracy: 0.7857

Epoch 00027: val_loss did not improve from 0.39176
Epoch 28/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3261 - accuracy: 0.8893 - val_loss: 0.5277 - val_accuracy: 0.7809

Epoch 00028: val_loss did not improve from 0.39176
Epoch 29/500
248/248 [==============================] - 17s 67ms/step - loss: 0.3304 - accuracy: 0.8868 - val_loss: 0.5266 - val_accuracy: 0.7972

Epoch 00029: val_loss did not improve from 0.39176
Epoch 00029: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_binary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQBhQJm\nBBkAUwApAk7pAgAAAKkAqQHaAXhyAgAAAHICAAAA+h8vaG9tZS9zYW1odWFuZy9NTC9DTk4vbW9k\nZWxzLnB52gg8bGFtYmRhPjMAAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
39804/39804 [==============================] - 152s 4ms/step - loss: 0.4022 - accuracy: 0.8252
Testing Loss = 0.402224, Testing Accuracy = 0.825168
The data set contains images
[[0.25070494413375854, 0.7492949962615967], [0.9287791848182678, 0.07122083008289337], [0.9842694997787476, 0.015730544924736023], [0.0368112288415432, 0.9631887078285217], [0.002210221951827407, 0.997789740562439], [0.9422428607940674, 0.057757195085287094], [0.13661187887191772, 0.8633881211280823], [0.01900145411491394, 0.9809985756874084], [0.9666221737861633, 0.03337787464261055], [0.9730096459388733, 0.02699039876461029]]
[[0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0]]
2
$W^+$ (auc = 0.91)
$W^-$ (auc = 0.91)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-17 13:09:10.609672
Binary task for  ['$W^+$', '$W^-$']
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
500/500 [==============================] - 77s 124ms/step - loss: 4.0376 - accuracy: 0.7743 - val_loss: 1.1910 - val_accuracy: 0.8187

Epoch 00001: val_loss improved from inf to 1.19101, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 2/500
500/500 [==============================] - 35s 69ms/step - loss: 0.7158 - accuracy: 0.8232 - val_loss: 0.4874 - val_accuracy: 0.8274

Epoch 00002: val_loss improved from 1.19101 to 0.48737, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 3/500
500/500 [==============================] - 35s 70ms/step - loss: 0.4468 - accuracy: 0.8261 - val_loss: 0.4216 - val_accuracy: 0.8282

Epoch 00003: val_loss improved from 0.48737 to 0.42162, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 4/500
500/500 [==============================] - 35s 70ms/step - loss: 0.4177 - accuracy: 0.8281 - val_loss: 0.4129 - val_accuracy: 0.8288

Epoch 00004: val_loss improved from 0.42162 to 0.41293, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 5/500
500/500 [==============================] - 35s 70ms/step - loss: 0.4118 - accuracy: 0.8287 - val_loss: 0.4138 - val_accuracy: 0.8266

Epoch 00005: val_loss did not improve from 0.41293
Epoch 6/500
500/500 [==============================] - 35s 70ms/step - loss: 0.4076 - accuracy: 0.8295 - val_loss: 0.4130 - val_accuracy: 0.8253

Epoch 00006: val_loss did not improve from 0.41293
Epoch 7/500
500/500 [==============================] - 35s 69ms/step - loss: 0.4051 - accuracy: 0.8297 - val_loss: 0.4151 - val_accuracy: 0.8239

Epoch 00007: val_loss did not improve from 0.41293
Epoch 8/500
500/500 [==============================] - 35s 69ms/step - loss: 0.4031 - accuracy: 0.8302 - val_loss: 0.4146 - val_accuracy: 0.8235

Epoch 00008: val_loss did not improve from 0.41293
Epoch 9/500
500/500 [==============================] - 58s 117ms/step - loss: 0.4005 - accuracy: 0.8304 - val_loss: 0.4115 - val_accuracy: 0.8247

Epoch 00009: val_loss improved from 0.41293 to 0.41146, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 10/500
500/500 [==============================] - 89s 178ms/step - loss: 0.3985 - accuracy: 0.8308 - val_loss: 0.4072 - val_accuracy: 0.8260

Epoch 00010: val_loss improved from 0.41146 to 0.40717, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 11/500
500/500 [==============================] - 34s 68ms/step - loss: 0.3971 - accuracy: 0.8313 - val_loss: 0.4064 - val_accuracy: 0.8262

Epoch 00011: val_loss improved from 0.40717 to 0.40643, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 12/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3954 - accuracy: 0.8313 - val_loss: 0.3998 - val_accuracy: 0.8288

Epoch 00012: val_loss improved from 0.40643 to 0.39978, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 13/500
500/500 [==============================] - 36s 71ms/step - loss: 0.3934 - accuracy: 0.8316 - val_loss: 0.4042 - val_accuracy: 0.8261

Epoch 00013: val_loss did not improve from 0.39978
Epoch 14/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3921 - accuracy: 0.8325 - val_loss: 0.3988 - val_accuracy: 0.8282

Epoch 00014: val_loss improved from 0.39978 to 0.39876, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 15/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3910 - accuracy: 0.8328 - val_loss: 0.3991 - val_accuracy: 0.8280

Epoch 00015: val_loss did not improve from 0.39876
Epoch 16/500
500/500 [==============================] - 35s 70ms/step - loss: 0.3893 - accuracy: 0.8332 - val_loss: 0.3973 - val_accuracy: 0.8289

Epoch 00016: val_loss improved from 0.39876 to 0.39729, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 17/500
500/500 [==============================] - 34s 69ms/step - loss: 0.3882 - accuracy: 0.8338 - val_loss: 0.3982 - val_accuracy: 0.8281

Epoch 00017: val_loss did not improve from 0.39729
Epoch 18/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3873 - accuracy: 0.8345 - val_loss: 0.3972 - val_accuracy: 0.8288

Epoch 00018: val_loss improved from 0.39729 to 0.39716, saving model to /home/samhuang/ML/best_model/best_model_binary-WpWm_CNN_kappa0.15/
Epoch 19/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3852 - accuracy: 0.8355 - val_loss: 0.3990 - val_accuracy: 0.8272

Epoch 00019: val_loss did not improve from 0.39716
Epoch 20/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3834 - accuracy: 0.8364 - val_loss: 0.4017 - val_accuracy: 0.8265

Epoch 00020: val_loss did not improve from 0.39716
Epoch 21/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3822 - accuracy: 0.8374 - val_loss: 0.4039 - val_accuracy: 0.8250

Epoch 00021: val_loss did not improve from 0.39716
Epoch 22/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3804 - accuracy: 0.8386 - val_loss: 0.4043 - val_accuracy: 0.8259

Epoch 00022: val_loss did not improve from 0.39716
Epoch 23/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3789 - accuracy: 0.8402 - val_loss: 0.4011 - val_accuracy: 0.8281

Epoch 00023: val_loss did not improve from 0.39716
Epoch 24/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3759 - accuracy: 0.8428 - val_loss: 0.4012 - val_accuracy: 0.8290

Epoch 00024: val_loss did not improve from 0.39716
Epoch 25/500
500/500 [==============================] - 35s 70ms/step - loss: 0.3730 - accuracy: 0.8449 - val_loss: 0.4046 - val_accuracy: 0.8285

Epoch 00025: val_loss did not improve from 0.39716
Epoch 26/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3698 - accuracy: 0.8483 - val_loss: 0.4075 - val_accuracy: 0.8279

Epoch 00026: val_loss did not improve from 0.39716
Epoch 27/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3652 - accuracy: 0.8520 - val_loss: 0.4161 - val_accuracy: 0.8260

Epoch 00027: val_loss did not improve from 0.39716
Epoch 28/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3597 - accuracy: 0.8566 - val_loss: 0.4269 - val_accuracy: 0.8225

Epoch 00028: val_loss did not improve from 0.39716
Epoch 29/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3529 - accuracy: 0.8621 - val_loss: 0.4424 - val_accuracy: 0.8187

Epoch 00029: val_loss did not improve from 0.39716
Epoch 30/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3455 - accuracy: 0.8679 - val_loss: 0.4595 - val_accuracy: 0.8142

Epoch 00030: val_loss did not improve from 0.39716
Epoch 31/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3360 - accuracy: 0.8758 - val_loss: 0.4767 - val_accuracy: 0.8124

Epoch 00031: val_loss did not improve from 0.39716
Epoch 32/500
500/500 [==============================] - 35s 70ms/step - loss: 0.3242 - accuracy: 0.8834 - val_loss: 0.4943 - val_accuracy: 0.8088

Epoch 00032: val_loss did not improve from 0.39716
Epoch 33/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3135 - accuracy: 0.8903 - val_loss: 0.5150 - val_accuracy: 0.8079

Epoch 00033: val_loss did not improve from 0.39716
Epoch 34/500
500/500 [==============================] - 35s 69ms/step - loss: 0.3023 - accuracy: 0.8969 - val_loss: 0.5159 - val_accuracy: 0.8076

Epoch 00034: val_loss did not improve from 0.39716
Epoch 35/500
500/500 [==============================] - 35s 69ms/step - loss: 0.2994 - accuracy: 0.8984 - val_loss: 0.5199 - val_accuracy: 0.8080

Epoch 00035: val_loss did not improve from 0.39716
Epoch 36/500
500/500 [==============================] - 35s 70ms/step - loss: 0.2913 - accuracy: 0.9029 - val_loss: 0.5143 - val_accuracy: 0.8074

Epoch 00036: val_loss did not improve from 0.39716
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1026      [0m
[92m=================================================================[0m
[92mTotal params: 12,128,938[0m
[92mTrainable params: 12,128,934[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
80098/80098 [==============================] - 326s 4ms/step - loss: 0.3971 - accuracy: 0.8283
Testing Loss = 0.397148, Testing Accuracy = 0.828310
The data set contains images
[[0.9321402907371521, 0.06785973906517029], [0.06610973179340363, 0.9338902831077576], [0.21471436321735382, 0.7852856516838074], [0.3855684697628021, 0.6144315004348755], [0.10577671229839325, 0.8942233324050903], [0.866645872592926, 0.1333540827035904], [0.5315595865249634, 0.468440443277359], [0.25313976407051086, 0.7468602657318115], [0.005685764364898205, 0.9943142533302307], [0.48695018887519836, 0.5130497813224792]]
[[1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [0.0, 1.0]]
2
$W^+$ (auc = 0.91)
$W^-$ (auc = 0.91)
