

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-30 14:20:43.375936
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 189896.
Epoch 1/100
370/370 [==============================] - 46s 73ms/step - loss: 5.5326 - accuracy: 0.5761 - val_loss: 2.3254 - val_accuracy: 0.6170

Epoch 00001: val_loss improved from inf to 2.32540, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 2/100
370/370 [==============================] - 25s 68ms/step - loss: 1.5715 - accuracy: 0.6508 - val_loss: 1.1299 - val_accuracy: 0.6589

Epoch 00002: val_loss improved from 2.32540 to 1.12987, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 3/100
370/370 [==============================] - 25s 68ms/step - loss: 0.9958 - accuracy: 0.6558 - val_loss: 0.8898 - val_accuracy: 0.6615

Epoch 00003: val_loss improved from 1.12987 to 0.88984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 4/100
370/370 [==============================] - 26s 69ms/step - loss: 0.8714 - accuracy: 0.6602 - val_loss: 0.8381 - val_accuracy: 0.6633

Epoch 00004: val_loss improved from 0.88984 to 0.83808, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 5/100
370/370 [==============================] - 26s 70ms/step - loss: 0.8397 - accuracy: 0.6629 - val_loss: 0.8236 - val_accuracy: 0.6638

Epoch 00005: val_loss improved from 0.83808 to 0.82357, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 6/100
370/370 [==============================] - 26s 69ms/step - loss: 0.8273 - accuracy: 0.6647 - val_loss: 0.8143 - val_accuracy: 0.6659

Epoch 00006: val_loss improved from 0.82357 to 0.81429, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 7/100
370/370 [==============================] - 26s 69ms/step - loss: 0.8198 - accuracy: 0.6670 - val_loss: 0.8121 - val_accuracy: 0.6656

Epoch 00007: val_loss improved from 0.81429 to 0.81211, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 8/100
370/370 [==============================] - 25s 68ms/step - loss: 0.8135 - accuracy: 0.6697 - val_loss: 0.8096 - val_accuracy: 0.6667

Epoch 00008: val_loss improved from 0.81211 to 0.80963, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 9/100
370/370 [==============================] - 26s 69ms/step - loss: 0.8093 - accuracy: 0.6720 - val_loss: 0.8061 - val_accuracy: 0.6684

Epoch 00009: val_loss improved from 0.80963 to 0.80613, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 10/100
370/370 [==============================] - 25s 69ms/step - loss: 0.8041 - accuracy: 0.6736 - val_loss: 0.7966 - val_accuracy: 0.6757

Epoch 00010: val_loss improved from 0.80613 to 0.79663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 11/100
370/370 [==============================] - 26s 70ms/step - loss: 0.7993 - accuracy: 0.6770 - val_loss: 0.7966 - val_accuracy: 0.6744

Epoch 00011: val_loss improved from 0.79663 to 0.79659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 12/100
370/370 [==============================] - 25s 68ms/step - loss: 0.7954 - accuracy: 0.6794 - val_loss: 0.7910 - val_accuracy: 0.6774

Epoch 00012: val_loss improved from 0.79659 to 0.79100, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 13/100
370/370 [==============================] - 25s 68ms/step - loss: 0.7917 - accuracy: 0.6813 - val_loss: 0.7872 - val_accuracy: 0.6789

Epoch 00013: val_loss improved from 0.79100 to 0.78722, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 14/100
370/370 [==============================] - 25s 69ms/step - loss: 0.7877 - accuracy: 0.6837 - val_loss: 0.7854 - val_accuracy: 0.6807

Epoch 00014: val_loss improved from 0.78722 to 0.78541, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 15/100
370/370 [==============================] - 26s 69ms/step - loss: 0.7845 - accuracy: 0.6852 - val_loss: 0.7856 - val_accuracy: 0.6805

Epoch 00015: val_loss did not improve from 0.78541
Epoch 16/100
370/370 [==============================] - 26s 69ms/step - loss: 0.7806 - accuracy: 0.6875 - val_loss: 0.7839 - val_accuracy: 0.6814

Epoch 00016: val_loss improved from 0.78541 to 0.78386, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 17/100
370/370 [==============================] - 25s 69ms/step - loss: 0.7791 - accuracy: 0.6893 - val_loss: 0.7814 - val_accuracy: 0.6830

Epoch 00017: val_loss improved from 0.78386 to 0.78144, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 18/100
370/370 [==============================] - 25s 68ms/step - loss: 0.7751 - accuracy: 0.6910 - val_loss: 0.7830 - val_accuracy: 0.6821

Epoch 00018: val_loss did not improve from 0.78144
Epoch 19/100
370/370 [==============================] - 26s 69ms/step - loss: 0.7736 - accuracy: 0.6923 - val_loss: 0.7813 - val_accuracy: 0.6828

Epoch 00019: val_loss improved from 0.78144 to 0.78128, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 20/100
370/370 [==============================] - 26s 69ms/step - loss: 0.7699 - accuracy: 0.6945 - val_loss: 0.7792 - val_accuracy: 0.6860

Epoch 00020: val_loss improved from 0.78128 to 0.77917, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 21/100
370/370 [==============================] - 25s 69ms/step - loss: 0.7669 - accuracy: 0.6970 - val_loss: 0.7813 - val_accuracy: 0.6845

Epoch 00021: val_loss did not improve from 0.77917
Epoch 22/100
370/370 [==============================] - 25s 68ms/step - loss: 0.7643 - accuracy: 0.6980 - val_loss: 0.7805 - val_accuracy: 0.6854

Epoch 00022: val_loss did not improve from 0.77917
Epoch 23/100
370/370 [==============================] - 26s 69ms/step - loss: 0.7623 - accuracy: 0.7002 - val_loss: 0.7819 - val_accuracy: 0.6841

Epoch 00023: val_loss did not improve from 0.77917
Epoch 24/100
370/370 [==============================] - 26s 69ms/step - loss: 0.7580 - accuracy: 0.7036 - val_loss: 0.7869 - val_accuracy: 0.6837

Epoch 00024: val_loss did not improve from 0.77917
Epoch 25/100
370/370 [==============================] - 26s 69ms/step - loss: 0.7539 - accuracy: 0.7056 - val_loss: 0.7888 - val_accuracy: 0.6813

Epoch 00025: val_loss did not improve from 0.77917
Epoch 26/100
370/370 [==============================] - 25s 68ms/step - loss: 0.7508 - accuracy: 0.7088 - val_loss: 0.7938 - val_accuracy: 0.6790

Epoch 00026: val_loss did not improve from 0.77917
Epoch 27/100
370/370 [==============================] - 26s 69ms/step - loss: 0.7480 - accuracy: 0.7108 - val_loss: 0.7942 - val_accuracy: 0.6805

Epoch 00027: val_loss did not improve from 0.77917
Epoch 28/100
370/370 [==============================] - 25s 69ms/step - loss: 0.7444 - accuracy: 0.7137 - val_loss: 0.7956 - val_accuracy: 0.6804

Epoch 00028: val_loss did not improve from 0.77917
Epoch 29/100
370/370 [==============================] - 26s 69ms/step - loss: 0.7394 - accuracy: 0.7171 - val_loss: 0.7973 - val_accuracy: 0.6811

Epoch 00029: val_loss did not improve from 0.77917
Epoch 30/100
370/370 [==============================] - 26s 69ms/step - loss: 0.7349 - accuracy: 0.7203 - val_loss: 0.8061 - val_accuracy: 0.6782

Epoch 00030: val_loss did not improve from 0.77917
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
59343/59343 [==============================] - 248s 4ms/step - loss: 0.7832 - accuracy: 0.6854
Testing Loss = 0.783243, Testing Accuracy = 0.685405
The data set contains images
N of classes 3
$W^+$ (auc = 85.56 +- 0.0000 %)
$W^-$ (auc = 85.40 +- 0.0000 %)
$Z$ (auc = 83.39 +- 0.0000 %)
The summarized testing accuracy = 68.54 +- 0.0000 (percent), with the loss = 0.7832 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-30 15:14:47.914090
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 189896.
Epoch 1/100
370/370 [==============================] - 31s 68ms/step - loss: 5.5670 - accuracy: 0.5762 - val_loss: 2.3479 - val_accuracy: 0.6209

Epoch 00001: val_loss improved from inf to 2.34788, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 2/100
370/370 [==============================] - 25s 67ms/step - loss: 1.5890 - accuracy: 0.6506 - val_loss: 1.1384 - val_accuracy: 0.6601

Epoch 00002: val_loss improved from 2.34788 to 1.13841, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 3/100
370/370 [==============================] - 25s 68ms/step - loss: 1.0007 - accuracy: 0.6563 - val_loss: 0.8941 - val_accuracy: 0.6605

Epoch 00003: val_loss improved from 1.13841 to 0.89411, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 4/100
370/370 [==============================] - 25s 68ms/step - loss: 0.8725 - accuracy: 0.6606 - val_loss: 0.8388 - val_accuracy: 0.6625

Epoch 00004: val_loss improved from 0.89411 to 0.83884, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 5/100
370/370 [==============================] - 25s 68ms/step - loss: 0.8404 - accuracy: 0.6621 - val_loss: 0.8243 - val_accuracy: 0.6629

Epoch 00005: val_loss improved from 0.83884 to 0.82432, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 6/100
370/370 [==============================] - 25s 68ms/step - loss: 0.8272 - accuracy: 0.6639 - val_loss: 0.8168 - val_accuracy: 0.6651

Epoch 00006: val_loss improved from 0.82432 to 0.81683, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 7/100
370/370 [==============================] - 25s 68ms/step - loss: 0.8199 - accuracy: 0.6675 - val_loss: 0.8113 - val_accuracy: 0.6672

Epoch 00007: val_loss improved from 0.81683 to 0.81130, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 8/100
370/370 [==============================] - 25s 68ms/step - loss: 0.8139 - accuracy: 0.6699 - val_loss: 0.8091 - val_accuracy: 0.6675

Epoch 00008: val_loss improved from 0.81130 to 0.80913, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 9/100
370/370 [==============================] - 25s 68ms/step - loss: 0.8082 - accuracy: 0.6721 - val_loss: 0.8035 - val_accuracy: 0.6698

Epoch 00009: val_loss improved from 0.80913 to 0.80348, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 10/100
370/370 [==============================] - 25s 68ms/step - loss: 0.8046 - accuracy: 0.6741 - val_loss: 0.8007 - val_accuracy: 0.6721

Epoch 00010: val_loss improved from 0.80348 to 0.80069, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 11/100
370/370 [==============================] - 25s 68ms/step - loss: 0.7998 - accuracy: 0.6768 - val_loss: 0.7964 - val_accuracy: 0.6755

Epoch 00011: val_loss improved from 0.80069 to 0.79645, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 12/100
370/370 [==============================] - 25s 68ms/step - loss: 0.7947 - accuracy: 0.6799 - val_loss: 0.7942 - val_accuracy: 0.6757

Epoch 00012: val_loss improved from 0.79645 to 0.79425, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 13/100
370/370 [==============================] - 26s 70ms/step - loss: 0.7903 - accuracy: 0.6828 - val_loss: 0.7877 - val_accuracy: 0.6804

Epoch 00013: val_loss improved from 0.79425 to 0.78775, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 14/100
370/370 [==============================] - 25s 68ms/step - loss: 0.7876 - accuracy: 0.6832 - val_loss: 0.7848 - val_accuracy: 0.6814

Epoch 00014: val_loss improved from 0.78775 to 0.78485, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 15/100
370/370 [==============================] - 25s 68ms/step - loss: 0.7843 - accuracy: 0.6851 - val_loss: 0.7838 - val_accuracy: 0.6826

Epoch 00015: val_loss improved from 0.78485 to 0.78380, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 16/100
370/370 [==============================] - 25s 68ms/step - loss: 0.7810 - accuracy: 0.6875 - val_loss: 0.7800 - val_accuracy: 0.6844

Epoch 00016: val_loss improved from 0.78380 to 0.77998, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 17/100
370/370 [==============================] - 32s 87ms/step - loss: 0.7780 - accuracy: 0.6883 - val_loss: 0.7812 - val_accuracy: 0.6840

Epoch 00017: val_loss did not improve from 0.77998
Epoch 18/100
370/370 [==============================] - 50s 136ms/step - loss: 0.7753 - accuracy: 0.6913 - val_loss: 0.7840 - val_accuracy: 0.6823

Epoch 00018: val_loss did not improve from 0.77998
Epoch 19/100
370/370 [==============================] - 50s 135ms/step - loss: 0.7725 - accuracy: 0.6930 - val_loss: 0.7773 - val_accuracy: 0.6863

Epoch 00019: val_loss improved from 0.77998 to 0.77731, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 20/100
370/370 [==============================] - 50s 136ms/step - loss: 0.7701 - accuracy: 0.6939 - val_loss: 0.7773 - val_accuracy: 0.6865

Epoch 00020: val_loss did not improve from 0.77731
Epoch 21/100
370/370 [==============================] - 50s 136ms/step - loss: 0.7674 - accuracy: 0.6949 - val_loss: 0.7770 - val_accuracy: 0.6866

Epoch 00021: val_loss improved from 0.77731 to 0.77704, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 22/100
370/370 [==============================] - 46s 125ms/step - loss: 0.7649 - accuracy: 0.6970 - val_loss: 0.7804 - val_accuracy: 0.6849

Epoch 00022: val_loss did not improve from 0.77704
Epoch 23/100
370/370 [==============================] - 50s 136ms/step - loss: 0.7630 - accuracy: 0.6979 - val_loss: 0.7779 - val_accuracy: 0.6869

Epoch 00023: val_loss did not improve from 0.77704
Epoch 24/100
370/370 [==============================] - 50s 135ms/step - loss: 0.7604 - accuracy: 0.7012 - val_loss: 0.7760 - val_accuracy: 0.6875

Epoch 00024: val_loss improved from 0.77704 to 0.77603, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 25/100
370/370 [==============================] - 50s 135ms/step - loss: 0.7573 - accuracy: 0.7020 - val_loss: 0.7829 - val_accuracy: 0.6839

Epoch 00025: val_loss did not improve from 0.77603
Epoch 26/100
370/370 [==============================] - 50s 136ms/step - loss: 0.7550 - accuracy: 0.7039 - val_loss: 0.7778 - val_accuracy: 0.6862

Epoch 00026: val_loss did not improve from 0.77603
Epoch 27/100
370/370 [==============================] - 47s 126ms/step - loss: 0.7506 - accuracy: 0.7073 - val_loss: 0.7878 - val_accuracy: 0.6810

Epoch 00027: val_loss did not improve from 0.77603
Epoch 28/100
370/370 [==============================] - 50s 136ms/step - loss: 0.7479 - accuracy: 0.7095 - val_loss: 0.7877 - val_accuracy: 0.6826

Epoch 00028: val_loss did not improve from 0.77603
Epoch 29/100
370/370 [==============================] - 50s 135ms/step - loss: 0.7450 - accuracy: 0.7112 - val_loss: 0.7925 - val_accuracy: 0.6810

Epoch 00029: val_loss did not improve from 0.77603
Epoch 30/100
370/370 [==============================] - 50s 135ms/step - loss: 0.7414 - accuracy: 0.7144 - val_loss: 0.7946 - val_accuracy: 0.6806

Epoch 00030: val_loss did not improve from 0.77603
Epoch 31/100
370/370 [==============================] - 50s 135ms/step - loss: 0.7363 - accuracy: 0.7183 - val_loss: 0.8022 - val_accuracy: 0.6767

Epoch 00031: val_loss did not improve from 0.77603
Epoch 32/100
370/370 [==============================] - 47s 127ms/step - loss: 0.7328 - accuracy: 0.7214 - val_loss: 0.8000 - val_accuracy: 0.6786

Epoch 00032: val_loss did not improve from 0.77603
Epoch 33/100
370/370 [==============================] - 50s 136ms/step - loss: 0.7262 - accuracy: 0.7254 - val_loss: 0.8101 - val_accuracy: 0.6760

Epoch 00033: val_loss did not improve from 0.77603
Epoch 34/100
370/370 [==============================] - 50s 135ms/step - loss: 0.7207 - accuracy: 0.7296 - val_loss: 0.8159 - val_accuracy: 0.6740

Epoch 00034: val_loss did not improve from 0.77603
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
59343/59343 [==============================] - 309s 5ms/step - loss: 0.7827 - accuracy: 0.6856
Testing Loss = 0.782699, Testing Accuracy = 0.685624
The data set contains images
N of classes 3
$W^+$ (auc = 85.61 +- 0.0000 %)
$W^-$ (auc = 85.45 +- 0.0000 %)
$Z$ (auc = 83.51 +- 0.0000 %)
The summarized testing accuracy = 68.56 +- 0.0000 %, with the loss = 0.7827 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-30 22:10:15.556866
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 168988.
Epoch 1/100
330/330 [==============================] - 28s 68ms/step - loss: 5.8836 - accuracy: 0.5702 - val_loss: 2.6054 - val_accuracy: 0.5957

Epoch 00001: val_loss improved from inf to 2.60543, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 2/100
330/330 [==============================] - 23s 71ms/step - loss: 1.7720 - accuracy: 0.6353 - val_loss: 1.2705 - val_accuracy: 0.6420

Epoch 00002: val_loss improved from 2.60543 to 1.27047, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 3/100
330/330 [==============================] - 23s 68ms/step - loss: 1.0833 - accuracy: 0.6413 - val_loss: 0.9534 - val_accuracy: 0.6456

Epoch 00003: val_loss improved from 1.27047 to 0.95341, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 4/100
330/330 [==============================] - 22s 68ms/step - loss: 0.9108 - accuracy: 0.6460 - val_loss: 0.8696 - val_accuracy: 0.6502

Epoch 00004: val_loss improved from 0.95341 to 0.86963, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 5/100
330/330 [==============================] - 23s 68ms/step - loss: 0.8651 - accuracy: 0.6495 - val_loss: 0.8466 - val_accuracy: 0.6526

Epoch 00005: val_loss improved from 0.86963 to 0.84657, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 6/100
330/330 [==============================] - 23s 70ms/step - loss: 0.8475 - accuracy: 0.6518 - val_loss: 0.8407 - val_accuracy: 0.6532

Epoch 00006: val_loss improved from 0.84657 to 0.84068, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 7/100
330/330 [==============================] - 24s 72ms/step - loss: 0.8388 - accuracy: 0.6536 - val_loss: 0.8323 - val_accuracy: 0.6554

Epoch 00007: val_loss improved from 0.84068 to 0.83228, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 8/100
330/330 [==============================] - 23s 69ms/step - loss: 0.8318 - accuracy: 0.6570 - val_loss: 0.8230 - val_accuracy: 0.6604

Epoch 00008: val_loss improved from 0.83228 to 0.82300, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 9/100
330/330 [==============================] - 22s 68ms/step - loss: 0.8269 - accuracy: 0.6597 - val_loss: 0.8205 - val_accuracy: 0.6623

Epoch 00009: val_loss improved from 0.82300 to 0.82054, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 10/100
330/330 [==============================] - 23s 70ms/step - loss: 0.8217 - accuracy: 0.6626 - val_loss: 0.8180 - val_accuracy: 0.6636

Epoch 00010: val_loss improved from 0.82054 to 0.81796, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 11/100
330/330 [==============================] - 23s 69ms/step - loss: 0.8165 - accuracy: 0.6648 - val_loss: 0.8152 - val_accuracy: 0.6650

Epoch 00011: val_loss improved from 0.81796 to 0.81515, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 12/100
330/330 [==============================] - 23s 69ms/step - loss: 0.8128 - accuracy: 0.6671 - val_loss: 0.8151 - val_accuracy: 0.6654

Epoch 00012: val_loss improved from 0.81515 to 0.81505, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 13/100
330/330 [==============================] - 23s 69ms/step - loss: 0.8088 - accuracy: 0.6694 - val_loss: 0.8102 - val_accuracy: 0.6688

Epoch 00013: val_loss improved from 0.81505 to 0.81022, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 14/100
330/330 [==============================] - 23s 69ms/step - loss: 0.8047 - accuracy: 0.6725 - val_loss: 0.8092 - val_accuracy: 0.6687

Epoch 00014: val_loss improved from 0.81022 to 0.80921, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 15/100
330/330 [==============================] - 23s 69ms/step - loss: 0.8004 - accuracy: 0.6743 - val_loss: 0.8064 - val_accuracy: 0.6704

Epoch 00015: val_loss improved from 0.80921 to 0.80645, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 16/100
330/330 [==============================] - 23s 69ms/step - loss: 0.7970 - accuracy: 0.6771 - val_loss: 0.8057 - val_accuracy: 0.6704

Epoch 00016: val_loss improved from 0.80645 to 0.80571, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 17/100
330/330 [==============================] - 23s 69ms/step - loss: 0.7941 - accuracy: 0.6798 - val_loss: 0.8050 - val_accuracy: 0.6710

Epoch 00017: val_loss improved from 0.80571 to 0.80502, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 18/100
330/330 [==============================] - 22s 68ms/step - loss: 0.7910 - accuracy: 0.6812 - val_loss: 0.8053 - val_accuracy: 0.6719

Epoch 00018: val_loss did not improve from 0.80502
Epoch 19/100
330/330 [==============================] - 23s 70ms/step - loss: 0.7880 - accuracy: 0.6830 - val_loss: 0.8064 - val_accuracy: 0.6723

Epoch 00019: val_loss did not improve from 0.80502
Epoch 20/100
330/330 [==============================] - 23s 71ms/step - loss: 0.7841 - accuracy: 0.6849 - val_loss: 0.8071 - val_accuracy: 0.6716

Epoch 00020: val_loss did not improve from 0.80502
Epoch 21/100
330/330 [==============================] - 23s 70ms/step - loss: 0.7826 - accuracy: 0.6869 - val_loss: 0.8062 - val_accuracy: 0.6718

Epoch 00021: val_loss did not improve from 0.80502
Epoch 22/100
330/330 [==============================] - 23s 69ms/step - loss: 0.7784 - accuracy: 0.6902 - val_loss: 0.8086 - val_accuracy: 0.6715

Epoch 00022: val_loss did not improve from 0.80502
Epoch 23/100
330/330 [==============================] - 23s 70ms/step - loss: 0.7750 - accuracy: 0.6923 - val_loss: 0.8116 - val_accuracy: 0.6705

Epoch 00023: val_loss did not improve from 0.80502
Epoch 24/100
330/330 [==============================] - 23s 70ms/step - loss: 0.7704 - accuracy: 0.6959 - val_loss: 0.8132 - val_accuracy: 0.6704

Epoch 00024: val_loss did not improve from 0.80502
Epoch 25/100
330/330 [==============================] - 23s 69ms/step - loss: 0.7667 - accuracy: 0.6992 - val_loss: 0.8162 - val_accuracy: 0.6689

Epoch 00025: val_loss did not improve from 0.80502
Epoch 26/100
330/330 [==============================] - 23s 68ms/step - loss: 0.7621 - accuracy: 0.7026 - val_loss: 0.8192 - val_accuracy: 0.6685

Epoch 00026: val_loss did not improve from 0.80502
Epoch 27/100
330/330 [==============================] - 23s 70ms/step - loss: 0.7579 - accuracy: 0.7059 - val_loss: 0.8253 - val_accuracy: 0.6686

Epoch 00027: val_loss did not improve from 0.80502
Epoch 00027: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
52809/52809 [==============================] - 215s 4ms/step - loss: 0.8039 - accuracy: 0.6684
Testing Loss = 0.803921, Testing Accuracy = 0.668409
The data set contains images
N of classes 3
$W^+$ (auc = 84.75 +- 0.0000 %)
$W^-$ (auc = 84.55 +- 0.0000 %)
$Z$ (auc = 81.87 +- 0.0000 %)
The summarized testing accuracy = 66.84 +- 0.0000 %, with the loss = 0.8039 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-31 01:19:41.988364
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 288000.
Epoch 1/100
562/562 [==============================] - 51s 68ms/step - loss: 4.3196 - accuracy: 0.6012 - val_loss: 1.4879 - val_accuracy: 0.6614

Epoch 00001: val_loss improved from inf to 1.48785, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 2/100
562/562 [==============================] - 38s 68ms/step - loss: 1.0980 - accuracy: 0.6538 - val_loss: 0.8647 - val_accuracy: 0.6762

Epoch 00002: val_loss improved from 1.48785 to 0.86470, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 3/100
562/562 [==============================] - 38s 67ms/step - loss: 0.8642 - accuracy: 0.6588 - val_loss: 0.8011 - val_accuracy: 0.6802

Epoch 00003: val_loss improved from 0.86470 to 0.80107, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 4/100
562/562 [==============================] - 38s 68ms/step - loss: 0.8328 - accuracy: 0.6618 - val_loss: 0.7868 - val_accuracy: 0.6827

Epoch 00004: val_loss improved from 0.80107 to 0.78676, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 5/100
562/562 [==============================] - 38s 68ms/step - loss: 0.8208 - accuracy: 0.6649 - val_loss: 0.7806 - val_accuracy: 0.6841

Epoch 00005: val_loss improved from 0.78676 to 0.78064, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 6/100
562/562 [==============================] - 38s 68ms/step - loss: 0.8139 - accuracy: 0.6672 - val_loss: 0.7722 - val_accuracy: 0.6877

Epoch 00006: val_loss improved from 0.78064 to 0.77224, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 7/100
562/562 [==============================] - 39s 69ms/step - loss: 0.8080 - accuracy: 0.6692 - val_loss: 0.7667 - val_accuracy: 0.6897

Epoch 00007: val_loss improved from 0.77224 to 0.76671, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 8/100
562/562 [==============================] - 38s 68ms/step - loss: 0.8023 - accuracy: 0.6729 - val_loss: 0.7684 - val_accuracy: 0.6885

Epoch 00008: val_loss did not improve from 0.76671
Epoch 9/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7972 - accuracy: 0.6749 - val_loss: 0.7625 - val_accuracy: 0.6914

Epoch 00009: val_loss improved from 0.76671 to 0.76245, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 10/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7920 - accuracy: 0.6777 - val_loss: 0.7558 - val_accuracy: 0.6951

Epoch 00010: val_loss improved from 0.76245 to 0.75575, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 11/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7886 - accuracy: 0.6799 - val_loss: 0.7531 - val_accuracy: 0.6966

Epoch 00011: val_loss improved from 0.75575 to 0.75307, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 12/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7849 - accuracy: 0.6816 - val_loss: 0.7500 - val_accuracy: 0.6963

Epoch 00012: val_loss improved from 0.75307 to 0.75004, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 13/100
562/562 [==============================] - 38s 67ms/step - loss: 0.7805 - accuracy: 0.6842 - val_loss: 0.7475 - val_accuracy: 0.6994

Epoch 00013: val_loss improved from 0.75004 to 0.74749, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 14/100
562/562 [==============================] - 39s 69ms/step - loss: 0.7787 - accuracy: 0.6860 - val_loss: 0.7464 - val_accuracy: 0.6989

Epoch 00014: val_loss improved from 0.74749 to 0.74642, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 15/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7755 - accuracy: 0.6875 - val_loss: 0.7459 - val_accuracy: 0.6993

Epoch 00015: val_loss improved from 0.74642 to 0.74591, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 16/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7732 - accuracy: 0.6888 - val_loss: 0.7451 - val_accuracy: 0.6995

Epoch 00016: val_loss improved from 0.74591 to 0.74507, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 17/100
562/562 [==============================] - 39s 69ms/step - loss: 0.7707 - accuracy: 0.6897 - val_loss: 0.7446 - val_accuracy: 0.7000

Epoch 00017: val_loss improved from 0.74507 to 0.74463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 18/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7680 - accuracy: 0.6917 - val_loss: 0.7437 - val_accuracy: 0.7007

Epoch 00018: val_loss improved from 0.74463 to 0.74370, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 19/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7658 - accuracy: 0.6929 - val_loss: 0.7432 - val_accuracy: 0.7011

Epoch 00019: val_loss improved from 0.74370 to 0.74323, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 20/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7650 - accuracy: 0.6931 - val_loss: 0.7436 - val_accuracy: 0.7003

Epoch 00020: val_loss did not improve from 0.74323
Epoch 21/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7624 - accuracy: 0.6954 - val_loss: 0.7408 - val_accuracy: 0.7028

Epoch 00021: val_loss improved from 0.74323 to 0.74081, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 22/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7597 - accuracy: 0.6967 - val_loss: 0.7396 - val_accuracy: 0.7032

Epoch 00022: val_loss improved from 0.74081 to 0.73961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15-special2/Try/0
Epoch 23/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7586 - accuracy: 0.6971 - val_loss: 0.7414 - val_accuracy: 0.7024

Epoch 00023: val_loss did not improve from 0.73961
Epoch 24/100
562/562 [==============================] - 39s 69ms/step - loss: 0.7560 - accuracy: 0.6994 - val_loss: 0.7413 - val_accuracy: 0.7034

Epoch 00024: val_loss did not improve from 0.73961
Epoch 25/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7544 - accuracy: 0.7009 - val_loss: 0.7403 - val_accuracy: 0.7042

Epoch 00025: val_loss did not improve from 0.73961
Epoch 26/100
562/562 [==============================] - 39s 69ms/step - loss: 0.7515 - accuracy: 0.7024 - val_loss: 0.7409 - val_accuracy: 0.7038

Epoch 00026: val_loss did not improve from 0.73961
Epoch 27/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7492 - accuracy: 0.7042 - val_loss: 0.7441 - val_accuracy: 0.7023

Epoch 00027: val_loss did not improve from 0.73961
Epoch 28/100
562/562 [==============================] - 38s 67ms/step - loss: 0.7483 - accuracy: 0.7054 - val_loss: 0.7421 - val_accuracy: 0.7036

Epoch 00028: val_loss did not improve from 0.73961
Epoch 29/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7445 - accuracy: 0.7076 - val_loss: 0.7432 - val_accuracy: 0.7031

Epoch 00029: val_loss did not improve from 0.73961
Epoch 30/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7412 - accuracy: 0.7102 - val_loss: 0.7462 - val_accuracy: 0.7022

Epoch 00030: val_loss did not improve from 0.73961
Epoch 31/100
562/562 [==============================] - 39s 68ms/step - loss: 0.7405 - accuracy: 0.7107 - val_loss: 0.7446 - val_accuracy: 0.7040

Epoch 00031: val_loss did not improve from 0.73961
Epoch 32/100
562/562 [==============================] - 38s 68ms/step - loss: 0.7364 - accuracy: 0.7134 - val_loss: 0.7484 - val_accuracy: 0.7012

Epoch 00032: val_loss did not improve from 0.73961
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
90000/90000 [==============================] - 403s 4ms/step - loss: 0.7291 - accuracy: 0.7091
Testing Loss = 0.729055, Testing Accuracy = 0.709100
The data set contains images
N of classes 3
$W^+$ (auc = 86.61 +- 0.0000 %)
$W^-$ (auc = 86.67 +- 0.0000 %)
$Z$ (auc = 87.55 +- 0.0000 %)
The summarized testing accuracy = 70.91 +- 0.0000 %, with the loss = 0.7291 +- 0.000000
