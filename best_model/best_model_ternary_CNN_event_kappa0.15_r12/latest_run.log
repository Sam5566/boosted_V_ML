

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-26 20:08:40.934624
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 15s 71ms/step - loss: 12.2557 - accuracy: 0.2174 - val_loss: 8.4972 - val_accuracy: 0.2623

Epoch 00001: val_loss improved from inf to 8.49720, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6353 - accuracy: 0.2723 - val_loss: 5.2940 - val_accuracy: 0.2968

Epoch 00002: val_loss improved from 8.49720 to 5.29398, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5421 - accuracy: 0.2864 - val_loss: 3.9464 - val_accuracy: 0.3084

Epoch 00003: val_loss improved from 5.29398 to 3.94641, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5622 - accuracy: 0.2940 - val_loss: 3.2148 - val_accuracy: 0.3134

Epoch 00004: val_loss improved from 3.94641 to 3.21484, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9796 - accuracy: 0.3041 - val_loss: 2.7451 - val_accuracy: 0.3135

Epoch 00005: val_loss improved from 3.21484 to 2.74506, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5893 - accuracy: 0.3064 - val_loss: 2.4189 - val_accuracy: 0.3207

Epoch 00006: val_loss improved from 2.74506 to 2.41890, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3142 - accuracy: 0.3122 - val_loss: 2.1910 - val_accuracy: 0.3207

Epoch 00007: val_loss improved from 2.41890 to 2.19103, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.1197 - accuracy: 0.3124 - val_loss: 2.0276 - val_accuracy: 0.3250

Epoch 00008: val_loss improved from 2.19103 to 2.02755, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9778 - accuracy: 0.3178 - val_loss: 1.9125 - val_accuracy: 0.3250

Epoch 00009: val_loss improved from 2.02755 to 1.91252, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8792 - accuracy: 0.3181 - val_loss: 1.8320 - val_accuracy: 0.3239

Epoch 00010: val_loss improved from 1.91252 to 1.83196, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8079 - accuracy: 0.3217 - val_loss: 1.7731 - val_accuracy: 0.3237

Epoch 00011: val_loss improved from 1.83196 to 1.77313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7568 - accuracy: 0.3196 - val_loss: 1.7319 - val_accuracy: 0.3267

Epoch 00012: val_loss improved from 1.77313 to 1.73192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7213 - accuracy: 0.3237 - val_loss: 1.7031 - val_accuracy: 0.3235

Epoch 00013: val_loss improved from 1.73192 to 1.70309, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6952 - accuracy: 0.3264 - val_loss: 1.6830 - val_accuracy: 0.3243

Epoch 00014: val_loss improved from 1.70309 to 1.68301, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6757 - accuracy: 0.3288 - val_loss: 1.6689 - val_accuracy: 0.3275

Epoch 00015: val_loss improved from 1.68301 to 1.66887, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6627 - accuracy: 0.3347 - val_loss: 1.6590 - val_accuracy: 0.3278

Epoch 00016: val_loss improved from 1.66887 to 1.65901, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6526 - accuracy: 0.3353 - val_loss: 1.6518 - val_accuracy: 0.3279

Epoch 00017: val_loss improved from 1.65901 to 1.65177, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6440 - accuracy: 0.3349 - val_loss: 1.6462 - val_accuracy: 0.3303

Epoch 00018: val_loss improved from 1.65177 to 1.64618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6371 - accuracy: 0.3386 - val_loss: 1.6431 - val_accuracy: 0.3307

Epoch 00019: val_loss improved from 1.64618 to 1.64315, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6335 - accuracy: 0.3382 - val_loss: 1.6410 - val_accuracy: 0.3325

Epoch 00020: val_loss improved from 1.64315 to 1.64102, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6294 - accuracy: 0.3399 - val_loss: 1.6408 - val_accuracy: 0.3344

Epoch 00021: val_loss improved from 1.64102 to 1.64077, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6247 - accuracy: 0.3430 - val_loss: 1.6404 - val_accuracy: 0.3331

Epoch 00022: val_loss improved from 1.64077 to 1.64038, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/0
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6234 - accuracy: 0.3465 - val_loss: 1.6405 - val_accuracy: 0.3340

Epoch 00023: val_loss did not improve from 1.64038
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6188 - accuracy: 0.3470 - val_loss: 1.6416 - val_accuracy: 0.3314

Epoch 00024: val_loss did not improve from 1.64038
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6187 - accuracy: 0.3512 - val_loss: 1.6444 - val_accuracy: 0.3347

Epoch 00025: val_loss did not improve from 1.64038
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6154 - accuracy: 0.3506 - val_loss: 1.6459 - val_accuracy: 0.3313

Epoch 00026: val_loss did not improve from 1.64038
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6156 - accuracy: 0.3520 - val_loss: 1.6481 - val_accuracy: 0.3337

Epoch 00027: val_loss did not improve from 1.64038
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6121 - accuracy: 0.3568 - val_loss: 1.6539 - val_accuracy: 0.3351

Epoch 00028: val_loss did not improve from 1.64038
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6095 - accuracy: 0.3595 - val_loss: 1.6569 - val_accuracy: 0.3345

Epoch 00029: val_loss did not improve from 1.64038
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6070 - accuracy: 0.3631 - val_loss: 1.6654 - val_accuracy: 0.3313

Epoch 00030: val_loss did not improve from 1.64038
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6070 - accuracy: 0.3680 - val_loss: 1.6733 - val_accuracy: 0.3286

Epoch 00031: val_loss did not improve from 1.64038
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6051 - accuracy: 0.3732 - val_loss: 1.6802 - val_accuracy: 0.3270

Epoch 00032: val_loss did not improve from 1.64038
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 58s 4ms/step - loss: 1.6476 - accuracy: 0.3324
Testing Loss = 1.647579, Testing Accuracy = 0.332391
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 70ms/step - loss: 12.2582 - accuracy: 0.2289 - val_loss: 8.5506 - val_accuracy: 0.2595

Epoch 00001: val_loss improved from inf to 8.55058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6957 - accuracy: 0.2756 - val_loss: 5.3498 - val_accuracy: 0.2953

Epoch 00002: val_loss improved from 8.55058 to 5.34979, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5925 - accuracy: 0.2884 - val_loss: 3.9895 - val_accuracy: 0.3047

Epoch 00003: val_loss improved from 5.34979 to 3.98946, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5979 - accuracy: 0.2949 - val_loss: 3.2451 - val_accuracy: 0.3074

Epoch 00004: val_loss improved from 3.98946 to 3.24505, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 3.0054 - accuracy: 0.3013 - val_loss: 2.7661 - val_accuracy: 0.3135

Epoch 00005: val_loss improved from 3.24505 to 2.76609, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.6087 - accuracy: 0.3056 - val_loss: 2.4344 - val_accuracy: 0.3157

Epoch 00006: val_loss improved from 2.76609 to 2.43439, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.3293 - accuracy: 0.3088 - val_loss: 2.2036 - val_accuracy: 0.3187

Epoch 00007: val_loss improved from 2.43439 to 2.20358, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.1291 - accuracy: 0.3137 - val_loss: 2.0378 - val_accuracy: 0.3220

Epoch 00008: val_loss improved from 2.20358 to 2.03782, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9889 - accuracy: 0.3168 - val_loss: 1.9200 - val_accuracy: 0.3237

Epoch 00009: val_loss improved from 2.03782 to 1.92000, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8864 - accuracy: 0.3166 - val_loss: 1.8365 - val_accuracy: 0.3234

Epoch 00010: val_loss improved from 1.92000 to 1.83650, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8115 - accuracy: 0.3215 - val_loss: 1.7771 - val_accuracy: 0.3256

Epoch 00011: val_loss improved from 1.83650 to 1.77706, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 12/100
83/83 [==============================] - 6s 70ms/step - loss: 1.7619 - accuracy: 0.3214 - val_loss: 1.7356 - val_accuracy: 0.3248

Epoch 00012: val_loss improved from 1.77706 to 1.73555, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7247 - accuracy: 0.3244 - val_loss: 1.7067 - val_accuracy: 0.3285

Epoch 00013: val_loss improved from 1.73555 to 1.70670, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6987 - accuracy: 0.3282 - val_loss: 1.6869 - val_accuracy: 0.3279

Epoch 00014: val_loss improved from 1.70670 to 1.68691, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6786 - accuracy: 0.3283 - val_loss: 1.6723 - val_accuracy: 0.3294

Epoch 00015: val_loss improved from 1.68691 to 1.67234, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6646 - accuracy: 0.3289 - val_loss: 1.6622 - val_accuracy: 0.3266

Epoch 00016: val_loss improved from 1.67234 to 1.66218, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6530 - accuracy: 0.3335 - val_loss: 1.6547 - val_accuracy: 0.3254

Epoch 00017: val_loss improved from 1.66218 to 1.65469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6450 - accuracy: 0.3342 - val_loss: 1.6493 - val_accuracy: 0.3294

Epoch 00018: val_loss improved from 1.65469 to 1.64933, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6377 - accuracy: 0.3385 - val_loss: 1.6464 - val_accuracy: 0.3290

Epoch 00019: val_loss improved from 1.64933 to 1.64641, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6333 - accuracy: 0.3396 - val_loss: 1.6450 - val_accuracy: 0.3290

Epoch 00020: val_loss improved from 1.64641 to 1.64504, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6275 - accuracy: 0.3432 - val_loss: 1.6448 - val_accuracy: 0.3273

Epoch 00021: val_loss improved from 1.64504 to 1.64484, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6245 - accuracy: 0.3423 - val_loss: 1.6435 - val_accuracy: 0.3319

Epoch 00022: val_loss improved from 1.64484 to 1.64354, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6231 - accuracy: 0.3443 - val_loss: 1.6434 - val_accuracy: 0.3339

Epoch 00023: val_loss improved from 1.64354 to 1.64337, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6195 - accuracy: 0.3477 - val_loss: 1.6434 - val_accuracy: 0.3341

Epoch 00024: val_loss did not improve from 1.64337
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6179 - accuracy: 0.3479 - val_loss: 1.6431 - val_accuracy: 0.3334

Epoch 00025: val_loss improved from 1.64337 to 1.64306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/1
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6145 - accuracy: 0.3504 - val_loss: 1.6484 - val_accuracy: 0.3313

Epoch 00026: val_loss did not improve from 1.64306
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6116 - accuracy: 0.3531 - val_loss: 1.6505 - val_accuracy: 0.3319

Epoch 00027: val_loss did not improve from 1.64306
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6113 - accuracy: 0.3587 - val_loss: 1.6530 - val_accuracy: 0.3316

Epoch 00028: val_loss did not improve from 1.64306
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6098 - accuracy: 0.3621 - val_loss: 1.6582 - val_accuracy: 0.3312

Epoch 00029: val_loss did not improve from 1.64306
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6068 - accuracy: 0.3636 - val_loss: 1.6612 - val_accuracy: 0.3292

Epoch 00030: val_loss did not improve from 1.64306
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6045 - accuracy: 0.3673 - val_loss: 1.6696 - val_accuracy: 0.3286

Epoch 00031: val_loss did not improve from 1.64306
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6037 - accuracy: 0.3734 - val_loss: 1.6763 - val_accuracy: 0.3286

Epoch 00032: val_loss did not improve from 1.64306
Epoch 33/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6018 - accuracy: 0.3737 - val_loss: 1.6842 - val_accuracy: 0.3289

Epoch 00033: val_loss did not improve from 1.64306
Epoch 34/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5960 - accuracy: 0.3818 - val_loss: 1.6991 - val_accuracy: 0.3268

Epoch 00034: val_loss did not improve from 1.64306
Epoch 35/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5957 - accuracy: 0.3862 - val_loss: 1.7076 - val_accuracy: 0.3250

Epoch 00035: val_loss did not improve from 1.64306
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 58s 4ms/step - loss: 1.6506 - accuracy: 0.3316
Testing Loss = 1.650618, Testing Accuracy = 0.331646
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.1793 - accuracy: 0.2193 - val_loss: 8.4132 - val_accuracy: 0.2570

Epoch 00001: val_loss improved from inf to 8.41322, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.5794 - accuracy: 0.2714 - val_loss: 5.2677 - val_accuracy: 0.2948

Epoch 00002: val_loss improved from 8.41322 to 5.26771, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5276 - accuracy: 0.2836 - val_loss: 3.9426 - val_accuracy: 0.3089

Epoch 00003: val_loss improved from 5.26771 to 3.94263, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5615 - accuracy: 0.2955 - val_loss: 3.2201 - val_accuracy: 0.3109

Epoch 00004: val_loss improved from 3.94263 to 3.22009, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9874 - accuracy: 0.3007 - val_loss: 2.7525 - val_accuracy: 0.3155

Epoch 00005: val_loss improved from 3.22009 to 2.75246, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5966 - accuracy: 0.3045 - val_loss: 2.4266 - val_accuracy: 0.3170

Epoch 00006: val_loss improved from 2.75246 to 2.42662, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3207 - accuracy: 0.3108 - val_loss: 2.1960 - val_accuracy: 0.3182

Epoch 00007: val_loss improved from 2.42662 to 2.19597, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.1239 - accuracy: 0.3122 - val_loss: 2.0328 - val_accuracy: 0.3210

Epoch 00008: val_loss improved from 2.19597 to 2.03283, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9840 - accuracy: 0.3148 - val_loss: 1.9171 - val_accuracy: 0.3213

Epoch 00009: val_loss improved from 2.03283 to 1.91709, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8826 - accuracy: 0.3174 - val_loss: 1.8338 - val_accuracy: 0.3266

Epoch 00010: val_loss improved from 1.91709 to 1.83377, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8112 - accuracy: 0.3195 - val_loss: 1.7768 - val_accuracy: 0.3271

Epoch 00011: val_loss improved from 1.83377 to 1.77675, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7593 - accuracy: 0.3238 - val_loss: 1.7359 - val_accuracy: 0.3245

Epoch 00012: val_loss improved from 1.77675 to 1.73594, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7231 - accuracy: 0.3260 - val_loss: 1.7082 - val_accuracy: 0.3231

Epoch 00013: val_loss improved from 1.73594 to 1.70824, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6971 - accuracy: 0.3272 - val_loss: 1.6873 - val_accuracy: 0.3250

Epoch 00014: val_loss improved from 1.70824 to 1.68730, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6783 - accuracy: 0.3304 - val_loss: 1.6743 - val_accuracy: 0.3250

Epoch 00015: val_loss improved from 1.68730 to 1.67433, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6640 - accuracy: 0.3315 - val_loss: 1.6625 - val_accuracy: 0.3299

Epoch 00016: val_loss improved from 1.67433 to 1.66251, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6527 - accuracy: 0.3347 - val_loss: 1.6581 - val_accuracy: 0.3275

Epoch 00017: val_loss improved from 1.66251 to 1.65814, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6460 - accuracy: 0.3351 - val_loss: 1.6516 - val_accuracy: 0.3295

Epoch 00018: val_loss improved from 1.65814 to 1.65159, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6372 - accuracy: 0.3401 - val_loss: 1.6482 - val_accuracy: 0.3303

Epoch 00019: val_loss improved from 1.65159 to 1.64823, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6327 - accuracy: 0.3417 - val_loss: 1.6467 - val_accuracy: 0.3299

Epoch 00020: val_loss improved from 1.64823 to 1.64674, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6284 - accuracy: 0.3436 - val_loss: 1.6469 - val_accuracy: 0.3298

Epoch 00021: val_loss did not improve from 1.64674
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6239 - accuracy: 0.3436 - val_loss: 1.6461 - val_accuracy: 0.3332

Epoch 00022: val_loss improved from 1.64674 to 1.64613, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/2
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6217 - accuracy: 0.3483 - val_loss: 1.6480 - val_accuracy: 0.3351

Epoch 00023: val_loss did not improve from 1.64613
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6187 - accuracy: 0.3527 - val_loss: 1.6506 - val_accuracy: 0.3310

Epoch 00024: val_loss did not improve from 1.64613
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6146 - accuracy: 0.3552 - val_loss: 1.6528 - val_accuracy: 0.3311

Epoch 00025: val_loss did not improve from 1.64613
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6116 - accuracy: 0.3566 - val_loss: 1.6561 - val_accuracy: 0.3275

Epoch 00026: val_loss did not improve from 1.64613
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6097 - accuracy: 0.3588 - val_loss: 1.6603 - val_accuracy: 0.3310

Epoch 00027: val_loss did not improve from 1.64613
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6084 - accuracy: 0.3634 - val_loss: 1.6652 - val_accuracy: 0.3304

Epoch 00028: val_loss did not improve from 1.64613
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6060 - accuracy: 0.3657 - val_loss: 1.6699 - val_accuracy: 0.3291

Epoch 00029: val_loss did not improve from 1.64613
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6020 - accuracy: 0.3700 - val_loss: 1.6780 - val_accuracy: 0.3277

Epoch 00030: val_loss did not improve from 1.64613
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6023 - accuracy: 0.3730 - val_loss: 1.6877 - val_accuracy: 0.3279

Epoch 00031: val_loss did not improve from 1.64613
Epoch 32/100
83/83 [==============================] - 6s 69ms/step - loss: 1.5968 - accuracy: 0.3813 - val_loss: 1.6989 - val_accuracy: 0.3208

Epoch 00032: val_loss did not improve from 1.64613
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6538 - accuracy: 0.3314
Testing Loss = 1.653803, Testing Accuracy = 0.331423
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.1656 - accuracy: 0.2226 - val_loss: 8.4207 - val_accuracy: 0.2546

Epoch 00001: val_loss improved from inf to 8.42072, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.5895 - accuracy: 0.2697 - val_loss: 5.2682 - val_accuracy: 0.2944

Epoch 00002: val_loss improved from 8.42072 to 5.26824, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5232 - accuracy: 0.2871 - val_loss: 3.9360 - val_accuracy: 0.3078

Epoch 00003: val_loss improved from 5.26824 to 3.93601, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5574 - accuracy: 0.2988 - val_loss: 3.2137 - val_accuracy: 0.3128

Epoch 00004: val_loss improved from 3.93601 to 3.21371, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9795 - accuracy: 0.3016 - val_loss: 2.7437 - val_accuracy: 0.3153

Epoch 00005: val_loss improved from 3.21371 to 2.74373, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.5891 - accuracy: 0.3076 - val_loss: 2.4196 - val_accuracy: 0.3167

Epoch 00006: val_loss improved from 2.74373 to 2.41956, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3163 - accuracy: 0.3109 - val_loss: 2.1894 - val_accuracy: 0.3195

Epoch 00007: val_loss improved from 2.41956 to 2.18944, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1187 - accuracy: 0.3125 - val_loss: 2.0278 - val_accuracy: 0.3230

Epoch 00008: val_loss improved from 2.18944 to 2.02778, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9778 - accuracy: 0.3172 - val_loss: 1.9112 - val_accuracy: 0.3239

Epoch 00009: val_loss improved from 2.02778 to 1.91118, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8774 - accuracy: 0.3185 - val_loss: 1.8309 - val_accuracy: 0.3224

Epoch 00010: val_loss improved from 1.91118 to 1.83089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8059 - accuracy: 0.3221 - val_loss: 1.7720 - val_accuracy: 0.3240

Epoch 00011: val_loss improved from 1.83089 to 1.77196, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7557 - accuracy: 0.3244 - val_loss: 1.7316 - val_accuracy: 0.3245

Epoch 00012: val_loss improved from 1.77196 to 1.73159, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7204 - accuracy: 0.3246 - val_loss: 1.7024 - val_accuracy: 0.3251

Epoch 00013: val_loss improved from 1.73159 to 1.70240, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6926 - accuracy: 0.3301 - val_loss: 1.6824 - val_accuracy: 0.3268

Epoch 00014: val_loss improved from 1.70240 to 1.68238, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6740 - accuracy: 0.3282 - val_loss: 1.6687 - val_accuracy: 0.3249

Epoch 00015: val_loss improved from 1.68238 to 1.66871, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6604 - accuracy: 0.3310 - val_loss: 1.6582 - val_accuracy: 0.3309

Epoch 00016: val_loss improved from 1.66871 to 1.65818, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6488 - accuracy: 0.3371 - val_loss: 1.6510 - val_accuracy: 0.3293

Epoch 00017: val_loss improved from 1.65818 to 1.65101, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6417 - accuracy: 0.3358 - val_loss: 1.6484 - val_accuracy: 0.3287

Epoch 00018: val_loss improved from 1.65101 to 1.64844, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6347 - accuracy: 0.3377 - val_loss: 1.6437 - val_accuracy: 0.3269

Epoch 00019: val_loss improved from 1.64844 to 1.64372, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6314 - accuracy: 0.3386 - val_loss: 1.6403 - val_accuracy: 0.3299

Epoch 00020: val_loss improved from 1.64372 to 1.64033, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/3
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6270 - accuracy: 0.3425 - val_loss: 1.6403 - val_accuracy: 0.3296

Epoch 00021: val_loss did not improve from 1.64033
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6226 - accuracy: 0.3473 - val_loss: 1.6404 - val_accuracy: 0.3289

Epoch 00022: val_loss did not improve from 1.64033
Epoch 23/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6194 - accuracy: 0.3454 - val_loss: 1.6421 - val_accuracy: 0.3284

Epoch 00023: val_loss did not improve from 1.64033
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6166 - accuracy: 0.3470 - val_loss: 1.6435 - val_accuracy: 0.3307

Epoch 00024: val_loss did not improve from 1.64033
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6156 - accuracy: 0.3498 - val_loss: 1.6456 - val_accuracy: 0.3286

Epoch 00025: val_loss did not improve from 1.64033
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6118 - accuracy: 0.3528 - val_loss: 1.6484 - val_accuracy: 0.3309

Epoch 00026: val_loss did not improve from 1.64033
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6121 - accuracy: 0.3541 - val_loss: 1.6507 - val_accuracy: 0.3313

Epoch 00027: val_loss did not improve from 1.64033
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6086 - accuracy: 0.3595 - val_loss: 1.6571 - val_accuracy: 0.3323

Epoch 00028: val_loss did not improve from 1.64033
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6087 - accuracy: 0.3623 - val_loss: 1.6606 - val_accuracy: 0.3301

Epoch 00029: val_loss did not improve from 1.64033
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6023 - accuracy: 0.3663 - val_loss: 1.6717 - val_accuracy: 0.3254

Epoch 00030: val_loss did not improve from 1.64033
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6477 - accuracy: 0.3316
Testing Loss = 1.647665, Testing Accuracy = 0.331646
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 7s 70ms/step - loss: 12.1694 - accuracy: 0.2299 - val_loss: 8.4609 - val_accuracy: 0.2526

Epoch 00001: val_loss improved from inf to 8.46090, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6194 - accuracy: 0.2741 - val_loss: 5.2905 - val_accuracy: 0.2979

Epoch 00002: val_loss improved from 8.46090 to 5.29050, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5475 - accuracy: 0.2863 - val_loss: 3.9549 - val_accuracy: 0.3063

Epoch 00003: val_loss improved from 5.29050 to 3.95490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5669 - accuracy: 0.2995 - val_loss: 3.2209 - val_accuracy: 0.3091

Epoch 00004: val_loss improved from 3.95490 to 3.22089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9833 - accuracy: 0.3058 - val_loss: 2.7466 - val_accuracy: 0.3161

Epoch 00005: val_loss improved from 3.22089 to 2.74659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5887 - accuracy: 0.3068 - val_loss: 2.4179 - val_accuracy: 0.3177

Epoch 00006: val_loss improved from 2.74659 to 2.41794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.3124 - accuracy: 0.3099 - val_loss: 2.1881 - val_accuracy: 0.3217

Epoch 00007: val_loss improved from 2.41794 to 2.18807, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.1156 - accuracy: 0.3139 - val_loss: 2.0261 - val_accuracy: 0.3223

Epoch 00008: val_loss improved from 2.18807 to 2.02607, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9744 - accuracy: 0.3203 - val_loss: 1.9086 - val_accuracy: 0.3212

Epoch 00009: val_loss improved from 2.02607 to 1.90864, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8763 - accuracy: 0.3171 - val_loss: 1.8274 - val_accuracy: 0.3271

Epoch 00010: val_loss improved from 1.90864 to 1.82737, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8056 - accuracy: 0.3210 - val_loss: 1.7702 - val_accuracy: 0.3270

Epoch 00011: val_loss improved from 1.82737 to 1.77021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7542 - accuracy: 0.3237 - val_loss: 1.7304 - val_accuracy: 0.3249

Epoch 00012: val_loss improved from 1.77021 to 1.73041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7192 - accuracy: 0.3282 - val_loss: 1.7023 - val_accuracy: 0.3270

Epoch 00013: val_loss improved from 1.73041 to 1.70226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6929 - accuracy: 0.3276 - val_loss: 1.6827 - val_accuracy: 0.3267

Epoch 00014: val_loss improved from 1.70226 to 1.68272, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6736 - accuracy: 0.3297 - val_loss: 1.6688 - val_accuracy: 0.3288

Epoch 00015: val_loss improved from 1.68272 to 1.66876, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6615 - accuracy: 0.3301 - val_loss: 1.6585 - val_accuracy: 0.3281

Epoch 00016: val_loss improved from 1.66876 to 1.65854, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6503 - accuracy: 0.3338 - val_loss: 1.6513 - val_accuracy: 0.3280

Epoch 00017: val_loss improved from 1.65854 to 1.65131, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6422 - accuracy: 0.3352 - val_loss: 1.6475 - val_accuracy: 0.3299

Epoch 00018: val_loss improved from 1.65131 to 1.64747, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6372 - accuracy: 0.3357 - val_loss: 1.6445 - val_accuracy: 0.3321

Epoch 00019: val_loss improved from 1.64747 to 1.64447, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6308 - accuracy: 0.3399 - val_loss: 1.6430 - val_accuracy: 0.3291

Epoch 00020: val_loss improved from 1.64447 to 1.64299, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 21/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6269 - accuracy: 0.3413 - val_loss: 1.6400 - val_accuracy: 0.3351

Epoch 00021: val_loss improved from 1.64299 to 1.63996, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/4
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6241 - accuracy: 0.3479 - val_loss: 1.6410 - val_accuracy: 0.3307

Epoch 00022: val_loss did not improve from 1.63996
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6203 - accuracy: 0.3448 - val_loss: 1.6408 - val_accuracy: 0.3334

Epoch 00023: val_loss did not improve from 1.63996
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6170 - accuracy: 0.3491 - val_loss: 1.6443 - val_accuracy: 0.3291

Epoch 00024: val_loss did not improve from 1.63996
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6167 - accuracy: 0.3486 - val_loss: 1.6446 - val_accuracy: 0.3323

Epoch 00025: val_loss did not improve from 1.63996
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6139 - accuracy: 0.3515 - val_loss: 1.6465 - val_accuracy: 0.3327

Epoch 00026: val_loss did not improve from 1.63996
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6112 - accuracy: 0.3543 - val_loss: 1.6518 - val_accuracy: 0.3319

Epoch 00027: val_loss did not improve from 1.63996
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6099 - accuracy: 0.3583 - val_loss: 1.6564 - val_accuracy: 0.3280

Epoch 00028: val_loss did not improve from 1.63996
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6071 - accuracy: 0.3598 - val_loss: 1.6621 - val_accuracy: 0.3285

Epoch 00029: val_loss did not improve from 1.63996
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6073 - accuracy: 0.3630 - val_loss: 1.6646 - val_accuracy: 0.3296

Epoch 00030: val_loss did not improve from 1.63996
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6036 - accuracy: 0.3689 - val_loss: 1.6686 - val_accuracy: 0.3307

Epoch 00031: val_loss did not improve from 1.63996
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 56s 4ms/step - loss: 1.6494 - accuracy: 0.3312
Testing Loss = 1.649400, Testing Accuracy = 0.331200
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.1902 - accuracy: 0.2247 - val_loss: 8.4709 - val_accuracy: 0.2551

Epoch 00001: val_loss improved from inf to 8.47089, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6261 - accuracy: 0.2715 - val_loss: 5.2967 - val_accuracy: 0.2976

Epoch 00002: val_loss improved from 8.47089 to 5.29669, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5455 - accuracy: 0.2894 - val_loss: 3.9556 - val_accuracy: 0.3089

Epoch 00003: val_loss improved from 5.29669 to 3.95564, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5709 - accuracy: 0.2943 - val_loss: 3.2241 - val_accuracy: 0.3092

Epoch 00004: val_loss improved from 3.95564 to 3.22412, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9862 - accuracy: 0.3018 - val_loss: 2.7501 - val_accuracy: 0.3119

Epoch 00005: val_loss improved from 3.22412 to 2.75014, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.5936 - accuracy: 0.3066 - val_loss: 2.4213 - val_accuracy: 0.3178

Epoch 00006: val_loss improved from 2.75014 to 2.42130, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.3155 - accuracy: 0.3081 - val_loss: 2.1921 - val_accuracy: 0.3199

Epoch 00007: val_loss improved from 2.42130 to 2.19209, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 8/100
83/83 [==============================] - 6s 69ms/step - loss: 2.1194 - accuracy: 0.3137 - val_loss: 2.0276 - val_accuracy: 0.3186

Epoch 00008: val_loss improved from 2.19209 to 2.02763, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9762 - accuracy: 0.3179 - val_loss: 1.9118 - val_accuracy: 0.3190

Epoch 00009: val_loss improved from 2.02763 to 1.91184, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8775 - accuracy: 0.3181 - val_loss: 1.8296 - val_accuracy: 0.3220

Epoch 00010: val_loss improved from 1.91184 to 1.82959, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 11/100
83/83 [==============================] - 6s 70ms/step - loss: 1.8057 - accuracy: 0.3222 - val_loss: 1.7707 - val_accuracy: 0.3210

Epoch 00011: val_loss improved from 1.82959 to 1.77068, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7546 - accuracy: 0.3245 - val_loss: 1.7306 - val_accuracy: 0.3237

Epoch 00012: val_loss improved from 1.77068 to 1.73062, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7185 - accuracy: 0.3265 - val_loss: 1.7034 - val_accuracy: 0.3253

Epoch 00013: val_loss improved from 1.73062 to 1.70338, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6929 - accuracy: 0.3277 - val_loss: 1.6816 - val_accuracy: 0.3287

Epoch 00014: val_loss improved from 1.70338 to 1.68161, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6733 - accuracy: 0.3281 - val_loss: 1.6670 - val_accuracy: 0.3295

Epoch 00015: val_loss improved from 1.68161 to 1.66702, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6596 - accuracy: 0.3316 - val_loss: 1.6584 - val_accuracy: 0.3306

Epoch 00016: val_loss improved from 1.66702 to 1.65840, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6497 - accuracy: 0.3345 - val_loss: 1.6521 - val_accuracy: 0.3309

Epoch 00017: val_loss improved from 1.65840 to 1.65211, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6422 - accuracy: 0.3350 - val_loss: 1.6467 - val_accuracy: 0.3289

Epoch 00018: val_loss improved from 1.65211 to 1.64668, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6366 - accuracy: 0.3366 - val_loss: 1.6442 - val_accuracy: 0.3312

Epoch 00019: val_loss improved from 1.64668 to 1.64422, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6312 - accuracy: 0.3380 - val_loss: 1.6422 - val_accuracy: 0.3315

Epoch 00020: val_loss improved from 1.64422 to 1.64220, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6268 - accuracy: 0.3420 - val_loss: 1.6411 - val_accuracy: 0.3335

Epoch 00021: val_loss improved from 1.64220 to 1.64108, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/5
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6227 - accuracy: 0.3458 - val_loss: 1.6414 - val_accuracy: 0.3323

Epoch 00022: val_loss did not improve from 1.64108
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6197 - accuracy: 0.3460 - val_loss: 1.6444 - val_accuracy: 0.3282

Epoch 00023: val_loss did not improve from 1.64108
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6176 - accuracy: 0.3482 - val_loss: 1.6435 - val_accuracy: 0.3340

Epoch 00024: val_loss did not improve from 1.64108
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6134 - accuracy: 0.3531 - val_loss: 1.6478 - val_accuracy: 0.3305

Epoch 00025: val_loss did not improve from 1.64108
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6130 - accuracy: 0.3533 - val_loss: 1.6498 - val_accuracy: 0.3308

Epoch 00026: val_loss did not improve from 1.64108
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6116 - accuracy: 0.3558 - val_loss: 1.6526 - val_accuracy: 0.3298

Epoch 00027: val_loss did not improve from 1.64108
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6093 - accuracy: 0.3583 - val_loss: 1.6557 - val_accuracy: 0.3308

Epoch 00028: val_loss did not improve from 1.64108
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6073 - accuracy: 0.3611 - val_loss: 1.6623 - val_accuracy: 0.3305

Epoch 00029: val_loss did not improve from 1.64108
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6044 - accuracy: 0.3642 - val_loss: 1.6656 - val_accuracy: 0.3320

Epoch 00030: val_loss did not improve from 1.64108
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6011 - accuracy: 0.3685 - val_loss: 1.6745 - val_accuracy: 0.3334

Epoch 00031: val_loss did not improve from 1.64108
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6485 - accuracy: 0.3340
Testing Loss = 1.648524, Testing Accuracy = 0.334028
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.1745 - accuracy: 0.2211 - val_loss: 8.4175 - val_accuracy: 0.2416

Epoch 00001: val_loss improved from inf to 8.41754, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.5767 - accuracy: 0.2769 - val_loss: 5.2554 - val_accuracy: 0.2930

Epoch 00002: val_loss improved from 8.41754 to 5.25544, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5147 - accuracy: 0.2896 - val_loss: 3.9292 - val_accuracy: 0.3058

Epoch 00003: val_loss improved from 5.25544 to 3.92919, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5510 - accuracy: 0.2932 - val_loss: 3.2059 - val_accuracy: 0.3115

Epoch 00004: val_loss improved from 3.92919 to 3.20586, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9744 - accuracy: 0.2967 - val_loss: 2.7388 - val_accuracy: 0.3140

Epoch 00005: val_loss improved from 3.20586 to 2.73882, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5839 - accuracy: 0.3053 - val_loss: 2.4163 - val_accuracy: 0.3166

Epoch 00006: val_loss improved from 2.73882 to 2.41635, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3114 - accuracy: 0.3137 - val_loss: 2.1878 - val_accuracy: 0.3204

Epoch 00007: val_loss improved from 2.41635 to 2.18777, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1142 - accuracy: 0.3145 - val_loss: 2.0257 - val_accuracy: 0.3207

Epoch 00008: val_loss improved from 2.18777 to 2.02565, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9765 - accuracy: 0.3160 - val_loss: 1.9108 - val_accuracy: 0.3231

Epoch 00009: val_loss improved from 2.02565 to 1.91081, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8773 - accuracy: 0.3176 - val_loss: 1.8284 - val_accuracy: 0.3252

Epoch 00010: val_loss improved from 1.91081 to 1.82843, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8068 - accuracy: 0.3207 - val_loss: 1.7712 - val_accuracy: 0.3235

Epoch 00011: val_loss improved from 1.82843 to 1.77122, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7559 - accuracy: 0.3243 - val_loss: 1.7308 - val_accuracy: 0.3263

Epoch 00012: val_loss improved from 1.77122 to 1.73080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7207 - accuracy: 0.3232 - val_loss: 1.7021 - val_accuracy: 0.3252

Epoch 00013: val_loss improved from 1.73080 to 1.70211, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6944 - accuracy: 0.3269 - val_loss: 1.6841 - val_accuracy: 0.3275

Epoch 00014: val_loss improved from 1.70211 to 1.68411, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6757 - accuracy: 0.3270 - val_loss: 1.6698 - val_accuracy: 0.3252

Epoch 00015: val_loss improved from 1.68411 to 1.66979, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6606 - accuracy: 0.3316 - val_loss: 1.6606 - val_accuracy: 0.3288

Epoch 00016: val_loss improved from 1.66979 to 1.66056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6508 - accuracy: 0.3335 - val_loss: 1.6539 - val_accuracy: 0.3306

Epoch 00017: val_loss improved from 1.66056 to 1.65387, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6436 - accuracy: 0.3339 - val_loss: 1.6503 - val_accuracy: 0.3309

Epoch 00018: val_loss improved from 1.65387 to 1.65034, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 19/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6382 - accuracy: 0.3377 - val_loss: 1.6453 - val_accuracy: 0.3335

Epoch 00019: val_loss improved from 1.65034 to 1.64526, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6317 - accuracy: 0.3413 - val_loss: 1.6450 - val_accuracy: 0.3296

Epoch 00020: val_loss improved from 1.64526 to 1.64503, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6281 - accuracy: 0.3422 - val_loss: 1.6431 - val_accuracy: 0.3300

Epoch 00021: val_loss improved from 1.64503 to 1.64313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/6
Epoch 22/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6235 - accuracy: 0.3432 - val_loss: 1.6449 - val_accuracy: 0.3324

Epoch 00022: val_loss did not improve from 1.64313
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6204 - accuracy: 0.3460 - val_loss: 1.6456 - val_accuracy: 0.3328

Epoch 00023: val_loss did not improve from 1.64313
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6180 - accuracy: 0.3490 - val_loss: 1.6456 - val_accuracy: 0.3330

Epoch 00024: val_loss did not improve from 1.64313
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6143 - accuracy: 0.3501 - val_loss: 1.6532 - val_accuracy: 0.3302

Epoch 00025: val_loss did not improve from 1.64313
Epoch 26/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6126 - accuracy: 0.3516 - val_loss: 1.6525 - val_accuracy: 0.3354

Epoch 00026: val_loss did not improve from 1.64313
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6110 - accuracy: 0.3585 - val_loss: 1.6551 - val_accuracy: 0.3339

Epoch 00027: val_loss did not improve from 1.64313
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6074 - accuracy: 0.3604 - val_loss: 1.6601 - val_accuracy: 0.3326

Epoch 00028: val_loss did not improve from 1.64313
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6040 - accuracy: 0.3639 - val_loss: 1.6681 - val_accuracy: 0.3322

Epoch 00029: val_loss did not improve from 1.64313
Epoch 30/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6045 - accuracy: 0.3670 - val_loss: 1.6755 - val_accuracy: 0.3300

Epoch 00030: val_loss did not improve from 1.64313
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6014 - accuracy: 0.3727 - val_loss: 1.6795 - val_accuracy: 0.3302

Epoch 00031: val_loss did not improve from 1.64313
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 59s 4ms/step - loss: 1.6509 - accuracy: 0.3304
Testing Loss = 1.650896, Testing Accuracy = 0.330381
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.2438 - accuracy: 0.2203 - val_loss: 8.4868 - val_accuracy: 0.2570

Epoch 00001: val_loss improved from inf to 8.48682, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6335 - accuracy: 0.2717 - val_loss: 5.3039 - val_accuracy: 0.2988

Epoch 00002: val_loss improved from 8.48682 to 5.30392, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5583 - accuracy: 0.2857 - val_loss: 3.9642 - val_accuracy: 0.3043

Epoch 00003: val_loss improved from 5.30392 to 3.96415, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5792 - accuracy: 0.2955 - val_loss: 3.2288 - val_accuracy: 0.3107

Epoch 00004: val_loss improved from 3.96415 to 3.22880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9948 - accuracy: 0.3018 - val_loss: 2.7564 - val_accuracy: 0.3126

Epoch 00005: val_loss improved from 3.22880 to 2.75637, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.6006 - accuracy: 0.3063 - val_loss: 2.4287 - val_accuracy: 0.3176

Epoch 00006: val_loss improved from 2.75637 to 2.42869, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3241 - accuracy: 0.3085 - val_loss: 2.1973 - val_accuracy: 0.3200

Epoch 00007: val_loss improved from 2.42869 to 2.19733, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1251 - accuracy: 0.3132 - val_loss: 2.0338 - val_accuracy: 0.3223

Epoch 00008: val_loss improved from 2.19733 to 2.03377, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9828 - accuracy: 0.3181 - val_loss: 1.9166 - val_accuracy: 0.3223

Epoch 00009: val_loss improved from 2.03377 to 1.91663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 10/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8812 - accuracy: 0.3190 - val_loss: 1.8343 - val_accuracy: 0.3248

Epoch 00010: val_loss improved from 1.91663 to 1.83433, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8105 - accuracy: 0.3218 - val_loss: 1.7759 - val_accuracy: 0.3242

Epoch 00011: val_loss improved from 1.83433 to 1.77593, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 12/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7578 - accuracy: 0.3245 - val_loss: 1.7348 - val_accuracy: 0.3260

Epoch 00012: val_loss improved from 1.77593 to 1.73480, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7224 - accuracy: 0.3249 - val_loss: 1.7055 - val_accuracy: 0.3261

Epoch 00013: val_loss improved from 1.73480 to 1.70546, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 14/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6964 - accuracy: 0.3265 - val_loss: 1.6843 - val_accuracy: 0.3271

Epoch 00014: val_loss improved from 1.70546 to 1.68431, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 15/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6762 - accuracy: 0.3304 - val_loss: 1.6691 - val_accuracy: 0.3279

Epoch 00015: val_loss improved from 1.68431 to 1.66907, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6620 - accuracy: 0.3311 - val_loss: 1.6608 - val_accuracy: 0.3294

Epoch 00016: val_loss improved from 1.66907 to 1.66083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6520 - accuracy: 0.3327 - val_loss: 1.6533 - val_accuracy: 0.3291

Epoch 00017: val_loss improved from 1.66083 to 1.65332, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6422 - accuracy: 0.3350 - val_loss: 1.6489 - val_accuracy: 0.3288

Epoch 00018: val_loss improved from 1.65332 to 1.64893, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6348 - accuracy: 0.3375 - val_loss: 1.6453 - val_accuracy: 0.3303

Epoch 00019: val_loss improved from 1.64893 to 1.64529, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6300 - accuracy: 0.3434 - val_loss: 1.6437 - val_accuracy: 0.3310

Epoch 00020: val_loss improved from 1.64529 to 1.64371, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6272 - accuracy: 0.3418 - val_loss: 1.6423 - val_accuracy: 0.3338

Epoch 00021: val_loss improved from 1.64371 to 1.64229, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/7
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6225 - accuracy: 0.3445 - val_loss: 1.6459 - val_accuracy: 0.3292

Epoch 00022: val_loss did not improve from 1.64229
Epoch 23/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6200 - accuracy: 0.3472 - val_loss: 1.6431 - val_accuracy: 0.3317

Epoch 00023: val_loss did not improve from 1.64229
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6161 - accuracy: 0.3522 - val_loss: 1.6475 - val_accuracy: 0.3309

Epoch 00024: val_loss did not improve from 1.64229
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6150 - accuracy: 0.3511 - val_loss: 1.6460 - val_accuracy: 0.3346

Epoch 00025: val_loss did not improve from 1.64229
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6115 - accuracy: 0.3558 - val_loss: 1.6542 - val_accuracy: 0.3301

Epoch 00026: val_loss did not improve from 1.64229
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6099 - accuracy: 0.3570 - val_loss: 1.6565 - val_accuracy: 0.3304

Epoch 00027: val_loss did not improve from 1.64229
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6076 - accuracy: 0.3610 - val_loss: 1.6610 - val_accuracy: 0.3299

Epoch 00028: val_loss did not improve from 1.64229
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6056 - accuracy: 0.3617 - val_loss: 1.6672 - val_accuracy: 0.3321

Epoch 00029: val_loss did not improve from 1.64229
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6044 - accuracy: 0.3683 - val_loss: 1.6750 - val_accuracy: 0.3276

Epoch 00030: val_loss did not improve from 1.64229
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6008 - accuracy: 0.3731 - val_loss: 1.6838 - val_accuracy: 0.3288

Epoch 00031: val_loss did not improve from 1.64229
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 60s 4ms/step - loss: 1.6495 - accuracy: 0.3303
Testing Loss = 1.649486, Testing Accuracy = 0.330307
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 69ms/step - loss: 12.1492 - accuracy: 0.2208 - val_loss: 8.3985 - val_accuracy: 0.2580

Epoch 00001: val_loss improved from inf to 8.39851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.5753 - accuracy: 0.2736 - val_loss: 5.2654 - val_accuracy: 0.2905

Epoch 00002: val_loss improved from 8.39851 to 5.26542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5255 - accuracy: 0.2882 - val_loss: 3.9401 - val_accuracy: 0.3040

Epoch 00003: val_loss improved from 5.26542 to 3.94010, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5585 - accuracy: 0.2961 - val_loss: 3.2127 - val_accuracy: 0.3089

Epoch 00004: val_loss improved from 3.94010 to 3.21271, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9791 - accuracy: 0.3055 - val_loss: 2.7431 - val_accuracy: 0.3141

Epoch 00005: val_loss improved from 3.21271 to 2.74313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 6/100
83/83 [==============================] - 6s 68ms/step - loss: 2.5899 - accuracy: 0.3063 - val_loss: 2.4179 - val_accuracy: 0.3168

Epoch 00006: val_loss improved from 2.74313 to 2.41794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 7/100
83/83 [==============================] - 6s 69ms/step - loss: 2.3134 - accuracy: 0.3096 - val_loss: 2.1902 - val_accuracy: 0.3176

Epoch 00007: val_loss improved from 2.41794 to 2.19022, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1177 - accuracy: 0.3121 - val_loss: 2.0250 - val_accuracy: 0.3199

Epoch 00008: val_loss improved from 2.19022 to 2.02498, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9754 - accuracy: 0.3148 - val_loss: 1.9088 - val_accuracy: 0.3262

Epoch 00009: val_loss improved from 2.02498 to 1.90876, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8763 - accuracy: 0.3199 - val_loss: 1.8276 - val_accuracy: 0.3240

Epoch 00010: val_loss improved from 1.90876 to 1.82761, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 11/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8046 - accuracy: 0.3206 - val_loss: 1.7690 - val_accuracy: 0.3255

Epoch 00011: val_loss improved from 1.82761 to 1.76898, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7541 - accuracy: 0.3215 - val_loss: 1.7300 - val_accuracy: 0.3232

Epoch 00012: val_loss improved from 1.76898 to 1.73001, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7188 - accuracy: 0.3253 - val_loss: 1.7012 - val_accuracy: 0.3254

Epoch 00013: val_loss improved from 1.73001 to 1.70117, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6937 - accuracy: 0.3255 - val_loss: 1.6816 - val_accuracy: 0.3245

Epoch 00014: val_loss improved from 1.70117 to 1.68162, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6728 - accuracy: 0.3277 - val_loss: 1.6675 - val_accuracy: 0.3258

Epoch 00015: val_loss improved from 1.68162 to 1.66754, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6583 - accuracy: 0.3318 - val_loss: 1.6575 - val_accuracy: 0.3258

Epoch 00016: val_loss improved from 1.66754 to 1.65751, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 17/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6498 - accuracy: 0.3321 - val_loss: 1.6515 - val_accuracy: 0.3277

Epoch 00017: val_loss improved from 1.65751 to 1.65154, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6418 - accuracy: 0.3332 - val_loss: 1.6463 - val_accuracy: 0.3277

Epoch 00018: val_loss improved from 1.65154 to 1.64629, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6348 - accuracy: 0.3393 - val_loss: 1.6437 - val_accuracy: 0.3295

Epoch 00019: val_loss improved from 1.64629 to 1.64369, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6313 - accuracy: 0.3371 - val_loss: 1.6421 - val_accuracy: 0.3313

Epoch 00020: val_loss improved from 1.64369 to 1.64211, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6269 - accuracy: 0.3402 - val_loss: 1.6399 - val_accuracy: 0.3313

Epoch 00021: val_loss improved from 1.64211 to 1.63994, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6226 - accuracy: 0.3439 - val_loss: 1.6398 - val_accuracy: 0.3321

Epoch 00022: val_loss improved from 1.63994 to 1.63978, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/8
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6206 - accuracy: 0.3441 - val_loss: 1.6403 - val_accuracy: 0.3316

Epoch 00023: val_loss did not improve from 1.63978
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6187 - accuracy: 0.3454 - val_loss: 1.6402 - val_accuracy: 0.3341

Epoch 00024: val_loss did not improve from 1.63978
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6149 - accuracy: 0.3505 - val_loss: 1.6445 - val_accuracy: 0.3290

Epoch 00025: val_loss did not improve from 1.63978
Epoch 26/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6133 - accuracy: 0.3520 - val_loss: 1.6463 - val_accuracy: 0.3301

Epoch 00026: val_loss did not improve from 1.63978
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6101 - accuracy: 0.3546 - val_loss: 1.6512 - val_accuracy: 0.3307

Epoch 00027: val_loss did not improve from 1.63978
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6080 - accuracy: 0.3566 - val_loss: 1.6523 - val_accuracy: 0.3315

Epoch 00028: val_loss did not improve from 1.63978
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6081 - accuracy: 0.3602 - val_loss: 1.6599 - val_accuracy: 0.3313

Epoch 00029: val_loss did not improve from 1.63978
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6053 - accuracy: 0.3635 - val_loss: 1.6631 - val_accuracy: 0.3289

Epoch 00030: val_loss did not improve from 1.63978
Epoch 31/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6033 - accuracy: 0.3663 - val_loss: 1.6679 - val_accuracy: 0.3297

Epoch 00031: val_loss did not improve from 1.63978
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 61s 5ms/step - loss: 1.6466 - accuracy: 0.3357
Testing Loss = 1.646579, Testing Accuracy = 0.335665
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 6s 70ms/step - loss: 12.2656 - accuracy: 0.2218 - val_loss: 8.5469 - val_accuracy: 0.2417

Epoch 00001: val_loss improved from inf to 8.54694, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.6864 - accuracy: 0.2719 - val_loss: 5.3456 - val_accuracy: 0.2950

Epoch 00002: val_loss improved from 8.54694 to 5.34558, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 3/100
83/83 [==============================] - 6s 68ms/step - loss: 4.5862 - accuracy: 0.2880 - val_loss: 3.9844 - val_accuracy: 0.3055

Epoch 00003: val_loss improved from 5.34558 to 3.98436, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 4/100
83/83 [==============================] - 6s 68ms/step - loss: 3.5941 - accuracy: 0.2953 - val_loss: 3.2434 - val_accuracy: 0.3066

Epoch 00004: val_loss improved from 3.98436 to 3.24343, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 5/100
83/83 [==============================] - 6s 69ms/step - loss: 3.0057 - accuracy: 0.3027 - val_loss: 2.7656 - val_accuracy: 0.3148

Epoch 00005: val_loss improved from 3.24343 to 2.76560, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 6/100
83/83 [==============================] - 6s 69ms/step - loss: 2.6091 - accuracy: 0.3087 - val_loss: 2.4374 - val_accuracy: 0.3182

Epoch 00006: val_loss improved from 2.76560 to 2.43744, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3309 - accuracy: 0.3119 - val_loss: 2.2046 - val_accuracy: 0.3186

Epoch 00007: val_loss improved from 2.43744 to 2.20460, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 8/100
83/83 [==============================] - 6s 68ms/step - loss: 2.1311 - accuracy: 0.3143 - val_loss: 2.0394 - val_accuracy: 0.3213

Epoch 00008: val_loss improved from 2.20460 to 2.03945, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 9/100
83/83 [==============================] - 6s 69ms/step - loss: 1.9879 - accuracy: 0.3160 - val_loss: 1.9208 - val_accuracy: 0.3198

Epoch 00009: val_loss improved from 2.03945 to 1.92079, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 10/100
83/83 [==============================] - 6s 69ms/step - loss: 1.8862 - accuracy: 0.3197 - val_loss: 1.8390 - val_accuracy: 0.3200

Epoch 00010: val_loss improved from 1.92079 to 1.83903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 11/100
83/83 [==============================] - 6s 68ms/step - loss: 1.8140 - accuracy: 0.3197 - val_loss: 1.7779 - val_accuracy: 0.3240

Epoch 00011: val_loss improved from 1.83903 to 1.77791, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 12/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7610 - accuracy: 0.3221 - val_loss: 1.7369 - val_accuracy: 0.3256

Epoch 00012: val_loss improved from 1.77791 to 1.73691, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 13/100
83/83 [==============================] - 6s 69ms/step - loss: 1.7234 - accuracy: 0.3262 - val_loss: 1.7071 - val_accuracy: 0.3255

Epoch 00013: val_loss improved from 1.73691 to 1.70712, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 14/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6977 - accuracy: 0.3284 - val_loss: 1.6879 - val_accuracy: 0.3255

Epoch 00014: val_loss improved from 1.70712 to 1.68785, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 15/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6775 - accuracy: 0.3324 - val_loss: 1.6726 - val_accuracy: 0.3290

Epoch 00015: val_loss improved from 1.68785 to 1.67261, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 16/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6632 - accuracy: 0.3327 - val_loss: 1.6630 - val_accuracy: 0.3297

Epoch 00016: val_loss improved from 1.67261 to 1.66298, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 17/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6535 - accuracy: 0.3345 - val_loss: 1.6558 - val_accuracy: 0.3275

Epoch 00017: val_loss improved from 1.66298 to 1.65580, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 18/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6446 - accuracy: 0.3355 - val_loss: 1.6495 - val_accuracy: 0.3270

Epoch 00018: val_loss improved from 1.65580 to 1.64950, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 19/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6388 - accuracy: 0.3383 - val_loss: 1.6471 - val_accuracy: 0.3268

Epoch 00019: val_loss improved from 1.64950 to 1.64708, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 20/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6334 - accuracy: 0.3397 - val_loss: 1.6432 - val_accuracy: 0.3296

Epoch 00020: val_loss improved from 1.64708 to 1.64322, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 21/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6281 - accuracy: 0.3429 - val_loss: 1.6427 - val_accuracy: 0.3348

Epoch 00021: val_loss improved from 1.64322 to 1.64270, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.15_r12/Try/9
Epoch 22/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6241 - accuracy: 0.3472 - val_loss: 1.6440 - val_accuracy: 0.3302

Epoch 00022: val_loss did not improve from 1.64270
Epoch 23/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6200 - accuracy: 0.3481 - val_loss: 1.6453 - val_accuracy: 0.3280

Epoch 00023: val_loss did not improve from 1.64270
Epoch 24/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6188 - accuracy: 0.3505 - val_loss: 1.6461 - val_accuracy: 0.3302

Epoch 00024: val_loss did not improve from 1.64270
Epoch 25/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6158 - accuracy: 0.3532 - val_loss: 1.6496 - val_accuracy: 0.3345

Epoch 00025: val_loss did not improve from 1.64270
Epoch 26/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6146 - accuracy: 0.3560 - val_loss: 1.6520 - val_accuracy: 0.3331

Epoch 00026: val_loss did not improve from 1.64270
Epoch 27/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6121 - accuracy: 0.3579 - val_loss: 1.6566 - val_accuracy: 0.3338

Epoch 00027: val_loss did not improve from 1.64270
Epoch 28/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6075 - accuracy: 0.3625 - val_loss: 1.6630 - val_accuracy: 0.3309

Epoch 00028: val_loss did not improve from 1.64270
Epoch 29/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6086 - accuracy: 0.3646 - val_loss: 1.6666 - val_accuracy: 0.3292

Epoch 00029: val_loss did not improve from 1.64270
Epoch 30/100
83/83 [==============================] - 6s 69ms/step - loss: 1.6052 - accuracy: 0.3674 - val_loss: 1.6765 - val_accuracy: 0.3267

Epoch 00030: val_loss did not improve from 1.64270
Epoch 31/100
83/83 [==============================] - 6s 70ms/step - loss: 1.6035 - accuracy: 0.3726 - val_loss: 1.6829 - val_accuracy: 0.3250

Epoch 00031: val_loss did not improve from 1.64270
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 62s 5ms/step - loss: 1.6515 - accuracy: 0.3304
Testing Loss = 1.651468, Testing Accuracy = 0.330381
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 80.78 +- 0.0606 %)
$W^-/W^-$ (auc = 79.90 +- 0.0934 %)
$Z/Z$ (auc = 63.91 +- 0.1393 %)
$W^+/W^-$ (auc = 64.29 +- 0.1217 %)
$W^+/Z$$ (auc = 64.65 +- 0.0465 %)
$W^-/Z$ (auc = 66.78 +- 0.0653 %)
The summarized testing accuracy = 33.19 +- 0.1642 %, with the loss = 1.6496 +- 0.002050
