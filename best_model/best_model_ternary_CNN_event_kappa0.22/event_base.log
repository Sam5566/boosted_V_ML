

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-12-17 01:13:33.265109
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
 - accuracy: 0.1965     83/Unknown - 491s 6s/step - loss: 12.5394 - accuracy: 0.1966
Epoch 1: val_loss improved from inf to 8.83339, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 565s 7s/step - loss: 12.5394 - accuracy: 0.1966 - val_loss: 8.8334 - val_accuracy: 0.2145
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.8808 - accuracy: 0.2070
Epoch 2: val_loss improved from 8.83339 to 5.41865, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 507s 6s/step - loss: 6.8808 - accuracy: 0.2070 - val_loss: 5.4187 - val_accuracy: 0.2187
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.6314 - accuracy: 0.2136
Epoch 3: val_loss improved from 5.41865 to 4.00082, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 503s 6s/step - loss: 4.6314 - accuracy: 0.2136 - val_loss: 4.0008 - val_accuracy: 0.2195
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.5339 - accuracy: 0.2620
Epoch 4: val_loss improved from 4.00082 to 3.20900, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 504s 6s/step - loss: 3.5339 - accuracy: 0.2620 - val_loss: 3.2090 - val_accuracy: 0.2635
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8918 - accuracy: 0.2950
Epoch 5: val_loss improved from 3.20900 to 2.70537, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 501s 6s/step - loss: 2.8918 - accuracy: 0.2950 - val_loss: 2.7054 - val_accuracy: 0.3016
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5019 - accuracy: 0.3075
Epoch 6: val_loss improved from 2.70537 to 2.36834, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 504s 6s/step - loss: 2.5019 - accuracy: 0.3075 - val_loss: 2.3683 - val_accuracy: 0.3154
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2339 - accuracy: 0.3146
Epoch 7: val_loss improved from 2.36834 to 2.12762, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 506s 6s/step - loss: 2.2339 - accuracy: 0.3146 - val_loss: 2.1276 - val_accuracy: 0.3287
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0454 - accuracy: 0.3231
Epoch 8: val_loss improved from 2.12762 to 1.96668, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 499s 6s/step - loss: 2.0454 - accuracy: 0.3231 - val_loss: 1.9667 - val_accuracy: 0.3359
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9155 - accuracy: 0.3283
Epoch 9: val_loss improved from 1.96668 to 1.85115, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 506s 6s/step - loss: 1.9155 - accuracy: 0.3283 - val_loss: 1.8511 - val_accuracy: 0.3448
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8217 - accuracy: 0.3370
Epoch 10: val_loss improved from 1.85115 to 1.77366, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 503s 6s/step - loss: 1.8217 - accuracy: 0.3370 - val_loss: 1.7737 - val_accuracy: 0.3513
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7515 - accuracy: 0.3438
Epoch 11: val_loss improved from 1.77366 to 1.71920, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 497s 6s/step - loss: 1.7515 - accuracy: 0.3438 - val_loss: 1.7192 - val_accuracy: 0.3557
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7048 - accuracy: 0.3519
Epoch 12: val_loss improved from 1.71920 to 1.68095, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 496s 6s/step - loss: 1.7048 - accuracy: 0.3519 - val_loss: 1.6810 - val_accuracy: 0.3580
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6643 - accuracy: 0.3617
Epoch 13: val_loss improved from 1.68095 to 1.64534, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 493s 6s/step - loss: 1.6643 - accuracy: 0.3617 - val_loss: 1.6453 - val_accuracy: 0.3642
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6331 - accuracy: 0.3692
Epoch 14: val_loss improved from 1.64534 to 1.62381, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 486s 6s/step - loss: 1.6331 - accuracy: 0.3692 - val_loss: 1.6238 - val_accuracy: 0.3712
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6106 - accuracy: 0.3802
Epoch 15: val_loss improved from 1.62381 to 1.61055, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 482s 6s/step - loss: 1.6106 - accuracy: 0.3802 - val_loss: 1.6105 - val_accuracy: 0.3738
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5930 - accuracy: 0.3824
Epoch 16: val_loss improved from 1.61055 to 1.60589, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 480s 6s/step - loss: 1.5930 - accuracy: 0.3824 - val_loss: 1.6059 - val_accuracy: 0.3706
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5776 - accuracy: 0.3902
Epoch 17: val_loss improved from 1.60589 to 1.59389, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 437s 5s/step - loss: 1.5776 - accuracy: 0.3902 - val_loss: 1.5939 - val_accuracy: 0.3808
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5662 - accuracy: 0.3977
Epoch 18: val_loss improved from 1.59389 to 1.58570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 424s 5s/step - loss: 1.5662 - accuracy: 0.3977 - val_loss: 1.5857 - val_accuracy: 0.3827
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5534 - accuracy: 0.4042
Epoch 19: val_loss improved from 1.58570 to 1.57742, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 359s 4s/step - loss: 1.5534 - accuracy: 0.4042 - val_loss: 1.5774 - val_accuracy: 0.3911
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5458 - accuracy: 0.4099
Epoch 20: val_loss did not improve from 1.57742
83/83 [==============================] - 281s 3s/step - loss: 1.5458 - accuracy: 0.4099 - val_loss: 1.5901 - val_accuracy: 0.3795
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5345 - accuracy: 0.4134
Epoch 21: val_loss improved from 1.57742 to 1.57149, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 259s 3s/step - loss: 1.5345 - accuracy: 0.4134 - val_loss: 1.5715 - val_accuracy: 0.3922
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5258 - accuracy: 0.4171
Epoch 22: val_loss did not improve from 1.57149
83/83 [==============================] - 166s 2s/step - loss: 1.5258 - accuracy: 0.4171 - val_loss: 1.5757 - val_accuracy: 0.3910
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5189 - accuracy: 0.4223
Epoch 23: val_loss did not improve from 1.57149
83/83 [==============================] - 106s 1s/step - loss: 1.5189 - accuracy: 0.4223 - val_loss: 1.5716 - val_accuracy: 0.3943
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5114 - accuracy: 0.4273
Epoch 24: val_loss improved from 1.57149 to 1.57034, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/0
83/83 [==============================] - 109s 1s/step - loss: 1.5114 - accuracy: 0.4273 - val_loss: 1.5703 - val_accuracy: 0.3937
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5075 - accuracy: 0.4299
Epoch 25: val_loss did not improve from 1.57034
83/83 [==============================] - 106s 1s/step - loss: 1.5075 - accuracy: 0.4299 - val_loss: 1.5865 - val_accuracy: 0.3864
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.5024 - accuracy: 0.4329
Epoch 26: val_loss did not improve from 1.57034
83/83 [==============================] - 106s 1s/step - loss: 1.5024 - accuracy: 0.4329 - val_loss: 1.5962 - val_accuracy: 0.3801
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4987 - accuracy: 0.4365
Epoch 27: val_loss did not improve from 1.57034
83/83 [==============================] - 107s 1s/step - loss: 1.4987 - accuracy: 0.4365 - val_loss: 1.5996 - val_accuracy: 0.3794
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4931 - accuracy: 0.4423
Epoch 28: val_loss did not improve from 1.57034
83/83 [==============================] - 104s 1s/step - loss: 1.4931 - accuracy: 0.4423 - val_loss: 1.6042 - val_accuracy: 0.3812
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4880 - accuracy: 0.4426
Epoch 29: val_loss did not improve from 1.57034
83/83 [==============================] - 105s 1s/step - loss: 1.4880 - accuracy: 0.4426 - val_loss: 1.5842 - val_accuracy: 0.3924
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4810 - accuracy: 0.4474
Epoch 30: val_loss did not improve from 1.57034
83/83 [==============================] - 102s 1s/step - loss: 1.4810 - accuracy: 0.4474 - val_loss: 1.5845 - val_accuracy: 0.3950
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4645 - accuracy: 0.4589
Epoch 31: val_loss did not improve from 1.57034
83/83 [==============================] - 102s 1s/step - loss: 1.4645 - accuracy: 0.4589 - val_loss: 1.6248 - val_accuracy: 0.3794
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4544 - accuracy: 0.4658
Epoch 32: val_loss did not improve from 1.57034
83/83 [==============================] - 103s 1s/step - loss: 1.4544 - accuracy: 0.4658 - val_loss: 1.6154 - val_accuracy: 0.3859
Epoch 33/100
83/83 [==============================] - ETA: 0s - loss: 1.4475 - accuracy: 0.4726
Epoch 33: val_loss did not improve from 1.57034
83/83 [==============================] - 114s 1s/step - loss: 1.4475 - accuracy: 0.4726 - val_loss: 1.6312 - val_accuracy: 0.3822
Epoch 34/100
83/83 [==============================] - ETA: 0s - loss: 1.4404 - accuracy: 0.4777
Epoch 34: val_loss did not improve from 1.57034
83/83 [==============================] - 116s 1s/step - loss: 1.4404 - accuracy: 0.4777 - val_loss: 1.6538 - val_accuracy: 0.3745
Epoch 34: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential (Sequential)     (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_2 (Dense)             multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda (Lambda)             (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization (BatchN  (None, 75, 75, 2)        8         [0m
[94m ormalization)                                                   [0m
[94m                                                                 [0m
[94m conv2d (Conv2D)             (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d (MaxPooling2D  (None, 37, 37, 32)       0         [0m
[94m )                                                               [0m
[94m                                                                 [0m
[94m conv2d_1 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_1 (MaxPooling  (None, 18, 18, 128)      0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_2 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_2 (MaxPooling  (None, 9, 9, 256)        0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m dropout (Dropout)           (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten (Flatten)           (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense (Dense)               (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_1 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_1 (Dense)             (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_2 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 158s 11ms/step - loss: 1.5786 - accuracy: 0.3980
Testing Loss = 1.578568, Testing Accuracy = 0.398035
The data set contains images
  13431/Unknown - 122s 9ms/step13437/13437 [==============================] - 122s 9ms/step
[[0.14135950803756714, 0.1097199022769928, 0.06206793338060379, 0.35367870330810547, 0.1833926886320114, 0.1497812420129776], [0.03274719789624214, 0.13064783811569214, 0.30447879433631897, 0.08443967252969742, 0.15192991495132446, 0.29575663805007935], [0.12370488792657852, 0.076483353972435, 0.15056157112121582, 0.2069690227508545, 0.270142138004303, 0.17213907837867737], [0.04968685656785965, 0.05462844297289848, 0.36715927720069885, 0.0689057782292366, 0.25052911043167114, 0.2090904712677002], [0.08801295608282089, 0.25360071659088135, 0.04848795011639595, 0.31800493597984314, 0.10326457023620605, 0.1886288821697235], [0.5810681581497192, 0.007796887774020433, 0.04853758588433266, 0.08248966932296753, 0.25181546807289124, 0.0282922200858593], [0.02017628774046898, 0.026176737621426582, 0.5745067596435547, 0.03138235956430435, 0.17257587611675262, 0.17518183588981628], [0.18689598143100739, 0.05521963909268379, 0.03440265357494354, 0.444320946931839, 0.1805223524570465, 0.09863842278718948], [0.30984073877334595, 0.09393052756786346, 0.05471358820796013, 0.26992371678352356, 0.1713504195213318, 0.10024099797010422], [0.19678674638271332, 0.06620509177446365, 0.15696556866168976, 0.16237914562225342, 0.2751120626926422, 0.14255137741565704]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
 - accuracy: 0.2010     83/Unknown - 109s 1s/step - loss: 12.4535 - accuracy: 0.2010
Epoch 1: val_loss improved from inf to 8.73699, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 118s 1s/step - loss: 12.4535 - accuracy: 0.2010 - val_loss: 8.7370 - val_accuracy: 0.2164
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.8076 - accuracy: 0.2068
Epoch 2: val_loss improved from 8.73699 to 5.36906, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 104s 1s/step - loss: 6.8076 - accuracy: 0.2068 - val_loss: 5.3691 - val_accuracy: 0.2158
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5567 - accuracy: 0.2406
Epoch 3: val_loss improved from 5.36906 to 3.94841, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 98s 1s/step - loss: 4.5567 - accuracy: 0.2406 - val_loss: 3.9484 - val_accuracy: 0.2544
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4777 - accuracy: 0.2897
Epoch 4: val_loss improved from 3.94841 to 3.19871, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 100s 1s/step - loss: 3.4777 - accuracy: 0.2897 - val_loss: 3.1987 - val_accuracy: 0.2742
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8908 - accuracy: 0.3009
Epoch 5: val_loss improved from 3.19871 to 2.71248, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 99s 1s/step - loss: 2.8908 - accuracy: 0.3009 - val_loss: 2.7125 - val_accuracy: 0.3047
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5103 - accuracy: 0.3070
Epoch 6: val_loss improved from 2.71248 to 2.37246, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 99s 1s/step - loss: 2.5103 - accuracy: 0.3070 - val_loss: 2.3725 - val_accuracy: 0.3250
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2437 - accuracy: 0.3181
Epoch 7: val_loss improved from 2.37246 to 2.13679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 99s 1s/step - loss: 2.2437 - accuracy: 0.3181 - val_loss: 2.1368 - val_accuracy: 0.3311
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0527 - accuracy: 0.3235
Epoch 8: val_loss improved from 2.13679 to 1.97615, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 98s 1s/step - loss: 2.0527 - accuracy: 0.3235 - val_loss: 1.9762 - val_accuracy: 0.3386
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9227 - accuracy: 0.3302
Epoch 9: val_loss improved from 1.97615 to 1.86114, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 100s 1s/step - loss: 1.9227 - accuracy: 0.3302 - val_loss: 1.8611 - val_accuracy: 0.3446
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8265 - accuracy: 0.3389
Epoch 10: val_loss improved from 1.86114 to 1.78075, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 100s 1s/step - loss: 1.8265 - accuracy: 0.3389 - val_loss: 1.7808 - val_accuracy: 0.3514
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7571 - accuracy: 0.3450
Epoch 11: val_loss improved from 1.78075 to 1.72488, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 103s 1s/step - loss: 1.7571 - accuracy: 0.3450 - val_loss: 1.7249 - val_accuracy: 0.3552
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7081 - accuracy: 0.3514
Epoch 12: val_loss improved from 1.72488 to 1.68193, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 106s 1s/step - loss: 1.7081 - accuracy: 0.3514 - val_loss: 1.6819 - val_accuracy: 0.3603
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6704 - accuracy: 0.3592
Epoch 13: val_loss improved from 1.68193 to 1.65578, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 102s 1s/step - loss: 1.6704 - accuracy: 0.3592 - val_loss: 1.6558 - val_accuracy: 0.3643
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6392 - accuracy: 0.3697
Epoch 14: val_loss improved from 1.65578 to 1.62830, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 104s 1s/step - loss: 1.6392 - accuracy: 0.3697 - val_loss: 1.6283 - val_accuracy: 0.3783
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6128 - accuracy: 0.3779
Epoch 15: val_loss improved from 1.62830 to 1.60622, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 102s 1s/step - loss: 1.6128 - accuracy: 0.3779 - val_loss: 1.6062 - val_accuracy: 0.3812
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5940 - accuracy: 0.3872
Epoch 16: val_loss improved from 1.60622 to 1.60403, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 103s 1s/step - loss: 1.5940 - accuracy: 0.3872 - val_loss: 1.6040 - val_accuracy: 0.3805
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5793 - accuracy: 0.3926
Epoch 17: val_loss improved from 1.60403 to 1.59470, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 101s 1s/step - loss: 1.5793 - accuracy: 0.3926 - val_loss: 1.5947 - val_accuracy: 0.3822
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5655 - accuracy: 0.4008
Epoch 18: val_loss improved from 1.59470 to 1.58800, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 105s 1s/step - loss: 1.5655 - accuracy: 0.4008 - val_loss: 1.5880 - val_accuracy: 0.3832
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5535 - accuracy: 0.4053
Epoch 19: val_loss did not improve from 1.58800
83/83 [==============================] - 99s 1s/step - loss: 1.5535 - accuracy: 0.4053 - val_loss: 1.5932 - val_accuracy: 0.3793
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5433 - accuracy: 0.4092
Epoch 20: val_loss improved from 1.58800 to 1.58175, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 102s 1s/step - loss: 1.5433 - accuracy: 0.4092 - val_loss: 1.5818 - val_accuracy: 0.3868
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5347 - accuracy: 0.4159
Epoch 21: val_loss did not improve from 1.58175
83/83 [==============================] - 100s 1s/step - loss: 1.5347 - accuracy: 0.4159 - val_loss: 1.5843 - val_accuracy: 0.3846
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5229 - accuracy: 0.4219
Epoch 22: val_loss improved from 1.58175 to 1.57545, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/1
83/83 [==============================] - 103s 1s/step - loss: 1.5229 - accuracy: 0.4219 - val_loss: 1.5754 - val_accuracy: 0.3915
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5175 - accuracy: 0.4277
Epoch 23: val_loss did not improve from 1.57545
83/83 [==============================] - 100s 1s/step - loss: 1.5175 - accuracy: 0.4277 - val_loss: 1.5791 - val_accuracy: 0.3881
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5098 - accuracy: 0.4313
Epoch 24: val_loss did not improve from 1.57545
83/83 [==============================] - 100s 1s/step - loss: 1.5098 - accuracy: 0.4313 - val_loss: 1.5850 - val_accuracy: 0.3890
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5040 - accuracy: 0.4348
Epoch 25: val_loss did not improve from 1.57545
83/83 [==============================] - 99s 1s/step - loss: 1.5040 - accuracy: 0.4348 - val_loss: 1.5832 - val_accuracy: 0.3920
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.4924 - accuracy: 0.4439
Epoch 26: val_loss did not improve from 1.57545
83/83 [==============================] - 100s 1s/step - loss: 1.4924 - accuracy: 0.4439 - val_loss: 1.5818 - val_accuracy: 0.3985
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4844 - accuracy: 0.4462
Epoch 27: val_loss did not improve from 1.57545
83/83 [==============================] - 100s 1s/step - loss: 1.4844 - accuracy: 0.4462 - val_loss: 1.5888 - val_accuracy: 0.3930
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4778 - accuracy: 0.4532
Epoch 28: val_loss did not improve from 1.57545
83/83 [==============================] - 99s 1s/step - loss: 1.4778 - accuracy: 0.4532 - val_loss: 1.5912 - val_accuracy: 0.3976
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4709 - accuracy: 0.4604
Epoch 29: val_loss did not improve from 1.57545
83/83 [==============================] - 99s 1s/step - loss: 1.4709 - accuracy: 0.4604 - val_loss: 1.6006 - val_accuracy: 0.3931
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4592 - accuracy: 0.4660
Epoch 30: val_loss did not improve from 1.57545
83/83 [==============================] - 105s 1s/step - loss: 1.4592 - accuracy: 0.4660 - val_loss: 1.6133 - val_accuracy: 0.3904
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4527 - accuracy: 0.4755
Epoch 31: val_loss did not improve from 1.57545
83/83 [==============================] - 99s 1s/step - loss: 1.4527 - accuracy: 0.4755 - val_loss: 1.6289 - val_accuracy: 0.3868
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4391 - accuracy: 0.4832
Epoch 32: val_loss did not improve from 1.57545
83/83 [==============================] - 100s 1s/step - loss: 1.4391 - accuracy: 0.4832 - val_loss: 1.6333 - val_accuracy: 0.3912
Epoch 32: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_1 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_5 (Dense)             multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_1 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_1 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_3 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_3 (MaxPooling  (None, 37, 37, 32)       0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_4 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_4 (MaxPooling  (None, 18, 18, 128)      0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_5 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_5 (MaxPooling  (None, 9, 9, 256)        0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m dropout_3 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_1 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_3 (Dense)             (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_4 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_4 (Dense)             (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_5 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 153s 11ms/step - loss: 1.5818 - accuracy: 0.3951
Testing Loss = 1.581758, Testing Accuracy = 0.395132
The data set contains images
  13431/Unknown - 120s 9ms/step13437/13437 [==============================] - 120s 9ms/step
[[0.1603090912103653, 0.11946429312229156, 0.05795912817120552, 0.360736221075058, 0.16345734894275665, 0.1380738914012909], [0.021037233993411064, 0.11062909662723541, 0.3897237181663513, 0.05906030535697937, 0.12183384597301483, 0.2977158725261688], [0.15221188962459564, 0.1089576855301857, 0.09683164954185486, 0.276523619890213, 0.20810051262378693, 0.15737468004226685], [0.0576150119304657, 0.0648682564496994, 0.3594602048397064, 0.07092582434415817, 0.23144075274467468, 0.21568997204303741], [0.12650655210018158, 0.22836308181285858, 0.04583839699625969, 0.33778685331344604, 0.11143208295106888, 0.1500730663537979], [0.5464404821395874, 0.008728866465389729, 0.07144464552402496, 0.07661300152540207, 0.263685941696167, 0.03308713063597679], [0.027721673250198364, 0.030096247792243958, 0.55024254322052, 0.039476048201322556, 0.17413152754306793, 0.1783318966627121], [0.1495644599199295, 0.07132646441459656, 0.04504578560590744, 0.44958919286727905, 0.16802480816841125, 0.11644919216632843], [0.332461416721344, 0.09211341291666031, 0.05913126841187477, 0.25721901655197144, 0.16736741364002228, 0.0917074903845787], [0.16316892206668854, 0.07169289141893387, 0.16992183029651642, 0.1774449348449707, 0.26106852293014526, 0.156702920794487]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
42 - accuracy: 0.1955     83/Unknown - 99s 1s/step - loss: 12.5196 - accuracy: 0.1954
Epoch 1: val_loss improved from inf to 8.79869, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 108s 1s/step - loss: 12.5196 - accuracy: 0.1954 - val_loss: 8.7987 - val_accuracy: 0.2142
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.8576 - accuracy: 0.2083
Epoch 2: val_loss improved from 8.79869 to 5.40773, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 105s 1s/step - loss: 6.8576 - accuracy: 0.2083 - val_loss: 5.4077 - val_accuracy: 0.2171
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.6164 - accuracy: 0.2236
Epoch 3: val_loss improved from 5.40773 to 3.98633, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 101s 1s/step - loss: 4.6164 - accuracy: 0.2236 - val_loss: 3.9863 - val_accuracy: 0.2420
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4985 - accuracy: 0.2855
Epoch 4: val_loss improved from 3.98633 to 3.21669, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 105s 1s/step - loss: 3.4985 - accuracy: 0.2855 - val_loss: 3.2167 - val_accuracy: 0.2668
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.9012 - accuracy: 0.2977
Epoch 5: val_loss improved from 3.21669 to 2.71803, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 103s 1s/step - loss: 2.9012 - accuracy: 0.2977 - val_loss: 2.7180 - val_accuracy: 0.2984
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5110 - accuracy: 0.3102
Epoch 6: val_loss improved from 2.71803 to 2.37622, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 103s 1s/step - loss: 2.5110 - accuracy: 0.3102 - val_loss: 2.3762 - val_accuracy: 0.3233
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2433 - accuracy: 0.3181
Epoch 7: val_loss improved from 2.37622 to 2.13467, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 102s 1s/step - loss: 2.2433 - accuracy: 0.3181 - val_loss: 2.1347 - val_accuracy: 0.3352
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0539 - accuracy: 0.3246
Epoch 8: val_loss improved from 2.13467 to 1.96983, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 102s 1s/step - loss: 2.0539 - accuracy: 0.3246 - val_loss: 1.9698 - val_accuracy: 0.3385
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9193 - accuracy: 0.3346
Epoch 9: val_loss improved from 1.96983 to 1.85568, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 102s 1s/step - loss: 1.9193 - accuracy: 0.3346 - val_loss: 1.8557 - val_accuracy: 0.3488
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8228 - accuracy: 0.3426
Epoch 10: val_loss improved from 1.85568 to 1.77449, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 105s 1s/step - loss: 1.8228 - accuracy: 0.3426 - val_loss: 1.7745 - val_accuracy: 0.3546
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7535 - accuracy: 0.3464
Epoch 11: val_loss improved from 1.77449 to 1.72297, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 102s 1s/step - loss: 1.7535 - accuracy: 0.3464 - val_loss: 1.7230 - val_accuracy: 0.3578
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7038 - accuracy: 0.3540
Epoch 12: val_loss improved from 1.72297 to 1.68237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 103s 1s/step - loss: 1.7038 - accuracy: 0.3540 - val_loss: 1.6824 - val_accuracy: 0.3604
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6637 - accuracy: 0.3630
Epoch 13: val_loss improved from 1.68237 to 1.64444, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 100s 1s/step - loss: 1.6637 - accuracy: 0.3630 - val_loss: 1.6444 - val_accuracy: 0.3717
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6311 - accuracy: 0.3759
Epoch 14: val_loss improved from 1.64444 to 1.62229, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 100s 1s/step - loss: 1.6311 - accuracy: 0.3759 - val_loss: 1.6223 - val_accuracy: 0.3762
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6114 - accuracy: 0.3799
Epoch 15: val_loss improved from 1.62229 to 1.60600, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 101s 1s/step - loss: 1.6114 - accuracy: 0.3799 - val_loss: 1.6060 - val_accuracy: 0.3792
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5904 - accuracy: 0.3883
Epoch 16: val_loss improved from 1.60600 to 1.59188, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 100s 1s/step - loss: 1.5904 - accuracy: 0.3883 - val_loss: 1.5919 - val_accuracy: 0.3874
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5763 - accuracy: 0.3898
Epoch 17: val_loss improved from 1.59188 to 1.58888, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 99s 1s/step - loss: 1.5763 - accuracy: 0.3898 - val_loss: 1.5889 - val_accuracy: 0.3841
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5650 - accuracy: 0.3986
Epoch 18: val_loss improved from 1.58888 to 1.57970, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 99s 1s/step - loss: 1.5650 - accuracy: 0.3986 - val_loss: 1.5797 - val_accuracy: 0.3868
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5537 - accuracy: 0.4046
Epoch 19: val_loss did not improve from 1.57970
83/83 [==============================] - 97s 1s/step - loss: 1.5537 - accuracy: 0.4046 - val_loss: 1.5849 - val_accuracy: 0.3844
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5448 - accuracy: 0.4071
Epoch 20: val_loss improved from 1.57970 to 1.57785, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 99s 1s/step - loss: 1.5448 - accuracy: 0.4071 - val_loss: 1.5779 - val_accuracy: 0.3897
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5372 - accuracy: 0.4106
Epoch 21: val_loss did not improve from 1.57785
83/83 [==============================] - 97s 1s/step - loss: 1.5372 - accuracy: 0.4106 - val_loss: 1.5866 - val_accuracy: 0.3867
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5332 - accuracy: 0.4142
Epoch 22: val_loss improved from 1.57785 to 1.57068, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 100s 1s/step - loss: 1.5332 - accuracy: 0.4142 - val_loss: 1.5707 - val_accuracy: 0.3955
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5218 - accuracy: 0.4184
Epoch 23: val_loss improved from 1.57068 to 1.56990, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 100s 1s/step - loss: 1.5218 - accuracy: 0.4184 - val_loss: 1.5699 - val_accuracy: 0.3972
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5158 - accuracy: 0.4250
Epoch 24: val_loss did not improve from 1.56990
83/83 [==============================] - 98s 1s/step - loss: 1.5158 - accuracy: 0.4250 - val_loss: 1.5791 - val_accuracy: 0.3905
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5107 - accuracy: 0.4299
Epoch 25: val_loss did not improve from 1.56990
83/83 [==============================] - 96s 1s/step - loss: 1.5107 - accuracy: 0.4299 - val_loss: 1.5732 - val_accuracy: 0.3959
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.5055 - accuracy: 0.4320
Epoch 26: val_loss did not improve from 1.56990
83/83 [==============================] - 97s 1s/step - loss: 1.5055 - accuracy: 0.4320 - val_loss: 1.5760 - val_accuracy: 0.3956
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4982 - accuracy: 0.4367
Epoch 27: val_loss improved from 1.56990 to 1.56856, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/2
83/83 [==============================] - 99s 1s/step - loss: 1.4982 - accuracy: 0.4367 - val_loss: 1.5686 - val_accuracy: 0.4015
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4900 - accuracy: 0.4412
Epoch 28: val_loss did not improve from 1.56856
83/83 [==============================] - 96s 1s/step - loss: 1.4900 - accuracy: 0.4412 - val_loss: 1.5803 - val_accuracy: 0.3948
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4819 - accuracy: 0.4481
Epoch 29: val_loss did not improve from 1.56856
83/83 [==============================] - 97s 1s/step - loss: 1.4819 - accuracy: 0.4481 - val_loss: 1.5809 - val_accuracy: 0.3986
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4793 - accuracy: 0.4509
Epoch 30: val_loss did not improve from 1.56856
83/83 [==============================] - 97s 1s/step - loss: 1.4793 - accuracy: 0.4509 - val_loss: 1.6016 - val_accuracy: 0.3888
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4808 - accuracy: 0.4509
Epoch 31: val_loss did not improve from 1.56856
83/83 [==============================] - 96s 1s/step - loss: 1.4808 - accuracy: 0.4509 - val_loss: 1.6038 - val_accuracy: 0.3872
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4744 - accuracy: 0.4564
Epoch 32: val_loss did not improve from 1.56856
83/83 [==============================] - 99s 1s/step - loss: 1.4744 - accuracy: 0.4564 - val_loss: 1.6016 - val_accuracy: 0.3892
Epoch 33/100
83/83 [==============================] - ETA: 0s - loss: 1.4689 - accuracy: 0.4577
Epoch 33: val_loss did not improve from 1.56856
83/83 [==============================] - 96s 1s/step - loss: 1.4689 - accuracy: 0.4577 - val_loss: 1.6104 - val_accuracy: 0.3891
Epoch 34/100
83/83 [==============================] - ETA: 0s - loss: 1.4630 - accuracy: 0.4623
Epoch 34: val_loss did not improve from 1.56856
83/83 [==============================] - 96s 1s/step - loss: 1.4630 - accuracy: 0.4623 - val_loss: 1.6095 - val_accuracy: 0.3915
Epoch 35/100
83/83 [==============================] - ETA: 0s - loss: 1.4561 - accuracy: 0.4688
Epoch 35: val_loss did not improve from 1.56856
83/83 [==============================] - 96s 1s/step - loss: 1.4561 - accuracy: 0.4688 - val_loss: 1.6101 - val_accuracy: 0.3935
Epoch 36/100
83/83 [==============================] - ETA: 0s - loss: 1.4385 - accuracy: 0.4787
Epoch 36: val_loss did not improve from 1.56856
83/83 [==============================] - 102s 1s/step - loss: 1.4385 - accuracy: 0.4787 - val_loss: 1.6242 - val_accuracy: 0.3926
Epoch 37/100
83/83 [==============================] - ETA: 0s - loss: 1.4280 - accuracy: 0.4890
Epoch 37: val_loss did not improve from 1.56856
83/83 [==============================] - 97s 1s/step - loss: 1.4280 - accuracy: 0.4890 - val_loss: 1.6687 - val_accuracy: 0.3789
Epoch 37: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_2 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_8 (Dense)             multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_2 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_2 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_6 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_6 (MaxPooling  (None, 37, 37, 32)       0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_7 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_7 (MaxPooling  (None, 18, 18, 128)      0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_8 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_8 (MaxPooling  (None, 9, 9, 256)        0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m dropout_6 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_2 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_6 (Dense)             (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_7 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_7 (Dense)             (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_8 (Dropout)         (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 141s 10ms/step - loss: 1.5793 - accuracy: 0.3957
Testing Loss = 1.579273, Testing Accuracy = 0.395653
The data set contains images
  13435/Unknown - 131s 10ms/step13437/13437 [==============================] - 131s 10ms/step
[[0.09679502248764038, 0.11572618037462234, 0.09812228381633759, 0.2875530421733856, 0.20234979689121246, 0.1994537115097046], [0.019670620560646057, 0.07107210159301758, 0.46532338857650757, 0.04616745561361313, 0.13918182253837585, 0.25858452916145325], [0.15587040781974792, 0.10322154313325882, 0.0976799800992012, 0.2519507110118866, 0.2390640377998352, 0.15221336483955383], [0.07491748780012131, 0.07536067813634872, 0.2840457856655121, 0.08707135915756226, 0.2675999104976654, 0.21100474894046783], [0.18765957653522491, 0.1640695333480835, 0.03501969203352928, 0.3644697964191437, 0.12276507169008255, 0.12601621448993683], [0.4776495695114136, 0.007366806268692017, 0.08518767356872559, 0.07044410705566406, 0.3234596252441406, 0.03589221462607384], [0.02150878496468067, 0.025900572538375854, 0.5656653642654419, 0.031843554228544235, 0.17693349719047546, 0.1781482696533203], [0.16181033849716187, 0.040804531425237656, 0.061199039220809937, 0.3753803074359894, 0.24493084847927094, 0.11587490141391754], [0.3917141556739807, 0.070954330265522, 0.04532847926020622, 0.2513798177242279, 0.16256240010261536, 0.07806079089641571], [0.17672500014305115, 0.05919024720788002, 0.17164376378059387, 0.1600313037633896, 0.289654403924942, 0.14275532960891724]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
60 - accuracy: 0.1967     83/Unknown - 94s 1s/step - loss: 12.4713 - accuracy: 0.1969
Epoch 1: val_loss improved from inf to 8.75052, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 106s 1s/step - loss: 12.4713 - accuracy: 0.1969 - val_loss: 8.7505 - val_accuracy: 0.2128
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.8129 - accuracy: 0.2086
Epoch 2: val_loss improved from 8.75052 to 5.37167, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 100s 1s/step - loss: 6.8129 - accuracy: 0.2086 - val_loss: 5.3717 - val_accuracy: 0.2187
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5342 - accuracy: 0.2542
Epoch 3: val_loss improved from 5.37167 to 3.95747, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 101s 1s/step - loss: 4.5342 - accuracy: 0.2542 - val_loss: 3.9575 - val_accuracy: 0.2522
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4799 - accuracy: 0.2898
Epoch 4: val_loss improved from 3.95747 to 3.20545, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 100s 1s/step - loss: 3.4799 - accuracy: 0.2898 - val_loss: 3.2054 - val_accuracy: 0.2741
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8964 - accuracy: 0.3045
Epoch 5: val_loss improved from 3.20545 to 2.71833, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 100s 1s/step - loss: 2.8964 - accuracy: 0.3045 - val_loss: 2.7183 - val_accuracy: 0.3044
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5153 - accuracy: 0.3095
Epoch 6: val_loss improved from 2.71833 to 2.37851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 110s 1s/step - loss: 2.5153 - accuracy: 0.3095 - val_loss: 2.3785 - val_accuracy: 0.3247
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2447 - accuracy: 0.3237
Epoch 7: val_loss improved from 2.37851 to 2.13925, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 105s 1s/step - loss: 2.2447 - accuracy: 0.3237 - val_loss: 2.1392 - val_accuracy: 0.3356
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0576 - accuracy: 0.3247
Epoch 8: val_loss improved from 2.13925 to 1.97554, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 105s 1s/step - loss: 2.0576 - accuracy: 0.3247 - val_loss: 1.9755 - val_accuracy: 0.3396
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9225 - accuracy: 0.3338
Epoch 9: val_loss improved from 1.97554 to 1.86088, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 104s 1s/step - loss: 1.9225 - accuracy: 0.3338 - val_loss: 1.8609 - val_accuracy: 0.3466
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8267 - accuracy: 0.3394
Epoch 10: val_loss improved from 1.86088 to 1.77896, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 104s 1s/step - loss: 1.8267 - accuracy: 0.3394 - val_loss: 1.7790 - val_accuracy: 0.3509
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7577 - accuracy: 0.3453
Epoch 11: val_loss improved from 1.77896 to 1.72508, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 102s 1s/step - loss: 1.7577 - accuracy: 0.3453 - val_loss: 1.7251 - val_accuracy: 0.3550
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7051 - accuracy: 0.3543
Epoch 12: val_loss improved from 1.72508 to 1.68287, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 102s 1s/step - loss: 1.7051 - accuracy: 0.3543 - val_loss: 1.6829 - val_accuracy: 0.3623
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6657 - accuracy: 0.3633
Epoch 13: val_loss improved from 1.68287 to 1.64458, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 103s 1s/step - loss: 1.6657 - accuracy: 0.3633 - val_loss: 1.6446 - val_accuracy: 0.3774
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6326 - accuracy: 0.3754
Epoch 14: val_loss improved from 1.64458 to 1.63430, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 108s 1s/step - loss: 1.6326 - accuracy: 0.3754 - val_loss: 1.6343 - val_accuracy: 0.3679
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6068 - accuracy: 0.3849
Epoch 15: val_loss improved from 1.63430 to 1.60722, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 111s 1s/step - loss: 1.6068 - accuracy: 0.3849 - val_loss: 1.6072 - val_accuracy: 0.3823
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5923 - accuracy: 0.3887
Epoch 16: val_loss improved from 1.60722 to 1.60125, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 111s 1s/step - loss: 1.5923 - accuracy: 0.3887 - val_loss: 1.6012 - val_accuracy: 0.3815
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5741 - accuracy: 0.3957
Epoch 17: val_loss improved from 1.60125 to 1.59041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 105s 1s/step - loss: 1.5741 - accuracy: 0.3957 - val_loss: 1.5904 - val_accuracy: 0.3846
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5616 - accuracy: 0.4005
Epoch 18: val_loss did not improve from 1.59041
83/83 [==============================] - 107s 1s/step - loss: 1.5616 - accuracy: 0.4005 - val_loss: 1.5913 - val_accuracy: 0.3843
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5497 - accuracy: 0.4052
Epoch 19: val_loss improved from 1.59041 to 1.58588, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 110s 1s/step - loss: 1.5497 - accuracy: 0.4052 - val_loss: 1.5859 - val_accuracy: 0.3855
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5402 - accuracy: 0.4118
Epoch 20: val_loss improved from 1.58588 to 1.58324, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 108s 1s/step - loss: 1.5402 - accuracy: 0.4118 - val_loss: 1.5832 - val_accuracy: 0.3883
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5334 - accuracy: 0.4145
Epoch 21: val_loss improved from 1.58324 to 1.57231, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/3
83/83 [==============================] - 105s 1s/step - loss: 1.5334 - accuracy: 0.4145 - val_loss: 1.5723 - val_accuracy: 0.3946
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5228 - accuracy: 0.4228
Epoch 22: val_loss did not improve from 1.57231
83/83 [==============================] - 106s 1s/step - loss: 1.5228 - accuracy: 0.4228 - val_loss: 1.5745 - val_accuracy: 0.3945
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5180 - accuracy: 0.4253
Epoch 23: val_loss did not improve from 1.57231
83/83 [==============================] - 99s 1s/step - loss: 1.5180 - accuracy: 0.4253 - val_loss: 1.5902 - val_accuracy: 0.3853
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5081 - accuracy: 0.4292
Epoch 24: val_loss did not improve from 1.57231
83/83 [==============================] - 98s 1s/step - loss: 1.5081 - accuracy: 0.4292 - val_loss: 1.5808 - val_accuracy: 0.3932
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5027 - accuracy: 0.4371
Epoch 25: val_loss did not improve from 1.57231
83/83 [==============================] - 99s 1s/step - loss: 1.5027 - accuracy: 0.4371 - val_loss: 1.5915 - val_accuracy: 0.3868
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.4949 - accuracy: 0.4409
Epoch 26: val_loss did not improve from 1.57231
83/83 [==============================] - 104s 1s/step - loss: 1.4949 - accuracy: 0.4409 - val_loss: 1.5833 - val_accuracy: 0.3950
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4838 - accuracy: 0.4478
Epoch 27: val_loss did not improve from 1.57231
83/83 [==============================] - 101s 1s/step - loss: 1.4838 - accuracy: 0.4478 - val_loss: 1.5845 - val_accuracy: 0.3966
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4815 - accuracy: 0.4517
Epoch 28: val_loss did not improve from 1.57231
83/83 [==============================] - 98s 1s/step - loss: 1.4815 - accuracy: 0.4517 - val_loss: 1.5887 - val_accuracy: 0.3920
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4731 - accuracy: 0.4569
Epoch 29: val_loss did not improve from 1.57231
83/83 [==============================] - 101s 1s/step - loss: 1.4731 - accuracy: 0.4569 - val_loss: 1.5961 - val_accuracy: 0.3915
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4626 - accuracy: 0.4634
Epoch 30: val_loss did not improve from 1.57231
83/83 [==============================] - 103s 1s/step - loss: 1.4626 - accuracy: 0.4634 - val_loss: 1.6031 - val_accuracy: 0.3947
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4592 - accuracy: 0.4679
Epoch 31: val_loss did not improve from 1.57231
83/83 [==============================] - 101s 1s/step - loss: 1.4592 - accuracy: 0.4679 - val_loss: 1.6082 - val_accuracy: 0.3931
Epoch 31: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_3 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_11 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_3 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_3 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_9 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_9 (MaxPooling  (None, 37, 37, 32)       0         [0m
[94m 2D)                                                             [0m
[94m                                                                 [0m
[94m conv2d_10 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_10 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_11 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_11 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_9 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_3 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_9 (Dense)             (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_10 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_10 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_11 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 160s 12ms/step - loss: 1.5782 - accuracy: 0.3951
Testing Loss = 1.578224, Testing Accuracy = 0.395132
The data set contains images
  13435/Unknown - 125s 9ms/step13437/13437 [==============================] - 125s 9ms/step
[[0.1595483422279358, 0.11650358140468597, 0.05396315082907677, 0.36496591567993164, 0.171287402510643, 0.13373161852359772], [0.05182814225554466, 0.13311100006103516, 0.2877828776836395, 0.09969127178192139, 0.1606092005968094, 0.2669775187969208], [0.19361644983291626, 0.06643699109554291, 0.10205080360174179, 0.25587454438209534, 0.25798189640045166, 0.12403932213783264], [0.05082804337143898, 0.042502447962760925, 0.4095534384250641, 0.05997705087065697, 0.24860645830631256, 0.18853257596492767], [0.1254248321056366, 0.2047705054283142, 0.039170000702142715, 0.3882766664028168, 0.10847588628530502, 0.13388216495513916], [0.6087583303451538, 0.005736283026635647, 0.044901832938194275, 0.0750274807214737, 0.24235768616199493, 0.023218471556901932], [0.023998688906431198, 0.029284043237566948, 0.5431895852088928, 0.04144273325800896, 0.17544209957122803, 0.1866428703069687], [0.1912512332201004, 0.05048626288771629, 0.039856184273958206, 0.43563809990882874, 0.18908695876598358, 0.09368126839399338], [0.3288097679615021, 0.07848707586526871, 0.06978408247232437, 0.2385120689868927, 0.18773122131824493, 0.09667586535215378], [0.19374734163284302, 0.09076228737831116, 0.14144954085350037, 0.18996933102607727, 0.23915940523147583, 0.14491207897663116]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
 - accuracy: 0.1991     83/Unknown - 429s 5s/step - loss: 12.4518 - accuracy: 0.1991
Epoch 1: val_loss improved from inf to 8.72812, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 486s 6s/step - loss: 12.4518 - accuracy: 0.1991 - val_loss: 8.7281 - val_accuracy: 0.2167
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.7970 - accuracy: 0.2076
Epoch 2: val_loss improved from 8.72812 to 5.35891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 270s 3s/step - loss: 6.7970 - accuracy: 0.2076 - val_loss: 5.3589 - val_accuracy: 0.2137
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5565 - accuracy: 0.2358
Epoch 3: val_loss improved from 5.35891 to 3.94435, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 164s 2s/step - loss: 4.5565 - accuracy: 0.2358 - val_loss: 3.9444 - val_accuracy: 0.2565
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4744 - accuracy: 0.2907
Epoch 4: val_loss improved from 3.94435 to 3.19257, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 110s 1s/step - loss: 3.4744 - accuracy: 0.2907 - val_loss: 3.1926 - val_accuracy: 0.2835
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8911 - accuracy: 0.3012
Epoch 5: val_loss improved from 3.19257 to 2.71432, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 103s 1s/step - loss: 2.8911 - accuracy: 0.3012 - val_loss: 2.7143 - val_accuracy: 0.3019
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5065 - accuracy: 0.3085
Epoch 6: val_loss improved from 2.71432 to 2.37469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 103s 1s/step - loss: 2.5065 - accuracy: 0.3085 - val_loss: 2.3747 - val_accuracy: 0.3187
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2407 - accuracy: 0.3185
Epoch 7: val_loss improved from 2.37469 to 2.13735, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 102s 1s/step - loss: 2.2407 - accuracy: 0.3185 - val_loss: 2.1373 - val_accuracy: 0.3345
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0515 - accuracy: 0.3247
Epoch 8: val_loss improved from 2.13735 to 1.96928, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 122s 1s/step - loss: 2.0515 - accuracy: 0.3247 - val_loss: 1.9693 - val_accuracy: 0.3389
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9192 - accuracy: 0.3307
Epoch 9: val_loss improved from 1.96928 to 1.85638, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 379s 5s/step - loss: 1.9192 - accuracy: 0.3307 - val_loss: 1.8564 - val_accuracy: 0.3419
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8237 - accuracy: 0.3385
Epoch 10: val_loss improved from 1.85638 to 1.77632, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 185s 2s/step - loss: 1.8237 - accuracy: 0.3385 - val_loss: 1.7763 - val_accuracy: 0.3520
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7557 - accuracy: 0.3465
Epoch 11: val_loss improved from 1.77632 to 1.72246, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 182s 2s/step - loss: 1.7557 - accuracy: 0.3465 - val_loss: 1.7225 - val_accuracy: 0.3560
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7062 - accuracy: 0.3520
Epoch 12: val_loss improved from 1.72246 to 1.68079, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 639s 8s/step - loss: 1.7062 - accuracy: 0.3520 - val_loss: 1.6808 - val_accuracy: 0.3570
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6673 - accuracy: 0.3584
Epoch 13: val_loss improved from 1.68079 to 1.65060, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 305s 4s/step - loss: 1.6673 - accuracy: 0.3584 - val_loss: 1.6506 - val_accuracy: 0.3702
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6348 - accuracy: 0.3719
Epoch 14: val_loss improved from 1.65060 to 1.62673, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 220s 3s/step - loss: 1.6348 - accuracy: 0.3719 - val_loss: 1.6267 - val_accuracy: 0.3718
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6141 - accuracy: 0.3744
Epoch 15: val_loss improved from 1.62673 to 1.61851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 181s 2s/step - loss: 1.6141 - accuracy: 0.3744 - val_loss: 1.6185 - val_accuracy: 0.3663
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5927 - accuracy: 0.3818
Epoch 16: val_loss improved from 1.61851 to 1.60065, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 111s 1s/step - loss: 1.5927 - accuracy: 0.3818 - val_loss: 1.6006 - val_accuracy: 0.3758
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5810 - accuracy: 0.3911
Epoch 17: val_loss improved from 1.60065 to 1.60064, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 109s 1s/step - loss: 1.5810 - accuracy: 0.3911 - val_loss: 1.6006 - val_accuracy: 0.3692
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5664 - accuracy: 0.3959
Epoch 18: val_loss improved from 1.60064 to 1.59174, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 104s 1s/step - loss: 1.5664 - accuracy: 0.3959 - val_loss: 1.5917 - val_accuracy: 0.3765
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5569 - accuracy: 0.4014
Epoch 19: val_loss improved from 1.59174 to 1.57594, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 115s 1s/step - loss: 1.5569 - accuracy: 0.4014 - val_loss: 1.5759 - val_accuracy: 0.3879
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5483 - accuracy: 0.4039
Epoch 20: val_loss improved from 1.57594 to 1.57576, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 135s 2s/step - loss: 1.5483 - accuracy: 0.4039 - val_loss: 1.5758 - val_accuracy: 0.3874
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5413 - accuracy: 0.4102
Epoch 21: val_loss did not improve from 1.57576
83/83 [==============================] - 103s 1s/step - loss: 1.5413 - accuracy: 0.4102 - val_loss: 1.5834 - val_accuracy: 0.3820
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5354 - accuracy: 0.4139
Epoch 22: val_loss improved from 1.57576 to 1.57231, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 100s 1s/step - loss: 1.5354 - accuracy: 0.4139 - val_loss: 1.5723 - val_accuracy: 0.3896
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5238 - accuracy: 0.4185
Epoch 23: val_loss did not improve from 1.57231
83/83 [==============================] - 137s 2s/step - loss: 1.5238 - accuracy: 0.4185 - val_loss: 1.5803 - val_accuracy: 0.3854
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5233 - accuracy: 0.4181
Epoch 24: val_loss improved from 1.57231 to 1.56767, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/4
83/83 [==============================] - 114s 1s/step - loss: 1.5233 - accuracy: 0.4181 - val_loss: 1.5677 - val_accuracy: 0.3934
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5113 - accuracy: 0.4263
Epoch 25: val_loss did not improve from 1.56767
83/83 [==============================] - 100s 1s/step - loss: 1.5113 - accuracy: 0.4263 - val_loss: 1.5684 - val_accuracy: 0.3966
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.5037 - accuracy: 0.4326
Epoch 26: val_loss did not improve from 1.56767
83/83 [==============================] - 96s 1s/step - loss: 1.5037 - accuracy: 0.4326 - val_loss: 1.5772 - val_accuracy: 0.3938
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4939 - accuracy: 0.4412
Epoch 27: val_loss did not improve from 1.56767
83/83 [==============================] - 101s 1s/step - loss: 1.4939 - accuracy: 0.4412 - val_loss: 1.5867 - val_accuracy: 0.3867
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4925 - accuracy: 0.4420
Epoch 28: val_loss did not improve from 1.56767
83/83 [==============================] - 117s 1s/step - loss: 1.4925 - accuracy: 0.4420 - val_loss: 1.5847 - val_accuracy: 0.3912
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4832 - accuracy: 0.4477
Epoch 29: val_loss did not improve from 1.56767
83/83 [==============================] - 124s 1s/step - loss: 1.4832 - accuracy: 0.4477 - val_loss: 1.5936 - val_accuracy: 0.3888
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4733 - accuracy: 0.4561
Epoch 30: val_loss did not improve from 1.56767
83/83 [==============================] - 99s 1s/step - loss: 1.4733 - accuracy: 0.4561 - val_loss: 1.5906 - val_accuracy: 0.3910
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4659 - accuracy: 0.4622
Epoch 31: val_loss did not improve from 1.56767
83/83 [==============================] - 113s 1s/step - loss: 1.4659 - accuracy: 0.4622 - val_loss: 1.5965 - val_accuracy: 0.3919
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4595 - accuracy: 0.4681
Epoch 32: val_loss did not improve from 1.56767
83/83 [==============================] - 148s 2s/step - loss: 1.4595 - accuracy: 0.4681 - val_loss: 1.6048 - val_accuracy: 0.3937
Epoch 33/100
83/83 [==============================] - ETA: 0s - loss: 1.4490 - accuracy: 0.4721
Epoch 33: val_loss did not improve from 1.56767
83/83 [==============================] - 178s 2s/step - loss: 1.4490 - accuracy: 0.4721 - val_loss: 1.6131 - val_accuracy: 0.3946
Epoch 34/100
83/83 [==============================] - ETA: 0s - loss: 1.4400 - accuracy: 0.4795
Epoch 34: val_loss did not improve from 1.56767
83/83 [==============================] - 99s 1s/step - loss: 1.4400 - accuracy: 0.4795 - val_loss: 1.6245 - val_accuracy: 0.3883
Epoch 34: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_4 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_14 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_4 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_4 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_12 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_12 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_13 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_13 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_14 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_14 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_12 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_4 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_12 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_13 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_13 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_14 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 163s 12ms/step - loss: 1.5771 - accuracy: 0.3912
Testing Loss = 1.577124, Testing Accuracy = 0.391188
The data set contains images
  13432/Unknown - 127s 9ms/step13437/13437 [==============================] - 127s 9ms/step
[[0.13486823439598083, 0.1317954808473587, 0.07190205901861191, 0.3316313326358795, 0.17557372152805328, 0.15422914922237396], [0.03164386376738548, 0.12772513926029205, 0.3407383859157562, 0.07495555281639099, 0.14095637202262878, 0.28398066759109497], [0.18904630839824677, 0.05811876058578491, 0.1049477681517601, 0.24421629309654236, 0.2808375358581543, 0.12283337861299515], [0.05523805320262909, 0.047414328902959824, 0.3870190978050232, 0.06135322526097298, 0.26064544916152954, 0.1883297860622406], [0.1314544975757599, 0.1994500607252121, 0.0417327918112278, 0.36883148550987244, 0.11663644760847092, 0.14189469814300537], [0.5489227175712585, 0.009369687177240849, 0.05907550826668739, 0.0863351970911026, 0.2646295428276062, 0.0316673219203949], [0.04460207372903824, 0.05538798123598099, 0.41865861415863037, 0.06829704344272614, 0.1996326893568039, 0.21342161297798157], [0.1632305234670639, 0.059540487825870514, 0.05711011588573456, 0.38477760553359985, 0.21715642511844635, 0.11818481981754303], [0.34224018454551697, 0.07532158493995667, 0.07641726732254028, 0.21733826398849487, 0.19615161418914795, 0.09253119677305222], [0.17408481240272522, 0.06073825806379318, 0.21031267940998077, 0.1298149973154068, 0.2825867235660553, 0.14246252179145813]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
 - accuracy: 0.2009     83/Unknown - 127s 1s/step - loss: 12.3829 - accuracy: 0.2012
Epoch 1: val_loss improved from inf to 8.63886, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 169s 2s/step - loss: 12.3829 - accuracy: 0.2012 - val_loss: 8.6389 - val_accuracy: 0.2141
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.7250 - accuracy: 0.2084
Epoch 2: val_loss improved from 8.63886 to 5.30567, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 105s 1s/step - loss: 6.7250 - accuracy: 0.2084 - val_loss: 5.3057 - val_accuracy: 0.2141
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5203 - accuracy: 0.2331
Epoch 3: val_loss improved from 5.30567 to 3.91705, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 104s 1s/step - loss: 4.5203 - accuracy: 0.2331 - val_loss: 3.9171 - val_accuracy: 0.2595
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4547 - accuracy: 0.2900
Epoch 4: val_loss improved from 3.91705 to 3.18331, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 136s 2s/step - loss: 3.4547 - accuracy: 0.2900 - val_loss: 3.1833 - val_accuracy: 0.2771
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8774 - accuracy: 0.3015
Epoch 5: val_loss improved from 3.18331 to 2.70027, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 126s 2s/step - loss: 2.8774 - accuracy: 0.3015 - val_loss: 2.7003 - val_accuracy: 0.3062
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.4987 - accuracy: 0.3089
Epoch 6: val_loss improved from 2.70027 to 2.36454, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 105s 1s/step - loss: 2.4987 - accuracy: 0.3089 - val_loss: 2.3645 - val_accuracy: 0.3228
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2349 - accuracy: 0.3186
Epoch 7: val_loss improved from 2.36454 to 2.13145, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 102s 1s/step - loss: 2.2349 - accuracy: 0.3186 - val_loss: 2.1314 - val_accuracy: 0.3339
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0488 - accuracy: 0.3235
Epoch 8: val_loss improved from 2.13145 to 1.96880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 101s 1s/step - loss: 2.0488 - accuracy: 0.3235 - val_loss: 1.9688 - val_accuracy: 0.3327
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9162 - accuracy: 0.3313
Epoch 9: val_loss improved from 1.96880 to 1.85572, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 101s 1s/step - loss: 1.9162 - accuracy: 0.3313 - val_loss: 1.8557 - val_accuracy: 0.3406
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8216 - accuracy: 0.3391
Epoch 10: val_loss improved from 1.85572 to 1.77891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 102s 1s/step - loss: 1.8216 - accuracy: 0.3391 - val_loss: 1.7789 - val_accuracy: 0.3504
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7535 - accuracy: 0.3456
Epoch 11: val_loss improved from 1.77891 to 1.72023, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 100s 1s/step - loss: 1.7535 - accuracy: 0.3456 - val_loss: 1.7202 - val_accuracy: 0.3595
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7024 - accuracy: 0.3540
Epoch 12: val_loss improved from 1.72023 to 1.68159, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 102s 1s/step - loss: 1.7024 - accuracy: 0.3540 - val_loss: 1.6816 - val_accuracy: 0.3628
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6648 - accuracy: 0.3613
Epoch 13: val_loss improved from 1.68159 to 1.64787, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 101s 1s/step - loss: 1.6648 - accuracy: 0.3613 - val_loss: 1.6479 - val_accuracy: 0.3662
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6325 - accuracy: 0.3698
Epoch 14: val_loss improved from 1.64787 to 1.62811, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 101s 1s/step - loss: 1.6325 - accuracy: 0.3698 - val_loss: 1.6281 - val_accuracy: 0.3689
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6086 - accuracy: 0.3793
Epoch 15: val_loss improved from 1.62811 to 1.61899, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 102s 1s/step - loss: 1.6086 - accuracy: 0.3793 - val_loss: 1.6190 - val_accuracy: 0.3701
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5932 - accuracy: 0.3838
Epoch 16: val_loss improved from 1.61899 to 1.60443, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 102s 1s/step - loss: 1.5932 - accuracy: 0.3838 - val_loss: 1.6044 - val_accuracy: 0.3742
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5763 - accuracy: 0.3917
Epoch 17: val_loss improved from 1.60443 to 1.59463, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 102s 1s/step - loss: 1.5763 - accuracy: 0.3917 - val_loss: 1.5946 - val_accuracy: 0.3804
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5623 - accuracy: 0.3996
Epoch 18: val_loss improved from 1.59463 to 1.59184, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 102s 1s/step - loss: 1.5623 - accuracy: 0.3996 - val_loss: 1.5918 - val_accuracy: 0.3806
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5540 - accuracy: 0.4032
Epoch 19: val_loss improved from 1.59184 to 1.58467, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 103s 1s/step - loss: 1.5540 - accuracy: 0.4032 - val_loss: 1.5847 - val_accuracy: 0.3856
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5431 - accuracy: 0.4094
Epoch 20: val_loss improved from 1.58467 to 1.58198, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 102s 1s/step - loss: 1.5431 - accuracy: 0.4094 - val_loss: 1.5820 - val_accuracy: 0.3866
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5329 - accuracy: 0.4133
Epoch 21: val_loss improved from 1.58198 to 1.57564, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 102s 1s/step - loss: 1.5329 - accuracy: 0.4133 - val_loss: 1.5756 - val_accuracy: 0.3946
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5276 - accuracy: 0.4176
Epoch 22: val_loss improved from 1.57564 to 1.57412, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/5
83/83 [==============================] - 102s 1s/step - loss: 1.5276 - accuracy: 0.4176 - val_loss: 1.5741 - val_accuracy: 0.3933
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5196 - accuracy: 0.4231
Epoch 23: val_loss did not improve from 1.57412
83/83 [==============================] - 100s 1s/step - loss: 1.5196 - accuracy: 0.4231 - val_loss: 1.5880 - val_accuracy: 0.3857
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5140 - accuracy: 0.4263
Epoch 24: val_loss did not improve from 1.57412
83/83 [==============================] - 99s 1s/step - loss: 1.5140 - accuracy: 0.4263 - val_loss: 1.5926 - val_accuracy: 0.3842
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5089 - accuracy: 0.4296
Epoch 25: val_loss did not improve from 1.57412
83/83 [==============================] - 99s 1s/step - loss: 1.5089 - accuracy: 0.4296 - val_loss: 1.5930 - val_accuracy: 0.3851
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.5033 - accuracy: 0.4334
Epoch 26: val_loss did not improve from 1.57412
83/83 [==============================] - 99s 1s/step - loss: 1.5033 - accuracy: 0.4334 - val_loss: 1.6013 - val_accuracy: 0.3826
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4938 - accuracy: 0.4403
Epoch 27: val_loss did not improve from 1.57412
83/83 [==============================] - 100s 1s/step - loss: 1.4938 - accuracy: 0.4403 - val_loss: 1.6191 - val_accuracy: 0.3729
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4959 - accuracy: 0.4402
Epoch 28: val_loss did not improve from 1.57412
83/83 [==============================] - 100s 1s/step - loss: 1.4959 - accuracy: 0.4402 - val_loss: 1.5951 - val_accuracy: 0.3896
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4932 - accuracy: 0.4406
Epoch 29: val_loss did not improve from 1.57412
83/83 [==============================] - 99s 1s/step - loss: 1.4932 - accuracy: 0.4406 - val_loss: 1.5794 - val_accuracy: 0.4015
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4738 - accuracy: 0.4524
Epoch 30: val_loss did not improve from 1.57412
83/83 [==============================] - 99s 1s/step - loss: 1.4738 - accuracy: 0.4524 - val_loss: 1.5990 - val_accuracy: 0.3915
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4677 - accuracy: 0.4604
Epoch 31: val_loss did not improve from 1.57412
83/83 [==============================] - 100s 1s/step - loss: 1.4677 - accuracy: 0.4604 - val_loss: 1.6235 - val_accuracy: 0.3789
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4613 - accuracy: 0.4679
Epoch 32: val_loss did not improve from 1.57412
83/83 [==============================] - 99s 1s/step - loss: 1.4613 - accuracy: 0.4679 - val_loss: 1.6276 - val_accuracy: 0.3822
Epoch 32: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_5 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_17 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_5 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_5 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_15 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_15 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_16 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_16 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_17 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_17 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_15 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_5 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_15 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_16 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_16 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_17 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 143s 10ms/step - loss: 1.5796 - accuracy: 0.3896
Testing Loss = 1.579625, Testing Accuracy = 0.389550
The data set contains images
  13432/Unknown - 127s 9ms/step13437/13437 [==============================] - 127s 9ms/step
[[0.14681552350521088, 0.10831374675035477, 0.05687997117638588, 0.3787599802017212, 0.17140677571296692, 0.13782398402690887], [0.04112352058291435, 0.13624760508537292, 0.30734413862228394, 0.08753133565187454, 0.14937368035316467, 0.2783796787261963], [0.12862876057624817, 0.0766662061214447, 0.14965315163135529, 0.218059241771698, 0.2586350440979004, 0.16835761070251465], [0.08493568748235703, 0.06025107204914093, 0.30175626277923584, 0.08967423439025879, 0.27193447947502136, 0.19144824147224426], [0.12101788818836212, 0.22226226329803467, 0.04221420735120773, 0.35929742455482483, 0.10880248993635178, 0.1464056819677353], [0.5283874869346619, 0.005470362026244402, 0.061760131269693375, 0.0845247209072113, 0.29159826040267944, 0.028258979320526123], [0.03723924607038498, 0.05190553516149521, 0.45131298899650574, 0.058724042028188705, 0.1853027641773224, 0.2155153751373291], [0.14337076246738434, 0.07952550798654556, 0.038778528571128845, 0.45674848556518555, 0.164896160364151, 0.1166805550456047], [0.34830018877983093, 0.07632651925086975, 0.06680362671613693, 0.23435942828655243, 0.18310099840164185, 0.09110920876264572], [0.1918794810771942, 0.07015525549650192, 0.1689816266298294, 0.1605178564786911, 0.2640223801136017, 0.14444339275360107]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
81 - accuracy: 0.2007     83/Unknown - 94s 1s/step - loss: 12.4335 - accuracy: 0.2010
Epoch 1: val_loss improved from inf to 8.71182, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 104s 1s/step - loss: 12.4335 - accuracy: 0.2010 - val_loss: 8.7118 - val_accuracy: 0.2162
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.7889 - accuracy: 0.2104
Epoch 2: val_loss improved from 8.71182 to 5.35237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 101s 1s/step - loss: 6.7889 - accuracy: 0.2104 - val_loss: 5.3524 - val_accuracy: 0.2165
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5552 - accuracy: 0.2332
Epoch 3: val_loss improved from 5.35237 to 3.94946, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 102s 1s/step - loss: 4.5552 - accuracy: 0.2332 - val_loss: 3.9495 - val_accuracy: 0.2365
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4727 - accuracy: 0.2930
Epoch 4: val_loss improved from 3.94946 to 3.19341, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 101s 1s/step - loss: 3.4727 - accuracy: 0.2930 - val_loss: 3.1934 - val_accuracy: 0.2729
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8906 - accuracy: 0.2978
Epoch 5: val_loss improved from 3.19341 to 2.70908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 100s 1s/step - loss: 2.8906 - accuracy: 0.2978 - val_loss: 2.7091 - val_accuracy: 0.3036
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5060 - accuracy: 0.3103
Epoch 6: val_loss improved from 2.70908 to 2.37265, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 101s 1s/step - loss: 2.5060 - accuracy: 0.3103 - val_loss: 2.3727 - val_accuracy: 0.3241
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2427 - accuracy: 0.3157
Epoch 7: val_loss improved from 2.37265 to 2.13731, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 101s 1s/step - loss: 2.2427 - accuracy: 0.3157 - val_loss: 2.1373 - val_accuracy: 0.3309
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0546 - accuracy: 0.3259
Epoch 8: val_loss improved from 2.13731 to 1.97312, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 100s 1s/step - loss: 2.0546 - accuracy: 0.3259 - val_loss: 1.9731 - val_accuracy: 0.3395
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9217 - accuracy: 0.3296
Epoch 9: val_loss improved from 1.97312 to 1.85826, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 100s 1s/step - loss: 1.9217 - accuracy: 0.3296 - val_loss: 1.8583 - val_accuracy: 0.3460
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8280 - accuracy: 0.3394
Epoch 10: val_loss improved from 1.85826 to 1.77974, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 100s 1s/step - loss: 1.8280 - accuracy: 0.3394 - val_loss: 1.7797 - val_accuracy: 0.3500
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7584 - accuracy: 0.3439
Epoch 11: val_loss improved from 1.77974 to 1.72696, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 99s 1s/step - loss: 1.7584 - accuracy: 0.3439 - val_loss: 1.7270 - val_accuracy: 0.3545
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7102 - accuracy: 0.3509
Epoch 12: val_loss improved from 1.72696 to 1.68362, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 99s 1s/step - loss: 1.7102 - accuracy: 0.3509 - val_loss: 1.6836 - val_accuracy: 0.3589
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6679 - accuracy: 0.3617
Epoch 13: val_loss improved from 1.68362 to 1.65045, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 100s 1s/step - loss: 1.6679 - accuracy: 0.3617 - val_loss: 1.6504 - val_accuracy: 0.3691
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6375 - accuracy: 0.3715
Epoch 14: val_loss improved from 1.65045 to 1.62764, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 99s 1s/step - loss: 1.6375 - accuracy: 0.3715 - val_loss: 1.6276 - val_accuracy: 0.3734
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6176 - accuracy: 0.3742
Epoch 15: val_loss improved from 1.62764 to 1.60720, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 99s 1s/step - loss: 1.6176 - accuracy: 0.3742 - val_loss: 1.6072 - val_accuracy: 0.3832
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5963 - accuracy: 0.3806
Epoch 16: val_loss improved from 1.60720 to 1.60383, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 100s 1s/step - loss: 1.5963 - accuracy: 0.3806 - val_loss: 1.6038 - val_accuracy: 0.3786
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5787 - accuracy: 0.3895
Epoch 17: val_loss improved from 1.60383 to 1.59159, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 100s 1s/step - loss: 1.5787 - accuracy: 0.3895 - val_loss: 1.5916 - val_accuracy: 0.3850
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5704 - accuracy: 0.3949
Epoch 18: val_loss improved from 1.59159 to 1.58686, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 99s 1s/step - loss: 1.5704 - accuracy: 0.3949 - val_loss: 1.5869 - val_accuracy: 0.3859
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5576 - accuracy: 0.4023
Epoch 19: val_loss improved from 1.58686 to 1.57631, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 100s 1s/step - loss: 1.5576 - accuracy: 0.4023 - val_loss: 1.5763 - val_accuracy: 0.3912
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5461 - accuracy: 0.4070
Epoch 20: val_loss did not improve from 1.57631
83/83 [==============================] - 98s 1s/step - loss: 1.5461 - accuracy: 0.4070 - val_loss: 1.5790 - val_accuracy: 0.3900
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5403 - accuracy: 0.4082
Epoch 21: val_loss did not improve from 1.57631
83/83 [==============================] - 97s 1s/step - loss: 1.5403 - accuracy: 0.4082 - val_loss: 1.5803 - val_accuracy: 0.3872
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5289 - accuracy: 0.4164
Epoch 22: val_loss improved from 1.57631 to 1.57317, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/6
83/83 [==============================] - 99s 1s/step - loss: 1.5289 - accuracy: 0.4164 - val_loss: 1.5732 - val_accuracy: 0.3953
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5230 - accuracy: 0.4194
Epoch 23: val_loss did not improve from 1.57317
83/83 [==============================] - 97s 1s/step - loss: 1.5230 - accuracy: 0.4194 - val_loss: 1.5868 - val_accuracy: 0.3832
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5167 - accuracy: 0.4244
Epoch 24: val_loss did not improve from 1.57317
83/83 [==============================] - 95s 1s/step - loss: 1.5167 - accuracy: 0.4244 - val_loss: 1.5815 - val_accuracy: 0.3885
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5111 - accuracy: 0.4284
Epoch 25: val_loss did not improve from 1.57317
83/83 [==============================] - 93s 1s/step - loss: 1.5111 - accuracy: 0.4284 - val_loss: 1.5789 - val_accuracy: 0.3919
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.5013 - accuracy: 0.4367
Epoch 26: val_loss did not improve from 1.57317
83/83 [==============================] - 94s 1s/step - loss: 1.5013 - accuracy: 0.4367 - val_loss: 1.5772 - val_accuracy: 0.3983
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4938 - accuracy: 0.4390
Epoch 27: val_loss did not improve from 1.57317
83/83 [==============================] - 94s 1s/step - loss: 1.4938 - accuracy: 0.4390 - val_loss: 1.5825 - val_accuracy: 0.3973
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4880 - accuracy: 0.4454
Epoch 28: val_loss did not improve from 1.57317
83/83 [==============================] - 93s 1s/step - loss: 1.4880 - accuracy: 0.4454 - val_loss: 1.5961 - val_accuracy: 0.3896
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4848 - accuracy: 0.4469
Epoch 29: val_loss did not improve from 1.57317
83/83 [==============================] - 93s 1s/step - loss: 1.4848 - accuracy: 0.4469 - val_loss: 1.6038 - val_accuracy: 0.3864
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4767 - accuracy: 0.4533
Epoch 30: val_loss did not improve from 1.57317
83/83 [==============================] - 94s 1s/step - loss: 1.4767 - accuracy: 0.4533 - val_loss: 1.6086 - val_accuracy: 0.3878
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4695 - accuracy: 0.4557
Epoch 31: val_loss did not improve from 1.57317
83/83 [==============================] - 93s 1s/step - loss: 1.4695 - accuracy: 0.4557 - val_loss: 1.6089 - val_accuracy: 0.3906
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4627 - accuracy: 0.4631
Epoch 32: val_loss did not improve from 1.57317
83/83 [==============================] - 94s 1s/step - loss: 1.4627 - accuracy: 0.4631 - val_loss: 1.6053 - val_accuracy: 0.3956
Epoch 32: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_6 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_20 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_6 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_6 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_18 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_18 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_19 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_19 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_20 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_20 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_18 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_6 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_18 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_19 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_19 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_20 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 131s 10ms/step - loss: 1.5817 - accuracy: 0.3913
Testing Loss = 1.581736, Testing Accuracy = 0.391262
The data set contains images
  13433/Unknown - 124s 9ms/step13437/13437 [==============================] - 124s 9ms/step
[[0.1500583440065384, 0.11183676868677139, 0.05827433243393898, 0.37508103251457214, 0.16650253534317017, 0.13824696838855743], [0.038721077144145966, 0.09066308289766312, 0.3969082534313202, 0.06847922503948212, 0.15641741454601288, 0.24881097674369812], [0.17204810678958893, 0.08190978318452835, 0.07784570753574371, 0.31737780570983887, 0.2252151370048523, 0.12560349702835083], [0.08330510556697845, 0.06764563173055649, 0.31467777490615845, 0.0827101618051529, 0.25924667716026306, 0.19241468608379364], [0.10832329839468002, 0.2600573003292084, 0.036527764052152634, 0.3470124900341034, 0.09581505507230759, 0.15226396918296814], [0.5005486607551575, 0.007661790587007999, 0.07796622812747955, 0.08171506226062775, 0.2981546223163605, 0.033953554928302765], [0.044170621782541275, 0.043580397963523865, 0.4598838984966278, 0.060555510222911835, 0.19422006607055664, 0.1975894421339035], [0.1819169521331787, 0.055570848286151886, 0.03969600796699524, 0.4388689696788788, 0.18614797294139862, 0.09779921174049377], [0.33991119265556335, 0.07968296855688095, 0.07546250522136688, 0.21911412477493286, 0.18946075439453125, 0.09636843204498291], [0.22682777047157288, 0.0769282877445221, 0.14649508893489838, 0.16567321121692657, 0.2531432807445526, 0.13093242049217224]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
92 - accuracy: 0.1991     83/Unknown - 90s 1s/step - loss: 12.5149 - accuracy: 0.1991
Epoch 1: val_loss improved from inf to 8.81363, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 98s 1s/step - loss: 12.5149 - accuracy: 0.1991 - val_loss: 8.8136 - val_accuracy: 0.2134
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.8651 - accuracy: 0.2079
Epoch 2: val_loss improved from 8.81363 to 5.40596, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 96s 1s/step - loss: 6.8651 - accuracy: 0.2079 - val_loss: 5.4060 - val_accuracy: 0.2179
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5727 - accuracy: 0.2500
Epoch 3: val_loss improved from 5.40596 to 3.96305, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 98s 1s/step - loss: 4.5727 - accuracy: 0.2500 - val_loss: 3.9631 - val_accuracy: 0.2558
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4863 - accuracy: 0.2893
Epoch 4: val_loss improved from 3.96305 to 3.20430, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 96s 1s/step - loss: 3.4863 - accuracy: 0.2893 - val_loss: 3.2043 - val_accuracy: 0.2797
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8940 - accuracy: 0.3065
Epoch 5: val_loss improved from 3.20430 to 2.71409, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 97s 1s/step - loss: 2.8940 - accuracy: 0.3065 - val_loss: 2.7141 - val_accuracy: 0.3027
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5081 - accuracy: 0.3163
Epoch 6: val_loss improved from 2.71409 to 2.37668, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 95s 1s/step - loss: 2.5081 - accuracy: 0.3163 - val_loss: 2.3767 - val_accuracy: 0.3185
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2427 - accuracy: 0.3189
Epoch 7: val_loss improved from 2.37668 to 2.13926, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 97s 1s/step - loss: 2.2427 - accuracy: 0.3189 - val_loss: 2.1393 - val_accuracy: 0.3316
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0523 - accuracy: 0.3274
Epoch 8: val_loss improved from 2.13926 to 1.97125, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 97s 1s/step - loss: 2.0523 - accuracy: 0.3274 - val_loss: 1.9712 - val_accuracy: 0.3395
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9170 - accuracy: 0.3354
Epoch 9: val_loss improved from 1.97125 to 1.85591, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 95s 1s/step - loss: 1.9170 - accuracy: 0.3354 - val_loss: 1.8559 - val_accuracy: 0.3486
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8222 - accuracy: 0.3396
Epoch 10: val_loss improved from 1.85591 to 1.77493, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 96s 1s/step - loss: 1.8222 - accuracy: 0.3396 - val_loss: 1.7749 - val_accuracy: 0.3543
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7532 - accuracy: 0.3486
Epoch 11: val_loss improved from 1.77493 to 1.71982, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 97s 1s/step - loss: 1.7532 - accuracy: 0.3486 - val_loss: 1.7198 - val_accuracy: 0.3572
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7002 - accuracy: 0.3581
Epoch 12: val_loss improved from 1.71982 to 1.67911, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 97s 1s/step - loss: 1.7002 - accuracy: 0.3581 - val_loss: 1.6791 - val_accuracy: 0.3666
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6596 - accuracy: 0.3697
Epoch 13: val_loss improved from 1.67911 to 1.64313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 96s 1s/step - loss: 1.6596 - accuracy: 0.3697 - val_loss: 1.6431 - val_accuracy: 0.3746
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6289 - accuracy: 0.3760
Epoch 14: val_loss improved from 1.64313 to 1.62998, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 96s 1s/step - loss: 1.6289 - accuracy: 0.3760 - val_loss: 1.6300 - val_accuracy: 0.3703
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6060 - accuracy: 0.3834
Epoch 15: val_loss improved from 1.62998 to 1.60617, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 96s 1s/step - loss: 1.6060 - accuracy: 0.3834 - val_loss: 1.6062 - val_accuracy: 0.3814
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5899 - accuracy: 0.3916
Epoch 16: val_loss improved from 1.60617 to 1.60200, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 97s 1s/step - loss: 1.5899 - accuracy: 0.3916 - val_loss: 1.6020 - val_accuracy: 0.3796
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5703 - accuracy: 0.3964
Epoch 17: val_loss improved from 1.60200 to 1.59210, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 96s 1s/step - loss: 1.5703 - accuracy: 0.3964 - val_loss: 1.5921 - val_accuracy: 0.3841
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5589 - accuracy: 0.4046
Epoch 18: val_loss improved from 1.59210 to 1.58631, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 97s 1s/step - loss: 1.5589 - accuracy: 0.4046 - val_loss: 1.5863 - val_accuracy: 0.3857
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5470 - accuracy: 0.4075
Epoch 19: val_loss improved from 1.58631 to 1.57741, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 97s 1s/step - loss: 1.5470 - accuracy: 0.4075 - val_loss: 1.5774 - val_accuracy: 0.3930
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5399 - accuracy: 0.4113
Epoch 20: val_loss improved from 1.57741 to 1.56989, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/7
83/83 [==============================] - 98s 1s/step - loss: 1.5399 - accuracy: 0.4113 - val_loss: 1.5699 - val_accuracy: 0.3980
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5294 - accuracy: 0.4154
Epoch 21: val_loss did not improve from 1.56989
83/83 [==============================] - 94s 1s/step - loss: 1.5294 - accuracy: 0.4154 - val_loss: 1.5828 - val_accuracy: 0.3874
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5290 - accuracy: 0.4199
Epoch 22: val_loss did not improve from 1.56989
83/83 [==============================] - 93s 1s/step - loss: 1.5290 - accuracy: 0.4199 - val_loss: 1.5736 - val_accuracy: 0.3925
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5171 - accuracy: 0.4244
Epoch 23: val_loss did not improve from 1.56989
83/83 [==============================] - 93s 1s/step - loss: 1.5171 - accuracy: 0.4244 - val_loss: 1.5756 - val_accuracy: 0.3952
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5097 - accuracy: 0.4296
Epoch 24: val_loss did not improve from 1.56989
83/83 [==============================] - 95s 1s/step - loss: 1.5097 - accuracy: 0.4296 - val_loss: 1.5770 - val_accuracy: 0.3928
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5023 - accuracy: 0.4343
Epoch 25: val_loss did not improve from 1.56989
83/83 [==============================] - 149s 2s/step - loss: 1.5023 - accuracy: 0.4343 - val_loss: 1.5764 - val_accuracy: 0.3945
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.4951 - accuracy: 0.4399
Epoch 26: val_loss did not improve from 1.56989
83/83 [==============================] - 94s 1s/step - loss: 1.4951 - accuracy: 0.4399 - val_loss: 1.5732 - val_accuracy: 0.4002
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4896 - accuracy: 0.4416
Epoch 27: val_loss did not improve from 1.56989
83/83 [==============================] - 94s 1s/step - loss: 1.4896 - accuracy: 0.4416 - val_loss: 1.5865 - val_accuracy: 0.3898
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4800 - accuracy: 0.4511
Epoch 28: val_loss did not improve from 1.56989
83/83 [==============================] - 94s 1s/step - loss: 1.4800 - accuracy: 0.4511 - val_loss: 1.5813 - val_accuracy: 0.3989
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4738 - accuracy: 0.4552
Epoch 29: val_loss did not improve from 1.56989
83/83 [==============================] - 95s 1s/step - loss: 1.4738 - accuracy: 0.4552 - val_loss: 1.5914 - val_accuracy: 0.3916
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4678 - accuracy: 0.4605
Epoch 30: val_loss did not improve from 1.56989
83/83 [==============================] - 94s 1s/step - loss: 1.4678 - accuracy: 0.4605 - val_loss: 1.5883 - val_accuracy: 0.4009
Epoch 30: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_7 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_23 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_7 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_7 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_21 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_21 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_22 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_22 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_23 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_23 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_21 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_7 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_21 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_22 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_22 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_23 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 132s 10ms/step - loss: 1.5782 - accuracy: 0.3928
Testing Loss = 1.578239, Testing Accuracy = 0.392825
The data set contains images
  13433/Unknown - 124s 9ms/step13437/13437 [==============================] - 124s 9ms/step
[[0.11565238237380981, 0.10670986026525497, 0.11239670217037201, 0.26389825344085693, 0.20934316515922546, 0.19199970364570618], [0.042476631700992584, 0.08146069198846817, 0.3832463026046753, 0.07900919765233994, 0.17184512317180634, 0.2419620007276535], [0.14784128963947296, 0.08427585661411285, 0.13461682200431824, 0.21428021788597107, 0.2597041726112366, 0.1592816561460495], [0.045622747391462326, 0.04204583913087845, 0.42551061511039734, 0.06025006249547005, 0.22948835790157318, 0.19708232581615448], [0.11682125180959702, 0.19403059780597687, 0.04933752864599228, 0.3522980213165283, 0.12404095381498337, 0.16347163915634155], [0.5102358460426331, 0.007858661003410816, 0.07590827345848083, 0.08067773282527924, 0.29210731387138367, 0.033212240785360336], [0.03776521980762482, 0.04576067999005318, 0.4510880410671234, 0.06437691301107407, 0.19080521166324615, 0.21020393073558807], [0.1825484186410904, 0.052482664585113525, 0.04288754239678383, 0.41672325134277344, 0.20434823632240295, 0.10100988298654556], [0.30513298511505127, 0.08819366246461868, 0.07500690966844559, 0.23839816451072693, 0.18679413199424744, 0.10647416859865189], [0.2182091623544693, 0.08148680627346039, 0.12837855517864227, 0.1914721429347992, 0.2433290332555771, 0.1371242105960846]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
81 - accuracy: 0.1994     83/Unknown - 89s 1s/step - loss: 12.5037 - accuracy: 0.1998
Epoch 1: val_loss improved from inf to 8.79725, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 97s 1s/step - loss: 12.5037 - accuracy: 0.1998 - val_loss: 8.7973 - val_accuracy: 0.2144
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.8575 - accuracy: 0.2067
Epoch 2: val_loss improved from 8.79725 to 5.40609, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 96s 1s/step - loss: 6.8575 - accuracy: 0.2067 - val_loss: 5.4061 - val_accuracy: 0.2154
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.6069 - accuracy: 0.2271
Epoch 3: val_loss improved from 5.40609 to 3.97049, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 95s 1s/step - loss: 4.6069 - accuracy: 0.2271 - val_loss: 3.9705 - val_accuracy: 0.2512
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4975 - accuracy: 0.2882
Epoch 4: val_loss improved from 3.97049 to 3.20588, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 97s 1s/step - loss: 3.4975 - accuracy: 0.2882 - val_loss: 3.2059 - val_accuracy: 0.2761
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.8993 - accuracy: 0.2994
Epoch 5: val_loss improved from 3.20588 to 2.72065, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 96s 1s/step - loss: 2.8993 - accuracy: 0.2994 - val_loss: 2.7206 - val_accuracy: 0.2965
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5118 - accuracy: 0.3135
Epoch 6: val_loss improved from 2.72065 to 2.37777, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 96s 1s/step - loss: 2.5118 - accuracy: 0.3135 - val_loss: 2.3778 - val_accuracy: 0.3187
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2450 - accuracy: 0.3181
Epoch 7: val_loss improved from 2.37777 to 2.13872, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 96s 1s/step - loss: 2.2450 - accuracy: 0.3181 - val_loss: 2.1387 - val_accuracy: 0.3306
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0531 - accuracy: 0.3264
Epoch 8: val_loss improved from 2.13872 to 1.97124, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 96s 1s/step - loss: 2.0531 - accuracy: 0.3264 - val_loss: 1.9712 - val_accuracy: 0.3405
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9199 - accuracy: 0.3344
Epoch 9: val_loss improved from 1.97124 to 1.85824, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 97s 1s/step - loss: 1.9199 - accuracy: 0.3344 - val_loss: 1.8582 - val_accuracy: 0.3499
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8235 - accuracy: 0.3423
Epoch 10: val_loss improved from 1.85824 to 1.77653, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 96s 1s/step - loss: 1.8235 - accuracy: 0.3423 - val_loss: 1.7765 - val_accuracy: 0.3544
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7530 - accuracy: 0.3499
Epoch 11: val_loss improved from 1.77653 to 1.72093, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 98s 1s/step - loss: 1.7530 - accuracy: 0.3499 - val_loss: 1.7209 - val_accuracy: 0.3607
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7015 - accuracy: 0.3572
Epoch 12: val_loss improved from 1.72093 to 1.68139, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 97s 1s/step - loss: 1.7015 - accuracy: 0.3572 - val_loss: 1.6814 - val_accuracy: 0.3647
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6614 - accuracy: 0.3646
Epoch 13: val_loss improved from 1.68139 to 1.64551, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 95s 1s/step - loss: 1.6614 - accuracy: 0.3646 - val_loss: 1.6455 - val_accuracy: 0.3759
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6279 - accuracy: 0.3757
Epoch 14: val_loss improved from 1.64551 to 1.63086, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 97s 1s/step - loss: 1.6279 - accuracy: 0.3757 - val_loss: 1.6309 - val_accuracy: 0.3659
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6082 - accuracy: 0.3810
Epoch 15: val_loss improved from 1.63086 to 1.61275, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 96s 1s/step - loss: 1.6082 - accuracy: 0.3810 - val_loss: 1.6128 - val_accuracy: 0.3730
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5838 - accuracy: 0.3908
Epoch 16: val_loss improved from 1.61275 to 1.59924, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 95s 1s/step - loss: 1.5838 - accuracy: 0.3908 - val_loss: 1.5992 - val_accuracy: 0.3747
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5710 - accuracy: 0.3964
Epoch 17: val_loss improved from 1.59924 to 1.59493, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 97s 1s/step - loss: 1.5710 - accuracy: 0.3964 - val_loss: 1.5949 - val_accuracy: 0.3785
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5582 - accuracy: 0.4015
Epoch 18: val_loss improved from 1.59493 to 1.58587, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 95s 1s/step - loss: 1.5582 - accuracy: 0.4015 - val_loss: 1.5859 - val_accuracy: 0.3823
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5461 - accuracy: 0.4078
Epoch 19: val_loss did not improve from 1.58587
83/83 [==============================] - 93s 1s/step - loss: 1.5461 - accuracy: 0.4078 - val_loss: 1.5861 - val_accuracy: 0.3812
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5396 - accuracy: 0.4107
Epoch 20: val_loss improved from 1.58587 to 1.58464, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 96s 1s/step - loss: 1.5396 - accuracy: 0.4107 - val_loss: 1.5846 - val_accuracy: 0.3807
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5309 - accuracy: 0.4139
Epoch 21: val_loss improved from 1.58464 to 1.57614, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/8
83/83 [==============================] - 95s 1s/step - loss: 1.5309 - accuracy: 0.4139 - val_loss: 1.5761 - val_accuracy: 0.3870
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5233 - accuracy: 0.4207
Epoch 22: val_loss did not improve from 1.57614
83/83 [==============================] - 94s 1s/step - loss: 1.5233 - accuracy: 0.4207 - val_loss: 1.5820 - val_accuracy: 0.3846
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5170 - accuracy: 0.4252
Epoch 23: val_loss did not improve from 1.57614
83/83 [==============================] - 94s 1s/step - loss: 1.5170 - accuracy: 0.4252 - val_loss: 1.5893 - val_accuracy: 0.3809
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5081 - accuracy: 0.4306
Epoch 24: val_loss did not improve from 1.57614
83/83 [==============================] - 93s 1s/step - loss: 1.5081 - accuracy: 0.4306 - val_loss: 1.5867 - val_accuracy: 0.3839
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5005 - accuracy: 0.4374
Epoch 25: val_loss did not improve from 1.57614
83/83 [==============================] - 93s 1s/step - loss: 1.5005 - accuracy: 0.4374 - val_loss: 1.5913 - val_accuracy: 0.3829
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.4895 - accuracy: 0.4432
Epoch 26: val_loss did not improve from 1.57614
83/83 [==============================] - 94s 1s/step - loss: 1.4895 - accuracy: 0.4432 - val_loss: 1.5987 - val_accuracy: 0.3795
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4854 - accuracy: 0.4448
Epoch 27: val_loss did not improve from 1.57614
83/83 [==============================] - 93s 1s/step - loss: 1.4854 - accuracy: 0.4448 - val_loss: 1.6015 - val_accuracy: 0.3835
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4773 - accuracy: 0.4545
Epoch 28: val_loss did not improve from 1.57614
83/83 [==============================] - 94s 1s/step - loss: 1.4773 - accuracy: 0.4545 - val_loss: 1.5893 - val_accuracy: 0.3933
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4683 - accuracy: 0.4599
Epoch 29: val_loss did not improve from 1.57614
83/83 [==============================] - 93s 1s/step - loss: 1.4683 - accuracy: 0.4599 - val_loss: 1.6064 - val_accuracy: 0.3872
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4627 - accuracy: 0.4651
Epoch 30: val_loss did not improve from 1.57614
83/83 [==============================] - 94s 1s/step - loss: 1.4627 - accuracy: 0.4651 - val_loss: 1.6153 - val_accuracy: 0.3870
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4571 - accuracy: 0.4707
Epoch 31: val_loss did not improve from 1.57614
83/83 [==============================] - 93s 1s/step - loss: 1.4571 - accuracy: 0.4707 - val_loss: 1.6552 - val_accuracy: 0.3688
Epoch 31: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_8 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_26 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_8 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_8 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_24 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_24 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_25 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_25 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_26 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_26 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_24 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_8 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_24 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_25 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_25 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_26 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 131s 10ms/step - loss: 1.5797 - accuracy: 0.3919
Testing Loss = 1.579657, Testing Accuracy = 0.391932
The data set contains images
  13431/Unknown - 124s 9ms/step13437/13437 [==============================] - 124s 9ms/step
[[0.1344766765832901, 0.15558023750782013, 0.05642217397689819, 0.3607131540775299, 0.1463785469532013, 0.14642922580242157], [0.02866608276963234, 0.10596409440040588, 0.3789047300815582, 0.06862837076187134, 0.13776147365570068, 0.2800752818584442], [0.13395832479000092, 0.08657421171665192, 0.1358547955751419, 0.23024772107601166, 0.24474792182445526, 0.16861701011657715], [0.07025524973869324, 0.042533211410045624, 0.3731836974620819, 0.07148997485637665, 0.26816698908805847, 0.1743708848953247], [0.10862594097852707, 0.1954190880060196, 0.042345039546489716, 0.3967936336994171, 0.10868939012289047, 0.14812692999839783], [0.5159511566162109, 0.008928266353905201, 0.07983578741550446, 0.07986313849687576, 0.2802509367465973, 0.03517081215977669], [0.03312361240386963, 0.04406458139419556, 0.48732155561447144, 0.053495123982429504, 0.17941412329673767, 0.2025810182094574], [0.1739620715379715, 0.05890536680817604, 0.045947086066007614, 0.4229932725429535, 0.19147905707359314, 0.10671311616897583], [0.28672316670417786, 0.09625352919101715, 0.0763583853840828, 0.25152361392974854, 0.18029385805130005, 0.10884752124547958], [0.15138296782970428, 0.07162846624851227, 0.20392152667045593, 0.15168234705924988, 0.2604528069496155, 0.16093192994594574]]
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
56 - accuracy: 0.2001     83/Unknown - 90s 1s/step - loss: 12.5011 - accuracy: 0.1999
Epoch 1: val_loss improved from inf to 8.79373, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 99s 1s/step - loss: 12.5011 - accuracy: 0.1999 - val_loss: 8.7937 - val_accuracy: 0.2140
Epoch 2/100
83/83 [==============================] - ETA: 0s - loss: 6.8522 - accuracy: 0.2096
Epoch 2: val_loss improved from 8.79373 to 5.40379, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 98s 1s/step - loss: 6.8522 - accuracy: 0.2096 - val_loss: 5.4038 - val_accuracy: 0.2163
Epoch 3/100
83/83 [==============================] - ETA: 0s - loss: 4.5756 - accuracy: 0.2433
Epoch 3: val_loss improved from 5.40379 to 3.97086, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 97s 1s/step - loss: 4.5756 - accuracy: 0.2433 - val_loss: 3.9709 - val_accuracy: 0.2541
Epoch 4/100
83/83 [==============================] - ETA: 0s - loss: 3.4976 - accuracy: 0.2871
Epoch 4: val_loss improved from 3.97086 to 3.22032, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 96s 1s/step - loss: 3.4976 - accuracy: 0.2871 - val_loss: 3.2203 - val_accuracy: 0.2717
Epoch 5/100
83/83 [==============================] - ETA: 0s - loss: 2.9031 - accuracy: 0.3011
Epoch 5: val_loss improved from 3.22032 to 2.72891, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 97s 1s/step - loss: 2.9031 - accuracy: 0.3011 - val_loss: 2.7289 - val_accuracy: 0.3003
Epoch 6/100
83/83 [==============================] - ETA: 0s - loss: 2.5158 - accuracy: 0.3115
Epoch 6: val_loss improved from 2.72891 to 2.38526, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 98s 1s/step - loss: 2.5158 - accuracy: 0.3115 - val_loss: 2.3853 - val_accuracy: 0.3207
Epoch 7/100
83/83 [==============================] - ETA: 0s - loss: 2.2484 - accuracy: 0.3187
Epoch 7: val_loss improved from 2.38526 to 2.14386, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 97s 1s/step - loss: 2.2484 - accuracy: 0.3187 - val_loss: 2.1439 - val_accuracy: 0.3329
Epoch 8/100
83/83 [==============================] - ETA: 0s - loss: 2.0572 - accuracy: 0.3287
Epoch 8: val_loss improved from 2.14386 to 1.97737, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 97s 1s/step - loss: 2.0572 - accuracy: 0.3287 - val_loss: 1.9774 - val_accuracy: 0.3387
Epoch 9/100
83/83 [==============================] - ETA: 0s - loss: 1.9219 - accuracy: 0.3367
Epoch 9: val_loss improved from 1.97737 to 1.86399, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 97s 1s/step - loss: 1.9219 - accuracy: 0.3367 - val_loss: 1.8640 - val_accuracy: 0.3455
Epoch 10/100
83/83 [==============================] - ETA: 0s - loss: 1.8264 - accuracy: 0.3405
Epoch 10: val_loss improved from 1.86399 to 1.78038, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 96s 1s/step - loss: 1.8264 - accuracy: 0.3405 - val_loss: 1.7804 - val_accuracy: 0.3521
Epoch 11/100
83/83 [==============================] - ETA: 0s - loss: 1.7577 - accuracy: 0.3507
Epoch 11: val_loss improved from 1.78038 to 1.72538, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 97s 1s/step - loss: 1.7577 - accuracy: 0.3507 - val_loss: 1.7254 - val_accuracy: 0.3550
Epoch 12/100
83/83 [==============================] - ETA: 0s - loss: 1.7043 - accuracy: 0.3585
Epoch 12: val_loss improved from 1.72538 to 1.67924, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 97s 1s/step - loss: 1.7043 - accuracy: 0.3585 - val_loss: 1.6792 - val_accuracy: 0.3683
Epoch 13/100
83/83 [==============================] - ETA: 0s - loss: 1.6648 - accuracy: 0.3682
Epoch 13: val_loss improved from 1.67924 to 1.64855, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 97s 1s/step - loss: 1.6648 - accuracy: 0.3682 - val_loss: 1.6485 - val_accuracy: 0.3698
Epoch 14/100
83/83 [==============================] - ETA: 0s - loss: 1.6323 - accuracy: 0.3775
Epoch 14: val_loss improved from 1.64855 to 1.62971, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 97s 1s/step - loss: 1.6323 - accuracy: 0.3775 - val_loss: 1.6297 - val_accuracy: 0.3781
Epoch 15/100
83/83 [==============================] - ETA: 0s - loss: 1.6094 - accuracy: 0.3831
Epoch 15: val_loss improved from 1.62971 to 1.61934, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 97s 1s/step - loss: 1.6094 - accuracy: 0.3831 - val_loss: 1.6193 - val_accuracy: 0.3756
Epoch 16/100
83/83 [==============================] - ETA: 0s - loss: 1.5936 - accuracy: 0.3891
Epoch 16: val_loss improved from 1.61934 to 1.59663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 98s 1s/step - loss: 1.5936 - accuracy: 0.3891 - val_loss: 1.5966 - val_accuracy: 0.3894
Epoch 17/100
83/83 [==============================] - ETA: 0s - loss: 1.5743 - accuracy: 0.3972
Epoch 17: val_loss improved from 1.59663 to 1.59264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 96s 1s/step - loss: 1.5743 - accuracy: 0.3972 - val_loss: 1.5926 - val_accuracy: 0.3898
Epoch 18/100
83/83 [==============================] - ETA: 0s - loss: 1.5639 - accuracy: 0.3996
Epoch 18: val_loss improved from 1.59264 to 1.58921, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 98s 1s/step - loss: 1.5639 - accuracy: 0.3996 - val_loss: 1.5892 - val_accuracy: 0.3858
Epoch 19/100
83/83 [==============================] - ETA: 0s - loss: 1.5528 - accuracy: 0.4066
Epoch 19: val_loss improved from 1.58921 to 1.58354, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 98s 1s/step - loss: 1.5528 - accuracy: 0.4066 - val_loss: 1.5835 - val_accuracy: 0.3928
Epoch 20/100
83/83 [==============================] - ETA: 0s - loss: 1.5448 - accuracy: 0.4085
Epoch 20: val_loss improved from 1.58354 to 1.57747, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 97s 1s/step - loss: 1.5448 - accuracy: 0.4085 - val_loss: 1.5775 - val_accuracy: 0.3932
Epoch 21/100
83/83 [==============================] - ETA: 0s - loss: 1.5343 - accuracy: 0.4147
Epoch 21: val_loss did not improve from 1.57747
83/83 [==============================] - 96s 1s/step - loss: 1.5343 - accuracy: 0.4147 - val_loss: 1.5799 - val_accuracy: 0.3937
Epoch 22/100
83/83 [==============================] - ETA: 0s - loss: 1.5275 - accuracy: 0.4171
Epoch 22: val_loss improved from 1.57747 to 1.57148, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.22/Try/9
83/83 [==============================] - 99s 1s/step - loss: 1.5275 - accuracy: 0.4171 - val_loss: 1.5715 - val_accuracy: 0.3970
Epoch 23/100
83/83 [==============================] - ETA: 0s - loss: 1.5199 - accuracy: 0.4238
Epoch 23: val_loss did not improve from 1.57148
83/83 [==============================] - 96s 1s/step - loss: 1.5199 - accuracy: 0.4238 - val_loss: 1.5738 - val_accuracy: 0.3960
Epoch 24/100
83/83 [==============================] - ETA: 0s - loss: 1.5115 - accuracy: 0.4303
Epoch 24: val_loss did not improve from 1.57148
83/83 [==============================] - 97s 1s/step - loss: 1.5115 - accuracy: 0.4303 - val_loss: 1.5771 - val_accuracy: 0.3946
Epoch 25/100
83/83 [==============================] - ETA: 0s - loss: 1.5046 - accuracy: 0.4351
Epoch 25: val_loss did not improve from 1.57148
83/83 [==============================] - 98s 1s/step - loss: 1.5046 - accuracy: 0.4351 - val_loss: 1.5823 - val_accuracy: 0.3929
Epoch 26/100
83/83 [==============================] - ETA: 0s - loss: 1.4999 - accuracy: 0.4389
Epoch 26: val_loss did not improve from 1.57148
83/83 [==============================] - 98s 1s/step - loss: 1.4999 - accuracy: 0.4389 - val_loss: 1.5796 - val_accuracy: 0.3965
Epoch 27/100
83/83 [==============================] - ETA: 0s - loss: 1.4943 - accuracy: 0.4425
Epoch 27: val_loss did not improve from 1.57148
83/83 [==============================] - 97s 1s/step - loss: 1.4943 - accuracy: 0.4425 - val_loss: 1.5829 - val_accuracy: 0.3941
Epoch 28/100
83/83 [==============================] - ETA: 0s - loss: 1.4891 - accuracy: 0.4457
Epoch 28: val_loss did not improve from 1.57148
83/83 [==============================] - 97s 1s/step - loss: 1.4891 - accuracy: 0.4457 - val_loss: 1.5892 - val_accuracy: 0.3923
Epoch 29/100
83/83 [==============================] - ETA: 0s - loss: 1.4822 - accuracy: 0.4497
Epoch 29: val_loss did not improve from 1.57148
83/83 [==============================] - 96s 1s/step - loss: 1.4822 - accuracy: 0.4497 - val_loss: 1.5899 - val_accuracy: 0.3947
Epoch 30/100
83/83 [==============================] - ETA: 0s - loss: 1.4723 - accuracy: 0.4593
Epoch 30: val_loss did not improve from 1.57148
83/83 [==============================] - 97s 1s/step - loss: 1.4723 - accuracy: 0.4593 - val_loss: 1.6089 - val_accuracy: 0.3861
Epoch 31/100
83/83 [==============================] - ETA: 0s - loss: 1.4633 - accuracy: 0.4641
Epoch 31: val_loss did not improve from 1.57148
83/83 [==============================] - 95s 1s/step - loss: 1.4633 - accuracy: 0.4641 - val_loss: 1.6078 - val_accuracy: 0.3918
Epoch 32/100
83/83 [==============================] - ETA: 0s - loss: 1.4576 - accuracy: 0.4694
Epoch 32: val_loss did not improve from 1.57148
83/83 [==============================] - 94s 1s/step - loss: 1.4576 - accuracy: 0.4694 - val_loss: 1.6300 - val_accuracy: 0.3821
Epoch 32: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92m Layer (type)                Output Shape              Param #   [0m
[92m=================================================================[0m
[92m sequential_9 (Sequential)   (None, 512)               12127912  [0m
[92m                                                                 [0m
[92m dense_29 (Dense)            multiple                  3078      [0m
[92m                                                                 [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94m Layer (type)                Output Shape              Param #   [0m
[94m=================================================================[0m
[94m lambda_9 (Lambda)           (None, 75, 75, 2)         0         [0m
[94m                                                                 [0m
[94m batch_normalization_9 (Batc  (None, 75, 75, 2)        8         [0m
[94m hNormalization)                                                 [0m
[94m                                                                 [0m
[94m conv2d_27 (Conv2D)          (None, 75, 75, 32)        2336      [0m
[94m                                                                 [0m
[94m max_pooling2d_27 (MaxPoolin  (None, 37, 37, 32)       0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_28 (Conv2D)          (None, 37, 37, 128)       65664     [0m
[94m                                                                 [0m
[94m max_pooling2d_28 (MaxPoolin  (None, 18, 18, 128)      0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m conv2d_29 (Conv2D)          (None, 18, 18, 256)       1179904   [0m
[94m                                                                 [0m
[94m max_pooling2d_29 (MaxPoolin  (None, 9, 9, 256)        0         [0m
[94m g2D)                                                            [0m
[94m                                                                 [0m
[94m dropout_27 (Dropout)        (None, 9, 9, 256)         0         [0m
[94m                                                                 [0m
[94m flatten_9 (Flatten)         (None, 20736)             0         [0m
[94m                                                                 [0m
[94m dense_27 (Dense)            (None, 512)               10617344  [0m
[94m                                                                 [0m
[94m dropout_28 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m dense_28 (Dense)            (None, 512)               262656    [0m
[94m                                                                 [0m
[94m dropout_29 (Dropout)        (None, 512)               0         [0m
[94m                                                                 [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'jit_compile': False, 'is_legacy_optimizer': False, 'learning_rate': 1e-04, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 129s 10ms/step - loss: 1.5759 - accuracy: 0.3957
Testing Loss = 1.575910, Testing Accuracy = 0.395653
The data set contains images
  13433/Unknown - 122s 9ms/step13437/13437 [==============================] - 122s 9ms/step
[[0.14590802788734436, 0.13906793296337128, 0.06674803048372269, 0.32685428857803345, 0.1727200299501419, 0.14870165288448334], [0.03337446227669716, 0.10219956934452057, 0.3733457326889038, 0.07264398038387299, 0.1525895744562149, 0.2658466398715973], [0.1412734091281891, 0.07131454348564148, 0.14933428168296814, 0.2207670509815216, 0.26935383677482605, 0.14795684814453125], [0.04299406707286835, 0.0480223223567009, 0.44213855266571045, 0.05621236190199852, 0.2219923883676529, 0.18864034116268158], [0.1646994948387146, 0.17734768986701965, 0.04311491549015045, 0.3635188341140747, 0.12079786509275436, 0.13052113354206085], [0.5178955793380737, 0.0057084811851382256, 0.08342260122299194, 0.06496142596006393, 0.2974531650543213, 0.030558818951249123], [0.029648462310433388, 0.03702809289097786, 0.5244313478469849, 0.04818398132920265, 0.17716683447360992, 0.18354131281375885], [0.12806543707847595, 0.0627111867070198, 0.060711465775966644, 0.4199463129043579, 0.19568850100040436, 0.13287711143493652], [0.36655858159065247, 0.06672388315200806, 0.06741916388273239, 0.22744978964328766, 0.18594536185264587, 0.08590327948331833], [0.20342974364757538, 0.07116461545228958, 0.16490791738033295, 0.16004578769207, 0.26053330302238464, 0.13991856575012207]]
N of classes 6
$W^+/W^+$ (auc = 84.23 +- 0.0583 %)
$W^-/W^-$ (auc = 83.65 +- 0.0731 %)
$Z/Z$ (auc = 76.39 +- 0.2579 %)
$W^+/W^-$ (auc = 70.70 +- 0.1556 %)
$W^+/Z$$ (auc = 67.53 +- 0.1024 %)
$W^-/Z$ (auc = 68.87 +- 0.1360 %)
The summarized testing accuracy = 39.36 +- 0.2527 %, with the loss = 1.5790 +- 0.001744
