

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-27 21:11:42.445490
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 13s 71ms/step - loss: 11.8931 - accuracy: 0.2456 - val_loss: 8.2115 - val_accuracy: 0.2942

Epoch 00001: val_loss improved from inf to 8.21151, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 2/100
83/83 [==============================] - 6s 68ms/step - loss: 6.4651 - accuracy: 0.2723 - val_loss: 5.1601 - val_accuracy: 0.2978

Epoch 00002: val_loss improved from 8.21151 to 5.16007, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 3/100
83/83 [==============================] - 6s 69ms/step - loss: 4.4809 - accuracy: 0.2796 - val_loss: 3.9014 - val_accuracy: 0.3069

Epoch 00003: val_loss improved from 5.16007 to 3.90136, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 4/100
83/83 [==============================] - 6s 67ms/step - loss: 3.5500 - accuracy: 0.2864 - val_loss: 3.2086 - val_accuracy: 0.3017

Epoch 00004: val_loss improved from 3.90136 to 3.20864, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 5/100
83/83 [==============================] - 6s 68ms/step - loss: 2.9834 - accuracy: 0.2942 - val_loss: 2.7500 - val_accuracy: 0.3047

Epoch 00005: val_loss improved from 3.20864 to 2.75001, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 6/100
83/83 [==============================] - 6s 67ms/step - loss: 2.5968 - accuracy: 0.2932 - val_loss: 2.4264 - val_accuracy: 0.3078

Epoch 00006: val_loss improved from 2.75001 to 2.42640, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 7/100
83/83 [==============================] - 6s 68ms/step - loss: 2.3232 - accuracy: 0.2949 - val_loss: 2.1971 - val_accuracy: 0.3092

Epoch 00007: val_loss improved from 2.42640 to 2.19711, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 8/100
83/83 [==============================] - 6s 67ms/step - loss: 2.1269 - accuracy: 0.2981 - val_loss: 2.0334 - val_accuracy: 0.3095

Epoch 00008: val_loss improved from 2.19711 to 2.03345, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 9/100
83/83 [==============================] - 6s 68ms/step - loss: 1.9876 - accuracy: 0.2979 - val_loss: 1.9160 - val_accuracy: 0.3129

Epoch 00009: val_loss improved from 2.03345 to 1.91601, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 10/100
83/83 [==============================] - 6s 67ms/step - loss: 1.8886 - accuracy: 0.3003 - val_loss: 1.8324 - val_accuracy: 0.3136

Epoch 00010: val_loss improved from 1.91601 to 1.83243, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 11/100
83/83 [==============================] - 6s 67ms/step - loss: 1.8176 - accuracy: 0.2994 - val_loss: 1.7746 - val_accuracy: 0.3141

Epoch 00011: val_loss improved from 1.83243 to 1.77464, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 12/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7670 - accuracy: 0.3013 - val_loss: 1.7329 - val_accuracy: 0.3149

Epoch 00012: val_loss improved from 1.77464 to 1.73289, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 13/100
83/83 [==============================] - 6s 68ms/step - loss: 1.7311 - accuracy: 0.3022 - val_loss: 1.7050 - val_accuracy: 0.3167

Epoch 00013: val_loss improved from 1.73289 to 1.70498, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 14/100
83/83 [==============================] - 6s 67ms/step - loss: 1.7077 - accuracy: 0.3022 - val_loss: 1.6843 - val_accuracy: 0.3139

Epoch 00014: val_loss improved from 1.70498 to 1.68431, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 15/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6899 - accuracy: 0.3018 - val_loss: 1.6697 - val_accuracy: 0.3190

Epoch 00015: val_loss improved from 1.68431 to 1.66973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 16/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6776 - accuracy: 0.3027 - val_loss: 1.6597 - val_accuracy: 0.3181

Epoch 00016: val_loss improved from 1.66973 to 1.65971, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 17/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6683 - accuracy: 0.3019 - val_loss: 1.6508 - val_accuracy: 0.3173

Epoch 00017: val_loss improved from 1.65971 to 1.65079, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 18/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6606 - accuracy: 0.3062 - val_loss: 1.6468 - val_accuracy: 0.3159

Epoch 00018: val_loss improved from 1.65079 to 1.64676, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 19/100
83/83 [==============================] - 6s 67ms/step - loss: 1.6566 - accuracy: 0.3071 - val_loss: 1.6433 - val_accuracy: 0.3196

Epoch 00019: val_loss improved from 1.64676 to 1.64334, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 20/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6533 - accuracy: 0.3051 - val_loss: 1.6394 - val_accuracy: 0.3155

Epoch 00020: val_loss improved from 1.64334 to 1.63945, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 21/100
83/83 [==============================] - 6s 68ms/step - loss: 1.6481 - accuracy: 0.3063 - val_loss: 1.6368 - val_accuracy: 0.3194

Epoch 00021: val_loss improved from 1.63945 to 1.63679, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 22/100
83/83 [==============================] - 10s 120ms/step - loss: 1.6481 - accuracy: 0.3050 - val_loss: 1.6344 - val_accuracy: 0.3164

Epoch 00022: val_loss improved from 1.63679 to 1.63440, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 23/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6449 - accuracy: 0.3055 - val_loss: 1.6333 - val_accuracy: 0.3162

Epoch 00023: val_loss improved from 1.63440 to 1.63333, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 24/100
83/83 [==============================] - 8s 98ms/step - loss: 1.6437 - accuracy: 0.3031 - val_loss: 1.6323 - val_accuracy: 0.3184

Epoch 00024: val_loss improved from 1.63333 to 1.63230, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 25/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6416 - accuracy: 0.3053 - val_loss: 1.6315 - val_accuracy: 0.3172

Epoch 00025: val_loss improved from 1.63230 to 1.63151, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 26/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6411 - accuracy: 0.3052 - val_loss: 1.6307 - val_accuracy: 0.3172

Epoch 00026: val_loss improved from 1.63151 to 1.63070, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 27/100
83/83 [==============================] - 8s 98ms/step - loss: 1.6391 - accuracy: 0.3067 - val_loss: 1.6298 - val_accuracy: 0.3183

Epoch 00027: val_loss improved from 1.63070 to 1.62975, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 28/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6384 - accuracy: 0.3064 - val_loss: 1.6289 - val_accuracy: 0.3188

Epoch 00028: val_loss improved from 1.62975 to 1.62895, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 29/100
83/83 [==============================] - 8s 98ms/step - loss: 1.6377 - accuracy: 0.3074 - val_loss: 1.6283 - val_accuracy: 0.3197

Epoch 00029: val_loss improved from 1.62895 to 1.62835, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 30/100
83/83 [==============================] - 9s 107ms/step - loss: 1.6376 - accuracy: 0.3089 - val_loss: 1.6283 - val_accuracy: 0.3203

Epoch 00030: val_loss improved from 1.62835 to 1.62825, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 31/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6363 - accuracy: 0.3089 - val_loss: 1.6275 - val_accuracy: 0.3197

Epoch 00031: val_loss improved from 1.62825 to 1.62745, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 32/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6351 - accuracy: 0.3073 - val_loss: 1.6270 - val_accuracy: 0.3197

Epoch 00032: val_loss improved from 1.62745 to 1.62697, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 33/100
83/83 [==============================] - 10s 116ms/step - loss: 1.6350 - accuracy: 0.3088 - val_loss: 1.6283 - val_accuracy: 0.3199

Epoch 00033: val_loss did not improve from 1.62697
Epoch 34/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6353 - accuracy: 0.3090 - val_loss: 1.6269 - val_accuracy: 0.3202

Epoch 00034: val_loss improved from 1.62697 to 1.62690, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 35/100
83/83 [==============================] - 9s 114ms/step - loss: 1.6331 - accuracy: 0.3090 - val_loss: 1.6273 - val_accuracy: 0.3213

Epoch 00035: val_loss did not improve from 1.62690
Epoch 36/100
83/83 [==============================] - 8s 97ms/step - loss: 1.6339 - accuracy: 0.3087 - val_loss: 1.6271 - val_accuracy: 0.3189

Epoch 00036: val_loss did not improve from 1.62690
Epoch 37/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6330 - accuracy: 0.3087 - val_loss: 1.6272 - val_accuracy: 0.3209

Epoch 00037: val_loss did not improve from 1.62690
Epoch 38/100
83/83 [==============================] - 9s 113ms/step - loss: 1.6322 - accuracy: 0.3121 - val_loss: 1.6271 - val_accuracy: 0.3183

Epoch 00038: val_loss did not improve from 1.62690
Epoch 39/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6320 - accuracy: 0.3088 - val_loss: 1.6274 - val_accuracy: 0.3170

Epoch 00039: val_loss did not improve from 1.62690
Epoch 40/100
83/83 [==============================] - 10s 121ms/step - loss: 1.6299 - accuracy: 0.3121 - val_loss: 1.6267 - val_accuracy: 0.3213

Epoch 00040: val_loss improved from 1.62690 to 1.62666, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 41/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6306 - accuracy: 0.3103 - val_loss: 1.6266 - val_accuracy: 0.3207

Epoch 00041: val_loss improved from 1.62666 to 1.62659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/0
Epoch 42/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6292 - accuracy: 0.3131 - val_loss: 1.6269 - val_accuracy: 0.3205

Epoch 00042: val_loss did not improve from 1.62659
Epoch 43/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6295 - accuracy: 0.3117 - val_loss: 1.6266 - val_accuracy: 0.3193

Epoch 00043: val_loss did not improve from 1.62659
Epoch 44/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6294 - accuracy: 0.3123 - val_loss: 1.6282 - val_accuracy: 0.3192

Epoch 00044: val_loss did not improve from 1.62659
Epoch 45/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6291 - accuracy: 0.3123 - val_loss: 1.6285 - val_accuracy: 0.3184

Epoch 00045: val_loss did not improve from 1.62659
Epoch 46/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6295 - accuracy: 0.3141 - val_loss: 1.6291 - val_accuracy: 0.3178

Epoch 00046: val_loss did not improve from 1.62659
Epoch 47/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6273 - accuracy: 0.3140 - val_loss: 1.6293 - val_accuracy: 0.3185

Epoch 00047: val_loss did not improve from 1.62659
Epoch 48/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6272 - accuracy: 0.3151 - val_loss: 1.6306 - val_accuracy: 0.3165

Epoch 00048: val_loss did not improve from 1.62659
Epoch 49/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6269 - accuracy: 0.3149 - val_loss: 1.6309 - val_accuracy: 0.3166

Epoch 00049: val_loss did not improve from 1.62659
Epoch 50/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6267 - accuracy: 0.3165 - val_loss: 1.6310 - val_accuracy: 0.3178

Epoch 00050: val_loss did not improve from 1.62659
Epoch 00050: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 85s 6ms/step - loss: 1.6290 - accuracy: 0.3139
Testing Loss = 1.629037, Testing Accuracy = 0.313858
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 11s 129ms/step - loss: 12.0070 - accuracy: 0.2515 - val_loss: 8.3401 - val_accuracy: 0.2856

Epoch 00001: val_loss improved from inf to 8.34011, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 2/100
83/83 [==============================] - 11s 128ms/step - loss: 6.5750 - accuracy: 0.2752 - val_loss: 5.2506 - val_accuracy: 0.2923

Epoch 00002: val_loss improved from 8.34011 to 5.25055, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 3/100
83/83 [==============================] - 8s 101ms/step - loss: 4.5483 - accuracy: 0.2825 - val_loss: 3.9510 - val_accuracy: 0.3029

Epoch 00003: val_loss improved from 5.25055 to 3.95104, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 4/100
83/83 [==============================] - 7s 78ms/step - loss: 3.5873 - accuracy: 0.2888 - val_loss: 3.2341 - val_accuracy: 0.3061

Epoch 00004: val_loss improved from 3.95104 to 3.23409, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 5/100
83/83 [==============================] - 7s 80ms/step - loss: 3.0078 - accuracy: 0.2884 - val_loss: 2.7671 - val_accuracy: 0.3027

Epoch 00005: val_loss improved from 3.23409 to 2.76707, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 6/100
83/83 [==============================] - 7s 79ms/step - loss: 2.6115 - accuracy: 0.2924 - val_loss: 2.4363 - val_accuracy: 0.3076

Epoch 00006: val_loss improved from 2.76707 to 2.43632, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 7/100
83/83 [==============================] - 7s 80ms/step - loss: 2.3325 - accuracy: 0.2957 - val_loss: 2.2009 - val_accuracy: 0.3113

Epoch 00007: val_loss improved from 2.43632 to 2.20090, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 8/100
83/83 [==============================] - 7s 80ms/step - loss: 2.1321 - accuracy: 0.2967 - val_loss: 2.0360 - val_accuracy: 0.3113

Epoch 00008: val_loss improved from 2.20090 to 2.03603, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 9/100
83/83 [==============================] - 7s 81ms/step - loss: 1.9921 - accuracy: 0.2949 - val_loss: 1.9182 - val_accuracy: 0.3137

Epoch 00009: val_loss improved from 2.03603 to 1.91818, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 10/100
83/83 [==============================] - 7s 79ms/step - loss: 1.8910 - accuracy: 0.2982 - val_loss: 1.8345 - val_accuracy: 0.3114

Epoch 00010: val_loss improved from 1.91818 to 1.83447, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 11/100
83/83 [==============================] - 7s 81ms/step - loss: 1.8186 - accuracy: 0.3021 - val_loss: 1.7756 - val_accuracy: 0.3155

Epoch 00011: val_loss improved from 1.83447 to 1.77559, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 12/100
83/83 [==============================] - 7s 80ms/step - loss: 1.7706 - accuracy: 0.3032 - val_loss: 1.7345 - val_accuracy: 0.3141

Epoch 00012: val_loss improved from 1.77559 to 1.73454, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 13/100
83/83 [==============================] - 7s 79ms/step - loss: 1.7353 - accuracy: 0.3001 - val_loss: 1.7067 - val_accuracy: 0.3159

Epoch 00013: val_loss improved from 1.73454 to 1.70670, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 14/100
83/83 [==============================] - 6s 78ms/step - loss: 1.7104 - accuracy: 0.3035 - val_loss: 1.6868 - val_accuracy: 0.3176

Epoch 00014: val_loss improved from 1.70670 to 1.68682, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 15/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6913 - accuracy: 0.3031 - val_loss: 1.6722 - val_accuracy: 0.3173

Epoch 00015: val_loss improved from 1.68682 to 1.67223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 16/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6786 - accuracy: 0.3043 - val_loss: 1.6608 - val_accuracy: 0.3188

Epoch 00016: val_loss improved from 1.67223 to 1.66080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 17/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6687 - accuracy: 0.3056 - val_loss: 1.6534 - val_accuracy: 0.3188

Epoch 00017: val_loss improved from 1.66080 to 1.65336, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 18/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6627 - accuracy: 0.3031 - val_loss: 1.6479 - val_accuracy: 0.3186

Epoch 00018: val_loss improved from 1.65336 to 1.64787, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 19/100
83/83 [==============================] - 8s 90ms/step - loss: 1.6579 - accuracy: 0.3035 - val_loss: 1.6434 - val_accuracy: 0.3168

Epoch 00019: val_loss improved from 1.64787 to 1.64339, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 20/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6537 - accuracy: 0.3050 - val_loss: 1.6410 - val_accuracy: 0.3189

Epoch 00020: val_loss improved from 1.64339 to 1.64100, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 21/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6517 - accuracy: 0.3047 - val_loss: 1.6382 - val_accuracy: 0.3163

Epoch 00021: val_loss improved from 1.64100 to 1.63819, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 22/100
83/83 [==============================] - 9s 101ms/step - loss: 1.6472 - accuracy: 0.3076 - val_loss: 1.6357 - val_accuracy: 0.3186

Epoch 00022: val_loss improved from 1.63819 to 1.63575, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 23/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6457 - accuracy: 0.3058 - val_loss: 1.6345 - val_accuracy: 0.3179

Epoch 00023: val_loss improved from 1.63575 to 1.63454, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 24/100
83/83 [==============================] - 9s 114ms/step - loss: 1.6444 - accuracy: 0.3057 - val_loss: 1.6325 - val_accuracy: 0.3183

Epoch 00024: val_loss improved from 1.63454 to 1.63247, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 25/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6417 - accuracy: 0.3067 - val_loss: 1.6311 - val_accuracy: 0.3200

Epoch 00025: val_loss improved from 1.63247 to 1.63114, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 26/100
83/83 [==============================] - 10s 121ms/step - loss: 1.6399 - accuracy: 0.3078 - val_loss: 1.6309 - val_accuracy: 0.3191

Epoch 00026: val_loss improved from 1.63114 to 1.63094, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 27/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6398 - accuracy: 0.3073 - val_loss: 1.6296 - val_accuracy: 0.3182

Epoch 00027: val_loss improved from 1.63094 to 1.62965, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 28/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6388 - accuracy: 0.3067 - val_loss: 1.6296 - val_accuracy: 0.3184

Epoch 00028: val_loss improved from 1.62965 to 1.62963, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 29/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6377 - accuracy: 0.3091 - val_loss: 1.6298 - val_accuracy: 0.3185

Epoch 00029: val_loss did not improve from 1.62963
Epoch 30/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6363 - accuracy: 0.3091 - val_loss: 1.6293 - val_accuracy: 0.3171

Epoch 00030: val_loss improved from 1.62963 to 1.62925, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 31/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6367 - accuracy: 0.3081 - val_loss: 1.6285 - val_accuracy: 0.3195

Epoch 00031: val_loss improved from 1.62925 to 1.62853, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 32/100
83/83 [==============================] - 8s 96ms/step - loss: 1.6348 - accuracy: 0.3106 - val_loss: 1.6283 - val_accuracy: 0.3186

Epoch 00032: val_loss improved from 1.62853 to 1.62830, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 33/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6340 - accuracy: 0.3096 - val_loss: 1.6278 - val_accuracy: 0.3183

Epoch 00033: val_loss improved from 1.62830 to 1.62781, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 34/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6341 - accuracy: 0.3101 - val_loss: 1.6270 - val_accuracy: 0.3184

Epoch 00034: val_loss improved from 1.62781 to 1.62699, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 35/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6333 - accuracy: 0.3077 - val_loss: 1.6271 - val_accuracy: 0.3169

Epoch 00035: val_loss did not improve from 1.62699
Epoch 36/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6326 - accuracy: 0.3088 - val_loss: 1.6280 - val_accuracy: 0.3174

Epoch 00036: val_loss did not improve from 1.62699
Epoch 37/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6331 - accuracy: 0.3102 - val_loss: 1.6269 - val_accuracy: 0.3182

Epoch 00037: val_loss improved from 1.62699 to 1.62693, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/1
Epoch 38/100
83/83 [==============================] - 8s 98ms/step - loss: 1.6309 - accuracy: 0.3094 - val_loss: 1.6279 - val_accuracy: 0.3171

Epoch 00038: val_loss did not improve from 1.62693
Epoch 39/100
83/83 [==============================] - 9s 110ms/step - loss: 1.6307 - accuracy: 0.3098 - val_loss: 1.6271 - val_accuracy: 0.3172

Epoch 00039: val_loss did not improve from 1.62693
Epoch 40/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6313 - accuracy: 0.3125 - val_loss: 1.6278 - val_accuracy: 0.3173

Epoch 00040: val_loss did not improve from 1.62693
Epoch 41/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6309 - accuracy: 0.3118 - val_loss: 1.6278 - val_accuracy: 0.3176

Epoch 00041: val_loss did not improve from 1.62693
Epoch 42/100
83/83 [==============================] - 9s 106ms/step - loss: 1.6300 - accuracy: 0.3125 - val_loss: 1.6288 - val_accuracy: 0.3173

Epoch 00042: val_loss did not improve from 1.62693
Epoch 43/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6293 - accuracy: 0.3115 - val_loss: 1.6281 - val_accuracy: 0.3190

Epoch 00043: val_loss did not improve from 1.62693
Epoch 44/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6291 - accuracy: 0.3098 - val_loss: 1.6294 - val_accuracy: 0.3157

Epoch 00044: val_loss did not improve from 1.62693
Epoch 00044: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 80s 6ms/step - loss: 1.6293 - accuracy: 0.3124
Testing Loss = 1.629270, Testing Accuracy = 0.312444
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 11s 128ms/step - loss: 11.9608 - accuracy: 0.2526 - val_loss: 8.2877 - val_accuracy: 0.2910

Epoch 00001: val_loss improved from inf to 8.28766, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 2/100
83/83 [==============================] - 9s 102ms/step - loss: 6.5312 - accuracy: 0.2725 - val_loss: 5.2144 - val_accuracy: 0.2974

Epoch 00002: val_loss improved from 8.28766 to 5.21439, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 3/100
83/83 [==============================] - 11s 128ms/step - loss: 4.5263 - accuracy: 0.2862 - val_loss: 3.9358 - val_accuracy: 0.3076

Epoch 00003: val_loss improved from 5.21439 to 3.93579, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 4/100
83/83 [==============================] - 11s 128ms/step - loss: 3.5799 - accuracy: 0.2876 - val_loss: 3.2325 - val_accuracy: 0.3049

Epoch 00004: val_loss improved from 3.93579 to 3.23250, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 5/100
83/83 [==============================] - 11s 129ms/step - loss: 3.0050 - accuracy: 0.2905 - val_loss: 2.7632 - val_accuracy: 0.3109

Epoch 00005: val_loss improved from 3.23250 to 2.76322, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 6/100
83/83 [==============================] - 11s 129ms/step - loss: 2.6119 - accuracy: 0.2946 - val_loss: 2.4368 - val_accuracy: 0.3114

Epoch 00006: val_loss improved from 2.76322 to 2.43684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 7/100
83/83 [==============================] - 11s 128ms/step - loss: 2.3330 - accuracy: 0.2915 - val_loss: 2.2052 - val_accuracy: 0.3110

Epoch 00007: val_loss improved from 2.43684 to 2.20522, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 8/100
83/83 [==============================] - 11s 130ms/step - loss: 2.1353 - accuracy: 0.2957 - val_loss: 2.0381 - val_accuracy: 0.3140

Epoch 00008: val_loss improved from 2.20522 to 2.03810, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 9/100
83/83 [==============================] - 7s 79ms/step - loss: 1.9939 - accuracy: 0.2974 - val_loss: 1.9226 - val_accuracy: 0.3104

Epoch 00009: val_loss improved from 2.03810 to 1.92262, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 10/100
83/83 [==============================] - 7s 79ms/step - loss: 1.8927 - accuracy: 0.2978 - val_loss: 1.8368 - val_accuracy: 0.3163

Epoch 00010: val_loss improved from 1.92262 to 1.83680, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 11/100
83/83 [==============================] - 7s 79ms/step - loss: 1.8232 - accuracy: 0.2983 - val_loss: 1.7793 - val_accuracy: 0.3143

Epoch 00011: val_loss improved from 1.83680 to 1.77929, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 12/100
83/83 [==============================] - 7s 79ms/step - loss: 1.7725 - accuracy: 0.3014 - val_loss: 1.7366 - val_accuracy: 0.3162

Epoch 00012: val_loss improved from 1.77929 to 1.73663, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 13/100
83/83 [==============================] - 7s 79ms/step - loss: 1.7360 - accuracy: 0.2995 - val_loss: 1.7078 - val_accuracy: 0.3165

Epoch 00013: val_loss improved from 1.73663 to 1.70783, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 14/100
83/83 [==============================] - 7s 79ms/step - loss: 1.7113 - accuracy: 0.3025 - val_loss: 1.6871 - val_accuracy: 0.3189

Epoch 00014: val_loss improved from 1.70783 to 1.68710, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 15/100
83/83 [==============================] - 7s 80ms/step - loss: 1.6924 - accuracy: 0.3006 - val_loss: 1.6721 - val_accuracy: 0.3165

Epoch 00015: val_loss improved from 1.68710 to 1.67214, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 16/100
83/83 [==============================] - 7s 80ms/step - loss: 1.6803 - accuracy: 0.3032 - val_loss: 1.6624 - val_accuracy: 0.3165

Epoch 00016: val_loss improved from 1.67214 to 1.66238, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 17/100
83/83 [==============================] - 7s 81ms/step - loss: 1.6707 - accuracy: 0.3040 - val_loss: 1.6553 - val_accuracy: 0.3183

Epoch 00017: val_loss improved from 1.66238 to 1.65533, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 18/100
83/83 [==============================] - 6s 74ms/step - loss: 1.6635 - accuracy: 0.3058 - val_loss: 1.6481 - val_accuracy: 0.3195

Epoch 00018: val_loss improved from 1.65533 to 1.64810, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 19/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6581 - accuracy: 0.3041 - val_loss: 1.6438 - val_accuracy: 0.3187

Epoch 00019: val_loss improved from 1.64810 to 1.64383, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 20/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6534 - accuracy: 0.3051 - val_loss: 1.6410 - val_accuracy: 0.3199

Epoch 00020: val_loss improved from 1.64383 to 1.64096, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 21/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6495 - accuracy: 0.3061 - val_loss: 1.6386 - val_accuracy: 0.3183

Epoch 00021: val_loss improved from 1.64096 to 1.63861, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 22/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6488 - accuracy: 0.3079 - val_loss: 1.6370 - val_accuracy: 0.3172

Epoch 00022: val_loss improved from 1.63861 to 1.63696, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 23/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6464 - accuracy: 0.3056 - val_loss: 1.6342 - val_accuracy: 0.3181

Epoch 00023: val_loss improved from 1.63696 to 1.63418, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 24/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6450 - accuracy: 0.3051 - val_loss: 1.6332 - val_accuracy: 0.3180

Epoch 00024: val_loss improved from 1.63418 to 1.63324, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 25/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6410 - accuracy: 0.3085 - val_loss: 1.6316 - val_accuracy: 0.3184

Epoch 00025: val_loss improved from 1.63324 to 1.63156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 26/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6409 - accuracy: 0.3055 - val_loss: 1.6311 - val_accuracy: 0.3188

Epoch 00026: val_loss improved from 1.63156 to 1.63112, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 27/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6399 - accuracy: 0.3080 - val_loss: 1.6301 - val_accuracy: 0.3187

Epoch 00027: val_loss improved from 1.63112 to 1.63014, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 28/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6399 - accuracy: 0.3055 - val_loss: 1.6303 - val_accuracy: 0.3185

Epoch 00028: val_loss did not improve from 1.63014
Epoch 29/100
83/83 [==============================] - 8s 96ms/step - loss: 1.6369 - accuracy: 0.3070 - val_loss: 1.6295 - val_accuracy: 0.3174

Epoch 00029: val_loss improved from 1.63014 to 1.62945, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 30/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6368 - accuracy: 0.3079 - val_loss: 1.6287 - val_accuracy: 0.3184

Epoch 00030: val_loss improved from 1.62945 to 1.62871, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 31/100
83/83 [==============================] - 8s 97ms/step - loss: 1.6370 - accuracy: 0.3077 - val_loss: 1.6291 - val_accuracy: 0.3164

Epoch 00031: val_loss did not improve from 1.62871
Epoch 32/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6367 - accuracy: 0.3080 - val_loss: 1.6280 - val_accuracy: 0.3183

Epoch 00032: val_loss improved from 1.62871 to 1.62801, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 33/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6347 - accuracy: 0.3086 - val_loss: 1.6290 - val_accuracy: 0.3176

Epoch 00033: val_loss did not improve from 1.62801
Epoch 34/100
83/83 [==============================] - 9s 106ms/step - loss: 1.6348 - accuracy: 0.3092 - val_loss: 1.6283 - val_accuracy: 0.3163

Epoch 00034: val_loss did not improve from 1.62801
Epoch 35/100
83/83 [==============================] - 8s 96ms/step - loss: 1.6339 - accuracy: 0.3077 - val_loss: 1.6282 - val_accuracy: 0.3175

Epoch 00035: val_loss did not improve from 1.62801
Epoch 36/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6329 - accuracy: 0.3093 - val_loss: 1.6282 - val_accuracy: 0.3167

Epoch 00036: val_loss did not improve from 1.62801
Epoch 37/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6330 - accuracy: 0.3093 - val_loss: 1.6275 - val_accuracy: 0.3165

Epoch 00037: val_loss improved from 1.62801 to 1.62753, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/2
Epoch 38/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6311 - accuracy: 0.3114 - val_loss: 1.6276 - val_accuracy: 0.3164

Epoch 00038: val_loss did not improve from 1.62753
Epoch 39/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6316 - accuracy: 0.3099 - val_loss: 1.6284 - val_accuracy: 0.3178

Epoch 00039: val_loss did not improve from 1.62753
Epoch 40/100
83/83 [==============================] - 10s 124ms/step - loss: 1.6314 - accuracy: 0.3117 - val_loss: 1.6278 - val_accuracy: 0.3164

Epoch 00040: val_loss did not improve from 1.62753
Epoch 41/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6297 - accuracy: 0.3116 - val_loss: 1.6282 - val_accuracy: 0.3159

Epoch 00041: val_loss did not improve from 1.62753
Epoch 42/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6296 - accuracy: 0.3119 - val_loss: 1.6282 - val_accuracy: 0.3183

Epoch 00042: val_loss did not improve from 1.62753
Epoch 43/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6293 - accuracy: 0.3113 - val_loss: 1.6283 - val_accuracy: 0.3197

Epoch 00043: val_loss did not improve from 1.62753
Epoch 44/100
83/83 [==============================] - 8s 95ms/step - loss: 1.6285 - accuracy: 0.3113 - val_loss: 1.6281 - val_accuracy: 0.3184

Epoch 00044: val_loss did not improve from 1.62753
Epoch 45/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6297 - accuracy: 0.3138 - val_loss: 1.6296 - val_accuracy: 0.3166

Epoch 00045: val_loss did not improve from 1.62753
Epoch 46/100
83/83 [==============================] - 10s 120ms/step - loss: 1.6282 - accuracy: 0.3166 - val_loss: 1.6299 - val_accuracy: 0.3188

Epoch 00046: val_loss did not improve from 1.62753
Epoch 47/100
83/83 [==============================] - 8s 96ms/step - loss: 1.6280 - accuracy: 0.3150 - val_loss: 1.6300 - val_accuracy: 0.3189

Epoch 00047: val_loss did not improve from 1.62753
Epoch 00047: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 82s 6ms/step - loss: 1.6305 - accuracy: 0.3123
Testing Loss = 1.630521, Testing Accuracy = 0.312295
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 11s 129ms/step - loss: 11.9287 - accuracy: 0.2512 - val_loss: 8.2546 - val_accuracy: 0.2937

Epoch 00001: val_loss improved from inf to 8.25461, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 2/100
83/83 [==============================] - 11s 128ms/step - loss: 6.5110 - accuracy: 0.2724 - val_loss: 5.2047 - val_accuracy: 0.3018

Epoch 00002: val_loss improved from 8.25461 to 5.20465, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 3/100
83/83 [==============================] - 8s 95ms/step - loss: 4.5204 - accuracy: 0.2837 - val_loss: 3.9345 - val_accuracy: 0.3024

Epoch 00003: val_loss improved from 5.20465 to 3.93449, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 4/100
83/83 [==============================] - 11s 128ms/step - loss: 3.5798 - accuracy: 0.2877 - val_loss: 3.2303 - val_accuracy: 0.3082

Epoch 00004: val_loss improved from 3.93449 to 3.23026, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 5/100
83/83 [==============================] - 9s 106ms/step - loss: 3.0072 - accuracy: 0.2909 - val_loss: 2.7649 - val_accuracy: 0.3105

Epoch 00005: val_loss improved from 3.23026 to 2.76491, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 6/100
83/83 [==============================] - 11s 128ms/step - loss: 2.6135 - accuracy: 0.2896 - val_loss: 2.4394 - val_accuracy: 0.3065

Epoch 00006: val_loss improved from 2.76491 to 2.43941, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 7/100
83/83 [==============================] - 11s 127ms/step - loss: 2.3351 - accuracy: 0.2941 - val_loss: 2.2055 - val_accuracy: 0.3104

Epoch 00007: val_loss improved from 2.43941 to 2.20546, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 8/100
83/83 [==============================] - 11s 127ms/step - loss: 2.1386 - accuracy: 0.2940 - val_loss: 2.0398 - val_accuracy: 0.3127

Epoch 00008: val_loss improved from 2.20546 to 2.03983, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 9/100
83/83 [==============================] - 11s 128ms/step - loss: 1.9962 - accuracy: 0.2983 - val_loss: 1.9224 - val_accuracy: 0.3093

Epoch 00009: val_loss improved from 2.03983 to 1.92238, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 10/100
83/83 [==============================] - 11s 128ms/step - loss: 1.8939 - accuracy: 0.2984 - val_loss: 1.8377 - val_accuracy: 0.3152

Epoch 00010: val_loss improved from 1.92238 to 1.83774, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 11/100
83/83 [==============================] - 11s 128ms/step - loss: 1.8222 - accuracy: 0.3020 - val_loss: 1.7797 - val_accuracy: 0.3152

Epoch 00011: val_loss improved from 1.83774 to 1.77973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 12/100
83/83 [==============================] - 11s 129ms/step - loss: 1.7733 - accuracy: 0.2995 - val_loss: 1.7375 - val_accuracy: 0.3169

Epoch 00012: val_loss improved from 1.77973 to 1.73753, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 13/100
83/83 [==============================] - 7s 79ms/step - loss: 1.7365 - accuracy: 0.3017 - val_loss: 1.7084 - val_accuracy: 0.3165

Epoch 00013: val_loss improved from 1.73753 to 1.70838, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 14/100
83/83 [==============================] - 7s 81ms/step - loss: 1.7125 - accuracy: 0.2997 - val_loss: 1.6888 - val_accuracy: 0.3153

Epoch 00014: val_loss improved from 1.70838 to 1.68878, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 15/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6931 - accuracy: 0.3022 - val_loss: 1.6738 - val_accuracy: 0.3156

Epoch 00015: val_loss improved from 1.68878 to 1.67379, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 16/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6818 - accuracy: 0.3001 - val_loss: 1.6630 - val_accuracy: 0.3175

Epoch 00016: val_loss improved from 1.67379 to 1.66296, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 17/100
83/83 [==============================] - 7s 80ms/step - loss: 1.6712 - accuracy: 0.3003 - val_loss: 1.6539 - val_accuracy: 0.3187

Epoch 00017: val_loss improved from 1.66296 to 1.65389, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 18/100
83/83 [==============================] - 7s 80ms/step - loss: 1.6645 - accuracy: 0.3023 - val_loss: 1.6496 - val_accuracy: 0.3146

Epoch 00018: val_loss improved from 1.65389 to 1.64958, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 19/100
83/83 [==============================] - 7s 81ms/step - loss: 1.6582 - accuracy: 0.3063 - val_loss: 1.6453 - val_accuracy: 0.3177

Epoch 00019: val_loss improved from 1.64958 to 1.64530, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 20/100
83/83 [==============================] - 7s 82ms/step - loss: 1.6548 - accuracy: 0.3048 - val_loss: 1.6411 - val_accuracy: 0.3154

Epoch 00020: val_loss improved from 1.64530 to 1.64112, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 21/100
83/83 [==============================] - 7s 81ms/step - loss: 1.6512 - accuracy: 0.3043 - val_loss: 1.6382 - val_accuracy: 0.3193

Epoch 00021: val_loss improved from 1.64112 to 1.63824, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 22/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6492 - accuracy: 0.3042 - val_loss: 1.6363 - val_accuracy: 0.3166

Epoch 00022: val_loss improved from 1.63824 to 1.63631, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 23/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6458 - accuracy: 0.3031 - val_loss: 1.6349 - val_accuracy: 0.3181

Epoch 00023: val_loss improved from 1.63631 to 1.63490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 24/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6441 - accuracy: 0.3043 - val_loss: 1.6330 - val_accuracy: 0.3186

Epoch 00024: val_loss improved from 1.63490 to 1.63302, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 25/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6424 - accuracy: 0.3043 - val_loss: 1.6317 - val_accuracy: 0.3185

Epoch 00025: val_loss improved from 1.63302 to 1.63171, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 26/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6421 - accuracy: 0.3069 - val_loss: 1.6309 - val_accuracy: 0.3191

Epoch 00026: val_loss improved from 1.63171 to 1.63088, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 27/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6400 - accuracy: 0.3076 - val_loss: 1.6309 - val_accuracy: 0.3187

Epoch 00027: val_loss did not improve from 1.63088
Epoch 28/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6390 - accuracy: 0.3062 - val_loss: 1.6296 - val_accuracy: 0.3203

Epoch 00028: val_loss improved from 1.63088 to 1.62960, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 29/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6372 - accuracy: 0.3079 - val_loss: 1.6292 - val_accuracy: 0.3197

Epoch 00029: val_loss improved from 1.62960 to 1.62924, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 30/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6364 - accuracy: 0.3086 - val_loss: 1.6282 - val_accuracy: 0.3178

Epoch 00030: val_loss improved from 1.62924 to 1.62821, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 31/100
83/83 [==============================] - 10s 126ms/step - loss: 1.6359 - accuracy: 0.3094 - val_loss: 1.6276 - val_accuracy: 0.3195

Epoch 00031: val_loss improved from 1.62821 to 1.62756, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 32/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6359 - accuracy: 0.3072 - val_loss: 1.6282 - val_accuracy: 0.3204

Epoch 00032: val_loss did not improve from 1.62756
Epoch 33/100
83/83 [==============================] - 8s 97ms/step - loss: 1.6337 - accuracy: 0.3086 - val_loss: 1.6275 - val_accuracy: 0.3193

Epoch 00033: val_loss improved from 1.62756 to 1.62750, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 34/100
83/83 [==============================] - 8s 98ms/step - loss: 1.6334 - accuracy: 0.3091 - val_loss: 1.6271 - val_accuracy: 0.3213

Epoch 00034: val_loss improved from 1.62750 to 1.62714, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 35/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6330 - accuracy: 0.3108 - val_loss: 1.6266 - val_accuracy: 0.3187

Epoch 00035: val_loss improved from 1.62714 to 1.62657, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 36/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6329 - accuracy: 0.3085 - val_loss: 1.6264 - val_accuracy: 0.3195

Epoch 00036: val_loss improved from 1.62657 to 1.62636, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 37/100
83/83 [==============================] - 8s 98ms/step - loss: 1.6326 - accuracy: 0.3087 - val_loss: 1.6259 - val_accuracy: 0.3198

Epoch 00037: val_loss improved from 1.62636 to 1.62590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/3
Epoch 38/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6318 - accuracy: 0.3088 - val_loss: 1.6259 - val_accuracy: 0.3187

Epoch 00038: val_loss did not improve from 1.62590
Epoch 39/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6307 - accuracy: 0.3087 - val_loss: 1.6268 - val_accuracy: 0.3187

Epoch 00039: val_loss did not improve from 1.62590
Epoch 40/100
83/83 [==============================] - 8s 96ms/step - loss: 1.6314 - accuracy: 0.3113 - val_loss: 1.6268 - val_accuracy: 0.3172

Epoch 00040: val_loss did not improve from 1.62590
Epoch 41/100
83/83 [==============================] - 9s 106ms/step - loss: 1.6293 - accuracy: 0.3113 - val_loss: 1.6260 - val_accuracy: 0.3189

Epoch 00041: val_loss did not improve from 1.62590
Epoch 42/100
83/83 [==============================] - 10s 127ms/step - loss: 1.6289 - accuracy: 0.3119 - val_loss: 1.6274 - val_accuracy: 0.3168

Epoch 00042: val_loss did not improve from 1.62590
Epoch 43/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6301 - accuracy: 0.3111 - val_loss: 1.6267 - val_accuracy: 0.3177

Epoch 00043: val_loss did not improve from 1.62590
Epoch 44/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6289 - accuracy: 0.3131 - val_loss: 1.6267 - val_accuracy: 0.3182

Epoch 00044: val_loss did not improve from 1.62590
Epoch 45/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6282 - accuracy: 0.3126 - val_loss: 1.6262 - val_accuracy: 0.3165

Epoch 00045: val_loss did not improve from 1.62590
Epoch 46/100
83/83 [==============================] - 9s 103ms/step - loss: 1.6273 - accuracy: 0.3125 - val_loss: 1.6266 - val_accuracy: 0.3206

Epoch 00046: val_loss did not improve from 1.62590
Epoch 47/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6283 - accuracy: 0.3114 - val_loss: 1.6273 - val_accuracy: 0.3188

Epoch 00047: val_loss did not improve from 1.62590
Epoch 00047: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 83s 6ms/step - loss: 1.6287 - accuracy: 0.3133
Testing Loss = 1.628708, Testing Accuracy = 0.313263
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 11s 119ms/step - loss: 11.8312 - accuracy: 0.2478 - val_loss: 8.1415 - val_accuracy: 0.2919

Epoch 00001: val_loss improved from inf to 8.14149, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 2/100
83/83 [==============================] - 11s 128ms/step - loss: 6.4105 - accuracy: 0.2750 - val_loss: 5.1303 - val_accuracy: 0.2971

Epoch 00002: val_loss improved from 8.14149 to 5.13034, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 3/100
83/83 [==============================] - 11s 128ms/step - loss: 4.4555 - accuracy: 0.2840 - val_loss: 3.8833 - val_accuracy: 0.3031

Epoch 00003: val_loss improved from 5.13034 to 3.88330, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 4/100
83/83 [==============================] - 11s 129ms/step - loss: 3.5373 - accuracy: 0.2875 - val_loss: 3.1958 - val_accuracy: 0.3039

Epoch 00004: val_loss improved from 3.88330 to 3.19583, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 5/100
83/83 [==============================] - 9s 107ms/step - loss: 2.9757 - accuracy: 0.2913 - val_loss: 2.7408 - val_accuracy: 0.3051

Epoch 00005: val_loss improved from 3.19583 to 2.74075, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 6/100
83/83 [==============================] - 11s 129ms/step - loss: 2.5903 - accuracy: 0.2939 - val_loss: 2.4202 - val_accuracy: 0.3063

Epoch 00006: val_loss improved from 2.74075 to 2.42019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 7/100
83/83 [==============================] - 11s 127ms/step - loss: 2.3182 - accuracy: 0.2944 - val_loss: 2.1919 - val_accuracy: 0.3070

Epoch 00007: val_loss improved from 2.42019 to 2.19189, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 8/100
83/83 [==============================] - 10s 122ms/step - loss: 2.1215 - accuracy: 0.2956 - val_loss: 2.0257 - val_accuracy: 0.3140

Epoch 00008: val_loss improved from 2.19189 to 2.02569, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 9/100
83/83 [==============================] - 11s 129ms/step - loss: 1.9829 - accuracy: 0.2962 - val_loss: 1.9125 - val_accuracy: 0.3084

Epoch 00009: val_loss improved from 2.02569 to 1.91250, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 10/100
83/83 [==============================] - 11s 128ms/step - loss: 1.8834 - accuracy: 0.2997 - val_loss: 1.8299 - val_accuracy: 0.3125

Epoch 00010: val_loss improved from 1.91250 to 1.82992, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 11/100
83/83 [==============================] - 11s 128ms/step - loss: 1.8144 - accuracy: 0.2973 - val_loss: 1.7729 - val_accuracy: 0.3181

Epoch 00011: val_loss improved from 1.82992 to 1.77292, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 12/100
83/83 [==============================] - 11s 128ms/step - loss: 1.7668 - accuracy: 0.3022 - val_loss: 1.7322 - val_accuracy: 0.3126

Epoch 00012: val_loss improved from 1.77292 to 1.73220, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 13/100
83/83 [==============================] - 11s 128ms/step - loss: 1.7308 - accuracy: 0.3026 - val_loss: 1.7026 - val_accuracy: 0.3197

Epoch 00013: val_loss improved from 1.73220 to 1.70264, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 14/100
83/83 [==============================] - 11s 127ms/step - loss: 1.7078 - accuracy: 0.3005 - val_loss: 1.6830 - val_accuracy: 0.3203

Epoch 00014: val_loss improved from 1.70264 to 1.68297, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 15/100
83/83 [==============================] - 10s 122ms/step - loss: 1.6892 - accuracy: 0.3020 - val_loss: 1.6691 - val_accuracy: 0.3164

Epoch 00015: val_loss improved from 1.68297 to 1.66906, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 16/100
83/83 [==============================] - 7s 80ms/step - loss: 1.6766 - accuracy: 0.3034 - val_loss: 1.6590 - val_accuracy: 0.3192

Epoch 00016: val_loss improved from 1.66906 to 1.65896, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 17/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6697 - accuracy: 0.3012 - val_loss: 1.6512 - val_accuracy: 0.3166

Epoch 00017: val_loss improved from 1.65896 to 1.65122, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 18/100
83/83 [==============================] - 7s 80ms/step - loss: 1.6622 - accuracy: 0.3040 - val_loss: 1.6447 - val_accuracy: 0.3208

Epoch 00018: val_loss improved from 1.65122 to 1.64468, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 19/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6560 - accuracy: 0.3034 - val_loss: 1.6409 - val_accuracy: 0.3186

Epoch 00019: val_loss improved from 1.64468 to 1.64092, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 20/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6519 - accuracy: 0.3041 - val_loss: 1.6379 - val_accuracy: 0.3197

Epoch 00020: val_loss improved from 1.64092 to 1.63794, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 21/100
83/83 [==============================] - 7s 81ms/step - loss: 1.6490 - accuracy: 0.3033 - val_loss: 1.6367 - val_accuracy: 0.3192

Epoch 00021: val_loss improved from 1.63794 to 1.63668, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 22/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6464 - accuracy: 0.3063 - val_loss: 1.6340 - val_accuracy: 0.3198

Epoch 00022: val_loss improved from 1.63668 to 1.63396, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 23/100
83/83 [==============================] - 7s 80ms/step - loss: 1.6438 - accuracy: 0.3044 - val_loss: 1.6323 - val_accuracy: 0.3185

Epoch 00023: val_loss improved from 1.63396 to 1.63226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 24/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6428 - accuracy: 0.3053 - val_loss: 1.6313 - val_accuracy: 0.3189

Epoch 00024: val_loss improved from 1.63226 to 1.63128, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 25/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6424 - accuracy: 0.3050 - val_loss: 1.6309 - val_accuracy: 0.3212

Epoch 00025: val_loss improved from 1.63128 to 1.63092, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 26/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6405 - accuracy: 0.3046 - val_loss: 1.6296 - val_accuracy: 0.3189

Epoch 00026: val_loss improved from 1.63092 to 1.62961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 27/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6408 - accuracy: 0.3053 - val_loss: 1.6294 - val_accuracy: 0.3173

Epoch 00027: val_loss improved from 1.62961 to 1.62936, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 28/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6386 - accuracy: 0.3058 - val_loss: 1.6282 - val_accuracy: 0.3186

Epoch 00028: val_loss improved from 1.62936 to 1.62824, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 29/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6365 - accuracy: 0.3072 - val_loss: 1.6274 - val_accuracy: 0.3218

Epoch 00029: val_loss improved from 1.62824 to 1.62736, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 30/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6374 - accuracy: 0.3079 - val_loss: 1.6277 - val_accuracy: 0.3205

Epoch 00030: val_loss did not improve from 1.62736
Epoch 31/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6358 - accuracy: 0.3072 - val_loss: 1.6274 - val_accuracy: 0.3183

Epoch 00031: val_loss did not improve from 1.62736
Epoch 32/100
83/83 [==============================] - 10s 125ms/step - loss: 1.6357 - accuracy: 0.3078 - val_loss: 1.6269 - val_accuracy: 0.3192

Epoch 00032: val_loss improved from 1.62736 to 1.62695, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 33/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6334 - accuracy: 0.3100 - val_loss: 1.6265 - val_accuracy: 0.3186

Epoch 00033: val_loss improved from 1.62695 to 1.62648, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 34/100
83/83 [==============================] - 9s 110ms/step - loss: 1.6344 - accuracy: 0.3075 - val_loss: 1.6266 - val_accuracy: 0.3200

Epoch 00034: val_loss did not improve from 1.62648
Epoch 35/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6329 - accuracy: 0.3126 - val_loss: 1.6267 - val_accuracy: 0.3190

Epoch 00035: val_loss did not improve from 1.62648
Epoch 36/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6324 - accuracy: 0.3099 - val_loss: 1.6266 - val_accuracy: 0.3199

Epoch 00036: val_loss did not improve from 1.62648
Epoch 37/100
83/83 [==============================] - 10s 115ms/step - loss: 1.6332 - accuracy: 0.3091 - val_loss: 1.6258 - val_accuracy: 0.3193

Epoch 00037: val_loss improved from 1.62648 to 1.62584, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 38/100
83/83 [==============================] - 9s 112ms/step - loss: 1.6321 - accuracy: 0.3082 - val_loss: 1.6266 - val_accuracy: 0.3187

Epoch 00038: val_loss did not improve from 1.62584
Epoch 39/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6309 - accuracy: 0.3116 - val_loss: 1.6257 - val_accuracy: 0.3189

Epoch 00039: val_loss improved from 1.62584 to 1.62571, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/4
Epoch 40/100
83/83 [==============================] - 8s 96ms/step - loss: 1.6309 - accuracy: 0.3112 - val_loss: 1.6263 - val_accuracy: 0.3188

Epoch 00040: val_loss did not improve from 1.62571
Epoch 41/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6310 - accuracy: 0.3098 - val_loss: 1.6257 - val_accuracy: 0.3222

Epoch 00041: val_loss did not improve from 1.62571
Epoch 42/100
83/83 [==============================] - 9s 106ms/step - loss: 1.6293 - accuracy: 0.3113 - val_loss: 1.6261 - val_accuracy: 0.3186

Epoch 00042: val_loss did not improve from 1.62571
Epoch 43/100
83/83 [==============================] - 8s 99ms/step - loss: 1.6299 - accuracy: 0.3108 - val_loss: 1.6259 - val_accuracy: 0.3191

Epoch 00043: val_loss did not improve from 1.62571
Epoch 44/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6294 - accuracy: 0.3129 - val_loss: 1.6274 - val_accuracy: 0.3193

Epoch 00044: val_loss did not improve from 1.62571
Epoch 45/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6300 - accuracy: 0.3102 - val_loss: 1.6271 - val_accuracy: 0.3201

Epoch 00045: val_loss did not improve from 1.62571
Epoch 46/100
83/83 [==============================] - 9s 102ms/step - loss: 1.6293 - accuracy: 0.3119 - val_loss: 1.6266 - val_accuracy: 0.3221

Epoch 00046: val_loss did not improve from 1.62571
Epoch 47/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6282 - accuracy: 0.3142 - val_loss: 1.6273 - val_accuracy: 0.3189

Epoch 00047: val_loss did not improve from 1.62571
Epoch 00047: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 84s 6ms/step - loss: 1.6286 - accuracy: 0.3141
Testing Loss = 1.628553, Testing Accuracy = 0.314082
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 11s 124ms/step - loss: 11.9252 - accuracy: 0.2458 - val_loss: 8.2453 - val_accuracy: 0.2873

Epoch 00001: val_loss improved from inf to 8.24528, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 2/100
83/83 [==============================] - 11s 126ms/step - loss: 6.5121 - accuracy: 0.2747 - val_loss: 5.2099 - val_accuracy: 0.2999

Epoch 00002: val_loss improved from 8.24528 to 5.20995, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 3/100
83/83 [==============================] - 11s 127ms/step - loss: 4.5255 - accuracy: 0.2851 - val_loss: 3.9400 - val_accuracy: 0.3062

Epoch 00003: val_loss improved from 5.20995 to 3.93997, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 4/100
83/83 [==============================] - 8s 94ms/step - loss: 3.5863 - accuracy: 0.2846 - val_loss: 3.2361 - val_accuracy: 0.3083

Epoch 00004: val_loss improved from 3.93997 to 3.23609, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 5/100
83/83 [==============================] - 8s 100ms/step - loss: 3.0116 - accuracy: 0.2945 - val_loss: 2.7709 - val_accuracy: 0.3073

Epoch 00005: val_loss improved from 3.23609 to 2.77093, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 6/100
83/83 [==============================] - 8s 99ms/step - loss: 2.6183 - accuracy: 0.2913 - val_loss: 2.4439 - val_accuracy: 0.3095

Epoch 00006: val_loss improved from 2.77093 to 2.44386, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 7/100
83/83 [==============================] - 11s 127ms/step - loss: 2.3395 - accuracy: 0.2930 - val_loss: 2.2096 - val_accuracy: 0.3082

Epoch 00007: val_loss improved from 2.44386 to 2.20964, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 8/100
83/83 [==============================] - 8s 94ms/step - loss: 2.1402 - accuracy: 0.2995 - val_loss: 2.0435 - val_accuracy: 0.3111

Epoch 00008: val_loss improved from 2.20964 to 2.04352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 9/100
83/83 [==============================] - 11s 127ms/step - loss: 1.9989 - accuracy: 0.2975 - val_loss: 1.9239 - val_accuracy: 0.3174

Epoch 00009: val_loss improved from 2.04352 to 1.92390, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 10/100
83/83 [==============================] - 9s 103ms/step - loss: 1.8992 - accuracy: 0.2985 - val_loss: 1.8421 - val_accuracy: 0.3107

Epoch 00010: val_loss improved from 1.92390 to 1.84205, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 11/100
83/83 [==============================] - 11s 127ms/step - loss: 1.8255 - accuracy: 0.3007 - val_loss: 1.7829 - val_accuracy: 0.3109

Epoch 00011: val_loss improved from 1.84205 to 1.78293, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 12/100
83/83 [==============================] - 10s 121ms/step - loss: 1.7741 - accuracy: 0.3019 - val_loss: 1.7414 - val_accuracy: 0.3129

Epoch 00012: val_loss improved from 1.78293 to 1.74136, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 13/100
83/83 [==============================] - 11s 127ms/step - loss: 1.7389 - accuracy: 0.3013 - val_loss: 1.7102 - val_accuracy: 0.3170

Epoch 00013: val_loss improved from 1.74136 to 1.71019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 14/100
83/83 [==============================] - 11s 127ms/step - loss: 1.7133 - accuracy: 0.3038 - val_loss: 1.6902 - val_accuracy: 0.3152

Epoch 00014: val_loss improved from 1.71019 to 1.69024, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 15/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6952 - accuracy: 0.3019 - val_loss: 1.6747 - val_accuracy: 0.3154

Epoch 00015: val_loss improved from 1.69024 to 1.67466, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 16/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6814 - accuracy: 0.3021 - val_loss: 1.6628 - val_accuracy: 0.3153

Epoch 00016: val_loss improved from 1.67466 to 1.66283, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 17/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6726 - accuracy: 0.3021 - val_loss: 1.6556 - val_accuracy: 0.3165

Epoch 00017: val_loss improved from 1.66283 to 1.65557, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 18/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6643 - accuracy: 0.3017 - val_loss: 1.6491 - val_accuracy: 0.3193

Epoch 00018: val_loss improved from 1.65557 to 1.64908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 19/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6585 - accuracy: 0.3060 - val_loss: 1.6457 - val_accuracy: 0.3154

Epoch 00019: val_loss improved from 1.64908 to 1.64569, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 20/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6553 - accuracy: 0.3033 - val_loss: 1.6418 - val_accuracy: 0.3186

Epoch 00020: val_loss improved from 1.64569 to 1.64181, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 21/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6510 - accuracy: 0.3051 - val_loss: 1.6388 - val_accuracy: 0.3172

Epoch 00021: val_loss improved from 1.64181 to 1.63875, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 22/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6483 - accuracy: 0.3055 - val_loss: 1.6368 - val_accuracy: 0.3167

Epoch 00022: val_loss improved from 1.63875 to 1.63681, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 23/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6471 - accuracy: 0.3056 - val_loss: 1.6350 - val_accuracy: 0.3149

Epoch 00023: val_loss improved from 1.63681 to 1.63503, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 24/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6440 - accuracy: 0.3051 - val_loss: 1.6335 - val_accuracy: 0.3165

Epoch 00024: val_loss improved from 1.63503 to 1.63352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 25/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6428 - accuracy: 0.3067 - val_loss: 1.6330 - val_accuracy: 0.3133

Epoch 00025: val_loss improved from 1.63352 to 1.63298, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 26/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6418 - accuracy: 0.3083 - val_loss: 1.6325 - val_accuracy: 0.3149

Epoch 00026: val_loss improved from 1.63298 to 1.63246, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 27/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6410 - accuracy: 0.3098 - val_loss: 1.6306 - val_accuracy: 0.3153

Epoch 00027: val_loss improved from 1.63246 to 1.63058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 28/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6398 - accuracy: 0.3073 - val_loss: 1.6309 - val_accuracy: 0.3188

Epoch 00028: val_loss did not improve from 1.63058
Epoch 29/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6383 - accuracy: 0.3074 - val_loss: 1.6294 - val_accuracy: 0.3177

Epoch 00029: val_loss improved from 1.63058 to 1.62944, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 30/100
83/83 [==============================] - 6s 74ms/step - loss: 1.6384 - accuracy: 0.3106 - val_loss: 1.6293 - val_accuracy: 0.3171

Epoch 00030: val_loss improved from 1.62944 to 1.62928, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 31/100
83/83 [==============================] - 6s 76ms/step - loss: 1.6357 - accuracy: 0.3080 - val_loss: 1.6288 - val_accuracy: 0.3202

Epoch 00031: val_loss improved from 1.62928 to 1.62885, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 32/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6363 - accuracy: 0.3084 - val_loss: 1.6291 - val_accuracy: 0.3193

Epoch 00032: val_loss did not improve from 1.62885
Epoch 33/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6355 - accuracy: 0.3096 - val_loss: 1.6291 - val_accuracy: 0.3186

Epoch 00033: val_loss did not improve from 1.62885
Epoch 34/100
83/83 [==============================] - 6s 76ms/step - loss: 1.6343 - accuracy: 0.3104 - val_loss: 1.6285 - val_accuracy: 0.3195

Epoch 00034: val_loss improved from 1.62885 to 1.62851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 35/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6348 - accuracy: 0.3091 - val_loss: 1.6284 - val_accuracy: 0.3183

Epoch 00035: val_loss improved from 1.62851 to 1.62841, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 36/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6342 - accuracy: 0.3091 - val_loss: 1.6281 - val_accuracy: 0.3193

Epoch 00036: val_loss improved from 1.62841 to 1.62811, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 37/100
83/83 [==============================] - 6s 76ms/step - loss: 1.6332 - accuracy: 0.3085 - val_loss: 1.6293 - val_accuracy: 0.3186

Epoch 00037: val_loss did not improve from 1.62811
Epoch 38/100
83/83 [==============================] - 8s 96ms/step - loss: 1.6317 - accuracy: 0.3119 - val_loss: 1.6281 - val_accuracy: 0.3187

Epoch 00038: val_loss improved from 1.62811 to 1.62809, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/5
Epoch 39/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6315 - accuracy: 0.3111 - val_loss: 1.6294 - val_accuracy: 0.3152

Epoch 00039: val_loss did not improve from 1.62809
Epoch 40/100
83/83 [==============================] - 9s 109ms/step - loss: 1.6312 - accuracy: 0.3116 - val_loss: 1.6293 - val_accuracy: 0.3170

Epoch 00040: val_loss did not improve from 1.62809
Epoch 41/100
83/83 [==============================] - 10s 116ms/step - loss: 1.6313 - accuracy: 0.3131 - val_loss: 1.6291 - val_accuracy: 0.3175

Epoch 00041: val_loss did not improve from 1.62809
Epoch 42/100
83/83 [==============================] - 8s 101ms/step - loss: 1.6309 - accuracy: 0.3119 - val_loss: 1.6285 - val_accuracy: 0.3180

Epoch 00042: val_loss did not improve from 1.62809
Epoch 43/100
83/83 [==============================] - 10s 114ms/step - loss: 1.6298 - accuracy: 0.3135 - val_loss: 1.6287 - val_accuracy: 0.3200

Epoch 00043: val_loss did not improve from 1.62809
Epoch 44/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6290 - accuracy: 0.3138 - val_loss: 1.6292 - val_accuracy: 0.3167

Epoch 00044: val_loss did not improve from 1.62809
Epoch 45/100
83/83 [==============================] - 8s 93ms/step - loss: 1.6302 - accuracy: 0.3125 - val_loss: 1.6292 - val_accuracy: 0.3214

Epoch 00045: val_loss did not improve from 1.62809
Epoch 46/100
83/83 [==============================] - 10s 121ms/step - loss: 1.6294 - accuracy: 0.3143 - val_loss: 1.6307 - val_accuracy: 0.3164

Epoch 00046: val_loss did not improve from 1.62809
Epoch 00046: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 76s 6ms/step - loss: 1.6305 - accuracy: 0.3150
Testing Loss = 1.630459, Testing Accuracy = 0.315049
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 11s 124ms/step - loss: 11.8646 - accuracy: 0.2481 - val_loss: 8.1722 - val_accuracy: 0.2907

Epoch 00001: val_loss improved from inf to 8.17217, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 2/100
83/83 [==============================] - 10s 125ms/step - loss: 6.4466 - accuracy: 0.2741 - val_loss: 5.1592 - val_accuracy: 0.3030

Epoch 00002: val_loss improved from 8.17217 to 5.15919, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 3/100
83/83 [==============================] - 11s 127ms/step - loss: 4.4846 - accuracy: 0.2807 - val_loss: 3.9097 - val_accuracy: 0.3063

Epoch 00003: val_loss improved from 5.15919 to 3.90973, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 4/100
83/83 [==============================] - 10s 119ms/step - loss: 3.5582 - accuracy: 0.2859 - val_loss: 3.2131 - val_accuracy: 0.3070

Epoch 00004: val_loss improved from 3.90973 to 3.21306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 5/100
83/83 [==============================] - 10s 117ms/step - loss: 2.9910 - accuracy: 0.2903 - val_loss: 2.7552 - val_accuracy: 0.3045

Epoch 00005: val_loss improved from 3.21306 to 2.75525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 6/100
83/83 [==============================] - 9s 109ms/step - loss: 2.6039 - accuracy: 0.2910 - val_loss: 2.4299 - val_accuracy: 0.3059

Epoch 00006: val_loss improved from 2.75525 to 2.42986, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 7/100
83/83 [==============================] - 9s 103ms/step - loss: 2.3268 - accuracy: 0.2959 - val_loss: 2.2005 - val_accuracy: 0.3115

Epoch 00007: val_loss improved from 2.42986 to 2.20049, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 8/100
83/83 [==============================] - 9s 102ms/step - loss: 2.1311 - accuracy: 0.2960 - val_loss: 2.0362 - val_accuracy: 0.3112

Epoch 00008: val_loss improved from 2.20049 to 2.03625, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 9/100
83/83 [==============================] - 8s 100ms/step - loss: 1.9905 - accuracy: 0.2977 - val_loss: 1.9196 - val_accuracy: 0.3117

Epoch 00009: val_loss improved from 2.03625 to 1.91963, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 10/100
83/83 [==============================] - 8s 94ms/step - loss: 1.8910 - accuracy: 0.2990 - val_loss: 1.8364 - val_accuracy: 0.3149

Epoch 00010: val_loss improved from 1.91963 to 1.83640, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 11/100
83/83 [==============================] - 11s 126ms/step - loss: 1.8197 - accuracy: 0.3020 - val_loss: 1.7780 - val_accuracy: 0.3146

Epoch 00011: val_loss improved from 1.83640 to 1.77796, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 12/100
83/83 [==============================] - 11s 127ms/step - loss: 1.7712 - accuracy: 0.3048 - val_loss: 1.7363 - val_accuracy: 0.3182

Epoch 00012: val_loss improved from 1.77796 to 1.73627, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 13/100
83/83 [==============================] - 11s 128ms/step - loss: 1.7352 - accuracy: 0.3035 - val_loss: 1.7076 - val_accuracy: 0.3192

Epoch 00013: val_loss improved from 1.73627 to 1.70762, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 14/100
83/83 [==============================] - 11s 127ms/step - loss: 1.7112 - accuracy: 0.3017 - val_loss: 1.6872 - val_accuracy: 0.3179

Epoch 00014: val_loss improved from 1.70762 to 1.68719, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 15/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6924 - accuracy: 0.3031 - val_loss: 1.6726 - val_accuracy: 0.3184

Epoch 00015: val_loss improved from 1.68719 to 1.67263, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 16/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6790 - accuracy: 0.3041 - val_loss: 1.6632 - val_accuracy: 0.3186

Epoch 00016: val_loss improved from 1.67263 to 1.66322, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 17/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6712 - accuracy: 0.3030 - val_loss: 1.6539 - val_accuracy: 0.3197

Epoch 00017: val_loss improved from 1.66322 to 1.65386, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 18/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6621 - accuracy: 0.3057 - val_loss: 1.6483 - val_accuracy: 0.3201

Epoch 00018: val_loss improved from 1.65386 to 1.64826, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 19/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6584 - accuracy: 0.3016 - val_loss: 1.6444 - val_accuracy: 0.3180

Epoch 00019: val_loss improved from 1.64826 to 1.64437, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 20/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6541 - accuracy: 0.3054 - val_loss: 1.6425 - val_accuracy: 0.3163

Epoch 00020: val_loss improved from 1.64437 to 1.64253, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 21/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6494 - accuracy: 0.3046 - val_loss: 1.6384 - val_accuracy: 0.3196

Epoch 00021: val_loss improved from 1.64253 to 1.63842, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 22/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6485 - accuracy: 0.3071 - val_loss: 1.6365 - val_accuracy: 0.3199

Epoch 00022: val_loss improved from 1.63842 to 1.63646, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 23/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6454 - accuracy: 0.3068 - val_loss: 1.6347 - val_accuracy: 0.3177

Epoch 00023: val_loss improved from 1.63646 to 1.63472, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 24/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6431 - accuracy: 0.3063 - val_loss: 1.6338 - val_accuracy: 0.3192

Epoch 00024: val_loss improved from 1.63472 to 1.63377, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 25/100
83/83 [==============================] - 7s 80ms/step - loss: 1.6428 - accuracy: 0.3073 - val_loss: 1.6324 - val_accuracy: 0.3192

Epoch 00025: val_loss improved from 1.63377 to 1.63242, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 26/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6419 - accuracy: 0.3054 - val_loss: 1.6324 - val_accuracy: 0.3197

Epoch 00026: val_loss did not improve from 1.63242
Epoch 27/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6404 - accuracy: 0.3075 - val_loss: 1.6314 - val_accuracy: 0.3161

Epoch 00027: val_loss improved from 1.63242 to 1.63144, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 28/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6393 - accuracy: 0.3077 - val_loss: 1.6315 - val_accuracy: 0.3173

Epoch 00028: val_loss did not improve from 1.63144
Epoch 29/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6379 - accuracy: 0.3058 - val_loss: 1.6294 - val_accuracy: 0.3199

Epoch 00029: val_loss improved from 1.63144 to 1.62943, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 30/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6376 - accuracy: 0.3068 - val_loss: 1.6303 - val_accuracy: 0.3172

Epoch 00030: val_loss did not improve from 1.62943
Epoch 31/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6364 - accuracy: 0.3086 - val_loss: 1.6292 - val_accuracy: 0.3187

Epoch 00031: val_loss improved from 1.62943 to 1.62925, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 32/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6354 - accuracy: 0.3109 - val_loss: 1.6280 - val_accuracy: 0.3180

Epoch 00032: val_loss improved from 1.62925 to 1.62802, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 33/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6342 - accuracy: 0.3089 - val_loss: 1.6277 - val_accuracy: 0.3180

Epoch 00033: val_loss improved from 1.62802 to 1.62767, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/6
Epoch 34/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6339 - accuracy: 0.3105 - val_loss: 1.6282 - val_accuracy: 0.3195

Epoch 00034: val_loss did not improve from 1.62767
Epoch 35/100
83/83 [==============================] - 6s 72ms/step - loss: 1.6336 - accuracy: 0.3116 - val_loss: 1.6285 - val_accuracy: 0.3192

Epoch 00035: val_loss did not improve from 1.62767
Epoch 36/100
83/83 [==============================] - 6s 76ms/step - loss: 1.6326 - accuracy: 0.3088 - val_loss: 1.6280 - val_accuracy: 0.3188

Epoch 00036: val_loss did not improve from 1.62767
Epoch 37/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6318 - accuracy: 0.3088 - val_loss: 1.6292 - val_accuracy: 0.3188

Epoch 00037: val_loss did not improve from 1.62767
Epoch 38/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6325 - accuracy: 0.3108 - val_loss: 1.6283 - val_accuracy: 0.3176

Epoch 00038: val_loss did not improve from 1.62767
Epoch 39/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6313 - accuracy: 0.3123 - val_loss: 1.6277 - val_accuracy: 0.3177

Epoch 00039: val_loss did not improve from 1.62767
Epoch 40/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6308 - accuracy: 0.3100 - val_loss: 1.6286 - val_accuracy: 0.3172

Epoch 00040: val_loss did not improve from 1.62767
Epoch 41/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6310 - accuracy: 0.3136 - val_loss: 1.6288 - val_accuracy: 0.3184

Epoch 00041: val_loss did not improve from 1.62767
Epoch 42/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6296 - accuracy: 0.3115 - val_loss: 1.6296 - val_accuracy: 0.3166

Epoch 00042: val_loss did not improve from 1.62767
Epoch 43/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6310 - accuracy: 0.3130 - val_loss: 1.6306 - val_accuracy: 0.3193

Epoch 00043: val_loss did not improve from 1.62767
Epoch 00043: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 75s 6ms/step - loss: 1.6313 - accuracy: 0.3107
Testing Loss = 1.631303, Testing Accuracy = 0.310732
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 9s 101ms/step - loss: 11.8617 - accuracy: 0.2495 - val_loss: 8.1727 - val_accuracy: 0.2922

Epoch 00001: val_loss improved from inf to 8.17265, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 2/100
83/83 [==============================] - 8s 97ms/step - loss: 6.4330 - accuracy: 0.2751 - val_loss: 5.1386 - val_accuracy: 0.2993

Epoch 00002: val_loss improved from 8.17265 to 5.13861, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 3/100
83/83 [==============================] - 9s 102ms/step - loss: 4.4644 - accuracy: 0.2806 - val_loss: 3.8873 - val_accuracy: 0.3064

Epoch 00003: val_loss improved from 5.13861 to 3.88728, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 4/100
83/83 [==============================] - 9s 103ms/step - loss: 3.5405 - accuracy: 0.2886 - val_loss: 3.1971 - val_accuracy: 0.3065

Epoch 00004: val_loss improved from 3.88728 to 3.19714, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 5/100
83/83 [==============================] - 9s 108ms/step - loss: 2.9770 - accuracy: 0.2907 - val_loss: 2.7398 - val_accuracy: 0.3049

Epoch 00005: val_loss improved from 3.19714 to 2.73980, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 6/100
83/83 [==============================] - 10s 121ms/step - loss: 2.5909 - accuracy: 0.2926 - val_loss: 2.4186 - val_accuracy: 0.3074

Epoch 00006: val_loss improved from 2.73980 to 2.41860, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 7/100
83/83 [==============================] - 10s 124ms/step - loss: 2.3160 - accuracy: 0.2950 - val_loss: 2.1910 - val_accuracy: 0.3102

Epoch 00007: val_loss improved from 2.41860 to 2.19104, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 8/100
83/83 [==============================] - 11s 128ms/step - loss: 2.1220 - accuracy: 0.2949 - val_loss: 2.0280 - val_accuracy: 0.3089

Epoch 00008: val_loss improved from 2.19104 to 2.02798, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 9/100
83/83 [==============================] - 10s 121ms/step - loss: 1.9830 - accuracy: 0.2969 - val_loss: 1.9119 - val_accuracy: 0.3129

Epoch 00009: val_loss improved from 2.02798 to 1.91193, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 10/100
83/83 [==============================] - 10s 119ms/step - loss: 1.8848 - accuracy: 0.2975 - val_loss: 1.8297 - val_accuracy: 0.3120

Epoch 00010: val_loss improved from 1.91193 to 1.82968, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 11/100
83/83 [==============================] - 9s 113ms/step - loss: 1.8152 - accuracy: 0.3003 - val_loss: 1.7724 - val_accuracy: 0.3137

Epoch 00011: val_loss improved from 1.82968 to 1.77243, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 12/100
83/83 [==============================] - 8s 102ms/step - loss: 1.7666 - accuracy: 0.3005 - val_loss: 1.7319 - val_accuracy: 0.3148

Epoch 00012: val_loss improved from 1.77243 to 1.73192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 13/100
83/83 [==============================] - 8s 102ms/step - loss: 1.7306 - accuracy: 0.3010 - val_loss: 1.7032 - val_accuracy: 0.3152

Epoch 00013: val_loss improved from 1.73192 to 1.70323, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 14/100
83/83 [==============================] - 8s 101ms/step - loss: 1.7062 - accuracy: 0.3023 - val_loss: 1.6838 - val_accuracy: 0.3160

Epoch 00014: val_loss improved from 1.70323 to 1.68385, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 15/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6898 - accuracy: 0.3022 - val_loss: 1.6696 - val_accuracy: 0.3165

Epoch 00015: val_loss improved from 1.68385 to 1.66964, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 16/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6771 - accuracy: 0.3053 - val_loss: 1.6595 - val_accuracy: 0.3153

Epoch 00016: val_loss improved from 1.66964 to 1.65951, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 17/100
83/83 [==============================] - 10s 126ms/step - loss: 1.6680 - accuracy: 0.3033 - val_loss: 1.6524 - val_accuracy: 0.3159

Epoch 00017: val_loss improved from 1.65951 to 1.65245, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 18/100
83/83 [==============================] - 10s 117ms/step - loss: 1.6605 - accuracy: 0.3052 - val_loss: 1.6466 - val_accuracy: 0.3170

Epoch 00018: val_loss improved from 1.65245 to 1.64660, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 19/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6572 - accuracy: 0.3053 - val_loss: 1.6419 - val_accuracy: 0.3182

Epoch 00019: val_loss improved from 1.64660 to 1.64190, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 20/100
83/83 [==============================] - 9s 104ms/step - loss: 1.6532 - accuracy: 0.3034 - val_loss: 1.6396 - val_accuracy: 0.3200

Epoch 00020: val_loss improved from 1.64190 to 1.63957, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 21/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6504 - accuracy: 0.3051 - val_loss: 1.6369 - val_accuracy: 0.3182

Epoch 00021: val_loss improved from 1.63957 to 1.63692, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 22/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6485 - accuracy: 0.3063 - val_loss: 1.6353 - val_accuracy: 0.3184

Epoch 00022: val_loss improved from 1.63692 to 1.63531, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 23/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6456 - accuracy: 0.3059 - val_loss: 1.6339 - val_accuracy: 0.3158

Epoch 00023: val_loss improved from 1.63531 to 1.63386, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 24/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6436 - accuracy: 0.3054 - val_loss: 1.6319 - val_accuracy: 0.3178

Epoch 00024: val_loss improved from 1.63386 to 1.63195, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 25/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6419 - accuracy: 0.3068 - val_loss: 1.6320 - val_accuracy: 0.3167

Epoch 00025: val_loss did not improve from 1.63195
Epoch 26/100
83/83 [==============================] - 9s 105ms/step - loss: 1.6412 - accuracy: 0.3070 - val_loss: 1.6307 - val_accuracy: 0.3170

Epoch 00026: val_loss improved from 1.63195 to 1.63074, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 27/100
83/83 [==============================] - 7s 80ms/step - loss: 1.6404 - accuracy: 0.3063 - val_loss: 1.6302 - val_accuracy: 0.3163

Epoch 00027: val_loss improved from 1.63074 to 1.63023, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 28/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6390 - accuracy: 0.3091 - val_loss: 1.6293 - val_accuracy: 0.3190

Epoch 00028: val_loss improved from 1.63023 to 1.62931, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 29/100
83/83 [==============================] - 7s 80ms/step - loss: 1.6375 - accuracy: 0.3090 - val_loss: 1.6289 - val_accuracy: 0.3191

Epoch 00029: val_loss improved from 1.62931 to 1.62894, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 30/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6370 - accuracy: 0.3080 - val_loss: 1.6278 - val_accuracy: 0.3185

Epoch 00030: val_loss improved from 1.62894 to 1.62776, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 31/100
83/83 [==============================] - 7s 80ms/step - loss: 1.6378 - accuracy: 0.3074 - val_loss: 1.6284 - val_accuracy: 0.3203

Epoch 00031: val_loss did not improve from 1.62776
Epoch 32/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6358 - accuracy: 0.3079 - val_loss: 1.6275 - val_accuracy: 0.3178

Epoch 00032: val_loss improved from 1.62776 to 1.62754, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 33/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6364 - accuracy: 0.3068 - val_loss: 1.6272 - val_accuracy: 0.3188

Epoch 00033: val_loss improved from 1.62754 to 1.62724, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 34/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6357 - accuracy: 0.3082 - val_loss: 1.6275 - val_accuracy: 0.3189

Epoch 00034: val_loss did not improve from 1.62724
Epoch 35/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6329 - accuracy: 0.3093 - val_loss: 1.6272 - val_accuracy: 0.3188

Epoch 00035: val_loss improved from 1.62724 to 1.62718, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 36/100
83/83 [==============================] - 6s 73ms/step - loss: 1.6335 - accuracy: 0.3100 - val_loss: 1.6264 - val_accuracy: 0.3213

Epoch 00036: val_loss improved from 1.62718 to 1.62635, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/7
Epoch 37/100
83/83 [==============================] - 6s 76ms/step - loss: 1.6329 - accuracy: 0.3103 - val_loss: 1.6264 - val_accuracy: 0.3196

Epoch 00037: val_loss did not improve from 1.62635
Epoch 38/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6322 - accuracy: 0.3090 - val_loss: 1.6269 - val_accuracy: 0.3191

Epoch 00038: val_loss did not improve from 1.62635
Epoch 39/100
83/83 [==============================] - 6s 76ms/step - loss: 1.6320 - accuracy: 0.3108 - val_loss: 1.6264 - val_accuracy: 0.3204

Epoch 00039: val_loss did not improve from 1.62635
Epoch 40/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6322 - accuracy: 0.3090 - val_loss: 1.6264 - val_accuracy: 0.3215

Epoch 00040: val_loss did not improve from 1.62635
Epoch 41/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6315 - accuracy: 0.3104 - val_loss: 1.6269 - val_accuracy: 0.3196

Epoch 00041: val_loss did not improve from 1.62635
Epoch 42/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6308 - accuracy: 0.3109 - val_loss: 1.6271 - val_accuracy: 0.3190

Epoch 00042: val_loss did not improve from 1.62635
Epoch 43/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6305 - accuracy: 0.3105 - val_loss: 1.6269 - val_accuracy: 0.3198

Epoch 00043: val_loss did not improve from 1.62635
Epoch 44/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6306 - accuracy: 0.3116 - val_loss: 1.6278 - val_accuracy: 0.3187

Epoch 00044: val_loss did not improve from 1.62635
Epoch 45/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6299 - accuracy: 0.3110 - val_loss: 1.6273 - val_accuracy: 0.3222

Epoch 00045: val_loss did not improve from 1.62635
Epoch 46/100
83/83 [==============================] - 10s 126ms/step - loss: 1.6285 - accuracy: 0.3130 - val_loss: 1.6282 - val_accuracy: 0.3167

Epoch 00046: val_loss did not improve from 1.62635
Epoch 00046: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 78s 6ms/step - loss: 1.6290 - accuracy: 0.3118
Testing Loss = 1.629041, Testing Accuracy = 0.311849
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 9s 97ms/step - loss: 11.9313 - accuracy: 0.2538 - val_loss: 8.2561 - val_accuracy: 0.2875

Epoch 00001: val_loss improved from inf to 8.25606, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 2/100
83/83 [==============================] - 9s 109ms/step - loss: 6.5159 - accuracy: 0.2760 - val_loss: 5.2105 - val_accuracy: 0.2979

Epoch 00002: val_loss improved from 8.25606 to 5.21052, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 3/100
83/83 [==============================] - 10s 117ms/step - loss: 4.5244 - accuracy: 0.2824 - val_loss: 3.9364 - val_accuracy: 0.3031

Epoch 00003: val_loss improved from 5.21052 to 3.93635, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 4/100
83/83 [==============================] - 10s 121ms/step - loss: 3.5757 - accuracy: 0.2884 - val_loss: 3.2269 - val_accuracy: 0.3076

Epoch 00004: val_loss improved from 3.93635 to 3.22694, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 5/100
83/83 [==============================] - 11s 127ms/step - loss: 3.0018 - accuracy: 0.2927 - val_loss: 2.7620 - val_accuracy: 0.3059

Epoch 00005: val_loss improved from 3.22694 to 2.76202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 6/100
83/83 [==============================] - 10s 126ms/step - loss: 2.6100 - accuracy: 0.2932 - val_loss: 2.4366 - val_accuracy: 0.3060

Epoch 00006: val_loss improved from 2.76202 to 2.43659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 7/100
83/83 [==============================] - 10s 124ms/step - loss: 2.3310 - accuracy: 0.2953 - val_loss: 2.2044 - val_accuracy: 0.3064

Epoch 00007: val_loss improved from 2.43659 to 2.20436, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 8/100
83/83 [==============================] - 9s 112ms/step - loss: 2.1337 - accuracy: 0.2948 - val_loss: 2.0378 - val_accuracy: 0.3114

Epoch 00008: val_loss improved from 2.20436 to 2.03783, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 9/100
83/83 [==============================] - 9s 104ms/step - loss: 1.9924 - accuracy: 0.2957 - val_loss: 1.9200 - val_accuracy: 0.3154

Epoch 00009: val_loss improved from 2.03783 to 1.91999, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 10/100
83/83 [==============================] - 8s 100ms/step - loss: 1.8914 - accuracy: 0.3011 - val_loss: 1.8376 - val_accuracy: 0.3085

Epoch 00010: val_loss improved from 1.91999 to 1.83762, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 11/100
83/83 [==============================] - 8s 96ms/step - loss: 1.8194 - accuracy: 0.2978 - val_loss: 1.7781 - val_accuracy: 0.3137

Epoch 00011: val_loss improved from 1.83762 to 1.77813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 12/100
83/83 [==============================] - 8s 100ms/step - loss: 1.7696 - accuracy: 0.3017 - val_loss: 1.7370 - val_accuracy: 0.3159

Epoch 00012: val_loss improved from 1.77813 to 1.73704, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 13/100
83/83 [==============================] - 8s 100ms/step - loss: 1.7363 - accuracy: 0.3002 - val_loss: 1.7081 - val_accuracy: 0.3161

Epoch 00013: val_loss improved from 1.73704 to 1.70805, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 14/100
83/83 [==============================] - 8s 95ms/step - loss: 1.7093 - accuracy: 0.3037 - val_loss: 1.6877 - val_accuracy: 0.3166

Epoch 00014: val_loss improved from 1.70805 to 1.68770, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 15/100
83/83 [==============================] - 9s 108ms/step - loss: 1.6933 - accuracy: 0.3010 - val_loss: 1.6739 - val_accuracy: 0.3161

Epoch 00015: val_loss improved from 1.68770 to 1.67392, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 16/100
83/83 [==============================] - 10s 116ms/step - loss: 1.6788 - accuracy: 0.3046 - val_loss: 1.6622 - val_accuracy: 0.3151

Epoch 00016: val_loss improved from 1.67392 to 1.66219, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 17/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6709 - accuracy: 0.3015 - val_loss: 1.6558 - val_accuracy: 0.3191

Epoch 00017: val_loss improved from 1.66219 to 1.65581, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 18/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6628 - accuracy: 0.3069 - val_loss: 1.6500 - val_accuracy: 0.3150

Epoch 00018: val_loss improved from 1.65581 to 1.65002, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 19/100
83/83 [==============================] - 8s 95ms/step - loss: 1.6588 - accuracy: 0.3047 - val_loss: 1.6446 - val_accuracy: 0.3194

Epoch 00019: val_loss improved from 1.65002 to 1.64458, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 20/100
83/83 [==============================] - 8s 100ms/step - loss: 1.6553 - accuracy: 0.3034 - val_loss: 1.6418 - val_accuracy: 0.3165

Epoch 00020: val_loss improved from 1.64458 to 1.64182, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 21/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6515 - accuracy: 0.3039 - val_loss: 1.6390 - val_accuracy: 0.3173

Epoch 00021: val_loss improved from 1.64182 to 1.63900, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 22/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6483 - accuracy: 0.3060 - val_loss: 1.6378 - val_accuracy: 0.3166

Epoch 00022: val_loss improved from 1.63900 to 1.63775, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 23/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6470 - accuracy: 0.3060 - val_loss: 1.6362 - val_accuracy: 0.3194

Epoch 00023: val_loss improved from 1.63775 to 1.63624, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 24/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6446 - accuracy: 0.3054 - val_loss: 1.6346 - val_accuracy: 0.3187

Epoch 00024: val_loss improved from 1.63624 to 1.63464, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 25/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6427 - accuracy: 0.3061 - val_loss: 1.6328 - val_accuracy: 0.3172

Epoch 00025: val_loss improved from 1.63464 to 1.63285, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 26/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6411 - accuracy: 0.3065 - val_loss: 1.6318 - val_accuracy: 0.3179

Epoch 00026: val_loss improved from 1.63285 to 1.63177, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 27/100
83/83 [==============================] - 11s 126ms/step - loss: 1.6402 - accuracy: 0.3065 - val_loss: 1.6311 - val_accuracy: 0.3192

Epoch 00027: val_loss improved from 1.63177 to 1.63110, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 28/100
83/83 [==============================] - 8s 92ms/step - loss: 1.6395 - accuracy: 0.3062 - val_loss: 1.6306 - val_accuracy: 0.3182

Epoch 00028: val_loss improved from 1.63110 to 1.63062, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 29/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6388 - accuracy: 0.3084 - val_loss: 1.6305 - val_accuracy: 0.3182

Epoch 00029: val_loss improved from 1.63062 to 1.63048, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 30/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6377 - accuracy: 0.3059 - val_loss: 1.6298 - val_accuracy: 0.3189

Epoch 00030: val_loss improved from 1.63048 to 1.62978, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 31/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6364 - accuracy: 0.3090 - val_loss: 1.6300 - val_accuracy: 0.3176

Epoch 00031: val_loss did not improve from 1.62978
Epoch 32/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6353 - accuracy: 0.3090 - val_loss: 1.6287 - val_accuracy: 0.3186

Epoch 00032: val_loss improved from 1.62978 to 1.62871, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 33/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6342 - accuracy: 0.3104 - val_loss: 1.6287 - val_accuracy: 0.3161

Epoch 00033: val_loss did not improve from 1.62871
Epoch 34/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6349 - accuracy: 0.3090 - val_loss: 1.6290 - val_accuracy: 0.3175

Epoch 00034: val_loss did not improve from 1.62871
Epoch 35/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6338 - accuracy: 0.3108 - val_loss: 1.6291 - val_accuracy: 0.3162

Epoch 00035: val_loss did not improve from 1.62871
Epoch 36/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6342 - accuracy: 0.3085 - val_loss: 1.6284 - val_accuracy: 0.3186

Epoch 00036: val_loss improved from 1.62871 to 1.62838, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 37/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6327 - accuracy: 0.3084 - val_loss: 1.6279 - val_accuracy: 0.3168

Epoch 00037: val_loss improved from 1.62838 to 1.62787, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/8
Epoch 38/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6319 - accuracy: 0.3123 - val_loss: 1.6285 - val_accuracy: 0.3160

Epoch 00038: val_loss did not improve from 1.62787
Epoch 39/100
83/83 [==============================] - 6s 73ms/step - loss: 1.6332 - accuracy: 0.3096 - val_loss: 1.6283 - val_accuracy: 0.3191

Epoch 00039: val_loss did not improve from 1.62787
Epoch 40/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6311 - accuracy: 0.3118 - val_loss: 1.6286 - val_accuracy: 0.3172

Epoch 00040: val_loss did not improve from 1.62787
Epoch 41/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6314 - accuracy: 0.3138 - val_loss: 1.6292 - val_accuracy: 0.3162

Epoch 00041: val_loss did not improve from 1.62787
Epoch 42/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6309 - accuracy: 0.3115 - val_loss: 1.6289 - val_accuracy: 0.3179

Epoch 00042: val_loss did not improve from 1.62787
Epoch 43/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6303 - accuracy: 0.3092 - val_loss: 1.6284 - val_accuracy: 0.3169

Epoch 00043: val_loss did not improve from 1.62787
Epoch 44/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6296 - accuracy: 0.3140 - val_loss: 1.6299 - val_accuracy: 0.3162

Epoch 00044: val_loss did not improve from 1.62787
Epoch 45/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6286 - accuracy: 0.3111 - val_loss: 1.6293 - val_accuracy: 0.3210

Epoch 00045: val_loss did not improve from 1.62787
Epoch 46/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6292 - accuracy: 0.3129 - val_loss: 1.6295 - val_accuracy: 0.3161

Epoch 00046: val_loss did not improve from 1.62787
Epoch 47/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6273 - accuracy: 0.3174 - val_loss: 1.6301 - val_accuracy: 0.3177

Epoch 00047: val_loss did not improve from 1.62787
Epoch 00047: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 82s 6ms/step - loss: 1.6296 - accuracy: 0.3119
Testing Loss = 1.629599, Testing Accuracy = 0.311923
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 42992.
Epoch 1/100
83/83 [==============================] - 11s 126ms/step - loss: 11.8711 - accuracy: 0.2525 - val_loss: 8.1884 - val_accuracy: 0.2935

Epoch 00001: val_loss improved from inf to 8.18842, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 2/100
83/83 [==============================] - 10s 123ms/step - loss: 6.4551 - accuracy: 0.2746 - val_loss: 5.1650 - val_accuracy: 0.2987

Epoch 00002: val_loss improved from 8.18842 to 5.16495, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 3/100
83/83 [==============================] - 10s 118ms/step - loss: 4.4850 - accuracy: 0.2832 - val_loss: 3.9096 - val_accuracy: 0.3031

Epoch 00003: val_loss improved from 5.16495 to 3.90964, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 4/100
83/83 [==============================] - 9s 108ms/step - loss: 3.5579 - accuracy: 0.2877 - val_loss: 3.2129 - val_accuracy: 0.3055

Epoch 00004: val_loss improved from 3.90964 to 3.21286, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 5/100
83/83 [==============================] - 8s 101ms/step - loss: 2.9903 - accuracy: 0.2888 - val_loss: 2.7520 - val_accuracy: 0.3073

Epoch 00005: val_loss improved from 3.21286 to 2.75203, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 6/100
83/83 [==============================] - 8s 101ms/step - loss: 2.6000 - accuracy: 0.2945 - val_loss: 2.4263 - val_accuracy: 0.3052

Epoch 00006: val_loss improved from 2.75203 to 2.42628, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 7/100
83/83 [==============================] - 8s 93ms/step - loss: 2.3234 - accuracy: 0.2969 - val_loss: 2.1948 - val_accuracy: 0.3081

Epoch 00007: val_loss improved from 2.42628 to 2.19483, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 8/100
83/83 [==============================] - 8s 96ms/step - loss: 2.1269 - accuracy: 0.2972 - val_loss: 2.0314 - val_accuracy: 0.3100

Epoch 00008: val_loss improved from 2.19483 to 2.03137, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 9/100
83/83 [==============================] - 8s 100ms/step - loss: 1.9879 - accuracy: 0.2996 - val_loss: 1.9145 - val_accuracy: 0.3094

Epoch 00009: val_loss improved from 2.03137 to 1.91448, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 10/100
83/83 [==============================] - 8s 97ms/step - loss: 1.8869 - accuracy: 0.2979 - val_loss: 1.8321 - val_accuracy: 0.3105

Epoch 00010: val_loss improved from 1.91448 to 1.83209, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 11/100
83/83 [==============================] - 10s 114ms/step - loss: 1.8158 - accuracy: 0.3010 - val_loss: 1.7738 - val_accuracy: 0.3126

Epoch 00011: val_loss improved from 1.83209 to 1.77384, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 12/100
83/83 [==============================] - 10s 122ms/step - loss: 1.7668 - accuracy: 0.3006 - val_loss: 1.7344 - val_accuracy: 0.3124

Epoch 00012: val_loss improved from 1.77384 to 1.73436, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 13/100
83/83 [==============================] - 11s 128ms/step - loss: 1.7322 - accuracy: 0.3014 - val_loss: 1.7041 - val_accuracy: 0.3187

Epoch 00013: val_loss improved from 1.73436 to 1.70407, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 14/100
83/83 [==============================] - 8s 101ms/step - loss: 1.7063 - accuracy: 0.3060 - val_loss: 1.6850 - val_accuracy: 0.3196

Epoch 00014: val_loss improved from 1.70407 to 1.68495, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 15/100
83/83 [==============================] - 9s 110ms/step - loss: 1.6893 - accuracy: 0.3034 - val_loss: 1.6704 - val_accuracy: 0.3198

Epoch 00015: val_loss improved from 1.68495 to 1.67038, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 16/100
83/83 [==============================] - 10s 123ms/step - loss: 1.6774 - accuracy: 0.3022 - val_loss: 1.6599 - val_accuracy: 0.3176

Epoch 00016: val_loss improved from 1.67038 to 1.65991, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 17/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6691 - accuracy: 0.3024 - val_loss: 1.6519 - val_accuracy: 0.3173

Epoch 00017: val_loss improved from 1.65991 to 1.65189, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 18/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6616 - accuracy: 0.3038 - val_loss: 1.6471 - val_accuracy: 0.3182

Epoch 00018: val_loss improved from 1.65189 to 1.64710, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 19/100
83/83 [==============================] - 8s 97ms/step - loss: 1.6569 - accuracy: 0.3044 - val_loss: 1.6433 - val_accuracy: 0.3192

Epoch 00019: val_loss improved from 1.64710 to 1.64326, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 20/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6533 - accuracy: 0.3046 - val_loss: 1.6396 - val_accuracy: 0.3200

Epoch 00020: val_loss improved from 1.64326 to 1.63964, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 21/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6494 - accuracy: 0.3063 - val_loss: 1.6366 - val_accuracy: 0.3196

Epoch 00021: val_loss improved from 1.63964 to 1.63662, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 22/100
83/83 [==============================] - 10s 119ms/step - loss: 1.6474 - accuracy: 0.3045 - val_loss: 1.6346 - val_accuracy: 0.3186

Epoch 00022: val_loss improved from 1.63662 to 1.63465, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 23/100
83/83 [==============================] - 11s 130ms/step - loss: 1.6447 - accuracy: 0.3043 - val_loss: 1.6347 - val_accuracy: 0.3155

Epoch 00023: val_loss did not improve from 1.63465
Epoch 24/100
83/83 [==============================] - 11s 129ms/step - loss: 1.6436 - accuracy: 0.3069 - val_loss: 1.6325 - val_accuracy: 0.3185

Epoch 00024: val_loss improved from 1.63465 to 1.63247, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 25/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6416 - accuracy: 0.3067 - val_loss: 1.6313 - val_accuracy: 0.3186

Epoch 00025: val_loss improved from 1.63247 to 1.63126, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 26/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6400 - accuracy: 0.3065 - val_loss: 1.6301 - val_accuracy: 0.3191

Epoch 00026: val_loss improved from 1.63126 to 1.63006, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 27/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6404 - accuracy: 0.3073 - val_loss: 1.6299 - val_accuracy: 0.3181

Epoch 00027: val_loss improved from 1.63006 to 1.62989, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 28/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6394 - accuracy: 0.3042 - val_loss: 1.6293 - val_accuracy: 0.3180

Epoch 00028: val_loss improved from 1.62989 to 1.62927, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 29/100
83/83 [==============================] - 11s 127ms/step - loss: 1.6380 - accuracy: 0.3069 - val_loss: 1.6285 - val_accuracy: 0.3172

Epoch 00029: val_loss improved from 1.62927 to 1.62851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 30/100
83/83 [==============================] - 11s 128ms/step - loss: 1.6369 - accuracy: 0.3089 - val_loss: 1.6277 - val_accuracy: 0.3195

Epoch 00030: val_loss improved from 1.62851 to 1.62768, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 31/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6367 - accuracy: 0.3069 - val_loss: 1.6274 - val_accuracy: 0.3190

Epoch 00031: val_loss improved from 1.62768 to 1.62738, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 32/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6356 - accuracy: 0.3088 - val_loss: 1.6275 - val_accuracy: 0.3181

Epoch 00032: val_loss did not improve from 1.62738
Epoch 33/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6352 - accuracy: 0.3092 - val_loss: 1.6278 - val_accuracy: 0.3179

Epoch 00033: val_loss did not improve from 1.62738
Epoch 34/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6340 - accuracy: 0.3070 - val_loss: 1.6276 - val_accuracy: 0.3184

Epoch 00034: val_loss did not improve from 1.62738
Epoch 35/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6321 - accuracy: 0.3100 - val_loss: 1.6273 - val_accuracy: 0.3174

Epoch 00035: val_loss improved from 1.62738 to 1.62728, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 36/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6326 - accuracy: 0.3105 - val_loss: 1.6280 - val_accuracy: 0.3167

Epoch 00036: val_loss did not improve from 1.62728
Epoch 37/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6331 - accuracy: 0.3117 - val_loss: 1.6268 - val_accuracy: 0.3169

Epoch 00037: val_loss improved from 1.62728 to 1.62681, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 38/100
83/83 [==============================] - 7s 79ms/step - loss: 1.6313 - accuracy: 0.3109 - val_loss: 1.6264 - val_accuracy: 0.3204

Epoch 00038: val_loss improved from 1.62681 to 1.62640, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_event_kappa0.2_r13/Try/9
Epoch 39/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6317 - accuracy: 0.3060 - val_loss: 1.6275 - val_accuracy: 0.3176

Epoch 00039: val_loss did not improve from 1.62640
Epoch 40/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6300 - accuracy: 0.3098 - val_loss: 1.6282 - val_accuracy: 0.3175

Epoch 00040: val_loss did not improve from 1.62640
Epoch 41/100
83/83 [==============================] - 7s 78ms/step - loss: 1.6304 - accuracy: 0.3128 - val_loss: 1.6274 - val_accuracy: 0.3174

Epoch 00041: val_loss did not improve from 1.62640
Epoch 42/100
83/83 [==============================] - 6s 76ms/step - loss: 1.6310 - accuracy: 0.3124 - val_loss: 1.6279 - val_accuracy: 0.3196

Epoch 00042: val_loss did not improve from 1.62640
Epoch 43/100
83/83 [==============================] - 6s 74ms/step - loss: 1.6298 - accuracy: 0.3119 - val_loss: 1.6285 - val_accuracy: 0.3195

Epoch 00043: val_loss did not improve from 1.62640
Epoch 44/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6287 - accuracy: 0.3100 - val_loss: 1.6290 - val_accuracy: 0.3179

Epoch 00044: val_loss did not improve from 1.62640
Epoch 45/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6298 - accuracy: 0.3111 - val_loss: 1.6294 - val_accuracy: 0.3190

Epoch 00045: val_loss did not improve from 1.62640
Epoch 46/100
83/83 [==============================] - 6s 77ms/step - loss: 1.6288 - accuracy: 0.3127 - val_loss: 1.6294 - val_accuracy: 0.3193

Epoch 00046: val_loss did not improve from 1.62640
Epoch 47/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6280 - accuracy: 0.3150 - val_loss: 1.6303 - val_accuracy: 0.3199

Epoch 00047: val_loss did not improve from 1.62640
Epoch 48/100
83/83 [==============================] - 6s 78ms/step - loss: 1.6282 - accuracy: 0.3122 - val_loss: 1.6296 - val_accuracy: 0.3162

Epoch 00048: val_loss did not improve from 1.62640
Epoch 00048: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4RAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13436/13436 [==============================] - 79s 6ms/step - loss: 1.6290 - accuracy: 0.3122
Testing Loss = 1.629018, Testing Accuracy = 0.312221
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 79.54 +- 0.0393 %)
$W^-/W^-$ (auc = 79.30 +- 0.0286 %)
$Z/Z$ (auc = 59.81 +- 0.0790 %)
$W^+/W^-$ (auc = 62.82 +- 0.1159 %)
$W^+/Z$$ (auc = 63.69 +- 0.0260 %)
$W^-/Z$ (auc = 66.10 +- 0.0441 %)
The summarized testing accuracy = 31.28 +- 0.1212 %, with the loss = 1.6296 +- 0.000862
