

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-20 15:03:32.638887
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
937/937 [==============================] - 70s 69ms/step - loss: 3.0403 - accuracy: 0.6455 - val_loss: 0.9169 - val_accuracy: 0.6939

Epoch 00001: val_loss improved from inf to 0.91690, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 2/500
937/937 [==============================] - 64s 68ms/step - loss: 0.8163 - accuracy: 0.6921 - val_loss: 0.7555 - val_accuracy: 0.7013

Epoch 00002: val_loss improved from 0.91690 to 0.75547, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 3/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7578 - accuracy: 0.6974 - val_loss: 0.7388 - val_accuracy: 0.7028

Epoch 00003: val_loss improved from 0.75547 to 0.73877, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 4/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7456 - accuracy: 0.7001 - val_loss: 0.7306 - val_accuracy: 0.7039

Epoch 00004: val_loss improved from 0.73877 to 0.73057, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 5/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7376 - accuracy: 0.7019 - val_loss: 0.7250 - val_accuracy: 0.7050

Epoch 00005: val_loss improved from 0.73057 to 0.72503, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 6/500
937/937 [==============================] - 65s 69ms/step - loss: 0.7322 - accuracy: 0.7033 - val_loss: 0.7219 - val_accuracy: 0.7056

Epoch 00006: val_loss improved from 0.72503 to 0.72191, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 7/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7282 - accuracy: 0.7044 - val_loss: 0.7178 - val_accuracy: 0.7074

Epoch 00007: val_loss improved from 0.72191 to 0.71782, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 8/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7240 - accuracy: 0.7064 - val_loss: 0.7159 - val_accuracy: 0.7075

Epoch 00008: val_loss improved from 0.71782 to 0.71590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 9/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7209 - accuracy: 0.7075 - val_loss: 0.7170 - val_accuracy: 0.7050

Epoch 00009: val_loss did not improve from 0.71590
Epoch 10/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7182 - accuracy: 0.7078 - val_loss: 0.7138 - val_accuracy: 0.7066

Epoch 00010: val_loss improved from 0.71590 to 0.71377, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 11/500
937/937 [==============================] - 65s 70ms/step - loss: 0.7154 - accuracy: 0.7082 - val_loss: 0.7103 - val_accuracy: 0.7095

Epoch 00011: val_loss improved from 0.71377 to 0.71027, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 12/500
937/937 [==============================] - 65s 70ms/step - loss: 0.7130 - accuracy: 0.7098 - val_loss: 0.7122 - val_accuracy: 0.7070

Epoch 00012: val_loss did not improve from 0.71027
Epoch 13/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7108 - accuracy: 0.7109 - val_loss: 0.7090 - val_accuracy: 0.7086

Epoch 00013: val_loss improved from 0.71027 to 0.70902, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 14/500
937/937 [==============================] - 65s 70ms/step - loss: 0.7090 - accuracy: 0.7116 - val_loss: 0.7079 - val_accuracy: 0.7088

Epoch 00014: val_loss improved from 0.70902 to 0.70787, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 15/500
937/937 [==============================] - 65s 69ms/step - loss: 0.7072 - accuracy: 0.7126 - val_loss: 0.7095 - val_accuracy: 0.7079

Epoch 00015: val_loss did not improve from 0.70787
Epoch 16/500
937/937 [==============================] - 65s 69ms/step - loss: 0.7055 - accuracy: 0.7131 - val_loss: 0.7064 - val_accuracy: 0.7099

Epoch 00016: val_loss improved from 0.70787 to 0.70642, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 17/500
937/937 [==============================] - 65s 69ms/step - loss: 0.7035 - accuracy: 0.7145 - val_loss: 0.7078 - val_accuracy: 0.7092

Epoch 00017: val_loss did not improve from 0.70642
Epoch 18/500
937/937 [==============================] - 65s 69ms/step - loss: 0.7020 - accuracy: 0.7147 - val_loss: 0.7097 - val_accuracy: 0.7074

Epoch 00018: val_loss did not improve from 0.70642
Epoch 19/500
937/937 [==============================] - 70s 75ms/step - loss: 0.7000 - accuracy: 0.7161 - val_loss: 0.7067 - val_accuracy: 0.7094

Epoch 00019: val_loss did not improve from 0.70642
Epoch 20/500
937/937 [==============================] - 64s 69ms/step - loss: 0.6984 - accuracy: 0.7167 - val_loss: 0.7108 - val_accuracy: 0.7066

Epoch 00020: val_loss did not improve from 0.70642
Epoch 21/500
937/937 [==============================] - 64s 69ms/step - loss: 0.6964 - accuracy: 0.7183 - val_loss: 0.7078 - val_accuracy: 0.7092

Epoch 00021: val_loss did not improve from 0.70642
Epoch 22/500
937/937 [==============================] - 64s 68ms/step - loss: 0.6943 - accuracy: 0.7194 - val_loss: 0.7097 - val_accuracy: 0.7079

Epoch 00022: val_loss did not improve from 0.70642
Epoch 23/500
937/937 [==============================] - 64s 68ms/step - loss: 0.6929 - accuracy: 0.7202 - val_loss: 0.7115 - val_accuracy: 0.7076

Epoch 00023: val_loss did not improve from 0.70642
Epoch 24/500
937/937 [==============================] - 64s 69ms/step - loss: 0.6903 - accuracy: 0.7222 - val_loss: 0.7138 - val_accuracy: 0.7058

Epoch 00024: val_loss did not improve from 0.70642
Epoch 25/500
937/937 [==============================] - 65s 69ms/step - loss: 0.6881 - accuracy: 0.7231 - val_loss: 0.7116 - val_accuracy: 0.7075

Epoch 00025: val_loss did not improve from 0.70642
Epoch 26/500
937/937 [==============================] - 64s 69ms/step - loss: 0.6858 - accuracy: 0.7247 - val_loss: 0.7153 - val_accuracy: 0.7056

Epoch 00026: val_loss did not improve from 0.70642
Epoch 27/500
937/937 [==============================] - 65s 69ms/step - loss: 0.6833 - accuracy: 0.7269 - val_loss: 0.7157 - val_accuracy: 0.7068

Epoch 00027: val_loss did not improve from 0.70642
Epoch 28/500
937/937 [==============================] - 64s 68ms/step - loss: 0.6804 - accuracy: 0.7288 - val_loss: 0.7171 - val_accuracy: 0.7064

Epoch 00028: val_loss did not improve from 0.70642
Epoch 29/500
937/937 [==============================] - 65s 69ms/step - loss: 0.6786 - accuracy: 0.7308 - val_loss: 0.7203 - val_accuracy: 0.7055

Epoch 00029: val_loss did not improve from 0.70642
Epoch 30/500
937/937 [==============================] - 65s 70ms/step - loss: 0.6750 - accuracy: 0.7328 - val_loss: 0.7242 - val_accuracy: 0.7030

Epoch 00030: val_loss did not improve from 0.70642
Epoch 31/500
937/937 [==============================] - 65s 69ms/step - loss: 0.6717 - accuracy: 0.7353 - val_loss: 0.7284 - val_accuracy: 0.7013

Epoch 00031: val_loss did not improve from 0.70642
Epoch 32/500
937/937 [==============================] - 64s 68ms/step - loss: 0.6680 - accuracy: 0.7383 - val_loss: 0.7357 - val_accuracy: 0.6980

Epoch 00032: val_loss did not improve from 0.70642
Epoch 33/500
937/937 [==============================] - 65s 70ms/step - loss: 0.6643 - accuracy: 0.7409 - val_loss: 0.7404 - val_accuracy: 0.6972

Epoch 00033: val_loss did not improve from 0.70642
Epoch 34/500
937/937 [==============================] - 65s 70ms/step - loss: 0.6599 - accuracy: 0.7437 - val_loss: 0.7489 - val_accuracy: 0.6944

Epoch 00034: val_loss did not improve from 0.70642
Epoch 35/500
937/937 [==============================] - 65s 70ms/step - loss: 0.6547 - accuracy: 0.7464 - val_loss: 0.7513 - val_accuracy: 0.6941

Epoch 00035: val_loss did not improve from 0.70642
Epoch 36/500
937/937 [==============================] - 64s 68ms/step - loss: 0.6502 - accuracy: 0.7496 - val_loss: 0.7548 - val_accuracy: 0.6930

Epoch 00036: val_loss did not improve from 0.70642
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 611s 4ms/step - loss: 0.7156 - accuracy: 0.7055
Testing Loss = 0.715618, Testing Accuracy = 0.705467
The data set contains images
[[0.634253740310669, 0.043180178850889206, 0.32256606221199036], [0.18475352227687836, 0.46202337741851807, 0.35322311520576477], [0.19534634053707123, 0.31769225001335144, 0.4869614243507385], [0.1201026439666748, 0.8509185910224915, 0.02897869609296322], [0.050576139241456985, 0.12455996870994568, 0.8248639106750488], [0.04668692871928215, 0.8943303227424622, 0.05898284167051315], [0.3848665952682495, 0.3104539215564728, 0.3046794831752777], [0.4185671806335449, 0.14344483613967896, 0.43798795342445374], [0.07278326153755188, 0.6963465213775635, 0.23087023198604584], [0.025407779961824417, 0.8963558673858643, 0.0782364159822464]]
[[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0]]
3
$W^+$ (auc = 0.8799)
$W^-$ (auc = 0.8802)
$Z$ (auc = 0.8547)
