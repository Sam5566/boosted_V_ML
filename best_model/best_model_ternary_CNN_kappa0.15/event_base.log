

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-04 16:26:36.571165
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 43467.
Epoch 1/100
84/84 [==============================] - 37s 232ms/step - loss: 12.3885 - accuracy: 0.1990 - val_loss: 8.6261 - val_accuracy: 0.2087

Epoch 00001: val_loss improved from inf to 8.62609, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 2/100
84/84 [==============================] - 18s 213ms/step - loss: 6.7065 - accuracy: 0.2082 - val_loss: 5.2888 - val_accuracy: 0.2094

Epoch 00002: val_loss improved from 8.62609 to 5.28884, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 3/100
84/84 [==============================] - 17s 205ms/step - loss: 4.5259 - accuracy: 0.2171 - val_loss: 3.9267 - val_accuracy: 0.2252

Epoch 00003: val_loss improved from 5.28884 to 3.92673, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 4/100
84/84 [==============================] - 18s 218ms/step - loss: 3.4565 - accuracy: 0.2663 - val_loss: 3.1414 - val_accuracy: 0.2866

Epoch 00004: val_loss improved from 3.92673 to 3.14143, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 5/100
84/84 [==============================] - 18s 217ms/step - loss: 2.8531 - accuracy: 0.2952 - val_loss: 2.6667 - val_accuracy: 0.3083

Epoch 00005: val_loss improved from 3.14143 to 2.66671, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 6/100
84/84 [==============================] - 18s 209ms/step - loss: 2.4774 - accuracy: 0.3042 - val_loss: 2.3465 - val_accuracy: 0.3088

Epoch 00006: val_loss improved from 2.66671 to 2.34650, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 7/100
84/84 [==============================] - 18s 212ms/step - loss: 2.2158 - accuracy: 0.3130 - val_loss: 2.1230 - val_accuracy: 0.3185

Epoch 00007: val_loss improved from 2.34650 to 2.12301, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 8/100
84/84 [==============================] - 18s 210ms/step - loss: 2.0303 - accuracy: 0.3260 - val_loss: 1.9673 - val_accuracy: 0.3292

Epoch 00008: val_loss improved from 2.12301 to 1.96729, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 9/100
84/84 [==============================] - 17s 198ms/step - loss: 1.9027 - accuracy: 0.3313 - val_loss: 1.8566 - val_accuracy: 0.3383

Epoch 00009: val_loss improved from 1.96729 to 1.85665, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 10/100
84/84 [==============================] - 18s 219ms/step - loss: 1.8108 - accuracy: 0.3385 - val_loss: 1.7814 - val_accuracy: 0.3414

Epoch 00010: val_loss improved from 1.85665 to 1.78142, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 11/100
84/84 [==============================] - 17s 199ms/step - loss: 1.7441 - accuracy: 0.3479 - val_loss: 1.7240 - val_accuracy: 0.3491

Epoch 00011: val_loss improved from 1.78142 to 1.72404, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 12/100
84/84 [==============================] - 16s 195ms/step - loss: 1.6981 - accuracy: 0.3547 - val_loss: 1.6883 - val_accuracy: 0.3556

Epoch 00012: val_loss improved from 1.72404 to 1.68829, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 13/100
84/84 [==============================] - 18s 217ms/step - loss: 1.6575 - accuracy: 0.3633 - val_loss: 1.6614 - val_accuracy: 0.3578

Epoch 00013: val_loss improved from 1.68829 to 1.66135, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 14/100
84/84 [==============================] - 19s 219ms/step - loss: 1.6299 - accuracy: 0.3737 - val_loss: 1.6314 - val_accuracy: 0.3701

Epoch 00014: val_loss improved from 1.66135 to 1.63142, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 15/100
84/84 [==============================] - 17s 203ms/step - loss: 1.6070 - accuracy: 0.3802 - val_loss: 1.6244 - val_accuracy: 0.3677

Epoch 00015: val_loss improved from 1.63142 to 1.62444, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 16/100
84/84 [==============================] - 19s 221ms/step - loss: 1.5889 - accuracy: 0.3840 - val_loss: 1.6124 - val_accuracy: 0.3688

Epoch 00016: val_loss improved from 1.62444 to 1.61236, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 17/100
84/84 [==============================] - 17s 204ms/step - loss: 1.5749 - accuracy: 0.3905 - val_loss: 1.6016 - val_accuracy: 0.3766

Epoch 00017: val_loss improved from 1.61236 to 1.60160, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 18/100
84/84 [==============================] - 19s 223ms/step - loss: 1.5597 - accuracy: 0.3983 - val_loss: 1.5894 - val_accuracy: 0.3825

Epoch 00018: val_loss improved from 1.60160 to 1.58936, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 19/100
84/84 [==============================] - 18s 212ms/step - loss: 1.5488 - accuracy: 0.4045 - val_loss: 1.5894 - val_accuracy: 0.3814

Epoch 00019: val_loss did not improve from 1.58936
Epoch 20/100
84/84 [==============================] - 20s 234ms/step - loss: 1.5391 - accuracy: 0.4083 - val_loss: 1.5861 - val_accuracy: 0.3878

Epoch 00020: val_loss improved from 1.58936 to 1.58606, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 21/100
84/84 [==============================] - 17s 200ms/step - loss: 1.5315 - accuracy: 0.4162 - val_loss: 1.5853 - val_accuracy: 0.3843

Epoch 00021: val_loss improved from 1.58606 to 1.58525, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 22/100
84/84 [==============================] - 19s 230ms/step - loss: 1.5234 - accuracy: 0.4190 - val_loss: 1.5926 - val_accuracy: 0.3826

Epoch 00022: val_loss did not improve from 1.58525
Epoch 23/100
84/84 [==============================] - 18s 213ms/step - loss: 1.5133 - accuracy: 0.4250 - val_loss: 1.5808 - val_accuracy: 0.3903

Epoch 00023: val_loss improved from 1.58525 to 1.58079, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 24/100
84/84 [==============================] - 17s 206ms/step - loss: 1.5064 - accuracy: 0.4296 - val_loss: 1.5871 - val_accuracy: 0.3890

Epoch 00024: val_loss did not improve from 1.58079
Epoch 25/100
84/84 [==============================] - 18s 218ms/step - loss: 1.5034 - accuracy: 0.4331 - val_loss: 1.6029 - val_accuracy: 0.3810

Epoch 00025: val_loss did not improve from 1.58079
Epoch 26/100
84/84 [==============================] - 18s 209ms/step - loss: 1.4908 - accuracy: 0.4405 - val_loss: 1.5964 - val_accuracy: 0.3873

Epoch 00026: val_loss did not improve from 1.58079
Epoch 27/100
84/84 [==============================] - 18s 211ms/step - loss: 1.4837 - accuracy: 0.4447 - val_loss: 1.6033 - val_accuracy: 0.3875

Epoch 00027: val_loss did not improve from 1.58079
Epoch 28/100
84/84 [==============================] - 19s 221ms/step - loss: 1.4775 - accuracy: 0.4490 - val_loss: 1.6062 - val_accuracy: 0.3914

Epoch 00028: val_loss did not improve from 1.58079
Epoch 29/100
84/84 [==============================] - 20s 232ms/step - loss: 1.4669 - accuracy: 0.4559 - val_loss: 1.6047 - val_accuracy: 0.3904

Epoch 00029: val_loss did not improve from 1.58079
Epoch 30/100
84/84 [==============================] - 21s 247ms/step - loss: 1.4608 - accuracy: 0.4626 - val_loss: 1.6227 - val_accuracy: 0.3837

Epoch 00030: val_loss did not improve from 1.58079
Epoch 31/100
84/84 [==============================] - 20s 241ms/step - loss: 1.4476 - accuracy: 0.4691 - val_loss: 1.6174 - val_accuracy: 0.3884

Epoch 00031: val_loss did not improve from 1.58079
Epoch 32/100
84/84 [==============================] - 17s 204ms/step - loss: 1.4379 - accuracy: 0.4765 - val_loss: 1.6291 - val_accuracy: 0.3892

Epoch 00032: val_loss did not improve from 1.58079
Epoch 33/100
84/84 [==============================] - 19s 223ms/step - loss: 1.4288 - accuracy: 0.4841 - val_loss: 1.6362 - val_accuracy: 0.3882

Epoch 00033: val_loss did not improve from 1.58079
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  3078      [0m
[92m=================================================================[0m
[92mTotal params: 12,130,990[0m
[92mTrainable params: 12,130,986[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 6, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
13584/13584 [==============================] - 43s 3ms/step - loss: 1.5722 - accuracy: 0.3885
Testing Loss = 1.572186, Testing Accuracy = 0.388472
The data set contains images
N of classes 6
$W^+/W^+$ (auc = 83.43 +- 0.0000 %)
$W^-/W^-$ (auc = 84.20 +- 0.0000 %)
$Z/Z$ (auc = 76.41 +- 0.0000 %)
$W^+/W^-$ (auc = 71.93 +- 0.0000 %)
$W^+/Z$$ (auc = 69.12 +- 0.0000 %)
$W^-/Z$ (auc = 69.39 +- 0.0000 %)
The summarized testing accuracy = 38.85 +- 0.0000 %, with the loss = 1.5722 +- 0.000000
