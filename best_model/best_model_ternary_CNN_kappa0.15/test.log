

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-19 15:10:44.909421
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
 - accuracy: 0.4238    452/Unknown - 33s 58ms/step - loss: 5.0882 - accuracy: 0.4238

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-20 21:33:43.528929
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-20 21:34:42.218179
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
795/795 [==============================] - 86s 69ms/step - loss: 3.4666 - accuracy: 0.6373 - val_loss: 1.0150 - val_accuracy: 0.6930

Epoch 00001: val_loss improved from inf to 1.01496, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
795/795 [==============================] - 56s 70ms/step - loss: 0.8384 - accuracy: 0.6895 - val_loss: 0.7494 - val_accuracy: 0.6996

Epoch 00002: val_loss improved from 1.01496 to 0.74941, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
795/795 [==============================] - 107s 134ms/step - loss: 0.7461 - accuracy: 0.6969 - val_loss: 0.7267 - val_accuracy: 0.7032

Epoch 00003: val_loss improved from 0.74941 to 0.72671, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
795/795 [==============================] - 105s 132ms/step - loss: 0.7319 - accuracy: 0.7017 - val_loss: 0.7226 - val_accuracy: 0.7043

Epoch 00004: val_loss improved from 0.72671 to 0.72258, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
795/795 [==============================] - 108s 136ms/step - loss: 0.7251 - accuracy: 0.7044 - val_loss: 0.7204 - val_accuracy: 0.7032

Epoch 00005: val_loss improved from 0.72258 to 0.72039, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
795/795 [==============================] - 103s 129ms/step - loss: 0.7198 - accuracy: 0.7072 - val_loss: 0.7183 - val_accuracy: 0.7039

Epoch 00006: val_loss improved from 0.72039 to 0.71833, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
795/795 [==============================] - 108s 135ms/step - loss: 0.7149 - accuracy: 0.7099 - val_loss: 0.7154 - val_accuracy: 0.7058

Epoch 00007: val_loss improved from 0.71833 to 0.71543, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
795/795 [==============================] - 103s 129ms/step - loss: 0.7112 - accuracy: 0.7115 - val_loss: 0.7114 - val_accuracy: 0.7077

Epoch 00008: val_loss improved from 0.71543 to 0.71138, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
795/795 [==============================] - 108s 135ms/step - loss: 0.7069 - accuracy: 0.7139 - val_loss: 0.7058 - val_accuracy: 0.7105

Epoch 00009: val_loss improved from 0.71138 to 0.70582, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 10/500
795/795 [==============================] - 102s 129ms/step - loss: 0.7030 - accuracy: 0.7166 - val_loss: 0.7060 - val_accuracy: 0.7110

Epoch 00010: val_loss did not improve from 0.70582
Epoch 11/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6992 - accuracy: 0.7186 - val_loss: 0.7032 - val_accuracy: 0.7119

Epoch 00011: val_loss improved from 0.70582 to 0.70321, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 12/500
795/795 [==============================] - 105s 132ms/step - loss: 0.6959 - accuracy: 0.7211 - val_loss: 0.6985 - val_accuracy: 0.7147

Epoch 00012: val_loss improved from 0.70321 to 0.69853, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 13/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6921 - accuracy: 0.7229 - val_loss: 0.6980 - val_accuracy: 0.7159

Epoch 00013: val_loss improved from 0.69853 to 0.69797, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 14/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6894 - accuracy: 0.7246 - val_loss: 0.6950 - val_accuracy: 0.7164

Epoch 00014: val_loss improved from 0.69797 to 0.69496, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 15/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6863 - accuracy: 0.7254 - val_loss: 0.6937 - val_accuracy: 0.7169

Epoch 00015: val_loss improved from 0.69496 to 0.69368, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 16/500
795/795 [==============================] - 101s 126ms/step - loss: 0.6844 - accuracy: 0.7272 - val_loss: 0.6936 - val_accuracy: 0.7174

Epoch 00016: val_loss improved from 0.69368 to 0.69357, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 17/500
795/795 [==============================] - 108s 135ms/step - loss: 0.6815 - accuracy: 0.7281 - val_loss: 0.6937 - val_accuracy: 0.7181

Epoch 00017: val_loss did not improve from 0.69357
Epoch 18/500
795/795 [==============================] - 106s 133ms/step - loss: 0.6797 - accuracy: 0.7292 - val_loss: 0.6907 - val_accuracy: 0.7189

Epoch 00018: val_loss improved from 0.69357 to 0.69066, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 19/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6774 - accuracy: 0.7309 - val_loss: 0.6930 - val_accuracy: 0.7183

Epoch 00019: val_loss did not improve from 0.69066
Epoch 20/500
795/795 [==============================] - 103s 129ms/step - loss: 0.6757 - accuracy: 0.7316 - val_loss: 0.6925 - val_accuracy: 0.7182

Epoch 00020: val_loss did not improve from 0.69066
Epoch 21/500
795/795 [==============================] - 108s 135ms/step - loss: 0.6729 - accuracy: 0.7335 - val_loss: 0.6906 - val_accuracy: 0.7202

Epoch 00021: val_loss improved from 0.69066 to 0.69060, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 22/500
795/795 [==============================] - 103s 129ms/step - loss: 0.6714 - accuracy: 0.7343 - val_loss: 0.6911 - val_accuracy: 0.7201

Epoch 00022: val_loss did not improve from 0.69060
Epoch 23/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6686 - accuracy: 0.7360 - val_loss: 0.6942 - val_accuracy: 0.7177

Epoch 00023: val_loss did not improve from 0.69060
Epoch 24/500
795/795 [==============================] - 103s 129ms/step - loss: 0.6672 - accuracy: 0.7375 - val_loss: 0.6912 - val_accuracy: 0.7192

Epoch 00024: val_loss did not improve from 0.69060
Epoch 25/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6647 - accuracy: 0.7390 - val_loss: 0.6924 - val_accuracy: 0.7192

Epoch 00025: val_loss did not improve from 0.69060
Epoch 26/500
795/795 [==============================] - 102s 129ms/step - loss: 0.6627 - accuracy: 0.7399 - val_loss: 0.6947 - val_accuracy: 0.7184

Epoch 00026: val_loss did not improve from 0.69060
Epoch 27/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6610 - accuracy: 0.7405 - val_loss: 0.6947 - val_accuracy: 0.7176

Epoch 00027: val_loss did not improve from 0.69060
Epoch 28/500
795/795 [==============================] - 103s 129ms/step - loss: 0.6588 - accuracy: 0.7415 - val_loss: 0.6893 - val_accuracy: 0.7211

Epoch 00028: val_loss improved from 0.69060 to 0.68926, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 29/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6566 - accuracy: 0.7431 - val_loss: 0.6937 - val_accuracy: 0.7189

Epoch 00029: val_loss did not improve from 0.68926
Epoch 30/500
795/795 [==============================] - 103s 129ms/step - loss: 0.6542 - accuracy: 0.7456 - val_loss: 0.6932 - val_accuracy: 0.7205

Epoch 00030: val_loss did not improve from 0.68926
Epoch 31/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6524 - accuracy: 0.7459 - val_loss: 0.6961 - val_accuracy: 0.7179

Epoch 00031: val_loss did not improve from 0.68926
Epoch 32/500
795/795 [==============================] - 103s 129ms/step - loss: 0.6507 - accuracy: 0.7471 - val_loss: 0.6920 - val_accuracy: 0.7202

Epoch 00032: val_loss did not improve from 0.68926
Epoch 33/500
795/795 [==============================] - 108s 135ms/step - loss: 0.6473 - accuracy: 0.7490 - val_loss: 0.6973 - val_accuracy: 0.7184

Epoch 00033: val_loss did not improve from 0.68926
Epoch 34/500
795/795 [==============================] - 102s 129ms/step - loss: 0.6454 - accuracy: 0.7516 - val_loss: 0.6958 - val_accuracy: 0.7191

Epoch 00034: val_loss did not improve from 0.68926
Epoch 35/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6427 - accuracy: 0.7524 - val_loss: 0.7015 - val_accuracy: 0.7165

Epoch 00035: val_loss did not improve from 0.68926
Epoch 36/500
795/795 [==============================] - 103s 129ms/step - loss: 0.6402 - accuracy: 0.7541 - val_loss: 0.6981 - val_accuracy: 0.7185

Epoch 00036: val_loss did not improve from 0.68926
Epoch 37/500
795/795 [==============================] - 108s 135ms/step - loss: 0.6375 - accuracy: 0.7556 - val_loss: 0.7010 - val_accuracy: 0.7177

Epoch 00037: val_loss did not improve from 0.68926
Epoch 38/500
795/795 [==============================] - 107s 135ms/step - loss: 0.6346 - accuracy: 0.7581 - val_loss: 0.7058 - val_accuracy: 0.7165

Epoch 00038: val_loss did not improve from 0.68926
Epoch 00038: early stopping
The data set contains images
127283/127283 [==============================] - 666s 5ms/step - loss: 0.7425 - accuracy: 0.6962
Testing Loss = 0.742479, Testing Accuracy = 0.696173
The data set contains images
[[0.40256598591804504, 0.5291622281074524, 0.06827180087566376], [0.3736947178840637, 0.5288774967193604, 0.09742776304483414], [0.023221168667078018, 0.911350429058075, 0.06542842835187912], [0.2912486493587494, 0.04826107248663902, 0.6604902744293213], [0.7997586131095886, 0.06662650406360626, 0.1336149126291275], [0.18206259608268738, 0.10433021187782288, 0.7136071920394897], [0.008165997453033924, 0.3031688332557678, 0.6886651515960693], [0.40929701924324036, 0.309902161359787, 0.28080081939697266], [0.04413123056292534, 0.4125598073005676, 0.5433089733123779], [0.9294219017028809, 0.02388077788054943, 0.04669729247689247]]
[[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]]
3


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-22 17:24:52.027440
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
 - accuracy: 0.5911    384/Unknown - 40s 72ms/step - loss: 5.6096 - accuracy: 0.5913

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-22 17:25:56.800665
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
795/795 [==============================] - 68s 79ms/step - loss: 3.4795 - accuracy: 0.6358 - val_loss: 1.0244 - val_accuracy: 0.6929

Epoch 00001: val_loss improved from inf to 1.02438, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
795/795 [==============================] - 55s 69ms/step - loss: 0.8424 - accuracy: 0.6886 - val_loss: 0.7506 - val_accuracy: 0.6998

Epoch 00002: val_loss improved from 1.02438 to 0.75056, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
795/795 [==============================] - 55s 69ms/step - loss: 0.7478 - accuracy: 0.6966 - val_loss: 0.7302 - val_accuracy: 0.7001

Epoch 00003: val_loss improved from 0.75056 to 0.73021, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
795/795 [==============================] - 54s 68ms/step - loss: 0.7333 - accuracy: 0.7012 - val_loss: 0.7264 - val_accuracy: 0.7002

Epoch 00004: val_loss improved from 0.73021 to 0.72640, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
795/795 [==============================] - 54s 68ms/step - loss: 0.7268 - accuracy: 0.7037 - val_loss: 0.7213 - val_accuracy: 0.7031

Epoch 00005: val_loss improved from 0.72640 to 0.72126, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
795/795 [==============================] - 55s 69ms/step - loss: 0.7217 - accuracy: 0.7060 - val_loss: 0.7176 - val_accuracy: 0.7046

Epoch 00006: val_loss improved from 0.72126 to 0.71763, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
795/795 [==============================] - 54s 68ms/step - loss: 0.7176 - accuracy: 0.7084 - val_loss: 0.7147 - val_accuracy: 0.7060

Epoch 00007: val_loss improved from 0.71763 to 0.71473, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
795/795 [==============================] - 55s 69ms/step - loss: 0.7142 - accuracy: 0.7104 - val_loss: 0.7175 - val_accuracy: 0.7037

Epoch 00008: val_loss did not improve from 0.71473
Epoch 9/500
795/795 [==============================] - 54s 68ms/step - loss: 0.7104 - accuracy: 0.7124 - val_loss: 0.7110 - val_accuracy: 0.7069

Epoch 00009: val_loss improved from 0.71473 to 0.71104, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 10/500
795/795 [==============================] - 54s 68ms/step - loss: 0.7064 - accuracy: 0.7146 - val_loss: 0.7108 - val_accuracy: 0.7073

Epoch 00010: val_loss improved from 0.71104 to 0.71076, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 11/500
795/795 [==============================] - 54s 68ms/step - loss: 0.7034 - accuracy: 0.7166 - val_loss: 0.7123 - val_accuracy: 0.7054

Epoch 00011: val_loss did not improve from 0.71076
Epoch 12/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6997 - accuracy: 0.7192 - val_loss: 0.7049 - val_accuracy: 0.7105

Epoch 00012: val_loss improved from 0.71076 to 0.70494, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 13/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6955 - accuracy: 0.7211 - val_loss: 0.7044 - val_accuracy: 0.7110

Epoch 00013: val_loss improved from 0.70494 to 0.70439, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 14/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6921 - accuracy: 0.7235 - val_loss: 0.6997 - val_accuracy: 0.7143

Epoch 00014: val_loss improved from 0.70439 to 0.69965, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 15/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6894 - accuracy: 0.7250 - val_loss: 0.6999 - val_accuracy: 0.7130

Epoch 00015: val_loss did not improve from 0.69965
Epoch 16/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6865 - accuracy: 0.7261 - val_loss: 0.6937 - val_accuracy: 0.7180

Epoch 00016: val_loss improved from 0.69965 to 0.69366, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 17/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6839 - accuracy: 0.7281 - val_loss: 0.6938 - val_accuracy: 0.7163

Epoch 00017: val_loss did not improve from 0.69366
Epoch 18/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6813 - accuracy: 0.7291 - val_loss: 0.6912 - val_accuracy: 0.7196

Epoch 00018: val_loss improved from 0.69366 to 0.69119, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 19/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6791 - accuracy: 0.7304 - val_loss: 0.6916 - val_accuracy: 0.7179

Epoch 00019: val_loss did not improve from 0.69119
Epoch 20/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6764 - accuracy: 0.7321 - val_loss: 0.6943 - val_accuracy: 0.7170

Epoch 00020: val_loss did not improve from 0.69119
Epoch 21/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6745 - accuracy: 0.7326 - val_loss: 0.6918 - val_accuracy: 0.7182

Epoch 00021: val_loss did not improve from 0.69119
Epoch 22/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6720 - accuracy: 0.7346 - val_loss: 0.6923 - val_accuracy: 0.7185

Epoch 00022: val_loss did not improve from 0.69119
Epoch 23/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6706 - accuracy: 0.7353 - val_loss: 0.6883 - val_accuracy: 0.7214

Epoch 00023: val_loss improved from 0.69119 to 0.68833, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 24/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6684 - accuracy: 0.7369 - val_loss: 0.6900 - val_accuracy: 0.7204

Epoch 00024: val_loss did not improve from 0.68833
Epoch 25/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6657 - accuracy: 0.7389 - val_loss: 0.6920 - val_accuracy: 0.7197

Epoch 00025: val_loss did not improve from 0.68833
Epoch 26/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6638 - accuracy: 0.7398 - val_loss: 0.6903 - val_accuracy: 0.7214

Epoch 00026: val_loss did not improve from 0.68833
Epoch 27/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6610 - accuracy: 0.7415 - val_loss: 0.6914 - val_accuracy: 0.7206

Epoch 00027: val_loss did not improve from 0.68833
Epoch 28/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6594 - accuracy: 0.7429 - val_loss: 0.6915 - val_accuracy: 0.7201

Epoch 00028: val_loss did not improve from 0.68833
Epoch 29/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6574 - accuracy: 0.7441 - val_loss: 0.6954 - val_accuracy: 0.7190

Epoch 00029: val_loss did not improve from 0.68833
Epoch 30/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6550 - accuracy: 0.7449 - val_loss: 0.6958 - val_accuracy: 0.7184

Epoch 00030: val_loss did not improve from 0.68833
Epoch 31/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6534 - accuracy: 0.7464 - val_loss: 0.6919 - val_accuracy: 0.7205

Epoch 00031: val_loss did not improve from 0.68833
Epoch 32/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6501 - accuracy: 0.7484 - val_loss: 0.6953 - val_accuracy: 0.7183

Epoch 00032: val_loss did not improve from 0.68833
Epoch 33/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6485 - accuracy: 0.7497 - val_loss: 0.6972 - val_accuracy: 0.7194

Epoch 00033: val_loss did not improve from 0.68833
Epoch 00033: early stopping
Model: "CNN"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
sequential (Sequential)      (None, 512)               12127912  
_________________________________________________________________
dense_2 (Dense)              multiple                  1539      
=================================================================
Total params: 12,129,451
Trainable params: 12,129,447
Non-trainable params: 4
_________________________________________________________________
None
The data set contains images
127283/127283 [==============================] - 469s 4ms/step - loss: 0.7315 - accuracy: 0.6980
Testing Loss = 0.731488, Testing Accuracy = 0.698004
The data set contains images
[[0.10764285922050476, 0.07586690783500671, 0.8164901733398438], [0.060358766466379166, 0.08049172908067703, 0.8591495156288147], [0.3090173304080963, 0.42097339034080505, 0.27000927925109863], [0.226052388548851, 0.4014029800891876, 0.3725445866584778], [0.01200012769550085, 0.24741201102733612, 0.7405878901481628], [0.483524352312088, 0.41823285818099976, 0.09824271500110626], [0.3910561800003052, 0.06701736152172089, 0.5419265031814575], [0.3002298176288605, 0.6264704465866089, 0.07329974323511124], [0.046393461525440216, 0.21337305009365082, 0.7402334809303284], [0.7260863780975342, 0.01900673285126686, 0.25490695238113403]]
[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]]
3
$W^+$ (auc = 0.88)
$W^-$ (auc = 0.89)
$Z$ (auc = 0.84)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-22 21:16:51.348897
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-08-22 21:17:23.045171
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
795/795 [==============================] - 82s 85ms/step - loss: 3.4392 - accuracy: 0.6386 - val_loss: 1.0204 - val_accuracy: 0.6911

Epoch 00001: val_loss improved from inf to 1.02038, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
795/795 [==============================] - 54s 68ms/step - loss: 0.8396 - accuracy: 0.6890 - val_loss: 0.7481 - val_accuracy: 0.6997

Epoch 00002: val_loss improved from 1.02038 to 0.74808, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
795/795 [==============================] - 54s 67ms/step - loss: 0.7462 - accuracy: 0.6976 - val_loss: 0.7299 - val_accuracy: 0.7011

Epoch 00003: val_loss improved from 0.74808 to 0.72987, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
795/795 [==============================] - 54s 67ms/step - loss: 0.7320 - accuracy: 0.7018 - val_loss: 0.7221 - val_accuracy: 0.7046

Epoch 00004: val_loss improved from 0.72987 to 0.72211, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
795/795 [==============================] - 184s 232ms/step - loss: 0.7253 - accuracy: 0.7047 - val_loss: 0.7240 - val_accuracy: 0.7004

Epoch 00005: val_loss did not improve from 0.72211
Epoch 6/500
795/795 [==============================] - 236s 297ms/step - loss: 0.7212 - accuracy: 0.7065 - val_loss: 0.7172 - val_accuracy: 0.7049

Epoch 00006: val_loss improved from 0.72211 to 0.71723, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
795/795 [==============================] - 72s 90ms/step - loss: 0.7163 - accuracy: 0.7089 - val_loss: 0.7188 - val_accuracy: 0.7027

Epoch 00007: val_loss did not improve from 0.71723
Epoch 8/500
795/795 [==============================] - 55s 69ms/step - loss: 0.7125 - accuracy: 0.7114 - val_loss: 0.7118 - val_accuracy: 0.7077

Epoch 00008: val_loss improved from 0.71723 to 0.71180, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
795/795 [==============================] - 55s 69ms/step - loss: 0.7094 - accuracy: 0.7130 - val_loss: 0.7091 - val_accuracy: 0.7085

Epoch 00009: val_loss improved from 0.71180 to 0.70914, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 10/500
795/795 [==============================] - 55s 69ms/step - loss: 0.7048 - accuracy: 0.7155 - val_loss: 0.7079 - val_accuracy: 0.7091

Epoch 00010: val_loss improved from 0.70914 to 0.70786, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 11/500
795/795 [==============================] - 55s 69ms/step - loss: 0.7004 - accuracy: 0.7176 - val_loss: 0.7044 - val_accuracy: 0.7112

Epoch 00011: val_loss improved from 0.70786 to 0.70442, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 12/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6969 - accuracy: 0.7204 - val_loss: 0.7022 - val_accuracy: 0.7126

Epoch 00012: val_loss improved from 0.70442 to 0.70219, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 13/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6935 - accuracy: 0.7220 - val_loss: 0.7020 - val_accuracy: 0.7130

Epoch 00013: val_loss improved from 0.70219 to 0.70203, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 14/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6900 - accuracy: 0.7241 - val_loss: 0.6958 - val_accuracy: 0.7173

Epoch 00014: val_loss improved from 0.70203 to 0.69583, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 15/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6872 - accuracy: 0.7254 - val_loss: 0.6954 - val_accuracy: 0.7167

Epoch 00015: val_loss improved from 0.69583 to 0.69544, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 16/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6843 - accuracy: 0.7269 - val_loss: 0.6937 - val_accuracy: 0.7176

Epoch 00016: val_loss improved from 0.69544 to 0.69371, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 17/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6819 - accuracy: 0.7282 - val_loss: 0.6896 - val_accuracy: 0.7206

Epoch 00017: val_loss improved from 0.69371 to 0.68960, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 18/500
795/795 [==============================] - 55s 70ms/step - loss: 0.6793 - accuracy: 0.7297 - val_loss: 0.6891 - val_accuracy: 0.7195

Epoch 00018: val_loss improved from 0.68960 to 0.68910, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 19/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6776 - accuracy: 0.7316 - val_loss: 0.6870 - val_accuracy: 0.7223

Epoch 00019: val_loss improved from 0.68910 to 0.68701, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 20/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6756 - accuracy: 0.7320 - val_loss: 0.6893 - val_accuracy: 0.7195

Epoch 00020: val_loss did not improve from 0.68701
Epoch 21/500
795/795 [==============================] - 55s 68ms/step - loss: 0.6729 - accuracy: 0.7339 - val_loss: 0.6883 - val_accuracy: 0.7206

Epoch 00021: val_loss did not improve from 0.68701
Epoch 22/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6712 - accuracy: 0.7341 - val_loss: 0.6881 - val_accuracy: 0.7207

Epoch 00022: val_loss did not improve from 0.68701
Epoch 23/500
795/795 [==============================] - 130s 164ms/step - loss: 0.6690 - accuracy: 0.7358 - val_loss: 0.6877 - val_accuracy: 0.7208

Epoch 00023: val_loss did not improve from 0.68701
Epoch 24/500
795/795 [==============================] - 170s 213ms/step - loss: 0.6671 - accuracy: 0.7370 - val_loss: 0.6864 - val_accuracy: 0.7225

Epoch 00024: val_loss improved from 0.68701 to 0.68636, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 25/500
795/795 [==============================] - 76s 95ms/step - loss: 0.6651 - accuracy: 0.7383 - val_loss: 0.6876 - val_accuracy: 0.7221

Epoch 00025: val_loss did not improve from 0.68636
Epoch 26/500
795/795 [==============================] - 56s 68ms/step - loss: 0.6626 - accuracy: 0.7396 - val_loss: 0.6881 - val_accuracy: 0.7216

Epoch 00026: val_loss did not improve from 0.68636
Epoch 27/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6609 - accuracy: 0.7407 - val_loss: 0.6880 - val_accuracy: 0.7220

Epoch 00027: val_loss did not improve from 0.68636
Epoch 28/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6593 - accuracy: 0.7418 - val_loss: 0.6880 - val_accuracy: 0.7225

Epoch 00028: val_loss did not improve from 0.68636
Epoch 29/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6576 - accuracy: 0.7430 - val_loss: 0.6931 - val_accuracy: 0.7197

Epoch 00029: val_loss did not improve from 0.68636
Epoch 30/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6549 - accuracy: 0.7444 - val_loss: 0.6896 - val_accuracy: 0.7216

Epoch 00030: val_loss did not improve from 0.68636
Epoch 31/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6520 - accuracy: 0.7461 - val_loss: 0.6904 - val_accuracy: 0.7212

Epoch 00031: val_loss did not improve from 0.68636
Epoch 32/500
795/795 [==============================] - 54s 68ms/step - loss: 0.6511 - accuracy: 0.7477 - val_loss: 0.6901 - val_accuracy: 0.7224

Epoch 00032: val_loss did not improve from 0.68636
Epoch 33/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6482 - accuracy: 0.7490 - val_loss: 0.6922 - val_accuracy: 0.7216

Epoch 00033: val_loss did not improve from 0.68636
Epoch 34/500
795/795 [==============================] - 55s 69ms/step - loss: 0.6461 - accuracy: 0.7500 - val_loss: 0.6953 - val_accuracy: 0.7195

Epoch 00034: val_loss did not improve from 0.68636
Epoch 00034: early stopping
Model: "CNN_ternary"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
sequential (Sequential)      (None, 512)               12127912  
_________________________________________________________________
dense_2 (Dense)              multiple                  1539      
=================================================================
Total params: 12,129,451
Trainable params: 12,129,447
Non-trainable params: 4
_________________________________________________________________
None
The data set contains images
127283/127283 [==============================] - 522s 4ms/step - loss: 0.7304 - accuracy: 0.6977
Testing Loss = 0.730418, Testing Accuracy = 0.697666
The data set contains images
[[0.14026528596878052, 0.07199445366859436, 0.7877402305603027], [0.05909733101725578, 0.07356002181768417, 0.8673425912857056], [0.44155845046043396, 0.2013774961233139, 0.3570640981197357], [0.22045382857322693, 0.3528085947036743, 0.42673754692077637], [0.012545003555715084, 0.21384593844413757, 0.7736090421676636], [0.5057499408721924, 0.37872689962387085, 0.11552311480045319], [0.5234716534614563, 0.09207303822040558, 0.3844553530216217], [0.4037218987941742, 0.4519522488117218, 0.14432594180107117], [0.14733444154262543, 0.716134786605835, 0.13653069734573364], [0.8151450753211975, 0.03179091587662697, 0.1530640423297882]]
[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]]
3
$W^+$ (auc = 0.88)
$W^-$ (auc = 0.89)
$Z$ (auc = 0.84)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 10:48:58.356192
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
352/352 [==============================] - 41s 70ms/step - loss: 5.9055 - accuracy: 0.6003 - val_loss: 2.4707 - val_accuracy: 0.6498

Epoch 00001: val_loss improved from inf to 2.47069, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
352/352 [==============================] - 24s 68ms/step - loss: 1.6542 - accuracy: 0.6758 - val_loss: 1.1393 - val_accuracy: 0.6934

Epoch 00002: val_loss improved from 2.47069 to 1.13932, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
352/352 [==============================] - 24s 68ms/step - loss: 0.9765 - accuracy: 0.6842 - val_loss: 0.8328 - val_accuracy: 0.7002

Epoch 00003: val_loss improved from 1.13932 to 0.83283, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
352/352 [==============================] - 24s 69ms/step - loss: 0.8128 - accuracy: 0.6890 - val_loss: 0.7580 - val_accuracy: 0.7040

Epoch 00004: val_loss improved from 0.83283 to 0.75804, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7677 - accuracy: 0.6923 - val_loss: 0.7344 - val_accuracy: 0.7055

Epoch 00005: val_loss improved from 0.75804 to 0.73435, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7518 - accuracy: 0.6939 - val_loss: 0.7267 - val_accuracy: 0.7069

Epoch 00006: val_loss improved from 0.73435 to 0.72673, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7435 - accuracy: 0.6962 - val_loss: 0.7241 - val_accuracy: 0.7070

Epoch 00007: val_loss improved from 0.72673 to 0.72413, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7384 - accuracy: 0.6982 - val_loss: 0.7181 - val_accuracy: 0.7092

Epoch 00008: val_loss improved from 0.72413 to 0.71812, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
352/352 [==============================] - 25s 69ms/step - loss: 0.7358 - accuracy: 0.6989 - val_loss: 0.7183 - val_accuracy: 0.7084

Epoch 00009: val_loss did not improve from 0.71812
Epoch 10/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7321 - accuracy: 0.7007 - val_loss: 0.7143 - val_accuracy: 0.7092

Epoch 00010: val_loss improved from 0.71812 to 0.71431, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 11/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7299 - accuracy: 0.7019 - val_loss: 0.7120 - val_accuracy: 0.7111

Epoch 00011: val_loss improved from 0.71431 to 0.71203, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 12/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7272 - accuracy: 0.7036 - val_loss: 0.7158 - val_accuracy: 0.7082

Epoch 00012: val_loss did not improve from 0.71203
Epoch 13/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7244 - accuracy: 0.7054 - val_loss: 0.7126 - val_accuracy: 0.7101

Epoch 00013: val_loss did not improve from 0.71203
Epoch 14/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7222 - accuracy: 0.7060 - val_loss: 0.7116 - val_accuracy: 0.7105

Epoch 00014: val_loss improved from 0.71203 to 0.71162, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 15/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7207 - accuracy: 0.7076 - val_loss: 0.7151 - val_accuracy: 0.7088

Epoch 00015: val_loss did not improve from 0.71162
Epoch 16/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7174 - accuracy: 0.7090 - val_loss: 0.7114 - val_accuracy: 0.7098

Epoch 00016: val_loss improved from 0.71162 to 0.71139, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 17/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7164 - accuracy: 0.7095 - val_loss: 0.7138 - val_accuracy: 0.7098

Epoch 00017: val_loss did not improve from 0.71139
Epoch 18/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7144 - accuracy: 0.7112 - val_loss: 0.7131 - val_accuracy: 0.7089

Epoch 00018: val_loss did not improve from 0.71139
Epoch 19/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7117 - accuracy: 0.7128 - val_loss: 0.7138 - val_accuracy: 0.7097

Epoch 00019: val_loss did not improve from 0.71139
Epoch 20/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7087 - accuracy: 0.7147 - val_loss: 0.7129 - val_accuracy: 0.7100

Epoch 00020: val_loss did not improve from 0.71139
Epoch 21/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7058 - accuracy: 0.7173 - val_loss: 0.7164 - val_accuracy: 0.7094

Epoch 00021: val_loss did not improve from 0.71139
Epoch 22/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7031 - accuracy: 0.7181 - val_loss: 0.7162 - val_accuracy: 0.7094

Epoch 00022: val_loss did not improve from 0.71139
Epoch 23/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7004 - accuracy: 0.7209 - val_loss: 0.7216 - val_accuracy: 0.7080

Epoch 00023: val_loss did not improve from 0.71139
Epoch 24/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6962 - accuracy: 0.7235 - val_loss: 0.7185 - val_accuracy: 0.7096

Epoch 00024: val_loss did not improve from 0.71139
Epoch 25/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6925 - accuracy: 0.7258 - val_loss: 0.7241 - val_accuracy: 0.7091

Epoch 00025: val_loss did not improve from 0.71139
Epoch 26/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6878 - accuracy: 0.7298 - val_loss: 0.7264 - val_accuracy: 0.7075

Epoch 00026: val_loss did not improve from 0.71139
Epoch 00026: early stopping
Model: "CNN_ternary"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
sequential (Sequential)      (None, 512)               12127912  
_________________________________________________________________
dense_2 (Dense)              multiple                  1539      
=================================================================
Total params: 12,129,451
Trainable params: 12,129,447
Non-trainable params: 4
_________________________________________________________________
None


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 11:56:52.156625
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
352/352 [==============================] - 30s 69ms/step - loss: 5.9208 - accuracy: 0.5976 - val_loss: 2.4783 - val_accuracy: 0.6469

Epoch 00001: val_loss improved from inf to 2.47831, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
352/352 [==============================] - 24s 68ms/step - loss: 1.6551 - accuracy: 0.6739 - val_loss: 1.1344 - val_accuracy: 0.6948

Epoch 00002: val_loss improved from 2.47831 to 1.13438, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
352/352 [==============================] - 24s 69ms/step - loss: 0.9745 - accuracy: 0.6838 - val_loss: 0.8346 - val_accuracy: 0.6983

Epoch 00003: val_loss improved from 1.13438 to 0.83464, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
352/352 [==============================] - 24s 69ms/step - loss: 0.8102 - accuracy: 0.6892 - val_loss: 0.7585 - val_accuracy: 0.7027

Epoch 00004: val_loss improved from 0.83464 to 0.75853, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7661 - accuracy: 0.6927 - val_loss: 0.7358 - val_accuracy: 0.7031

Epoch 00005: val_loss improved from 0.75853 to 0.73582, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7507 - accuracy: 0.6940 - val_loss: 0.7290 - val_accuracy: 0.7054

Epoch 00006: val_loss improved from 0.73582 to 0.72898, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7429 - accuracy: 0.6963 - val_loss: 0.7225 - val_accuracy: 0.7070

Epoch 00007: val_loss improved from 0.72898 to 0.72251, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7380 - accuracy: 0.6981 - val_loss: 0.7214 - val_accuracy: 0.7064

Epoch 00008: val_loss improved from 0.72251 to 0.72142, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7338 - accuracy: 0.7001 - val_loss: 0.7197 - val_accuracy: 0.7073

Epoch 00009: val_loss improved from 0.72142 to 0.71974, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 10/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7324 - accuracy: 0.7005 - val_loss: 0.7197 - val_accuracy: 0.7059

Epoch 00010: val_loss improved from 0.71974 to 0.71968, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 11/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7289 - accuracy: 0.7021 - val_loss: 0.7160 - val_accuracy: 0.7087

Epoch 00011: val_loss improved from 0.71968 to 0.71599, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 12/500
352/352 [==============================] - 25s 71ms/step - loss: 0.7267 - accuracy: 0.7027 - val_loss: 0.7151 - val_accuracy: 0.7085

Epoch 00012: val_loss improved from 0.71599 to 0.71506, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 13/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7244 - accuracy: 0.7057 - val_loss: 0.7144 - val_accuracy: 0.7084

Epoch 00013: val_loss improved from 0.71506 to 0.71439, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 14/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7225 - accuracy: 0.7059 - val_loss: 0.7172 - val_accuracy: 0.7073

Epoch 00014: val_loss did not improve from 0.71439
Epoch 15/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7204 - accuracy: 0.7071 - val_loss: 0.7145 - val_accuracy: 0.7090

Epoch 00015: val_loss did not improve from 0.71439
Epoch 16/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7183 - accuracy: 0.7081 - val_loss: 0.7153 - val_accuracy: 0.7083

Epoch 00016: val_loss did not improve from 0.71439
Epoch 17/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7154 - accuracy: 0.7114 - val_loss: 0.7142 - val_accuracy: 0.7087

Epoch 00017: val_loss improved from 0.71439 to 0.71423, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 18/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7134 - accuracy: 0.7117 - val_loss: 0.7138 - val_accuracy: 0.7097

Epoch 00018: val_loss improved from 0.71423 to 0.71377, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 19/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7120 - accuracy: 0.7131 - val_loss: 0.7160 - val_accuracy: 0.7077

Epoch 00019: val_loss did not improve from 0.71377
Epoch 20/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7080 - accuracy: 0.7149 - val_loss: 0.7163 - val_accuracy: 0.7089

Epoch 00020: val_loss did not improve from 0.71377
Epoch 21/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7055 - accuracy: 0.7175 - val_loss: 0.7172 - val_accuracy: 0.7092

Epoch 00021: val_loss did not improve from 0.71377
Epoch 22/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7021 - accuracy: 0.7198 - val_loss: 0.7216 - val_accuracy: 0.7063

Epoch 00022: val_loss did not improve from 0.71377
Epoch 23/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6988 - accuracy: 0.7228 - val_loss: 0.7208 - val_accuracy: 0.7071

Epoch 00023: val_loss did not improve from 0.71377
Epoch 24/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6955 - accuracy: 0.7243 - val_loss: 0.7261 - val_accuracy: 0.7063

Epoch 00024: val_loss did not improve from 0.71377
Epoch 25/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6914 - accuracy: 0.7281 - val_loss: 0.7267 - val_accuracy: 0.7054

Epoch 00025: val_loss did not improve from 0.71377
Epoch 26/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6870 - accuracy: 0.7315 - val_loss: 0.7308 - val_accuracy: 0.7063

Epoch 00026: val_loss did not improve from 0.71377
Epoch 27/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6821 - accuracy: 0.7340 - val_loss: 0.7338 - val_accuracy: 0.7039

Epoch 00027: val_loss did not improve from 0.71377
Epoch 28/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6764 - accuracy: 0.7388 - val_loss: 0.7383 - val_accuracy: 0.7045

Epoch 00028: val_loss did not improve from 0.71377
Epoch 00028: early stopping
Model: "CNN_ternary"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
sequential (Sequential)      (None, 512)               12127912  
_________________________________________________________________
dense_2 (Dense)              multiple                  1539      
=================================================================
Total params: 12,129,451
Trainable params: 12,129,447
Non-trainable params: 4
_________________________________________________________________
None
The data set contains images
56456/56456 [==============================] - 246s 4ms/step - loss: 0.7451 - accuracy: 0.6999
Testing Loss = 0.745068, Testing Accuracy = 0.699908
The data set contains images
[[0.503169596195221, 0.043762192130088806, 0.45306816697120667], [0.9431195259094238, 0.0024693687446415424, 0.054411113262176514], [0.6009036898612976, 0.10798563063144684, 0.29111069440841675], [0.8236117959022522, 0.06737709790468216, 0.10901103168725967], [0.7245510220527649, 0.16703097522258759, 0.10841810703277588], [0.43333572149276733, 0.4826292097568512, 0.08403512090444565], [0.6009036898612976, 0.10798563063144684, 0.29111069440841675], [0.7743280529975891, 0.10777511447668076, 0.11789683252573013], [0.5542575120925903, 0.13858264684677124, 0.30715981125831604], [0.9639020562171936, 0.01105376798659563, 0.025044230744242668]]
[[0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]]
3
$W^+$ (auc = 0.87)
$W^-$ (auc = 0.87)
$Z$ (auc = 0.83)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 12:20:40.386524
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
352/352 [==============================] - 32s 72ms/step - loss: 5.8920 - accuracy: 0.6010 - val_loss: 2.4764 - val_accuracy: 0.6383

Epoch 00001: val_loss improved from inf to 2.47640, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
352/352 [==============================] - 26s 74ms/step - loss: 1.6499 - accuracy: 0.6752 - val_loss: 1.1339 - val_accuracy: 0.6934

Epoch 00002: val_loss improved from 2.47640 to 1.13390, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
352/352 [==============================] - 24s 68ms/step - loss: 0.9761 - accuracy: 0.6836 - val_loss: 0.8373 - val_accuracy: 0.6952

Epoch 00003: val_loss improved from 1.13390 to 0.83734, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
352/352 [==============================] - 24s 68ms/step - loss: 0.8124 - accuracy: 0.6884 - val_loss: 0.7613 - val_accuracy: 0.7004

Epoch 00004: val_loss improved from 0.83734 to 0.76126, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7685 - accuracy: 0.6910 - val_loss: 0.7417 - val_accuracy: 0.7008

Epoch 00005: val_loss improved from 0.76126 to 0.74166, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7523 - accuracy: 0.6940 - val_loss: 0.7329 - val_accuracy: 0.7024

Epoch 00006: val_loss improved from 0.74166 to 0.73291, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7455 - accuracy: 0.6951 - val_loss: 0.7214 - val_accuracy: 0.7069

Epoch 00007: val_loss improved from 0.73291 to 0.72141, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7395 - accuracy: 0.6975 - val_loss: 0.7206 - val_accuracy: 0.7056

Epoch 00008: val_loss improved from 0.72141 to 0.72058, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7362 - accuracy: 0.6988 - val_loss: 0.7203 - val_accuracy: 0.7067

Epoch 00009: val_loss improved from 0.72058 to 0.72031, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 10/500
352/352 [==============================] - 26s 73ms/step - loss: 0.7341 - accuracy: 0.6988 - val_loss: 0.7167 - val_accuracy: 0.7082

Epoch 00010: val_loss improved from 0.72031 to 0.71672, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 11/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7313 - accuracy: 0.7001 - val_loss: 0.7140 - val_accuracy: 0.7094

Epoch 00011: val_loss improved from 0.71672 to 0.71404, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 12/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7291 - accuracy: 0.7024 - val_loss: 0.7147 - val_accuracy: 0.7087

Epoch 00012: val_loss did not improve from 0.71404
Epoch 13/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7261 - accuracy: 0.7036 - val_loss: 0.7130 - val_accuracy: 0.7081

Epoch 00013: val_loss improved from 0.71404 to 0.71302, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 14/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7242 - accuracy: 0.7054 - val_loss: 0.7161 - val_accuracy: 0.7080

Epoch 00014: val_loss did not improve from 0.71302
Epoch 15/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7229 - accuracy: 0.7061 - val_loss: 0.7156 - val_accuracy: 0.7086

Epoch 00015: val_loss did not improve from 0.71302
Epoch 16/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7195 - accuracy: 0.7081 - val_loss: 0.7124 - val_accuracy: 0.7100

Epoch 00016: val_loss improved from 0.71302 to 0.71238, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 17/500
352/352 [==============================] - 25s 72ms/step - loss: 0.7177 - accuracy: 0.7086 - val_loss: 0.7120 - val_accuracy: 0.7111

Epoch 00017: val_loss improved from 0.71238 to 0.71197, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 18/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7151 - accuracy: 0.7110 - val_loss: 0.7133 - val_accuracy: 0.7096

Epoch 00018: val_loss did not improve from 0.71197
Epoch 19/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7130 - accuracy: 0.7113 - val_loss: 0.7160 - val_accuracy: 0.7086

Epoch 00019: val_loss did not improve from 0.71197
Epoch 20/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7103 - accuracy: 0.7135 - val_loss: 0.7153 - val_accuracy: 0.7099

Epoch 00020: val_loss did not improve from 0.71197
Epoch 21/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7080 - accuracy: 0.7151 - val_loss: 0.7138 - val_accuracy: 0.7108

Epoch 00021: val_loss did not improve from 0.71197
Epoch 22/500
352/352 [==============================] - 26s 73ms/step - loss: 0.7047 - accuracy: 0.7182 - val_loss: 0.7146 - val_accuracy: 0.7110

Epoch 00022: val_loss did not improve from 0.71197
Epoch 23/500
352/352 [==============================] - 26s 73ms/step - loss: 0.7017 - accuracy: 0.7201 - val_loss: 0.7176 - val_accuracy: 0.7101

Epoch 00023: val_loss did not improve from 0.71197
Epoch 24/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6998 - accuracy: 0.7226 - val_loss: 0.7184 - val_accuracy: 0.7095

Epoch 00024: val_loss did not improve from 0.71197
Epoch 25/500
352/352 [==============================] - 25s 72ms/step - loss: 0.6944 - accuracy: 0.7250 - val_loss: 0.7201 - val_accuracy: 0.7103

Epoch 00025: val_loss did not improve from 0.71197
Epoch 26/500
352/352 [==============================] - 28s 80ms/step - loss: 0.6911 - accuracy: 0.7290 - val_loss: 0.7241 - val_accuracy: 0.7084

Epoch 00026: val_loss did not improve from 0.71197
Epoch 27/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6860 - accuracy: 0.7319 - val_loss: 0.7283 - val_accuracy: 0.7076

Epoch 00027: val_loss did not improve from 0.71197
Epoch 28/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6807 - accuracy: 0.7352 - val_loss: 0.7321 - val_accuracy: 0.7067

Epoch 00028: val_loss did not improve from 0.71197
Epoch 29/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6759 - accuracy: 0.7391 - val_loss: 0.7360 - val_accuracy: 0.7068

Epoch 00029: val_loss did not improve from 0.71197
Epoch 30/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6705 - accuracy: 0.7439 - val_loss: 0.7432 - val_accuracy: 0.7049

Epoch 00030: val_loss did not improve from 0.71197
Epoch 31/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6636 - accuracy: 0.7481 - val_loss: 0.7492 - val_accuracy: 0.7042

Epoch 00031: val_loss did not improve from 0.71197
Epoch 32/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6570 - accuracy: 0.7529 - val_loss: 0.7549 - val_accuracy: 0.7037

Epoch 00032: val_loss did not improve from 0.71197
Epoch 33/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6482 - accuracy: 0.7586 - val_loss: 0.7644 - val_accuracy: 0.7013

Epoch 00033: val_loss did not improve from 0.71197
Epoch 34/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6403 - accuracy: 0.7638 - val_loss: 0.7746 - val_accuracy: 0.6990

Epoch 00034: val_loss did not improve from 0.71197
Epoch 35/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6330 - accuracy: 0.7691 - val_loss: 0.7792 - val_accuracy: 0.6984

Epoch 00035: val_loss did not improve from 0.71197
Epoch 36/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6238 - accuracy: 0.7741 - val_loss: 0.7922 - val_accuracy: 0.6965

Epoch 00036: val_loss did not improve from 0.71197
Epoch 37/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6134 - accuracy: 0.7806 - val_loss: 0.8010 - val_accuracy: 0.6974

Epoch 00037: val_loss did not improve from 0.71197
Epoch 00037: early stopping
Model: "CNN_ternary"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
sequential (Sequential)      (None, 512)               12127912  
_________________________________________________________________
dense_2 (Dense)              multiple                  1539      
=================================================================
Total params: 12,129,451
Trainable params: 12,129,447
Non-trainable params: 4
_________________________________________________________________
None
The data set contains images
92 - accuracy: 0.6899  19746/Unknown - 62s 3ms/step - loss: 0.8089 - accuracy: 0.6900

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-07 12:41:14.536423
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
352/352 [==============================] - 30s 69ms/step - loss: 5.9106 - accuracy: 0.6036 - val_loss: 2.5075 - val_accuracy: 0.6235

Epoch 00001: val_loss improved from inf to 2.50748, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
352/352 [==============================] - 24s 68ms/step - loss: 1.6615 - accuracy: 0.6734 - val_loss: 1.1549 - val_accuracy: 0.6836

Epoch 00002: val_loss improved from 2.50748 to 1.15494, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
352/352 [==============================] - 24s 69ms/step - loss: 0.9778 - accuracy: 0.6827 - val_loss: 0.8377 - val_accuracy: 0.6949

Epoch 00003: val_loss improved from 1.15494 to 0.83772, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
352/352 [==============================] - 24s 69ms/step - loss: 0.8125 - accuracy: 0.6877 - val_loss: 0.7636 - val_accuracy: 0.6988

Epoch 00004: val_loss improved from 0.83772 to 0.76361, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7679 - accuracy: 0.6905 - val_loss: 0.7363 - val_accuracy: 0.7027

Epoch 00005: val_loss improved from 0.76361 to 0.73634, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7525 - accuracy: 0.6936 - val_loss: 0.7284 - val_accuracy: 0.7040

Epoch 00006: val_loss improved from 0.73634 to 0.72845, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7439 - accuracy: 0.6962 - val_loss: 0.7227 - val_accuracy: 0.7060

Epoch 00007: val_loss improved from 0.72845 to 0.72270, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7390 - accuracy: 0.6983 - val_loss: 0.7232 - val_accuracy: 0.7063

Epoch 00008: val_loss did not improve from 0.72270
Epoch 9/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7356 - accuracy: 0.6989 - val_loss: 0.7175 - val_accuracy: 0.7078

Epoch 00009: val_loss improved from 0.72270 to 0.71749, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 10/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7333 - accuracy: 0.7002 - val_loss: 0.7180 - val_accuracy: 0.7072

Epoch 00010: val_loss did not improve from 0.71749
Epoch 11/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7298 - accuracy: 0.7025 - val_loss: 0.7165 - val_accuracy: 0.7077

Epoch 00011: val_loss improved from 0.71749 to 0.71650, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 12/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7281 - accuracy: 0.7026 - val_loss: 0.7160 - val_accuracy: 0.7075

Epoch 00012: val_loss improved from 0.71650 to 0.71602, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 13/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7249 - accuracy: 0.7042 - val_loss: 0.7129 - val_accuracy: 0.7098

Epoch 00013: val_loss improved from 0.71602 to 0.71290, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 14/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7238 - accuracy: 0.7059 - val_loss: 0.7154 - val_accuracy: 0.7078

Epoch 00014: val_loss did not improve from 0.71290
Epoch 15/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7209 - accuracy: 0.7076 - val_loss: 0.7141 - val_accuracy: 0.7082

Epoch 00015: val_loss did not improve from 0.71290
Epoch 16/500
352/352 [==============================] - 24s 68ms/step - loss: 0.7183 - accuracy: 0.7092 - val_loss: 0.7130 - val_accuracy: 0.7093

Epoch 00016: val_loss did not improve from 0.71290
Epoch 17/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7162 - accuracy: 0.7104 - val_loss: 0.7125 - val_accuracy: 0.7095

Epoch 00017: val_loss improved from 0.71290 to 0.71246, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 18/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7136 - accuracy: 0.7121 - val_loss: 0.7149 - val_accuracy: 0.7091

Epoch 00018: val_loss did not improve from 0.71246
Epoch 19/500
352/352 [==============================] - 25s 70ms/step - loss: 0.7105 - accuracy: 0.7142 - val_loss: 0.7137 - val_accuracy: 0.7098

Epoch 00019: val_loss did not improve from 0.71246
Epoch 20/500
352/352 [==============================] - 26s 72ms/step - loss: 0.7089 - accuracy: 0.7154 - val_loss: 0.7149 - val_accuracy: 0.7085

Epoch 00020: val_loss did not improve from 0.71246
Epoch 21/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7058 - accuracy: 0.7172 - val_loss: 0.7175 - val_accuracy: 0.7092

Epoch 00021: val_loss did not improve from 0.71246
Epoch 22/500
352/352 [==============================] - 24s 69ms/step - loss: 0.7029 - accuracy: 0.7205 - val_loss: 0.7172 - val_accuracy: 0.7090

Epoch 00022: val_loss did not improve from 0.71246
Epoch 23/500
352/352 [==============================] - 208s 592ms/step - loss: 0.7002 - accuracy: 0.7210 - val_loss: 0.7198 - val_accuracy: 0.7083

Epoch 00023: val_loss did not improve from 0.71246
Epoch 24/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6960 - accuracy: 0.7249 - val_loss: 0.7200 - val_accuracy: 0.7088

Epoch 00024: val_loss did not improve from 0.71246
Epoch 25/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6921 - accuracy: 0.7272 - val_loss: 0.7226 - val_accuracy: 0.7079

Epoch 00025: val_loss did not improve from 0.71246
Epoch 26/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6878 - accuracy: 0.7309 - val_loss: 0.7276 - val_accuracy: 0.7062

Epoch 00026: val_loss did not improve from 0.71246
Epoch 27/500
352/352 [==============================] - 25s 70ms/step - loss: 0.6833 - accuracy: 0.7340 - val_loss: 0.7302 - val_accuracy: 0.7065

Epoch 00027: val_loss did not improve from 0.71246
Epoch 28/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6784 - accuracy: 0.7371 - val_loss: 0.7343 - val_accuracy: 0.7050

Epoch 00028: val_loss did not improve from 0.71246
Epoch 29/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6736 - accuracy: 0.7410 - val_loss: 0.7409 - val_accuracy: 0.7041

Epoch 00029: val_loss did not improve from 0.71246
Epoch 30/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6661 - accuracy: 0.7460 - val_loss: 0.7464 - val_accuracy: 0.7021

Epoch 00030: val_loss did not improve from 0.71246
Epoch 31/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6603 - accuracy: 0.7497 - val_loss: 0.7509 - val_accuracy: 0.7019

Epoch 00031: val_loss did not improve from 0.71246
Epoch 32/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6541 - accuracy: 0.7547 - val_loss: 0.7618 - val_accuracy: 0.6990

Epoch 00032: val_loss did not improve from 0.71246
Epoch 33/500
352/352 [==============================] - 25s 70ms/step - loss: 0.6459 - accuracy: 0.7594 - val_loss: 0.7705 - val_accuracy: 0.6974

Epoch 00033: val_loss did not improve from 0.71246
Epoch 34/500
352/352 [==============================] - 24s 68ms/step - loss: 0.6384 - accuracy: 0.7640 - val_loss: 0.7756 - val_accuracy: 0.6958

Epoch 00034: val_loss did not improve from 0.71246
Epoch 35/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6282 - accuracy: 0.7713 - val_loss: 0.7910 - val_accuracy: 0.6920

Epoch 00035: val_loss did not improve from 0.71246
Epoch 36/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6191 - accuracy: 0.7769 - val_loss: 0.7961 - val_accuracy: 0.6916

Epoch 00036: val_loss did not improve from 0.71246
Epoch 37/500
352/352 [==============================] - 24s 69ms/step - loss: 0.6104 - accuracy: 0.7818 - val_loss: 0.8070 - val_accuracy: 0.6900

Epoch 00037: val_loss did not improve from 0.71246
Epoch 00037: early stopping
Model: "CNN_ternary"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
sequential (Sequential)      (None, 512)               12127912  
_________________________________________________________________
dense_2 (Dense)              multiple                  1539      
=================================================================
Total params: 12,129,451
Trainable params: 12,129,447
Non-trainable params: 4
_________________________________________________________________
None
[<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f451c13c220>, <tensorflow.python.keras.layers.core.Dense object at 0x7f451c13ce20>]
The data set contains images
56456/56456 [==============================] - 235s 4ms/step - loss: 0.8169 - accuracy: 0.6864
Testing Loss = 0.816898, Testing Accuracy = 0.686446
The data set contains images
[[0.756135106086731, 0.040108196437358856, 0.2037566751241684], [0.5002595782279968, 0.007843520492315292, 0.49189692735671997], [0.7297767996788025, 0.11253813654184341, 0.15768501162528992], [0.8512972593307495, 0.06530867516994476, 0.08339406549930573], [0.8647065162658691, 0.07356970757246017, 0.06172383949160576], [0.5150576233863831, 0.21585966646671295, 0.269082635641098], [0.7297767996788025, 0.11253813654184341, 0.15768501162528992], [0.774043083190918, 0.15174497663974762, 0.07421190291643143], [0.5901638269424438, 0.17711015045642853, 0.23272599279880524], [0.9808657169342041, 0.011316685937345028, 0.007817563600838184]]
[[0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]]
3
$W^+$ (auc = 0.86)
$W^-$ (auc = 0.86)
$Z$ (auc = 0.82)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-10 01:33:33.710440
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
667/667 [==============================] - 60s 69ms/step - loss: 3.8078 - accuracy: 0.7514 - val_loss: 1.0528 - val_accuracy: 0.7820

Epoch 00001: val_loss improved from inf to 1.05283, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
667/667 [==============================] - 47s 70ms/step - loss: 0.7580 - accuracy: 0.7785 - val_loss: 0.6002 - val_accuracy: 0.7896

Epoch 00002: val_loss improved from 1.05283 to 0.60024, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5981 - accuracy: 0.7825 - val_loss: 0.5635 - val_accuracy: 0.7921

Epoch 00003: val_loss improved from 0.60024 to 0.56350, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
667/667 [==============================] - 47s 70ms/step - loss: 0.5789 - accuracy: 0.7852 - val_loss: 0.5548 - val_accuracy: 0.7933

Epoch 00004: val_loss improved from 0.56350 to 0.55480, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5728 - accuracy: 0.7857 - val_loss: 0.5527 - val_accuracy: 0.7928

Epoch 00005: val_loss improved from 0.55480 to 0.55268, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
667/667 [==============================] - 46s 68ms/step - loss: 0.5691 - accuracy: 0.7867 - val_loss: 0.5548 - val_accuracy: 0.7927

Epoch 00006: val_loss did not improve from 0.55268
Epoch 7/500
667/667 [==============================] - 47s 70ms/step - loss: 0.5658 - accuracy: 0.7880 - val_loss: 0.5555 - val_accuracy: 0.7928

Epoch 00007: val_loss did not improve from 0.55268
Epoch 8/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5634 - accuracy: 0.7893 - val_loss: 0.5562 - val_accuracy: 0.7932

Epoch 00008: val_loss did not improve from 0.55268
Epoch 9/500
667/667 [==============================] - 47s 70ms/step - loss: 0.5611 - accuracy: 0.7898 - val_loss: 0.5578 - val_accuracy: 0.7918

Epoch 00009: val_loss did not improve from 0.55268
Epoch 10/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5598 - accuracy: 0.7899 - val_loss: 0.5567 - val_accuracy: 0.7922

Epoch 00010: val_loss did not improve from 0.55268
Epoch 11/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5578 - accuracy: 0.7909 - val_loss: 0.5584 - val_accuracy: 0.7906

Epoch 00011: val_loss did not improve from 0.55268
Epoch 12/500
667/667 [==============================] - 46s 70ms/step - loss: 0.5553 - accuracy: 0.7918 - val_loss: 0.5534 - val_accuracy: 0.7933

Epoch 00012: val_loss did not improve from 0.55268
Epoch 13/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5537 - accuracy: 0.7924 - val_loss: 0.5515 - val_accuracy: 0.7939

Epoch 00013: val_loss improved from 0.55268 to 0.55154, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 14/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5524 - accuracy: 0.7933 - val_loss: 0.5548 - val_accuracy: 0.7918

Epoch 00014: val_loss did not improve from 0.55154
Epoch 15/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5510 - accuracy: 0.7931 - val_loss: 0.5553 - val_accuracy: 0.7919

Epoch 00015: val_loss did not improve from 0.55154
Epoch 16/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5490 - accuracy: 0.7939 - val_loss: 0.5536 - val_accuracy: 0.7934

Epoch 00016: val_loss did not improve from 0.55154
Epoch 17/500
667/667 [==============================] - 47s 70ms/step - loss: 0.5474 - accuracy: 0.7951 - val_loss: 0.5527 - val_accuracy: 0.7931

Epoch 00017: val_loss did not improve from 0.55154
Epoch 18/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5456 - accuracy: 0.7958 - val_loss: 0.5596 - val_accuracy: 0.7893

Epoch 00018: val_loss did not improve from 0.55154
Epoch 19/500
667/667 [==============================] - 46s 70ms/step - loss: 0.5447 - accuracy: 0.7968 - val_loss: 0.5546 - val_accuracy: 0.7923

Epoch 00019: val_loss did not improve from 0.55154
Epoch 20/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5421 - accuracy: 0.7977 - val_loss: 0.5566 - val_accuracy: 0.7908

Epoch 00020: val_loss did not improve from 0.55154
Epoch 21/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5405 - accuracy: 0.7986 - val_loss: 0.5571 - val_accuracy: 0.7904

Epoch 00021: val_loss did not improve from 0.55154
Epoch 22/500
667/667 [==============================] - 46s 70ms/step - loss: 0.5384 - accuracy: 0.8000 - val_loss: 0.5580 - val_accuracy: 0.7906

Epoch 00022: val_loss did not improve from 0.55154
Epoch 23/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5362 - accuracy: 0.8011 - val_loss: 0.5601 - val_accuracy: 0.7899

Epoch 00023: val_loss did not improve from 0.55154
Epoch 24/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5338 - accuracy: 0.8024 - val_loss: 0.5552 - val_accuracy: 0.7913

Epoch 00024: val_loss did not improve from 0.55154
Epoch 25/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5311 - accuracy: 0.8040 - val_loss: 0.5561 - val_accuracy: 0.7912

Epoch 00025: val_loss did not improve from 0.55154
Epoch 26/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5288 - accuracy: 0.8053 - val_loss: 0.5625 - val_accuracy: 0.7894

Epoch 00026: val_loss did not improve from 0.55154
Epoch 27/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5263 - accuracy: 0.8068 - val_loss: 0.5683 - val_accuracy: 0.7865

Epoch 00027: val_loss did not improve from 0.55154
Epoch 28/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5231 - accuracy: 0.8089 - val_loss: 0.5597 - val_accuracy: 0.7922

Epoch 00028: val_loss did not improve from 0.55154
Epoch 29/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5197 - accuracy: 0.8106 - val_loss: 0.5660 - val_accuracy: 0.7891

Epoch 00029: val_loss did not improve from 0.55154
Epoch 30/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5161 - accuracy: 0.8129 - val_loss: 0.5662 - val_accuracy: 0.7892

Epoch 00030: val_loss did not improve from 0.55154
Epoch 31/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5121 - accuracy: 0.8149 - val_loss: 0.5675 - val_accuracy: 0.7901

Epoch 00031: val_loss did not improve from 0.55154
Epoch 32/500
667/667 [==============================] - 46s 69ms/step - loss: 0.5084 - accuracy: 0.8171 - val_loss: 0.5724 - val_accuracy: 0.7870

Epoch 00032: val_loss did not improve from 0.55154
Epoch 33/500
667/667 [==============================] - 46s 70ms/step - loss: 0.5037 - accuracy: 0.8199 - val_loss: 0.5796 - val_accuracy: 0.7835

Epoch 00033: val_loss did not improve from 0.55154
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_ternary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPobL2hvbWUvc2FtaHVhbmcvTUwvbW9kZWxzLnB52gg8\nbGFtYmRhPq4AAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
106836/106836 [==============================] - 440s 4ms/step - loss: 0.5873 - accuracy: 0.7787
Testing Loss = 0.587259, Testing Accuracy = 0.778736
The data set contains images
[[0.6878181099891663, 0.10632675886154175, 0.20585514605045319], [0.7897238731384277, 0.0472400039434433, 0.16303607821464539], [0.9475634694099426, 0.012176021933555603, 0.040260519832372665], [0.7993987202644348, 0.05190782994031906, 0.1486935019493103], [0.3037908375263214, 0.6410382390022278, 0.0551709309220314], [0.3913816511631012, 0.23352238535881042, 0.37509599328041077], [0.9549622535705566, 0.015604835934937, 0.02943296916782856], [0.9832783341407776, 0.0052998121827840805, 0.011421885341405869], [0.666324257850647, 0.2790948152542114, 0.054580897092819214], [0.3913816511631012, 0.23352238535881042, 0.37509599328041077]]
[[0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]
3
$W^+$ (auc = 0.86)
$W^-$ (auc = 0.89)
$Z$ (auc = 0.84)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-10 14:44:39.373452
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
1434/1434 [==============================] - 116s 69ms/step - loss: 2.3479 - accuracy: 0.6414 - val_loss: 0.7883 - val_accuracy: 0.6828

Epoch 00001: val_loss improved from inf to 0.78827, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
1434/1434 [==============================] - 100s 70ms/step - loss: 0.7783 - accuracy: 0.6785 - val_loss: 0.7524 - val_accuracy: 0.6867

Epoch 00002: val_loss improved from 0.78827 to 0.75239, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7622 - accuracy: 0.6827 - val_loss: 0.7456 - val_accuracy: 0.6897

Epoch 00003: val_loss improved from 0.75239 to 0.74557, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7564 - accuracy: 0.6848 - val_loss: 0.7429 - val_accuracy: 0.6900

Epoch 00004: val_loss improved from 0.74557 to 0.74286, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7521 - accuracy: 0.6874 - val_loss: 0.7419 - val_accuracy: 0.6905

Epoch 00005: val_loss improved from 0.74286 to 0.74189, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
1434/1434 [==============================] - 98s 68ms/step - loss: 0.7490 - accuracy: 0.6886 - val_loss: 0.7365 - val_accuracy: 0.6935

Epoch 00006: val_loss improved from 0.74189 to 0.73648, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7459 - accuracy: 0.6900 - val_loss: 0.7374 - val_accuracy: 0.6926

Epoch 00007: val_loss did not improve from 0.73648
Epoch 8/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7436 - accuracy: 0.6915 - val_loss: 0.7347 - val_accuracy: 0.6941

Epoch 00008: val_loss improved from 0.73648 to 0.73466, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7413 - accuracy: 0.6927 - val_loss: 0.7367 - val_accuracy: 0.6933

Epoch 00009: val_loss did not improve from 0.73466
Epoch 10/500
1434/1434 [==============================] - 98s 68ms/step - loss: 0.7394 - accuracy: 0.6940 - val_loss: 0.7340 - val_accuracy: 0.6947

Epoch 00010: val_loss improved from 0.73466 to 0.73403, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 11/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7376 - accuracy: 0.6945 - val_loss: 0.7332 - val_accuracy: 0.6957

Epoch 00011: val_loss improved from 0.73403 to 0.73318, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 12/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7363 - accuracy: 0.6953 - val_loss: 0.7329 - val_accuracy: 0.6959

Epoch 00012: val_loss improved from 0.73318 to 0.73294, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 13/500
1434/1434 [==============================] - 98s 68ms/step - loss: 0.7346 - accuracy: 0.6971 - val_loss: 0.7312 - val_accuracy: 0.6966

Epoch 00013: val_loss improved from 0.73294 to 0.73117, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 14/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7330 - accuracy: 0.6976 - val_loss: 0.7302 - val_accuracy: 0.6971

Epoch 00014: val_loss improved from 0.73117 to 0.73018, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 15/500
1434/1434 [==============================] - 98s 68ms/step - loss: 0.7315 - accuracy: 0.6986 - val_loss: 0.7294 - val_accuracy: 0.6977

Epoch 00015: val_loss improved from 0.73018 to 0.72943, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 16/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7300 - accuracy: 0.6993 - val_loss: 0.7291 - val_accuracy: 0.6983

Epoch 00016: val_loss improved from 0.72943 to 0.72909, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 17/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7283 - accuracy: 0.7011 - val_loss: 0.7304 - val_accuracy: 0.6973

Epoch 00017: val_loss did not improve from 0.72909
Epoch 18/500
1434/1434 [==============================] - 98s 69ms/step - loss: 0.7268 - accuracy: 0.7015 - val_loss: 0.7299 - val_accuracy: 0.6973

Epoch 00018: val_loss did not improve from 0.72909
Epoch 19/500
1434/1434 [==============================] - 98s 68ms/step - loss: 0.7255 - accuracy: 0.7024 - val_loss: 0.7303 - val_accuracy: 0.6978

Epoch 00019: val_loss did not improve from 0.72909
Epoch 20/500
1434/1434 [==============================] - 98s 68ms/step - loss: 0.7241 - accuracy: 0.7034 - val_loss: 0.7313 - val_accuracy: 0.6971

Epoch 00020: val_loss did not improve from 0.72909
Epoch 21/500
1434/1434 [==============================] - 98s 69ms/step - loss: 0.7221 - accuracy: 0.7044 - val_loss: 0.7302 - val_accuracy: 0.6979

Epoch 00021: val_loss did not improve from 0.72909
Epoch 22/500
1434/1434 [==============================] - 98s 68ms/step - loss: 0.7205 - accuracy: 0.7058 - val_loss: 0.7321 - val_accuracy: 0.6968

Epoch 00022: val_loss did not improve from 0.72909
Epoch 23/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7187 - accuracy: 0.7071 - val_loss: 0.7303 - val_accuracy: 0.6980

Epoch 00023: val_loss did not improve from 0.72909
Epoch 24/500
1434/1434 [==============================] - 271s 189ms/step - loss: 0.7170 - accuracy: 0.7084 - val_loss: 0.7309 - val_accuracy: 0.6975

Epoch 00024: val_loss did not improve from 0.72909
Epoch 25/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7156 - accuracy: 0.7094 - val_loss: 0.7329 - val_accuracy: 0.6975

Epoch 00025: val_loss did not improve from 0.72909
Epoch 26/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7134 - accuracy: 0.7110 - val_loss: 0.7311 - val_accuracy: 0.6985

Epoch 00026: val_loss did not improve from 0.72909
Epoch 27/500
1434/1434 [==============================] - 98s 68ms/step - loss: 0.7116 - accuracy: 0.7121 - val_loss: 0.7326 - val_accuracy: 0.6983

Epoch 00027: val_loss did not improve from 0.72909
Epoch 28/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7097 - accuracy: 0.7132 - val_loss: 0.7337 - val_accuracy: 0.6982

Epoch 00028: val_loss did not improve from 0.72909
Epoch 29/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7075 - accuracy: 0.7158 - val_loss: 0.7339 - val_accuracy: 0.6975

Epoch 00029: val_loss did not improve from 0.72909
Epoch 30/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7053 - accuracy: 0.7168 - val_loss: 0.7362 - val_accuracy: 0.6967

Epoch 00030: val_loss did not improve from 0.72909
Epoch 31/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.7028 - accuracy: 0.7191 - val_loss: 0.7366 - val_accuracy: 0.6968

Epoch 00031: val_loss did not improve from 0.72909
Epoch 32/500
1434/1434 [==============================] - 98s 69ms/step - loss: 0.7007 - accuracy: 0.7201 - val_loss: 0.7389 - val_accuracy: 0.6967

Epoch 00032: val_loss did not improve from 0.72909
Epoch 33/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.6980 - accuracy: 0.7220 - val_loss: 0.7387 - val_accuracy: 0.6971

Epoch 00033: val_loss did not improve from 0.72909
Epoch 34/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.6955 - accuracy: 0.7241 - val_loss: 0.7452 - val_accuracy: 0.6943

Epoch 00034: val_loss did not improve from 0.72909
Epoch 35/500
1434/1434 [==============================] - 99s 69ms/step - loss: 0.6930 - accuracy: 0.7255 - val_loss: 0.7439 - val_accuracy: 0.6959

Epoch 00035: val_loss did not improve from 0.72909
Epoch 36/500
1434/1434 [==============================] - 98s 69ms/step - loss: 0.6900 - accuracy: 0.7278 - val_loss: 0.7465 - val_accuracy: 0.6949

Epoch 00036: val_loss did not improve from 0.72909
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_ternary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPobL2hvbWUvc2FtaHVhbmcvTUwvbW9kZWxzLnB52gg8\nbGFtYmRhPq4AAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
229483/229483 [==============================] - 942s 4ms/step - loss: 0.7432 - accuracy: 0.6967
Testing Loss = 0.743229, Testing Accuracy = 0.696662
The data set contains images
[[0.01787823811173439, 0.010614044032990932, 0.971507728099823], [0.010878732427954674, 0.2651253640651703, 0.7239959239959717], [0.05253923684358597, 0.16510020196437836, 0.7823606133460999], [0.23160746693611145, 0.644228458404541, 0.12416408956050873], [0.08181614428758621, 0.8260180950164795, 0.09216570109128952], [0.654949426651001, 0.10089968889951706, 0.24415089190006256], [0.019749680534005165, 0.033808011561632156, 0.9464423060417175], [0.8749794363975525, 0.0357523038983345, 0.08926823735237122], [0.43613800406455994, 0.04080372303724289, 0.523058295249939], [0.792794942855835, 0.0727379322052002, 0.13446713984012604]]
[[0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]]
3
$W^+$ (auc = 0.87)
$W^-$ (auc = 0.87)
$Z$ (auc = 0.84)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-10 19:06:05.319132
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
750/750 [==============================] - 76s 76ms/step - loss: 3.6253 - accuracy: 0.6261 - val_loss: 1.1014 - val_accuracy: 0.6731

Epoch 00001: val_loss improved from inf to 1.10141, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
750/750 [==============================] - 52s 69ms/step - loss: 0.8914 - accuracy: 0.6707 - val_loss: 0.7855 - val_accuracy: 0.6807

Epoch 00002: val_loss improved from 1.10141 to 0.78553, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7828 - accuracy: 0.6777 - val_loss: 0.7703 - val_accuracy: 0.6798

Epoch 00003: val_loss improved from 0.78553 to 0.77026, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7695 - accuracy: 0.6806 - val_loss: 0.7612 - val_accuracy: 0.6842

Epoch 00004: val_loss improved from 0.77026 to 0.76120, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7634 - accuracy: 0.6831 - val_loss: 0.7554 - val_accuracy: 0.6871

Epoch 00005: val_loss improved from 0.76120 to 0.75540, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7592 - accuracy: 0.6844 - val_loss: 0.7577 - val_accuracy: 0.6857

Epoch 00006: val_loss did not improve from 0.75540
Epoch 7/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7562 - accuracy: 0.6869 - val_loss: 0.7558 - val_accuracy: 0.6865

Epoch 00007: val_loss did not improve from 0.75540
Epoch 8/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7540 - accuracy: 0.6876 - val_loss: 0.7591 - val_accuracy: 0.6844

Epoch 00008: val_loss did not improve from 0.75540
Epoch 9/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7514 - accuracy: 0.6890 - val_loss: 0.7540 - val_accuracy: 0.6863

Epoch 00009: val_loss improved from 0.75540 to 0.75396, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 10/500
750/750 [==============================] - 51s 69ms/step - loss: 0.7494 - accuracy: 0.6901 - val_loss: 0.7492 - val_accuracy: 0.6882

Epoch 00010: val_loss improved from 0.75396 to 0.74921, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 11/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7474 - accuracy: 0.6907 - val_loss: 0.7507 - val_accuracy: 0.6871

Epoch 00011: val_loss did not improve from 0.74921
Epoch 12/500
750/750 [==============================] - 51s 69ms/step - loss: 0.7455 - accuracy: 0.6918 - val_loss: 0.7477 - val_accuracy: 0.6881

Epoch 00012: val_loss improved from 0.74921 to 0.74766, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 13/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7437 - accuracy: 0.6928 - val_loss: 0.7483 - val_accuracy: 0.6886

Epoch 00013: val_loss did not improve from 0.74766
Epoch 14/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7414 - accuracy: 0.6945 - val_loss: 0.7459 - val_accuracy: 0.6900

Epoch 00014: val_loss improved from 0.74766 to 0.74588, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 15/500
750/750 [==============================] - 52s 70ms/step - loss: 0.7403 - accuracy: 0.6950 - val_loss: 0.7486 - val_accuracy: 0.6884

Epoch 00015: val_loss did not improve from 0.74588
Epoch 16/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7386 - accuracy: 0.6965 - val_loss: 0.7452 - val_accuracy: 0.6894

Epoch 00016: val_loss improved from 0.74588 to 0.74524, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 17/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7367 - accuracy: 0.6974 - val_loss: 0.7435 - val_accuracy: 0.6901

Epoch 00017: val_loss improved from 0.74524 to 0.74346, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 18/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7349 - accuracy: 0.6982 - val_loss: 0.7442 - val_accuracy: 0.6903

Epoch 00018: val_loss did not improve from 0.74346
Epoch 19/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7332 - accuracy: 0.6994 - val_loss: 0.7412 - val_accuracy: 0.6922

Epoch 00019: val_loss improved from 0.74346 to 0.74123, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 20/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7317 - accuracy: 0.7006 - val_loss: 0.7428 - val_accuracy: 0.6919

Epoch 00020: val_loss did not improve from 0.74123
Epoch 21/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7297 - accuracy: 0.7019 - val_loss: 0.7484 - val_accuracy: 0.6891

Epoch 00021: val_loss did not improve from 0.74123
Epoch 22/500
750/750 [==============================] - 51s 69ms/step - loss: 0.7276 - accuracy: 0.7033 - val_loss: 0.7436 - val_accuracy: 0.6914

Epoch 00022: val_loss did not improve from 0.74123
Epoch 23/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7255 - accuracy: 0.7053 - val_loss: 0.7457 - val_accuracy: 0.6912

Epoch 00023: val_loss did not improve from 0.74123
Epoch 24/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7236 - accuracy: 0.7064 - val_loss: 0.7463 - val_accuracy: 0.6907

Epoch 00024: val_loss did not improve from 0.74123
Epoch 25/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7208 - accuracy: 0.7081 - val_loss: 0.7482 - val_accuracy: 0.6904

Epoch 00025: val_loss did not improve from 0.74123
Epoch 26/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7183 - accuracy: 0.7099 - val_loss: 0.7507 - val_accuracy: 0.6895

Epoch 00026: val_loss did not improve from 0.74123
Epoch 27/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7165 - accuracy: 0.7111 - val_loss: 0.7524 - val_accuracy: 0.6885

Epoch 00027: val_loss did not improve from 0.74123
Epoch 28/500
750/750 [==============================] - 51s 69ms/step - loss: 0.7136 - accuracy: 0.7136 - val_loss: 0.7537 - val_accuracy: 0.6888

Epoch 00028: val_loss did not improve from 0.74123
Epoch 29/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7104 - accuracy: 0.7162 - val_loss: 0.7587 - val_accuracy: 0.6874

Epoch 00029: val_loss did not improve from 0.74123
Epoch 30/500
750/750 [==============================] - 51s 69ms/step - loss: 0.7069 - accuracy: 0.7186 - val_loss: 0.7544 - val_accuracy: 0.6903

Epoch 00030: val_loss did not improve from 0.74123
Epoch 31/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7045 - accuracy: 0.7204 - val_loss: 0.7597 - val_accuracy: 0.6875

Epoch 00031: val_loss did not improve from 0.74123
Epoch 32/500
750/750 [==============================] - 52s 69ms/step - loss: 0.7006 - accuracy: 0.7235 - val_loss: 0.7639 - val_accuracy: 0.6862

Epoch 00032: val_loss did not improve from 0.74123
Epoch 33/500
750/750 [==============================] - 51s 69ms/step - loss: 0.6968 - accuracy: 0.7257 - val_loss: 0.7649 - val_accuracy: 0.6865

Epoch 00033: val_loss did not improve from 0.74123
Epoch 34/500
750/750 [==============================] - 51s 69ms/step - loss: 0.6930 - accuracy: 0.7290 - val_loss: 0.7678 - val_accuracy: 0.6863

Epoch 00034: val_loss did not improve from 0.74123
Epoch 35/500
750/750 [==============================] - 52s 69ms/step - loss: 0.6886 - accuracy: 0.7315 - val_loss: 0.7701 - val_accuracy: 0.6857

Epoch 00035: val_loss did not improve from 0.74123
Epoch 36/500
750/750 [==============================] - 52s 69ms/step - loss: 0.6846 - accuracy: 0.7348 - val_loss: 0.7758 - val_accuracy: 0.6843

Epoch 00036: val_loss did not improve from 0.74123
Epoch 37/500
750/750 [==============================] - 51s 68ms/step - loss: 0.6795 - accuracy: 0.7383 - val_loss: 0.7823 - val_accuracy: 0.6820

Epoch 00037: val_loss did not improve from 0.74123
Epoch 38/500
750/750 [==============================] - 51s 69ms/step - loss: 0.6745 - accuracy: 0.7409 - val_loss: 0.7907 - val_accuracy: 0.6801

Epoch 00038: val_loss did not improve from 0.74123
Epoch 39/500
750/750 [==============================] - 52s 69ms/step - loss: 0.6696 - accuracy: 0.7443 - val_loss: 0.7930 - val_accuracy: 0.6802

Epoch 00039: val_loss did not improve from 0.74123
Epoch 00039: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_ternary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPobL2hvbWUvc2FtaHVhbmcvTUwvbW9kZWxzLnB52gg8\nbGFtYmRhPq4AAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
120000/120000 [==============================] - 498s 4ms/step - loss: 0.7904 - accuracy: 0.6819
Testing Loss = 0.790449, Testing Accuracy = 0.681875
The data set contains images
[[0.12057167291641235, 0.7381906509399414, 0.14123769104480743], [0.8874197006225586, 0.03545459732413292, 0.0771256536245346], [0.4627624452114105, 0.010952064767479897, 0.5262855291366577], [0.04234637692570686, 0.04359816387295723, 0.9140554666519165], [0.8554507493972778, 0.04419025406241417, 0.1003590002655983], [0.20936931669712067, 0.010088901966810226, 0.7805417776107788], [0.9456073045730591, 0.019081464037299156, 0.0353112667798996], [0.06606728583574295, 0.0026816371828317642, 0.931251049041748], [0.30145612359046936, 0.49307385087013245, 0.20547008514404297], [0.36807456612586975, 0.13474297523498535, 0.4971824288368225]]
[[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]
3
$W^+$ (auc = 0.87)
$W^-$ (auc = 0.87)
$Z$ (auc = 0.82)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-10 20:35:03.352738
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
937/937 [==============================] - 72s 71ms/step - loss: 3.1138 - accuracy: 0.6272 - val_loss: 0.9221 - val_accuracy: 0.6775

Epoch 00001: val_loss improved from inf to 0.92212, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
937/937 [==============================] - 64s 69ms/step - loss: 0.8262 - accuracy: 0.6735 - val_loss: 0.7644 - val_accuracy: 0.6852

Epoch 00002: val_loss improved from 0.92212 to 0.76444, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7751 - accuracy: 0.6789 - val_loss: 0.7552 - val_accuracy: 0.6876

Epoch 00003: val_loss improved from 0.76444 to 0.75518, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
937/937 [==============================] - 63s 68ms/step - loss: 0.7665 - accuracy: 0.6822 - val_loss: 0.7495 - val_accuracy: 0.6898

Epoch 00004: val_loss improved from 0.75518 to 0.74951, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
937/937 [==============================] - 63s 68ms/step - loss: 0.7618 - accuracy: 0.6837 - val_loss: 0.7446 - val_accuracy: 0.6910

Epoch 00005: val_loss improved from 0.74951 to 0.74457, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7581 - accuracy: 0.6855 - val_loss: 0.7421 - val_accuracy: 0.6931

Epoch 00006: val_loss improved from 0.74457 to 0.74214, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7552 - accuracy: 0.6865 - val_loss: 0.7404 - val_accuracy: 0.6934

Epoch 00007: val_loss improved from 0.74214 to 0.74044, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
937/937 [==============================] - 64s 69ms/step - loss: 0.7525 - accuracy: 0.6882 - val_loss: 0.7391 - val_accuracy: 0.6947

Epoch 00008: val_loss improved from 0.74044 to 0.73915, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7501 - accuracy: 0.6890 - val_loss: 0.7376 - val_accuracy: 0.6947

Epoch 00009: val_loss improved from 0.73915 to 0.73759, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 10/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7482 - accuracy: 0.6900 - val_loss: 0.7370 - val_accuracy: 0.6940

Epoch 00010: val_loss improved from 0.73759 to 0.73701, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 11/500
937/937 [==============================] - 65s 69ms/step - loss: 0.7462 - accuracy: 0.6910 - val_loss: 0.7374 - val_accuracy: 0.6944

Epoch 00011: val_loss did not improve from 0.73701
Epoch 12/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7442 - accuracy: 0.6925 - val_loss: 0.7355 - val_accuracy: 0.6954

Epoch 00012: val_loss improved from 0.73701 to 0.73553, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 13/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7425 - accuracy: 0.6939 - val_loss: 0.7356 - val_accuracy: 0.6960

Epoch 00013: val_loss did not improve from 0.73553
Epoch 14/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7407 - accuracy: 0.6943 - val_loss: 0.7346 - val_accuracy: 0.6957

Epoch 00014: val_loss improved from 0.73553 to 0.73464, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 15/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7393 - accuracy: 0.6953 - val_loss: 0.7345 - val_accuracy: 0.6959

Epoch 00015: val_loss improved from 0.73464 to 0.73452, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 16/500
937/937 [==============================] - 63s 67ms/step - loss: 0.7376 - accuracy: 0.6965 - val_loss: 0.7342 - val_accuracy: 0.6971

Epoch 00016: val_loss improved from 0.73452 to 0.73419, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 17/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7361 - accuracy: 0.6973 - val_loss: 0.7349 - val_accuracy: 0.6965

Epoch 00017: val_loss did not improve from 0.73419
Epoch 18/500
937/937 [==============================] - 63s 67ms/step - loss: 0.7346 - accuracy: 0.6983 - val_loss: 0.7342 - val_accuracy: 0.6964

Epoch 00018: val_loss did not improve from 0.73419
Epoch 19/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7328 - accuracy: 0.6995 - val_loss: 0.7353 - val_accuracy: 0.6959

Epoch 00019: val_loss did not improve from 0.73419
Epoch 20/500
937/937 [==============================] - 65s 69ms/step - loss: 0.7311 - accuracy: 0.7009 - val_loss: 0.7363 - val_accuracy: 0.6957

Epoch 00020: val_loss did not improve from 0.73419
Epoch 21/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7298 - accuracy: 0.7015 - val_loss: 0.7359 - val_accuracy: 0.6958

Epoch 00021: val_loss did not improve from 0.73419
Epoch 22/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7274 - accuracy: 0.7031 - val_loss: 0.7374 - val_accuracy: 0.6962

Epoch 00022: val_loss did not improve from 0.73419
Epoch 23/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7262 - accuracy: 0.7040 - val_loss: 0.7377 - val_accuracy: 0.6955

Epoch 00023: val_loss did not improve from 0.73419
Epoch 24/500
937/937 [==============================] - 64s 69ms/step - loss: 0.7237 - accuracy: 0.7060 - val_loss: 0.7385 - val_accuracy: 0.6957

Epoch 00024: val_loss did not improve from 0.73419
Epoch 25/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7219 - accuracy: 0.7068 - val_loss: 0.7406 - val_accuracy: 0.6945

Epoch 00025: val_loss did not improve from 0.73419
Epoch 26/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7194 - accuracy: 0.7086 - val_loss: 0.7436 - val_accuracy: 0.6940

Epoch 00026: val_loss did not improve from 0.73419
Epoch 27/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7173 - accuracy: 0.7104 - val_loss: 0.7435 - val_accuracy: 0.6950

Epoch 00027: val_loss did not improve from 0.73419
Epoch 28/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7144 - accuracy: 0.7123 - val_loss: 0.7457 - val_accuracy: 0.6943

Epoch 00028: val_loss did not improve from 0.73419
Epoch 29/500
937/937 [==============================] - 247s 264ms/step - loss: 0.7119 - accuracy: 0.7142 - val_loss: 0.7454 - val_accuracy: 0.6945

Epoch 00029: val_loss did not improve from 0.73419
Epoch 30/500
937/937 [==============================] - 64s 68ms/step - loss: 0.7092 - accuracy: 0.7160 - val_loss: 0.7501 - val_accuracy: 0.6949

Epoch 00030: val_loss did not improve from 0.73419
Epoch 31/500
937/937 [==============================] - 63s 67ms/step - loss: 0.7069 - accuracy: 0.7180 - val_loss: 0.7521 - val_accuracy: 0.6923

Epoch 00031: val_loss did not improve from 0.73419
Epoch 32/500
937/937 [==============================] - 65s 69ms/step - loss: 0.7038 - accuracy: 0.7202 - val_loss: 0.7544 - val_accuracy: 0.6921

Epoch 00032: val_loss did not improve from 0.73419
Epoch 33/500
937/937 [==============================] - 64s 69ms/step - loss: 0.7006 - accuracy: 0.7227 - val_loss: 0.7592 - val_accuracy: 0.6907

Epoch 00033: val_loss did not improve from 0.73419
Epoch 34/500
937/937 [==============================] - 64s 69ms/step - loss: 0.6979 - accuracy: 0.7247 - val_loss: 0.7607 - val_accuracy: 0.6914

Epoch 00034: val_loss did not improve from 0.73419
Epoch 35/500
937/937 [==============================] - 64s 68ms/step - loss: 0.6935 - accuracy: 0.7274 - val_loss: 0.7673 - val_accuracy: 0.6900

Epoch 00035: val_loss did not improve from 0.73419
Epoch 36/500
937/937 [==============================] - 63s 68ms/step - loss: 0.6907 - accuracy: 0.7297 - val_loss: 0.7672 - val_accuracy: 0.6900

Epoch 00036: val_loss did not improve from 0.73419
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_ternary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPobL2hvbWUvc2FtaHVhbmcvTUwvbW9kZWxzLnB52gg8\nbGFtYmRhPq4AAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 613s 4ms/step - loss: 0.7654 - accuracy: 0.6896
Testing Loss = 0.765448, Testing Accuracy = 0.689607
The data set contains images
[[0.2176709771156311, 0.4822932779788971, 0.3000357449054718], [0.8043925166130066, 0.1021382138133049, 0.09346933662891388], [0.2500034272670746, 0.03730768337845802, 0.7126889228820801], [0.18616662919521332, 0.6917709708213806, 0.12206245213747025], [0.23142310976982117, 0.5679442286491394, 0.20063264667987823], [0.06785155832767487, 0.8948677182197571, 0.03728080168366432], [0.3202417194843292, 0.1028342917561531, 0.5769239664077759], [0.9955775737762451, 0.0005678765010088682, 0.003854532493278384], [0.025123467668890953, 0.9486148953437805, 0.026261664927005768], [0.05309417471289635, 0.9160178303718567, 0.03088807687163353]]
[[0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]
3
$W^+$ (auc = 0.87)
$W^-$ (auc = 0.87)
$Z$ (auc = 0.83)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-10 22:24:18.293429
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
881/881 [==============================] - 68s 71ms/step - loss: 3.2367 - accuracy: 0.6292 - val_loss: 0.9606 - val_accuracy: 0.6792

Epoch 00001: val_loss improved from inf to 0.96060, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
881/881 [==============================] - 61s 69ms/step - loss: 0.8354 - accuracy: 0.6768 - val_loss: 0.7735 - val_accuracy: 0.6823

Epoch 00002: val_loss improved from 0.96060 to 0.77352, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7732 - accuracy: 0.6810 - val_loss: 0.7606 - val_accuracy: 0.6844

Epoch 00003: val_loss improved from 0.77352 to 0.76064, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
881/881 [==============================] - 61s 69ms/step - loss: 0.7633 - accuracy: 0.6845 - val_loss: 0.7547 - val_accuracy: 0.6871

Epoch 00004: val_loss improved from 0.76064 to 0.75468, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
881/881 [==============================] - 61s 69ms/step - loss: 0.7585 - accuracy: 0.6863 - val_loss: 0.7504 - val_accuracy: 0.6895

Epoch 00005: val_loss improved from 0.75468 to 0.75040, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
881/881 [==============================] - 61s 69ms/step - loss: 0.7544 - accuracy: 0.6883 - val_loss: 0.7477 - val_accuracy: 0.6913

Epoch 00006: val_loss improved from 0.75040 to 0.74766, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
881/881 [==============================] - 61s 69ms/step - loss: 0.7520 - accuracy: 0.6892 - val_loss: 0.7446 - val_accuracy: 0.6919

Epoch 00007: val_loss improved from 0.74766 to 0.74462, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7496 - accuracy: 0.6903 - val_loss: 0.7418 - val_accuracy: 0.6941

Epoch 00008: val_loss improved from 0.74462 to 0.74178, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
881/881 [==============================] - 60s 69ms/step - loss: 0.7472 - accuracy: 0.6918 - val_loss: 0.7396 - val_accuracy: 0.6944

Epoch 00009: val_loss improved from 0.74178 to 0.73964, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 10/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7453 - accuracy: 0.6923 - val_loss: 0.7414 - val_accuracy: 0.6939

Epoch 00010: val_loss did not improve from 0.73964
Epoch 11/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7428 - accuracy: 0.6941 - val_loss: 0.7400 - val_accuracy: 0.6945

Epoch 00011: val_loss did not improve from 0.73964
Epoch 12/500
881/881 [==============================] - 61s 69ms/step - loss: 0.7406 - accuracy: 0.6953 - val_loss: 0.7417 - val_accuracy: 0.6936

Epoch 00012: val_loss did not improve from 0.73964
Epoch 13/500
881/881 [==============================] - 61s 69ms/step - loss: 0.7394 - accuracy: 0.6957 - val_loss: 0.7402 - val_accuracy: 0.6940

Epoch 00013: val_loss did not improve from 0.73964
Epoch 14/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7376 - accuracy: 0.6969 - val_loss: 0.7355 - val_accuracy: 0.6964

Epoch 00014: val_loss improved from 0.73964 to 0.73553, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 15/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7355 - accuracy: 0.6981 - val_loss: 0.7391 - val_accuracy: 0.6953

Epoch 00015: val_loss did not improve from 0.73553
Epoch 16/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7339 - accuracy: 0.6984 - val_loss: 0.7369 - val_accuracy: 0.6969

Epoch 00016: val_loss did not improve from 0.73553
Epoch 17/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7322 - accuracy: 0.7001 - val_loss: 0.7386 - val_accuracy: 0.6952

Epoch 00017: val_loss did not improve from 0.73553
Epoch 18/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7304 - accuracy: 0.7014 - val_loss: 0.7397 - val_accuracy: 0.6952

Epoch 00018: val_loss did not improve from 0.73553
Epoch 19/500
881/881 [==============================] - 61s 69ms/step - loss: 0.7289 - accuracy: 0.7020 - val_loss: 0.7346 - val_accuracy: 0.6983

Epoch 00019: val_loss improved from 0.73553 to 0.73462, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 20/500
881/881 [==============================] - 60s 69ms/step - loss: 0.7272 - accuracy: 0.7029 - val_loss: 0.7389 - val_accuracy: 0.6959

Epoch 00020: val_loss did not improve from 0.73462
Epoch 21/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7254 - accuracy: 0.7037 - val_loss: 0.7374 - val_accuracy: 0.6972

Epoch 00021: val_loss did not improve from 0.73462
Epoch 22/500
881/881 [==============================] - 60s 69ms/step - loss: 0.7233 - accuracy: 0.7059 - val_loss: 0.7387 - val_accuracy: 0.6964

Epoch 00022: val_loss did not improve from 0.73462
Epoch 23/500
881/881 [==============================] - 61s 69ms/step - loss: 0.7215 - accuracy: 0.7067 - val_loss: 0.7374 - val_accuracy: 0.6973

Epoch 00023: val_loss did not improve from 0.73462
Epoch 24/500
881/881 [==============================] - 60s 69ms/step - loss: 0.7192 - accuracy: 0.7089 - val_loss: 0.7394 - val_accuracy: 0.6971

Epoch 00024: val_loss did not improve from 0.73462
Epoch 25/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7168 - accuracy: 0.7102 - val_loss: 0.7394 - val_accuracy: 0.6959

Epoch 00025: val_loss did not improve from 0.73462
Epoch 26/500
881/881 [==============================] - 60s 69ms/step - loss: 0.7150 - accuracy: 0.7115 - val_loss: 0.7403 - val_accuracy: 0.6974

Epoch 00026: val_loss did not improve from 0.73462
Epoch 27/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7125 - accuracy: 0.7134 - val_loss: 0.7413 - val_accuracy: 0.6976

Epoch 00027: val_loss did not improve from 0.73462
Epoch 28/500
881/881 [==============================] - 61s 69ms/step - loss: 0.7095 - accuracy: 0.7156 - val_loss: 0.7431 - val_accuracy: 0.6969

Epoch 00028: val_loss did not improve from 0.73462
Epoch 29/500
881/881 [==============================] - 60s 69ms/step - loss: 0.7071 - accuracy: 0.7174 - val_loss: 0.7446 - val_accuracy: 0.6970

Epoch 00029: val_loss did not improve from 0.73462
Epoch 30/500
881/881 [==============================] - 60s 69ms/step - loss: 0.7039 - accuracy: 0.7194 - val_loss: 0.7503 - val_accuracy: 0.6953

Epoch 00030: val_loss did not improve from 0.73462
Epoch 31/500
881/881 [==============================] - 61s 69ms/step - loss: 0.7007 - accuracy: 0.7220 - val_loss: 0.7522 - val_accuracy: 0.6942

Epoch 00031: val_loss did not improve from 0.73462
Epoch 32/500
881/881 [==============================] - 60s 68ms/step - loss: 0.6974 - accuracy: 0.7242 - val_loss: 0.7538 - val_accuracy: 0.6946

Epoch 00032: val_loss did not improve from 0.73462
Epoch 33/500
881/881 [==============================] - 60s 69ms/step - loss: 0.6941 - accuracy: 0.7267 - val_loss: 0.7570 - val_accuracy: 0.6954

Epoch 00033: val_loss did not improve from 0.73462
Epoch 34/500
881/881 [==============================] - 60s 68ms/step - loss: 0.6904 - accuracy: 0.7287 - val_loss: 0.7614 - val_accuracy: 0.6930

Epoch 00034: val_loss did not improve from 0.73462
Epoch 35/500
881/881 [==============================] - 60s 68ms/step - loss: 0.6865 - accuracy: 0.7316 - val_loss: 0.7648 - val_accuracy: 0.6928

Epoch 00035: val_loss did not improve from 0.73462
Epoch 36/500
881/881 [==============================] - 60s 68ms/step - loss: 0.6832 - accuracy: 0.7346 - val_loss: 0.7698 - val_accuracy: 0.6923

Epoch 00036: val_loss did not improve from 0.73462
Epoch 37/500
881/881 [==============================] - 60s 69ms/step - loss: 0.6782 - accuracy: 0.7378 - val_loss: 0.7718 - val_accuracy: 0.6911

Epoch 00037: val_loss did not improve from 0.73462
Epoch 38/500
881/881 [==============================] - 60s 69ms/step - loss: 0.6739 - accuracy: 0.7409 - val_loss: 0.7764 - val_accuracy: 0.6896

Epoch 00038: val_loss did not improve from 0.73462
Epoch 39/500
881/881 [==============================] - 60s 68ms/step - loss: 0.6687 - accuracy: 0.7440 - val_loss: 0.7827 - val_accuracy: 0.6888

Epoch 00039: val_loss did not improve from 0.73462
Epoch 00039: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_ternary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPobL2hvbWUvc2FtaHVhbmcvTUwvbW9kZWxzLnB52gg8\nbGFtYmRhPq4AAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
141000/141000 [==============================] - 584s 4ms/step - loss: 0.7768 - accuracy: 0.6894
Testing Loss = 0.776805, Testing Accuracy = 0.689369
The data set contains images
[[0.6690330505371094, 0.023597195744514465, 0.30736979842185974], [0.0018822504207491875, 0.780591607093811, 0.2175261229276657], [0.40859454870224, 0.2977249026298523, 0.2936806082725525], [0.06479742377996445, 0.018006082624197006, 0.91719651222229], [0.09487119317054749, 0.031199445948004723, 0.8739293813705444], [0.5129345655441284, 0.05851994454860687, 0.4285455048084259], [0.07207466661930084, 0.07867974787950516, 0.849245548248291], [0.855770468711853, 0.09597917646169662, 0.04825026914477348], [0.7308763265609741, 0.215578094124794, 0.05354560539126396], [0.24486035108566284, 0.25546327233314514, 0.499676376581192]]
[[0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0]]
3
$W^+$ (auc = 0.87)
$W^-$ (auc = 0.87)
$Z$ (auc = 0.83)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-11 16:00:16.948127
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
881/881 [==============================] - 163s 178ms/step - loss: 1.3526 - accuracy: 0.4687 - val_loss: 0.9759 - val_accuracy: 0.4930

Epoch 00001: val_loss improved from inf to 0.97592, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9876 - accuracy: 0.4835 - val_loss: 0.9757 - val_accuracy: 0.4930

Epoch 00002: val_loss improved from 0.97592 to 0.97566, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9814 - accuracy: 0.4876 - val_loss: 0.9704 - val_accuracy: 0.4953

Epoch 00003: val_loss improved from 0.97566 to 0.97044, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9784 - accuracy: 0.4896 - val_loss: 0.9699 - val_accuracy: 0.4963

Epoch 00004: val_loss improved from 0.97044 to 0.96990, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9762 - accuracy: 0.4909 - val_loss: 0.9635 - val_accuracy: 0.4987

Epoch 00005: val_loss improved from 0.96990 to 0.96354, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9749 - accuracy: 0.4918 - val_loss: 0.9634 - val_accuracy: 0.5004

Epoch 00006: val_loss improved from 0.96354 to 0.96338, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9736 - accuracy: 0.4933 - val_loss: 0.9630 - val_accuracy: 0.5005

Epoch 00007: val_loss improved from 0.96338 to 0.96304, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9719 - accuracy: 0.4957 - val_loss: 0.9599 - val_accuracy: 0.5018

Epoch 00008: val_loss improved from 0.96304 to 0.95990, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
881/881 [==============================] - 60s 67ms/step - loss: 0.8581 - accuracy: 0.6339 - val_loss: 0.7801 - val_accuracy: 0.6872

Epoch 00009: val_loss improved from 0.95990 to 0.78013, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 10/500
881/881 [==============================] - 60s 69ms/step - loss: 0.8074 - accuracy: 0.6709 - val_loss: 0.7807 - val_accuracy: 0.6835

Epoch 00010: val_loss did not improve from 0.78013
Epoch 11/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7952 - accuracy: 0.6757 - val_loss: 0.7679 - val_accuracy: 0.6862

Epoch 00011: val_loss improved from 0.78013 to 0.76794, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 12/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7890 - accuracy: 0.6778 - val_loss: 0.7664 - val_accuracy: 0.6849

Epoch 00012: val_loss improved from 0.76794 to 0.76638, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 13/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7851 - accuracy: 0.6787 - val_loss: 0.7617 - val_accuracy: 0.6844

Epoch 00013: val_loss improved from 0.76638 to 0.76166, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 14/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7802 - accuracy: 0.6809 - val_loss: 0.7663 - val_accuracy: 0.6823

Epoch 00014: val_loss did not improve from 0.76166
Epoch 15/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7781 - accuracy: 0.6819 - val_loss: 0.7683 - val_accuracy: 0.6826

Epoch 00015: val_loss did not improve from 0.76166
Epoch 16/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7759 - accuracy: 0.6824 - val_loss: 0.7642 - val_accuracy: 0.6856

Epoch 00016: val_loss did not improve from 0.76166
Epoch 17/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7741 - accuracy: 0.6840 - val_loss: 0.7578 - val_accuracy: 0.6848

Epoch 00017: val_loss improved from 0.76166 to 0.75777, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 18/500
881/881 [==============================] - 60s 67ms/step - loss: 0.7724 - accuracy: 0.6846 - val_loss: 0.7702 - val_accuracy: 0.6856

Epoch 00018: val_loss did not improve from 0.75777
Epoch 19/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7705 - accuracy: 0.6854 - val_loss: 0.7533 - val_accuracy: 0.6885

Epoch 00019: val_loss improved from 0.75777 to 0.75326, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 20/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7693 - accuracy: 0.6866 - val_loss: 0.7586 - val_accuracy: 0.6880

Epoch 00020: val_loss did not improve from 0.75326
Epoch 21/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7686 - accuracy: 0.6874 - val_loss: 0.7582 - val_accuracy: 0.6869

Epoch 00021: val_loss did not improve from 0.75326
Epoch 22/500
881/881 [==============================] - 60s 69ms/step - loss: 0.7675 - accuracy: 0.6878 - val_loss: 0.7571 - val_accuracy: 0.6871

Epoch 00022: val_loss did not improve from 0.75326
Epoch 23/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7655 - accuracy: 0.6889 - val_loss: 0.7538 - val_accuracy: 0.6915

Epoch 00023: val_loss did not improve from 0.75326
Epoch 24/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7644 - accuracy: 0.6897 - val_loss: 0.7582 - val_accuracy: 0.6892

Epoch 00024: val_loss did not improve from 0.75326
Epoch 25/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7626 - accuracy: 0.6899 - val_loss: 0.7620 - val_accuracy: 0.6849

Epoch 00025: val_loss did not improve from 0.75326
Epoch 26/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7616 - accuracy: 0.6909 - val_loss: 0.7622 - val_accuracy: 0.6854

Epoch 00026: val_loss did not improve from 0.75326
Epoch 27/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7612 - accuracy: 0.6923 - val_loss: 0.7594 - val_accuracy: 0.6870

Epoch 00027: val_loss did not improve from 0.75326
Epoch 28/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7593 - accuracy: 0.6932 - val_loss: 0.7567 - val_accuracy: 0.6911

Epoch 00028: val_loss did not improve from 0.75326
Epoch 29/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7591 - accuracy: 0.6933 - val_loss: 0.7594 - val_accuracy: 0.6854

Epoch 00029: val_loss did not improve from 0.75326
Epoch 30/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7571 - accuracy: 0.6945 - val_loss: 0.7555 - val_accuracy: 0.6871

Epoch 00030: val_loss did not improve from 0.75326
Epoch 31/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7565 - accuracy: 0.6950 - val_loss: 0.7514 - val_accuracy: 0.6876

Epoch 00031: val_loss improved from 0.75326 to 0.75142, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 32/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7558 - accuracy: 0.6953 - val_loss: 0.7607 - val_accuracy: 0.6887

Epoch 00032: val_loss did not improve from 0.75142
Epoch 33/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7555 - accuracy: 0.6951 - val_loss: 0.7578 - val_accuracy: 0.6876

Epoch 00033: val_loss did not improve from 0.75142
Epoch 34/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7534 - accuracy: 0.6964 - val_loss: 0.7607 - val_accuracy: 0.6825

Epoch 00034: val_loss did not improve from 0.75142
Epoch 35/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7529 - accuracy: 0.6973 - val_loss: 0.7629 - val_accuracy: 0.6863

Epoch 00035: val_loss did not improve from 0.75142
Epoch 36/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7513 - accuracy: 0.6982 - val_loss: 0.7529 - val_accuracy: 0.6880

Epoch 00036: val_loss did not improve from 0.75142
Epoch 37/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7510 - accuracy: 0.6986 - val_loss: 0.7655 - val_accuracy: 0.6824

Epoch 00037: val_loss did not improve from 0.75142
Epoch 38/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7501 - accuracy: 0.6995 - val_loss: 0.7637 - val_accuracy: 0.6829

Epoch 00038: val_loss did not improve from 0.75142
Epoch 39/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7496 - accuracy: 0.6993 - val_loss: 0.7595 - val_accuracy: 0.6860

Epoch 00039: val_loss did not improve from 0.75142
Epoch 40/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7485 - accuracy: 0.7008 - val_loss: 0.7581 - val_accuracy: 0.6853

Epoch 00040: val_loss did not improve from 0.75142
Epoch 41/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7481 - accuracy: 0.6999 - val_loss: 0.7604 - val_accuracy: 0.6855

Epoch 00041: val_loss did not improve from 0.75142
Epoch 42/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7470 - accuracy: 0.7007 - val_loss: 0.7578 - val_accuracy: 0.6882

Epoch 00042: val_loss did not improve from 0.75142
Epoch 43/500
881/881 [==============================] - 69s 78ms/step - loss: 0.7468 - accuracy: 0.7014 - val_loss: 0.7632 - val_accuracy: 0.6856

Epoch 00043: val_loss did not improve from 0.75142
Epoch 44/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7463 - accuracy: 0.7019 - val_loss: 0.7623 - val_accuracy: 0.6860

Epoch 00044: val_loss did not improve from 0.75142
Epoch 45/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7449 - accuracy: 0.7028 - val_loss: 0.7595 - val_accuracy: 0.6861

Epoch 00045: val_loss did not improve from 0.75142
Epoch 46/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7443 - accuracy: 0.7030 - val_loss: 0.7683 - val_accuracy: 0.6868

Epoch 00046: val_loss did not improve from 0.75142
Epoch 47/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7442 - accuracy: 0.7041 - val_loss: 0.7605 - val_accuracy: 0.6851

Epoch 00047: val_loss did not improve from 0.75142
Epoch 48/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7432 - accuracy: 0.7040 - val_loss: 0.7611 - val_accuracy: 0.6865

Epoch 00048: val_loss did not improve from 0.75142
Epoch 49/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7424 - accuracy: 0.7043 - val_loss: 0.7606 - val_accuracy: 0.6869

Epoch 00049: val_loss did not improve from 0.75142
Epoch 50/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7427 - accuracy: 0.7044 - val_loss: 0.7619 - val_accuracy: 0.6850

Epoch 00050: val_loss did not improve from 0.75142
Epoch 51/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7408 - accuracy: 0.7056 - val_loss: 0.7627 - val_accuracy: 0.6861

Epoch 00051: val_loss did not improve from 0.75142
Epoch 00051: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_ternary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPobL2hvbWUvc2FtaHVhbmcvTUwvbW9kZWxzLnB52gg8\nbGFtYmRhPq4AAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
141000/141000 [==============================] - 592s 4ms/step - loss: 0.7574 - accuracy: 0.6878
Testing Loss = 0.757412, Testing Accuracy = 0.687816
The data set contains images
[[0.5252181887626648, 0.010761989280581474, 0.4640198051929474], [0.006457936018705368, 0.9649577140808105, 0.028584370389580727], [0.6979148387908936, 0.14008742570877075, 0.1619977205991745], [0.42681148648262024, 0.006147434003651142, 0.5670410394668579], [0.20184104144573212, 0.08595273643732071, 0.7122061848640442], [0.5267631411552429, 0.04869849607348442, 0.42453834414482117], [0.12303193658590317, 0.08330819755792618, 0.7936598062515259], [0.8149024248123169, 0.07392532378435135, 0.11117219179868698], [0.508277177810669, 0.3210979700088501, 0.170624777674675], [0.1529233157634735, 0.19420620799064636, 0.6528705358505249]]
[[0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0]]
3
$W^+$ (auc = 0.87)
$W^-$ (auc = 0.87)
$Z$ (auc = 0.83)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-11 17:39:10.169495
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
881/881 [==============================] - 65s 67ms/step - loss: 1.3473 - accuracy: 0.4712 - val_loss: 0.9805 - val_accuracy: 0.4899

Epoch 00001: val_loss improved from inf to 0.98046, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9863 - accuracy: 0.4852 - val_loss: 0.9703 - val_accuracy: 0.4966

Epoch 00002: val_loss improved from 0.98046 to 0.97027, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
881/881 [==============================] - 59s 67ms/step - loss: 0.9825 - accuracy: 0.4872 - val_loss: 0.9721 - val_accuracy: 0.4948

Epoch 00003: val_loss did not improve from 0.97027
Epoch 4/500
881/881 [==============================] - 60s 69ms/step - loss: 0.9796 - accuracy: 0.4888 - val_loss: 0.9657 - val_accuracy: 0.4997

Epoch 00004: val_loss improved from 0.97027 to 0.96566, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 5/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9773 - accuracy: 0.4906 - val_loss: 0.9678 - val_accuracy: 0.4967

Epoch 00005: val_loss did not improve from 0.96566
Epoch 6/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9756 - accuracy: 0.4915 - val_loss: 0.9729 - val_accuracy: 0.4953

Epoch 00006: val_loss did not improve from 0.96566
Epoch 7/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9745 - accuracy: 0.4929 - val_loss: 0.9647 - val_accuracy: 0.5005

Epoch 00007: val_loss improved from 0.96566 to 0.96465, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9725 - accuracy: 0.4941 - val_loss: 0.9645 - val_accuracy: 0.5017

Epoch 00008: val_loss improved from 0.96465 to 0.96455, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
881/881 [==============================] - 60s 68ms/step - loss: 0.9715 - accuracy: 0.4959 - val_loss: 0.9653 - val_accuracy: 0.5006

Epoch 00009: val_loss did not improve from 0.96455
Epoch 10/500
881/881 [==============================] - 60s 68ms/step - loss: 0.8781 - accuracy: 0.6182 - val_loss: 0.7813 - val_accuracy: 0.6852

Epoch 00010: val_loss improved from 0.96455 to 0.78125, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 11/500
881/881 [==============================] - 59s 67ms/step - loss: 0.8074 - accuracy: 0.6726 - val_loss: 0.7746 - val_accuracy: 0.6866

Epoch 00011: val_loss improved from 0.78125 to 0.77463, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 12/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7950 - accuracy: 0.6773 - val_loss: 0.7688 - val_accuracy: 0.6862

Epoch 00012: val_loss improved from 0.77463 to 0.76880, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 13/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7872 - accuracy: 0.6797 - val_loss: 0.7710 - val_accuracy: 0.6834

Epoch 00013: val_loss did not improve from 0.76880
Epoch 14/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7837 - accuracy: 0.6808 - val_loss: 0.7586 - val_accuracy: 0.6903

Epoch 00014: val_loss improved from 0.76880 to 0.75858, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 15/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7808 - accuracy: 0.6826 - val_loss: 0.7671 - val_accuracy: 0.6852

Epoch 00015: val_loss did not improve from 0.75858
Epoch 16/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7769 - accuracy: 0.6851 - val_loss: 0.7583 - val_accuracy: 0.6921

Epoch 00016: val_loss improved from 0.75858 to 0.75831, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 17/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7758 - accuracy: 0.6854 - val_loss: 0.7612 - val_accuracy: 0.6889

Epoch 00017: val_loss did not improve from 0.75831
Epoch 18/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7732 - accuracy: 0.6874 - val_loss: 0.7728 - val_accuracy: 0.6833

Epoch 00018: val_loss did not improve from 0.75831
Epoch 19/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7731 - accuracy: 0.6873 - val_loss: 0.7563 - val_accuracy: 0.6907

Epoch 00019: val_loss improved from 0.75831 to 0.75627, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 20/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7697 - accuracy: 0.6891 - val_loss: 0.7606 - val_accuracy: 0.6885

Epoch 00020: val_loss did not improve from 0.75627
Epoch 21/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7682 - accuracy: 0.6901 - val_loss: 0.7615 - val_accuracy: 0.6867

Epoch 00021: val_loss did not improve from 0.75627
Epoch 22/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7671 - accuracy: 0.6917 - val_loss: 0.7622 - val_accuracy: 0.6853

Epoch 00022: val_loss did not improve from 0.75627
Epoch 23/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7665 - accuracy: 0.6919 - val_loss: 0.7559 - val_accuracy: 0.6899

Epoch 00023: val_loss improved from 0.75627 to 0.75593, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 24/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7650 - accuracy: 0.6931 - val_loss: 0.7656 - val_accuracy: 0.6869

Epoch 00024: val_loss did not improve from 0.75593
Epoch 25/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7635 - accuracy: 0.6937 - val_loss: 0.7678 - val_accuracy: 0.6835

Epoch 00025: val_loss did not improve from 0.75593
Epoch 26/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7619 - accuracy: 0.6942 - val_loss: 0.7692 - val_accuracy: 0.6816

Epoch 00026: val_loss did not improve from 0.75593
Epoch 27/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7602 - accuracy: 0.6962 - val_loss: 0.7680 - val_accuracy: 0.6860

Epoch 00027: val_loss did not improve from 0.75593
Epoch 28/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7589 - accuracy: 0.6970 - val_loss: 0.7710 - val_accuracy: 0.6835

Epoch 00028: val_loss did not improve from 0.75593
Epoch 29/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7570 - accuracy: 0.6977 - val_loss: 0.7628 - val_accuracy: 0.6878

Epoch 00029: val_loss did not improve from 0.75593
Epoch 30/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7564 - accuracy: 0.6989 - val_loss: 0.7648 - val_accuracy: 0.6870

Epoch 00030: val_loss did not improve from 0.75593
Epoch 31/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7550 - accuracy: 0.7001 - val_loss: 0.7688 - val_accuracy: 0.6845

Epoch 00031: val_loss did not improve from 0.75593
Epoch 32/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7541 - accuracy: 0.7001 - val_loss: 0.7667 - val_accuracy: 0.6872

Epoch 00032: val_loss did not improve from 0.75593
Epoch 33/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7531 - accuracy: 0.7011 - val_loss: 0.7656 - val_accuracy: 0.6858

Epoch 00033: val_loss did not improve from 0.75593
Epoch 34/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7527 - accuracy: 0.7022 - val_loss: 0.7703 - val_accuracy: 0.6861

Epoch 00034: val_loss did not improve from 0.75593
Epoch 35/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7508 - accuracy: 0.7023 - val_loss: 0.7694 - val_accuracy: 0.6867

Epoch 00035: val_loss did not improve from 0.75593
Epoch 36/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7500 - accuracy: 0.7030 - val_loss: 0.7704 - val_accuracy: 0.6862

Epoch 00036: val_loss did not improve from 0.75593
Epoch 37/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7495 - accuracy: 0.7039 - val_loss: 0.7733 - val_accuracy: 0.6838

Epoch 00037: val_loss did not improve from 0.75593
Epoch 38/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7482 - accuracy: 0.7045 - val_loss: 0.7680 - val_accuracy: 0.6887

Epoch 00038: val_loss did not improve from 0.75593
Epoch 39/500
881/881 [==============================] - 59s 67ms/step - loss: 0.7468 - accuracy: 0.7059 - val_loss: 0.7689 - val_accuracy: 0.6876

Epoch 00039: val_loss did not improve from 0.75593
Epoch 40/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7461 - accuracy: 0.7064 - val_loss: 0.7685 - val_accuracy: 0.6859

Epoch 00040: val_loss did not improve from 0.75593
Epoch 41/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7447 - accuracy: 0.7079 - val_loss: 0.7772 - val_accuracy: 0.6825

Epoch 00041: val_loss did not improve from 0.75593
Epoch 42/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7454 - accuracy: 0.7070 - val_loss: 0.7759 - val_accuracy: 0.6817

Epoch 00042: val_loss did not improve from 0.75593
Epoch 43/500
881/881 [==============================] - 60s 68ms/step - loss: 0.7438 - accuracy: 0.7082 - val_loss: 0.7795 - val_accuracy: 0.6795

Epoch 00043: val_loss did not improve from 0.75593
Epoch 00043: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_ternary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPobL2hvbWUvc2FtaHVhbmcvTUwvbW9kZWxzLnB52gg8\nbGFtYmRhPq4AAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
141000/141000 [==============================] - 575s 4ms/step - loss: 0.7524 - accuracy: 0.6903
Testing Loss = 0.752383, Testing Accuracy = 0.690319
The data set contains images
[[0.6074475049972534, 0.009782426059246063, 0.3827701210975647], [0.011383724398911, 0.7880945205688477, 0.200521782040596], [0.4304388761520386, 0.22120055556297302, 0.3483606278896332], [0.4147540330886841, 0.02232312224805355, 0.5629227757453918], [0.33021605014801025, 0.06718845665454865, 0.6025954484939575], [0.6759800314903259, 0.047124069184064865, 0.2768959701061249], [0.14618539810180664, 0.054725565016269684, 0.7990890145301819], [0.7730141878128052, 0.09740922600030899, 0.12957659363746643], [0.6521900296211243, 0.18821322917938232, 0.1595967710018158], [0.29245033860206604, 0.1682119518518448, 0.539337694644928]]
[[0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0]]
3
$W^+$ (auc = 0.87)
$W^-$ (auc = 0.87)
$Z$ (auc = 0.83)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-12 01:44:52.685994
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
898/898 [==============================] - 82s 69ms/step - loss: 1.3828 - accuracy: 0.4710 - val_loss: 0.9823 - val_accuracy: 0.4846

Epoch 00001: val_loss improved from inf to 0.98234, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9856 - accuracy: 0.4820 - val_loss: 0.9764 - val_accuracy: 0.4882

Epoch 00002: val_loss improved from 0.98234 to 0.97644, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9811 - accuracy: 0.4844 - val_loss: 0.9741 - val_accuracy: 0.4887

Epoch 00003: val_loss improved from 0.97644 to 0.97409, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9790 - accuracy: 0.4860 - val_loss: 0.9771 - val_accuracy: 0.4859

Epoch 00004: val_loss did not improve from 0.97409
Epoch 5/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9771 - accuracy: 0.4868 - val_loss: 0.9696 - val_accuracy: 0.4911

Epoch 00005: val_loss improved from 0.97409 to 0.96961, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9756 - accuracy: 0.4877 - val_loss: 0.9700 - val_accuracy: 0.4903

Epoch 00006: val_loss did not improve from 0.96961
Epoch 7/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9742 - accuracy: 0.4888 - val_loss: 0.9683 - val_accuracy: 0.4926

Epoch 00007: val_loss improved from 0.96961 to 0.96828, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9730 - accuracy: 0.4895 - val_loss: 0.9653 - val_accuracy: 0.4949

Epoch 00008: val_loss improved from 0.96828 to 0.96535, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9714 - accuracy: 0.4904 - val_loss: 0.9675 - val_accuracy: 0.4942

Epoch 00009: val_loss did not improve from 0.96535
Epoch 10/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9703 - accuracy: 0.4907 - val_loss: 0.9649 - val_accuracy: 0.4939

Epoch 00010: val_loss improved from 0.96535 to 0.96493, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 11/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9689 - accuracy: 0.4916 - val_loss: 0.9644 - val_accuracy: 0.4940

Epoch 00011: val_loss improved from 0.96493 to 0.96438, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 12/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9678 - accuracy: 0.4931 - val_loss: 0.9648 - val_accuracy: 0.4922

Epoch 00012: val_loss did not improve from 0.96438
Epoch 13/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9662 - accuracy: 0.4933 - val_loss: 0.9634 - val_accuracy: 0.4946

Epoch 00013: val_loss improved from 0.96438 to 0.96338, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 14/500
898/898 [==============================] - 62s 68ms/step - loss: 0.9653 - accuracy: 0.4950 - val_loss: 0.9624 - val_accuracy: 0.4948

Epoch 00014: val_loss improved from 0.96338 to 0.96237, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 15/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9638 - accuracy: 0.4957 - val_loss: 0.9622 - val_accuracy: 0.4949

Epoch 00015: val_loss improved from 0.96237 to 0.96220, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 16/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9629 - accuracy: 0.4968 - val_loss: 0.9623 - val_accuracy: 0.4951

Epoch 00016: val_loss did not improve from 0.96220
Epoch 17/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9611 - accuracy: 0.4977 - val_loss: 0.9621 - val_accuracy: 0.4954

Epoch 00017: val_loss improved from 0.96220 to 0.96206, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 18/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9595 - accuracy: 0.4989 - val_loss: 0.9622 - val_accuracy: 0.4957

Epoch 00018: val_loss did not improve from 0.96206
Epoch 19/500
898/898 [==============================] - 62s 68ms/step - loss: 0.9579 - accuracy: 0.5003 - val_loss: 0.9602 - val_accuracy: 0.4972

Epoch 00019: val_loss improved from 0.96206 to 0.96015, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 20/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9575 - accuracy: 0.5003 - val_loss: 0.9625 - val_accuracy: 0.4963

Epoch 00020: val_loss did not improve from 0.96015
Epoch 21/500
898/898 [==============================] - 62s 68ms/step - loss: 0.9560 - accuracy: 0.5010 - val_loss: 0.9632 - val_accuracy: 0.4950

Epoch 00021: val_loss did not improve from 0.96015
Epoch 22/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9545 - accuracy: 0.5022 - val_loss: 0.9643 - val_accuracy: 0.4957

Epoch 00022: val_loss did not improve from 0.96015
Epoch 23/500
898/898 [==============================] - 62s 68ms/step - loss: 0.9540 - accuracy: 0.5029 - val_loss: 0.9622 - val_accuracy: 0.4975

Epoch 00023: val_loss did not improve from 0.96015
Epoch 24/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9526 - accuracy: 0.5033 - val_loss: 0.9641 - val_accuracy: 0.4960

Epoch 00024: val_loss did not improve from 0.96015
Epoch 25/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9508 - accuracy: 0.5050 - val_loss: 0.9642 - val_accuracy: 0.4968

Epoch 00025: val_loss did not improve from 0.96015
Epoch 26/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9499 - accuracy: 0.5062 - val_loss: 0.9648 - val_accuracy: 0.4946

Epoch 00026: val_loss did not improve from 0.96015
Epoch 27/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9486 - accuracy: 0.5060 - val_loss: 0.9681 - val_accuracy: 0.4948

Epoch 00027: val_loss did not improve from 0.96015
Epoch 28/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9471 - accuracy: 0.5073 - val_loss: 0.9657 - val_accuracy: 0.4954

Epoch 00028: val_loss did not improve from 0.96015
Epoch 29/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9462 - accuracy: 0.5091 - val_loss: 0.9663 - val_accuracy: 0.4956

Epoch 00029: val_loss did not improve from 0.96015
Epoch 30/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9457 - accuracy: 0.5095 - val_loss: 0.9673 - val_accuracy: 0.4960

Epoch 00030: val_loss did not improve from 0.96015
Epoch 31/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9438 - accuracy: 0.5100 - val_loss: 0.9716 - val_accuracy: 0.4946

Epoch 00031: val_loss did not improve from 0.96015
Epoch 32/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9427 - accuracy: 0.5111 - val_loss: 0.9712 - val_accuracy: 0.4945

Epoch 00032: val_loss did not improve from 0.96015
Epoch 33/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9415 - accuracy: 0.5106 - val_loss: 0.9699 - val_accuracy: 0.4947

Epoch 00033: val_loss did not improve from 0.96015
Epoch 34/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9398 - accuracy: 0.5131 - val_loss: 0.9730 - val_accuracy: 0.4933

Epoch 00034: val_loss did not improve from 0.96015
Epoch 35/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9387 - accuracy: 0.5132 - val_loss: 0.9731 - val_accuracy: 0.4948

Epoch 00035: val_loss did not improve from 0.96015
Epoch 36/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9379 - accuracy: 0.5147 - val_loss: 0.9730 - val_accuracy: 0.4941

Epoch 00036: val_loss did not improve from 0.96015
Epoch 37/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9364 - accuracy: 0.5146 - val_loss: 0.9764 - val_accuracy: 0.4939

Epoch 00037: val_loss did not improve from 0.96015
Epoch 38/500
898/898 [==============================] - 62s 69ms/step - loss: 0.9364 - accuracy: 0.5140 - val_loss: 0.9756 - val_accuracy: 0.4932

Epoch 00038: val_loss did not improve from 0.96015
Epoch 39/500
898/898 [==============================] - 61s 68ms/step - loss: 0.9347 - accuracy: 0.5161 - val_loss: 0.9810 - val_accuracy: 0.4931

Epoch 00039: val_loss did not improve from 0.96015
Epoch 00039: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_ternary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPobL2hvbWUvc2FtaHVhbmcvTUwvbW9kZWxzLnB52gg8\nbGFtYmRhPq4AAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
143782/143782 [==============================] - 591s 4ms/step - loss: 0.9597 - accuracy: 0.4997
Testing Loss = 0.959724, Testing Accuracy = 0.499666
The data set contains images
[[0.3871977925300598, 0.39242035150527954, 0.22038182616233826], [0.45799434185028076, 0.46731725335121155, 0.07468851655721664], [0.41811856627464294, 0.4252992868423462, 0.15658214688301086], [0.4665921628475189, 0.47726738452911377, 0.0561404824256897], [0.15684178471565247, 0.15678995847702026, 0.6863682270050049], [0.3446081876754761, 0.3478933870792389, 0.30749839544296265], [0.4284411668777466, 0.436401903629303, 0.13515695929527283], [0.3951932191848755, 0.401088148355484, 0.20371860265731812], [0.3186783790588379, 0.3211926519870758, 0.3601289987564087], [0.4206925332546234, 0.4283754229545593, 0.15093207359313965]]
[[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]
3
$W^+$ (auc = 0.66)
$W^-$ (auc = 0.66)
$Z$ (auc = 0.82)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-12 12:13:39.682856
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
450/450 [==============================] - 47s 68ms/step - loss: 1.6767 - accuracy: 0.5286 - val_loss: 0.9424 - val_accuracy: 0.5455

Epoch 00001: val_loss improved from inf to 0.94236, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
450/450 [==============================] - 30s 67ms/step - loss: 0.9352 - accuracy: 0.5450 - val_loss: 0.9112 - val_accuracy: 0.5546

Epoch 00002: val_loss improved from 0.94236 to 0.91117, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
450/450 [==============================] - 31s 68ms/step - loss: 0.9256 - accuracy: 0.5480 - val_loss: 0.9060 - val_accuracy: 0.5584

Epoch 00003: val_loss improved from 0.91117 to 0.90598, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
450/450 [==============================] - 31s 68ms/step - loss: 0.9215 - accuracy: 0.5489 - val_loss: 0.9064 - val_accuracy: 0.5546

Epoch 00004: val_loss did not improve from 0.90598
Epoch 5/500
450/450 [==============================] - 31s 68ms/step - loss: 0.9169 - accuracy: 0.5535 - val_loss: 0.9032 - val_accuracy: 0.5579

Epoch 00005: val_loss improved from 0.90598 to 0.90321, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
450/450 [==============================] - 31s 68ms/step - loss: 0.9146 - accuracy: 0.5539 - val_loss: 0.9026 - val_accuracy: 0.5589

Epoch 00006: val_loss improved from 0.90321 to 0.90261, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 7/500
450/450 [==============================] - 31s 68ms/step - loss: 0.9116 - accuracy: 0.5557 - val_loss: 0.9042 - val_accuracy: 0.5576

Epoch 00007: val_loss did not improve from 0.90261
Epoch 8/500
450/450 [==============================] - 30s 67ms/step - loss: 0.9098 - accuracy: 0.5572 - val_loss: 0.8992 - val_accuracy: 0.5614

Epoch 00008: val_loss improved from 0.90261 to 0.89919, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 9/500
450/450 [==============================] - 30s 67ms/step - loss: 0.9072 - accuracy: 0.5587 - val_loss: 0.9019 - val_accuracy: 0.5603

Epoch 00009: val_loss did not improve from 0.89919
Epoch 10/500
450/450 [==============================] - 30s 67ms/step - loss: 0.9060 - accuracy: 0.5593 - val_loss: 0.9025 - val_accuracy: 0.5623

Epoch 00010: val_loss did not improve from 0.89919
Epoch 11/500
450/450 [==============================] - 30s 67ms/step - loss: 0.9028 - accuracy: 0.5605 - val_loss: 0.8987 - val_accuracy: 0.5613

Epoch 00011: val_loss improved from 0.89919 to 0.89869, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 12/500
450/450 [==============================] - 30s 68ms/step - loss: 0.9012 - accuracy: 0.5610 - val_loss: 0.9023 - val_accuracy: 0.5607

Epoch 00012: val_loss did not improve from 0.89869
Epoch 13/500
450/450 [==============================] - 30s 68ms/step - loss: 0.9000 - accuracy: 0.5637 - val_loss: 0.9033 - val_accuracy: 0.5633

Epoch 00013: val_loss did not improve from 0.89869
Epoch 14/500
450/450 [==============================] - 30s 68ms/step - loss: 0.8974 - accuracy: 0.5641 - val_loss: 0.9064 - val_accuracy: 0.5620

Epoch 00014: val_loss did not improve from 0.89869
Epoch 15/500
450/450 [==============================] - 30s 67ms/step - loss: 0.8951 - accuracy: 0.5665 - val_loss: 0.9014 - val_accuracy: 0.5622

Epoch 00015: val_loss did not improve from 0.89869
Epoch 16/500
450/450 [==============================] - 30s 67ms/step - loss: 0.8934 - accuracy: 0.5687 - val_loss: 0.9049 - val_accuracy: 0.5647

Epoch 00016: val_loss did not improve from 0.89869
Epoch 17/500
450/450 [==============================] - 30s 67ms/step - loss: 0.8915 - accuracy: 0.5699 - val_loss: 0.9055 - val_accuracy: 0.5639

Epoch 00017: val_loss did not improve from 0.89869
Epoch 18/500
450/450 [==============================] - 30s 67ms/step - loss: 0.8900 - accuracy: 0.5717 - val_loss: 0.9143 - val_accuracy: 0.5618

Epoch 00018: val_loss did not improve from 0.89869
Epoch 19/500
450/450 [==============================] - 30s 67ms/step - loss: 0.8875 - accuracy: 0.5738 - val_loss: 0.9115 - val_accuracy: 0.5675

Epoch 00019: val_loss did not improve from 0.89869
Epoch 20/500
450/450 [==============================] - 31s 68ms/step - loss: 0.8869 - accuracy: 0.5766 - val_loss: 0.9120 - val_accuracy: 0.5760

Epoch 00020: val_loss did not improve from 0.89869
Epoch 21/500
450/450 [==============================] - 251s 560ms/step - loss: 0.8413 - accuracy: 0.6403 - val_loss: 0.7643 - val_accuracy: 0.6955

Epoch 00021: val_loss improved from 0.89869 to 0.76425, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 22/500
450/450 [==============================] - 30s 66ms/step - loss: 0.7808 - accuracy: 0.6897 - val_loss: 0.7468 - val_accuracy: 0.7014

Epoch 00022: val_loss improved from 0.76425 to 0.74679, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 23/500
450/450 [==============================] - 30s 67ms/step - loss: 0.7675 - accuracy: 0.6972 - val_loss: 0.7399 - val_accuracy: 0.7009

Epoch 00023: val_loss improved from 0.74679 to 0.73987, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 24/500
450/450 [==============================] - 30s 68ms/step - loss: 0.7572 - accuracy: 0.7004 - val_loss: 0.7356 - val_accuracy: 0.7036

Epoch 00024: val_loss improved from 0.73987 to 0.73557, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 25/500
450/450 [==============================] - 30s 67ms/step - loss: 0.7499 - accuracy: 0.7039 - val_loss: 0.7359 - val_accuracy: 0.7037

Epoch 00025: val_loss did not improve from 0.73557
Epoch 26/500
450/450 [==============================] - 30s 67ms/step - loss: 0.7426 - accuracy: 0.7073 - val_loss: 0.7479 - val_accuracy: 0.6979

Epoch 00026: val_loss did not improve from 0.73557
Epoch 27/500
450/450 [==============================] - 30s 67ms/step - loss: 0.7368 - accuracy: 0.7105 - val_loss: 0.7485 - val_accuracy: 0.6979

Epoch 00027: val_loss did not improve from 0.73557
Epoch 28/500
450/450 [==============================] - 30s 68ms/step - loss: 0.7350 - accuracy: 0.7114 - val_loss: 0.7391 - val_accuracy: 0.7020

Epoch 00028: val_loss did not improve from 0.73557
Epoch 29/500
450/450 [==============================] - 30s 67ms/step - loss: 0.7309 - accuracy: 0.7145 - val_loss: 0.7405 - val_accuracy: 0.7021

Epoch 00029: val_loss did not improve from 0.73557
Epoch 30/500
450/450 [==============================] - 30s 67ms/step - loss: 0.7252 - accuracy: 0.7178 - val_loss: 0.7386 - val_accuracy: 0.7024

Epoch 00030: val_loss did not improve from 0.73557
Epoch 31/500
450/450 [==============================] - 41s 92ms/step - loss: 0.7248 - accuracy: 0.7187 - val_loss: 0.7482 - val_accuracy: 0.7006

Epoch 00031: val_loss did not improve from 0.73557
Epoch 32/500
450/450 [==============================] - 30s 67ms/step - loss: 0.7210 - accuracy: 0.7209 - val_loss: 0.7523 - val_accuracy: 0.6985

Epoch 00032: val_loss did not improve from 0.73557
Epoch 33/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7160 - accuracy: 0.7229 - val_loss: 0.7487 - val_accuracy: 0.7008

Epoch 00033: val_loss did not improve from 0.73557
Epoch 34/500
450/450 [==============================] - 30s 67ms/step - loss: 0.7148 - accuracy: 0.7247 - val_loss: 0.7587 - val_accuracy: 0.6989

Epoch 00034: val_loss did not improve from 0.73557
Epoch 35/500
450/450 [==============================] - 30s 67ms/step - loss: 0.7124 - accuracy: 0.7273 - val_loss: 0.7504 - val_accuracy: 0.7019

Epoch 00035: val_loss did not improve from 0.73557
Epoch 36/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7095 - accuracy: 0.7291 - val_loss: 0.7568 - val_accuracy: 0.6979

Epoch 00036: val_loss did not improve from 0.73557
Epoch 37/500
450/450 [==============================] - 37s 82ms/step - loss: 0.7060 - accuracy: 0.7299 - val_loss: 0.7624 - val_accuracy: 0.6975

Epoch 00037: val_loss did not improve from 0.73557
Epoch 38/500
450/450 [==============================] - 36s 80ms/step - loss: 0.7036 - accuracy: 0.7321 - val_loss: 0.7663 - val_accuracy: 0.6965

Epoch 00038: val_loss did not improve from 0.73557
Epoch 39/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7018 - accuracy: 0.7336 - val_loss: 0.7698 - val_accuracy: 0.6975

Epoch 00039: val_loss did not improve from 0.73557
Epoch 40/500
450/450 [==============================] - 30s 67ms/step - loss: 0.6977 - accuracy: 0.7360 - val_loss: 0.7803 - val_accuracy: 0.6963

Epoch 00040: val_loss did not improve from 0.73557
Epoch 41/500
450/450 [==============================] - 30s 67ms/step - loss: 0.6948 - accuracy: 0.7378 - val_loss: 0.7703 - val_accuracy: 0.6979

Epoch 00041: val_loss did not improve from 0.73557
Epoch 42/500
450/450 [==============================] - 30s 67ms/step - loss: 0.6934 - accuracy: 0.7397 - val_loss: 0.7754 - val_accuracy: 0.6953

Epoch 00042: val_loss did not improve from 0.73557
Epoch 43/500
450/450 [==============================] - 30s 67ms/step - loss: 0.6926 - accuracy: 0.7405 - val_loss: 0.7884 - val_accuracy: 0.6931

Epoch 00043: val_loss did not improve from 0.73557
Epoch 44/500
450/450 [==============================] - 30s 66ms/step - loss: 0.6895 - accuracy: 0.7410 - val_loss: 0.7800 - val_accuracy: 0.6946

Epoch 00044: val_loss did not improve from 0.73557
Epoch 00044: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_ternary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPobL2hvbWUvc2FtaHVhbmcvTUwvbW9kZWxzLnB52gg8\nbGFtYmRhPq4AAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
72123/72123 [==============================] - 313s 4ms/step - loss: 0.7400 - accuracy: 0.7025
Testing Loss = 0.739998, Testing Accuracy = 0.702550
The data set contains images
[[0.5801021456718445, 0.05695450305938721, 0.3629433512687683], [0.07699692994356155, 0.647948682308197, 0.275054395198822], [0.29677265882492065, 0.5023605227470398, 0.20086686313152313], [0.9186672568321228, 0.03510782867670059, 0.0462249331176281], [0.9073859453201294, 0.02712131477892399, 0.06549279391765594], [0.46862664818763733, 0.2899430990219116, 0.24143025279045105], [0.04717705026268959, 0.3339569568634033, 0.6188660264015198], [0.9417293667793274, 0.02939923293888569, 0.02887147292494774], [0.04470069706439972, 0.08508147299289703, 0.8702178597450256], [0.0220290869474411, 0.043970655649900436, 0.9340001940727234]]
[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0]]
3
$W^+$ (auc = 0.87)
$W^-$ (auc = 0.87)
$Z$ (auc = 0.85)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-09-12 12:54:52.554020
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/500
450/450 [==============================] - 36s 67ms/step - loss: 1.7134 - accuracy: 0.5787 - val_loss: 0.9086 - val_accuracy: 0.6054

Epoch 00001: val_loss improved from inf to 0.90864, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 2/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7899 - accuracy: 0.6838 - val_loss: 0.7885 - val_accuracy: 0.6717

Epoch 00002: val_loss improved from 0.90864 to 0.78845, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 3/500
450/450 [==============================] - 31s 69ms/step - loss: 0.7711 - accuracy: 0.6878 - val_loss: 0.7351 - val_accuracy: 0.7001

Epoch 00003: val_loss improved from 0.78845 to 0.73512, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 4/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7606 - accuracy: 0.6921 - val_loss: 0.7487 - val_accuracy: 0.6927

Epoch 00004: val_loss did not improve from 0.73512
Epoch 5/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7553 - accuracy: 0.6943 - val_loss: 0.7294 - val_accuracy: 0.7057

Epoch 00005: val_loss improved from 0.73512 to 0.72943, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 6/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7494 - accuracy: 0.6970 - val_loss: 0.7396 - val_accuracy: 0.6968

Epoch 00006: val_loss did not improve from 0.72943
Epoch 7/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7458 - accuracy: 0.6998 - val_loss: 0.7260 - val_accuracy: 0.7057

Epoch 00007: val_loss improved from 0.72943 to 0.72603, saving model to best_model_ternary_CNN_kappa0.15/
Epoch 8/500
450/450 [==============================] - 30s 67ms/step - loss: 0.7434 - accuracy: 0.7020 - val_loss: 0.7353 - val_accuracy: 0.7016

Epoch 00008: val_loss did not improve from 0.72603
Epoch 9/500
450/450 [==============================] - 31s 69ms/step - loss: 0.7387 - accuracy: 0.7050 - val_loss: 0.7690 - val_accuracy: 0.6872

Epoch 00009: val_loss did not improve from 0.72603
Epoch 10/500
450/450 [==============================] - 30s 67ms/step - loss: 0.7365 - accuracy: 0.7077 - val_loss: 0.7521 - val_accuracy: 0.6983

Epoch 00010: val_loss did not improve from 0.72603
Epoch 11/500
450/450 [==============================] - 31s 69ms/step - loss: 0.7341 - accuracy: 0.7100 - val_loss: 0.7329 - val_accuracy: 0.7044

Epoch 00011: val_loss did not improve from 0.72603
Epoch 12/500
450/450 [==============================] - 31s 69ms/step - loss: 0.7283 - accuracy: 0.7139 - val_loss: 0.7342 - val_accuracy: 0.7042

Epoch 00012: val_loss did not improve from 0.72603
Epoch 13/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7235 - accuracy: 0.7177 - val_loss: 0.7347 - val_accuracy: 0.7045

Epoch 00013: val_loss did not improve from 0.72603
Epoch 14/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7197 - accuracy: 0.7206 - val_loss: 0.7482 - val_accuracy: 0.7014

Epoch 00014: val_loss did not improve from 0.72603
Epoch 15/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7143 - accuracy: 0.7252 - val_loss: 0.7617 - val_accuracy: 0.6942

Epoch 00015: val_loss did not improve from 0.72603
Epoch 16/500
450/450 [==============================] - 30s 68ms/step - loss: 0.7106 - accuracy: 0.7294 - val_loss: 0.7677 - val_accuracy: 0.6950

Epoch 00016: val_loss did not improve from 0.72603
Epoch 17/500
450/450 [==============================] - 30s 68ms/step - loss: 0.7074 - accuracy: 0.7328 - val_loss: 0.7654 - val_accuracy: 0.6957

Epoch 00017: val_loss did not improve from 0.72603
Epoch 18/500
450/450 [==============================] - 31s 68ms/step - loss: 0.7032 - accuracy: 0.7369 - val_loss: 0.7959 - val_accuracy: 0.6886

Epoch 00018: val_loss did not improve from 0.72603
Epoch 19/500
450/450 [==============================] - 31s 69ms/step - loss: 0.7006 - accuracy: 0.7392 - val_loss: 0.7988 - val_accuracy: 0.6932

Epoch 00019: val_loss did not improve from 0.72603
Epoch 20/500
450/450 [==============================] - 31s 69ms/step - loss: 0.6914 - accuracy: 0.7450 - val_loss: 0.8018 - val_accuracy: 0.6945

Epoch 00020: val_loss did not improve from 0.72603
Epoch 21/500
450/450 [==============================] - 31s 68ms/step - loss: 0.6841 - accuracy: 0.7508 - val_loss: 0.8093 - val_accuracy: 0.6911

Epoch 00021: val_loss did not improve from 0.72603
Epoch 22/500
450/450 [==============================] - 31s 68ms/step - loss: 0.6801 - accuracy: 0.7544 - val_loss: 0.8222 - val_accuracy: 0.6871

Epoch 00022: val_loss did not improve from 0.72603
Epoch 23/500
450/450 [==============================] - 31s 69ms/step - loss: 0.6772 - accuracy: 0.7572 - val_loss: 0.8300 - val_accuracy: 0.6842

Epoch 00023: val_loss did not improve from 0.72603
Epoch 24/500
450/450 [==============================] - 31s 69ms/step - loss: 0.6672 - accuracy: 0.7620 - val_loss: 0.8548 - val_accuracy: 0.6785

Epoch 00024: val_loss did not improve from 0.72603
Epoch 25/500
450/450 [==============================] - 31s 68ms/step - loss: 0.6619 - accuracy: 0.7657 - val_loss: 0.8612 - val_accuracy: 0.6797

Epoch 00025: val_loss did not improve from 0.72603
Epoch 26/500
450/450 [==============================] - 31s 68ms/step - loss: 0.6552 - accuracy: 0.7704 - val_loss: 0.9100 - val_accuracy: 0.6643

Epoch 00026: val_loss did not improve from 0.72603
Epoch 27/500
450/450 [==============================] - 31s 68ms/step - loss: 0.6466 - accuracy: 0.7756 - val_loss: 0.9071 - val_accuracy: 0.6660

Epoch 00027: val_loss did not improve from 0.72603
Epoch 00027: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN_ternary"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPobL2hvbWUvc2FtaHVhbmcvTUwvbW9kZWxzLnB52gg8\nbGFtYmRhPq4AAADzAAAAAA==\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 500, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
72123/72123 [==============================] - 296s 4ms/step - loss: 0.7293 - accuracy: 0.7043
Testing Loss = 0.729296, Testing Accuracy = 0.704325
The data set contains images
[[0.4967491030693054, 0.026318248361349106, 0.4769325852394104], [0.08829204738140106, 0.663896381855011, 0.24781152606010437], [0.09451448917388916, 0.8011148571968079, 0.10437063872814178], [0.9264733791351318, 0.01345706544816494, 0.0600694939494133], [0.932741105556488, 0.015739744529128075, 0.05151922628283501], [0.6011968851089478, 0.23750491440296173, 0.16129820048809052], [0.03335001692175865, 0.14878417551517487, 0.8178658485412598], [0.9466304183006287, 0.03430362418293953, 0.019065991044044495], [0.03454752266407013, 0.05127203091979027, 0.9141805171966553], [0.010187889449298382, 0.02627994678914547, 0.9635321497917175]]
[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0]]
3
$W^+$ (auc = 0.87)
$W^-$ (auc = 0.87)
$Z$ (auc = 0.85)
