

$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-05 17:51:39.987354
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 69s 68ms/step - loss: 3.0723 - accuracy: 0.5963 - val_loss: 0.9970 - val_accuracy: 0.6313

Epoch 00001: val_loss improved from inf to 0.99705, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 2/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8978 - accuracy: 0.6352 - val_loss: 0.8523 - val_accuracy: 0.6400

Epoch 00002: val_loss improved from 0.99705 to 0.85228, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 3/100
937/937 [==============================] - 62s 66ms/step - loss: 0.8506 - accuracy: 0.6401 - val_loss: 0.8370 - val_accuracy: 0.6445

Epoch 00003: val_loss improved from 0.85228 to 0.83702, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 4/100
937/937 [==============================] - 62s 67ms/step - loss: 0.8397 - accuracy: 0.6436 - val_loss: 0.8261 - val_accuracy: 0.6491

Epoch 00004: val_loss improved from 0.83702 to 0.82607, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 5/100
937/937 [==============================] - 62s 66ms/step - loss: 0.8311 - accuracy: 0.6478 - val_loss: 0.8188 - val_accuracy: 0.6528

Epoch 00005: val_loss improved from 0.82607 to 0.81883, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 6/100
937/937 [==============================] - 62s 66ms/step - loss: 0.8232 - accuracy: 0.6516 - val_loss: 0.8113 - val_accuracy: 0.6577

Epoch 00006: val_loss improved from 0.81883 to 0.81128, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 7/100
937/937 [==============================] - 61s 65ms/step - loss: 0.8167 - accuracy: 0.6557 - val_loss: 0.8015 - val_accuracy: 0.6625

Epoch 00007: val_loss improved from 0.81128 to 0.80151, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 8/100
937/937 [==============================] - 62s 66ms/step - loss: 0.8113 - accuracy: 0.6585 - val_loss: 0.7995 - val_accuracy: 0.6637

Epoch 00008: val_loss improved from 0.80151 to 0.79946, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 9/100
937/937 [==============================] - 62s 66ms/step - loss: 0.8071 - accuracy: 0.6608 - val_loss: 0.7951 - val_accuracy: 0.6655

Epoch 00009: val_loss improved from 0.79946 to 0.79514, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 10/100
937/937 [==============================] - 62s 66ms/step - loss: 0.8035 - accuracy: 0.6620 - val_loss: 0.7926 - val_accuracy: 0.6663

Epoch 00010: val_loss improved from 0.79514 to 0.79255, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 11/100
937/937 [==============================] - 62s 66ms/step - loss: 0.8005 - accuracy: 0.6643 - val_loss: 0.7897 - val_accuracy: 0.6680

Epoch 00011: val_loss improved from 0.79255 to 0.78971, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 12/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7980 - accuracy: 0.6652 - val_loss: 0.7885 - val_accuracy: 0.6679

Epoch 00012: val_loss improved from 0.78971 to 0.78852, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 13/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7957 - accuracy: 0.6670 - val_loss: 0.7865 - val_accuracy: 0.6689

Epoch 00013: val_loss improved from 0.78852 to 0.78654, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 14/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7932 - accuracy: 0.6677 - val_loss: 0.7848 - val_accuracy: 0.6726

Epoch 00014: val_loss improved from 0.78654 to 0.78478, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 15/100
937/937 [==============================] - 61s 65ms/step - loss: 0.7915 - accuracy: 0.6690 - val_loss: 0.7854 - val_accuracy: 0.6722

Epoch 00015: val_loss did not improve from 0.78478
Epoch 16/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7899 - accuracy: 0.6702 - val_loss: 0.7842 - val_accuracy: 0.6724

Epoch 00016: val_loss improved from 0.78478 to 0.78421, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 17/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7885 - accuracy: 0.6709 - val_loss: 0.7843 - val_accuracy: 0.6728

Epoch 00017: val_loss did not improve from 0.78421
Epoch 18/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7868 - accuracy: 0.6716 - val_loss: 0.7820 - val_accuracy: 0.6733

Epoch 00018: val_loss improved from 0.78421 to 0.78201, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 19/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7848 - accuracy: 0.6732 - val_loss: 0.7819 - val_accuracy: 0.6736

Epoch 00019: val_loss improved from 0.78201 to 0.78192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 20/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7841 - accuracy: 0.6733 - val_loss: 0.7819 - val_accuracy: 0.6742

Epoch 00020: val_loss improved from 0.78192 to 0.78187, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 21/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7823 - accuracy: 0.6746 - val_loss: 0.7804 - val_accuracy: 0.6744

Epoch 00021: val_loss improved from 0.78187 to 0.78043, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 22/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7810 - accuracy: 0.6751 - val_loss: 0.7800 - val_accuracy: 0.6749

Epoch 00022: val_loss improved from 0.78043 to 0.78004, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 23/100
937/937 [==============================] - 62s 67ms/step - loss: 0.7795 - accuracy: 0.6760 - val_loss: 0.7802 - val_accuracy: 0.6743

Epoch 00023: val_loss did not improve from 0.78004
Epoch 24/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7777 - accuracy: 0.6774 - val_loss: 0.7799 - val_accuracy: 0.6751

Epoch 00024: val_loss improved from 0.78004 to 0.77994, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 25/100
937/937 [==============================] - 61s 65ms/step - loss: 0.7772 - accuracy: 0.6782 - val_loss: 0.7803 - val_accuracy: 0.6746

Epoch 00025: val_loss did not improve from 0.77994
Epoch 26/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7755 - accuracy: 0.6786 - val_loss: 0.7802 - val_accuracy: 0.6751

Epoch 00026: val_loss did not improve from 0.77994
Epoch 27/100
937/937 [==============================] - 62s 67ms/step - loss: 0.7743 - accuracy: 0.6795 - val_loss: 0.7805 - val_accuracy: 0.6745

Epoch 00027: val_loss did not improve from 0.77994
Epoch 28/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7728 - accuracy: 0.6809 - val_loss: 0.7811 - val_accuracy: 0.6747

Epoch 00028: val_loss did not improve from 0.77994
Epoch 29/100
937/937 [==============================] - 62s 67ms/step - loss: 0.7714 - accuracy: 0.6821 - val_loss: 0.7825 - val_accuracy: 0.6741

Epoch 00029: val_loss did not improve from 0.77994
Epoch 30/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7699 - accuracy: 0.6829 - val_loss: 0.7820 - val_accuracy: 0.6749

Epoch 00030: val_loss did not improve from 0.77994
Epoch 31/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7689 - accuracy: 0.6837 - val_loss: 0.7845 - val_accuracy: 0.6733

Epoch 00031: val_loss did not improve from 0.77994
Epoch 32/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7669 - accuracy: 0.6852 - val_loss: 0.7851 - val_accuracy: 0.6731

Epoch 00032: val_loss did not improve from 0.77994
Epoch 33/100
937/937 [==============================] - 61s 65ms/step - loss: 0.7655 - accuracy: 0.6862 - val_loss: 0.7851 - val_accuracy: 0.6736

Epoch 00033: val_loss did not improve from 0.77994
Epoch 34/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7637 - accuracy: 0.6874 - val_loss: 0.7868 - val_accuracy: 0.6730

Epoch 00034: val_loss did not improve from 0.77994
Epoch 35/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7625 - accuracy: 0.6889 - val_loss: 0.7874 - val_accuracy: 0.6723

Epoch 00035: val_loss did not improve from 0.77994
Epoch 36/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7607 - accuracy: 0.6900 - val_loss: 0.7901 - val_accuracy: 0.6719

Epoch 00036: val_loss did not improve from 0.77994
Epoch 37/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7584 - accuracy: 0.6917 - val_loss: 0.7904 - val_accuracy: 0.6713

Epoch 00037: val_loss did not improve from 0.77994
Epoch 38/100
937/937 [==============================] - 62s 66ms/step - loss: 0.7569 - accuracy: 0.6925 - val_loss: 0.7917 - val_accuracy: 0.6725

Epoch 00038: val_loss did not improve from 0.77994
Epoch 39/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7538 - accuracy: 0.6941 - val_loss: 0.7959 - val_accuracy: 0.6702

Epoch 00039: val_loss did not improve from 0.77994
Epoch 40/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7524 - accuracy: 0.6957 - val_loss: 0.7957 - val_accuracy: 0.6698

Epoch 00040: val_loss did not improve from 0.77994
Epoch 41/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7496 - accuracy: 0.6980 - val_loss: 0.8001 - val_accuracy: 0.6685

Epoch 00041: val_loss did not improve from 0.77994
Epoch 42/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7467 - accuracy: 0.7003 - val_loss: 0.8034 - val_accuracy: 0.6670

Epoch 00042: val_loss did not improve from 0.77994
Epoch 00042: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 600s 4ms/step - loss: 0.7917 - accuracy: 0.6680
Testing Loss = 0.791677, Testing Accuracy = 0.668013
The data set contains images
[[0.6645742058753967, 0.20860137045383453, 0.12682437896728516], [0.08242108672857285, 0.0326845608651638, 0.8848943114280701], [0.5580142736434937, 0.3353535532951355, 0.10663213580846786], [0.17318056523799896, 0.5653854608535767, 0.26143401861190796], [0.7846505045890808, 0.12462500482797623, 0.09072446078062057], [0.41851499676704407, 0.4101812243461609, 0.17130383849143982], [0.07267137616872787, 0.8594173789024353, 0.06791124492883682], [0.12084735184907913, 0.04571591317653656, 0.8334367871284485], [0.04508291557431221, 0.1985418051481247, 0.756375253200531], [0.46079570055007935, 0.12410787492990494, 0.41509637236595154]]
[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0]]
3
$W^+$ (auc = 0.8455)
$W^-$ (auc = 0.8459)
$Z$ (auc = 0.8281)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-14 11:15:17.606272
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 77s 68ms/step - loss: 3.0501 - accuracy: 0.5953 - val_loss: 0.9859 - val_accuracy: 0.6354

Epoch 00001: val_loss improved from inf to 0.98589, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 2/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8993 - accuracy: 0.6326 - val_loss: 0.8507 - val_accuracy: 0.6398

Epoch 00002: val_loss improved from 0.98589 to 0.85072, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 3/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8537 - accuracy: 0.6376 - val_loss: 0.8394 - val_accuracy: 0.6413

Epoch 00003: val_loss improved from 0.85072 to 0.83943, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 4/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8420 - accuracy: 0.6428 - val_loss: 0.8334 - val_accuracy: 0.6430

Epoch 00004: val_loss improved from 0.83943 to 0.83336, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 5/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8332 - accuracy: 0.6463 - val_loss: 0.8388 - val_accuracy: 0.6377

Epoch 00005: val_loss did not improve from 0.83336
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8251 - accuracy: 0.6509 - val_loss: 0.8247 - val_accuracy: 0.6469

Epoch 00006: val_loss improved from 0.83336 to 0.82465, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8194 - accuracy: 0.6544 - val_loss: 0.8278 - val_accuracy: 0.6435

Epoch 00007: val_loss did not improve from 0.82465
Epoch 8/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8141 - accuracy: 0.6570 - val_loss: 0.8190 - val_accuracy: 0.6487

Epoch 00008: val_loss improved from 0.82465 to 0.81896, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 9/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8091 - accuracy: 0.6592 - val_loss: 0.8210 - val_accuracy: 0.6468

Epoch 00009: val_loss did not improve from 0.81896
Epoch 10/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8062 - accuracy: 0.6612 - val_loss: 0.8116 - val_accuracy: 0.6525

Epoch 00010: val_loss improved from 0.81896 to 0.81158, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8029 - accuracy: 0.6622 - val_loss: 0.8128 - val_accuracy: 0.6515

Epoch 00011: val_loss did not improve from 0.81158
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8014 - accuracy: 0.6633 - val_loss: 0.8123 - val_accuracy: 0.6514

Epoch 00012: val_loss did not improve from 0.81158
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7981 - accuracy: 0.6652 - val_loss: 0.8111 - val_accuracy: 0.6521

Epoch 00013: val_loss improved from 0.81158 to 0.81113, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7964 - accuracy: 0.6656 - val_loss: 0.8090 - val_accuracy: 0.6562

Epoch 00014: val_loss improved from 0.81113 to 0.80899, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7944 - accuracy: 0.6675 - val_loss: 0.8067 - val_accuracy: 0.6577

Epoch 00015: val_loss improved from 0.80899 to 0.80670, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7920 - accuracy: 0.6685 - val_loss: 0.8054 - val_accuracy: 0.6582

Epoch 00016: val_loss improved from 0.80670 to 0.80542, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7909 - accuracy: 0.6692 - val_loss: 0.8022 - val_accuracy: 0.6601

Epoch 00017: val_loss improved from 0.80542 to 0.80223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 18/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7889 - accuracy: 0.6700 - val_loss: 0.8052 - val_accuracy: 0.6578

Epoch 00018: val_loss did not improve from 0.80223
Epoch 19/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7870 - accuracy: 0.6721 - val_loss: 0.8007 - val_accuracy: 0.6604

Epoch 00019: val_loss improved from 0.80223 to 0.80068, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7861 - accuracy: 0.6720 - val_loss: 0.8019 - val_accuracy: 0.6603

Epoch 00020: val_loss did not improve from 0.80068
Epoch 21/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7846 - accuracy: 0.6735 - val_loss: 0.7965 - val_accuracy: 0.6638

Epoch 00021: val_loss improved from 0.80068 to 0.79652, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7830 - accuracy: 0.6743 - val_loss: 0.8023 - val_accuracy: 0.6603

Epoch 00022: val_loss did not improve from 0.79652
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7819 - accuracy: 0.6744 - val_loss: 0.8037 - val_accuracy: 0.6592

Epoch 00023: val_loss did not improve from 0.79652
Epoch 24/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7802 - accuracy: 0.6761 - val_loss: 0.7990 - val_accuracy: 0.6620

Epoch 00024: val_loss did not improve from 0.79652
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7787 - accuracy: 0.6763 - val_loss: 0.8028 - val_accuracy: 0.6604

Epoch 00025: val_loss did not improve from 0.79652
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7770 - accuracy: 0.6778 - val_loss: 0.8003 - val_accuracy: 0.6616

Epoch 00026: val_loss did not improve from 0.79652
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7759 - accuracy: 0.6791 - val_loss: 0.7955 - val_accuracy: 0.6645

Epoch 00027: val_loss improved from 0.79652 to 0.79547, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7747 - accuracy: 0.6795 - val_loss: 0.7994 - val_accuracy: 0.6622

Epoch 00028: val_loss did not improve from 0.79547
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7725 - accuracy: 0.6814 - val_loss: 0.7997 - val_accuracy: 0.6631

Epoch 00029: val_loss did not improve from 0.79547
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7717 - accuracy: 0.6816 - val_loss: 0.8013 - val_accuracy: 0.6611

Epoch 00030: val_loss did not improve from 0.79547
Epoch 31/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7695 - accuracy: 0.6831 - val_loss: 0.7924 - val_accuracy: 0.6678

Epoch 00031: val_loss improved from 0.79547 to 0.79241, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 32/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7678 - accuracy: 0.6845 - val_loss: 0.7959 - val_accuracy: 0.6656

Epoch 00032: val_loss did not improve from 0.79241
Epoch 33/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7661 - accuracy: 0.6860 - val_loss: 0.8018 - val_accuracy: 0.6616

Epoch 00033: val_loss did not improve from 0.79241
Epoch 34/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7649 - accuracy: 0.6860 - val_loss: 0.7975 - val_accuracy: 0.6650

Epoch 00034: val_loss did not improve from 0.79241
Epoch 35/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7627 - accuracy: 0.6882 - val_loss: 0.8007 - val_accuracy: 0.6636

Epoch 00035: val_loss did not improve from 0.79241
Epoch 36/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7605 - accuracy: 0.6902 - val_loss: 0.7969 - val_accuracy: 0.6663

Epoch 00036: val_loss did not improve from 0.79241
Epoch 37/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7582 - accuracy: 0.6910 - val_loss: 0.8001 - val_accuracy: 0.6656

Epoch 00037: val_loss did not improve from 0.79241
Epoch 38/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7566 - accuracy: 0.6923 - val_loss: 0.8070 - val_accuracy: 0.6616

Epoch 00038: val_loss did not improve from 0.79241
Epoch 39/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7542 - accuracy: 0.6949 - val_loss: 0.8031 - val_accuracy: 0.6649

Epoch 00039: val_loss did not improve from 0.79241
Epoch 40/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7512 - accuracy: 0.6971 - val_loss: 0.8050 - val_accuracy: 0.6639

Epoch 00040: val_loss did not improve from 0.79241
Epoch 41/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7484 - accuracy: 0.6988 - val_loss: 0.8105 - val_accuracy: 0.6610

Epoch 00041: val_loss did not improve from 0.79241
Epoch 42/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7463 - accuracy: 0.7001 - val_loss: 0.8079 - val_accuracy: 0.6638

Epoch 00042: val_loss did not improve from 0.79241
Epoch 43/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7429 - accuracy: 0.7031 - val_loss: 0.8130 - val_accuracy: 0.6622

Epoch 00043: val_loss did not improve from 0.79241
Epoch 44/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7398 - accuracy: 0.7055 - val_loss: 0.8163 - val_accuracy: 0.6598

Epoch 00044: val_loss did not improve from 0.79241
Epoch 45/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7367 - accuracy: 0.7073 - val_loss: 0.8182 - val_accuracy: 0.6599

Epoch 00045: val_loss did not improve from 0.79241
Epoch 46/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7358 - accuracy: 0.7077 - val_loss: 0.8211 - val_accuracy: 0.6613

Epoch 00046: val_loss did not improve from 0.79241
Epoch 47/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7352 - accuracy: 0.7086 - val_loss: 0.8250 - val_accuracy: 0.6596

Epoch 00047: val_loss did not improve from 0.79241
Epoch 48/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7327 - accuracy: 0.7098 - val_loss: 0.8228 - val_accuracy: 0.6605

Epoch 00048: val_loss did not improve from 0.79241
Epoch 49/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7294 - accuracy: 0.7118 - val_loss: 0.8281 - val_accuracy: 0.6593

Epoch 00049: val_loss did not improve from 0.79241
Epoch 50/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7240 - accuracy: 0.7156 - val_loss: 0.8340 - val_accuracy: 0.6570

Epoch 00050: val_loss did not improve from 0.79241
Epoch 51/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7215 - accuracy: 0.7173 - val_loss: 0.8321 - val_accuracy: 0.6583

Epoch 00051: val_loss did not improve from 0.79241
Epoch 00051: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 667s 4ms/step - loss: 0.7927 - accuracy: 0.6661
Testing Loss = 0.792709, Testing Accuracy = 0.666067
The data set contains images
[[0.5238372087478638, 0.35953620076179504, 0.11662651598453522], [0.872698187828064, 0.0503249354660511, 0.07697681337594986], [0.11370818316936493, 0.031835079193115234, 0.8544566631317139], [0.2888917326927185, 0.30645862221717834, 0.40464961528778076], [0.44359061121940613, 0.2690402865409851, 0.28736910223960876], [0.29381731152534485, 0.060552582144737244, 0.6456301808357239], [0.12192577868700027, 0.05433708056807518, 0.8237371444702148], [0.5199971795082092, 0.05583944916725159, 0.4241634011268616], [0.09875421226024628, 0.6888695359230042, 0.21237628161907196], [0.03816147893667221, 0.4707050919532776, 0.4911334216594696]]
[[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0]]
3
$W^+$ (auc = 0.8459)
$W^-$ (auc = 0.8478)
$Z$ (auc = 0.8289)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-15 17:25:50.469196
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/100
94/94 [==============================] - 23s 73ms/step - loss: 10.7907 - accuracy: 0.4210 - val_loss: 6.9464 - val_accuracy: 0.4341

Epoch 00001: val_loss improved from inf to 6.94642, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 2/100
94/94 [==============================] - 6s 68ms/step - loss: 5.2846 - accuracy: 0.4891 - val_loss: 4.1502 - val_accuracy: 0.4702

Epoch 00002: val_loss improved from 6.94642 to 4.15017, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 3/100
94/94 [==============================] - 7s 69ms/step - loss: 3.4326 - accuracy: 0.5691 - val_loss: 3.0030 - val_accuracy: 0.5177

Epoch 00003: val_loss improved from 4.15017 to 3.00304, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 4/100
94/94 [==============================] - 6s 68ms/step - loss: 2.5461 - accuracy: 0.5957 - val_loss: 2.3115 - val_accuracy: 0.5493

Epoch 00004: val_loss improved from 3.00304 to 2.31151, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 5/100
94/94 [==============================] - 6s 68ms/step - loss: 2.0004 - accuracy: 0.6049 - val_loss: 1.8286 - val_accuracy: 0.5898

Epoch 00005: val_loss improved from 2.31151 to 1.82862, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 6/100
94/94 [==============================] - 7s 68ms/step - loss: 1.6355 - accuracy: 0.6095 - val_loss: 1.5078 - val_accuracy: 0.6059

Epoch 00006: val_loss improved from 1.82862 to 1.50785, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 7/100
94/94 [==============================] - 7s 69ms/step - loss: 1.3872 - accuracy: 0.6138 - val_loss: 1.2955 - val_accuracy: 0.6121

Epoch 00007: val_loss improved from 1.50785 to 1.29554, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 8/100
94/94 [==============================] - 6s 69ms/step - loss: 1.2165 - accuracy: 0.6169 - val_loss: 1.1584 - val_accuracy: 0.6139

Epoch 00008: val_loss improved from 1.29554 to 1.15838, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 9/100
94/94 [==============================] - 7s 69ms/step - loss: 1.1052 - accuracy: 0.6190 - val_loss: 1.0667 - val_accuracy: 0.6158

Epoch 00009: val_loss improved from 1.15838 to 1.06674, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 10/100
94/94 [==============================] - 7s 69ms/step - loss: 1.0291 - accuracy: 0.6224 - val_loss: 1.0059 - val_accuracy: 0.6153

Epoch 00010: val_loss improved from 1.06674 to 1.00590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 11/100
94/94 [==============================] - 7s 69ms/step - loss: 0.9778 - accuracy: 0.6240 - val_loss: 0.9683 - val_accuracy: 0.6133

Epoch 00011: val_loss improved from 1.00590 to 0.96833, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 12/100
94/94 [==============================] - 7s 69ms/step - loss: 0.9434 - accuracy: 0.6266 - val_loss: 0.9428 - val_accuracy: 0.6150

Epoch 00012: val_loss improved from 0.96833 to 0.94276, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 13/100
94/94 [==============================] - 7s 69ms/step - loss: 0.9170 - accuracy: 0.6327 - val_loss: 0.9299 - val_accuracy: 0.6155

Epoch 00013: val_loss improved from 0.94276 to 0.92990, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 14/100
94/94 [==============================] - 7s 69ms/step - loss: 0.9002 - accuracy: 0.6349 - val_loss: 0.9221 - val_accuracy: 0.6106

Epoch 00014: val_loss improved from 0.92990 to 0.92209, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 15/100
94/94 [==============================] - 7s 69ms/step - loss: 0.8878 - accuracy: 0.6383 - val_loss: 0.9147 - val_accuracy: 0.6118

Epoch 00015: val_loss improved from 0.92209 to 0.91473, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 16/100
94/94 [==============================] - 7s 70ms/step - loss: 0.8770 - accuracy: 0.6406 - val_loss: 0.9082 - val_accuracy: 0.6135

Epoch 00016: val_loss improved from 0.91473 to 0.90815, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 17/100
94/94 [==============================] - 7s 69ms/step - loss: 0.8662 - accuracy: 0.6492 - val_loss: 0.9062 - val_accuracy: 0.6139

Epoch 00017: val_loss improved from 0.90815 to 0.90617, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 18/100
94/94 [==============================] - 7s 69ms/step - loss: 0.8592 - accuracy: 0.6524 - val_loss: 0.9081 - val_accuracy: 0.6126

Epoch 00018: val_loss did not improve from 0.90617
Epoch 19/100
94/94 [==============================] - 7s 69ms/step - loss: 0.8458 - accuracy: 0.6610 - val_loss: 0.9114 - val_accuracy: 0.6133

Epoch 00019: val_loss did not improve from 0.90617
Epoch 20/100
94/94 [==============================] - 7s 70ms/step - loss: 0.8358 - accuracy: 0.6676 - val_loss: 0.9189 - val_accuracy: 0.6101

Epoch 00020: val_loss did not improve from 0.90617
Epoch 21/100
94/94 [==============================] - 7s 69ms/step - loss: 0.8238 - accuracy: 0.6790 - val_loss: 0.9281 - val_accuracy: 0.6077

Epoch 00021: val_loss did not improve from 0.90617
Epoch 22/100
94/94 [==============================] - 7s 69ms/step - loss: 0.8089 - accuracy: 0.6905 - val_loss: 0.9371 - val_accuracy: 0.6061

Epoch 00022: val_loss did not improve from 0.90617
Epoch 23/100
94/94 [==============================] - 7s 69ms/step - loss: 0.7932 - accuracy: 0.7031 - val_loss: 0.9490 - val_accuracy: 0.6036

Epoch 00023: val_loss did not improve from 0.90617
Epoch 24/100
94/94 [==============================] - 7s 69ms/step - loss: 0.7793 - accuracy: 0.7149 - val_loss: 0.9742 - val_accuracy: 0.5931

Epoch 00024: val_loss did not improve from 0.90617
Epoch 25/100
94/94 [==============================] - 7s 69ms/step - loss: 0.7583 - accuracy: 0.7291 - val_loss: 0.9787 - val_accuracy: 0.6036

Epoch 00025: val_loss did not improve from 0.90617
Epoch 26/100
94/94 [==============================] - 7s 69ms/step - loss: 0.7521 - accuracy: 0.7341 - val_loss: 1.0119 - val_accuracy: 0.5814

Epoch 00026: val_loss did not improve from 0.90617
Epoch 27/100
94/94 [==============================] - 7s 69ms/step - loss: 0.7182 - accuracy: 0.7546 - val_loss: 1.0232 - val_accuracy: 0.5923

Epoch 00027: val_loss did not improve from 0.90617
Epoch 28/100
94/94 [==============================] - 7s 69ms/step - loss: 0.6995 - accuracy: 0.7693 - val_loss: 1.0851 - val_accuracy: 0.5818

Epoch 00028: val_loss did not improve from 0.90617
Epoch 29/100
94/94 [==============================] - 7s 69ms/step - loss: 0.6937 - accuracy: 0.7767 - val_loss: 1.0797 - val_accuracy: 0.5870

Epoch 00029: val_loss did not improve from 0.90617
Epoch 30/100
94/94 [==============================] - 7s 69ms/step - loss: 0.6579 - accuracy: 0.7959 - val_loss: 1.1210 - val_accuracy: 0.5722

Epoch 00030: val_loss did not improve from 0.90617
Epoch 31/100
94/94 [==============================] - 7s 69ms/step - loss: 0.6209 - accuracy: 0.8166 - val_loss: 1.1432 - val_accuracy: 0.5756

Epoch 00031: val_loss did not improve from 0.90617
Epoch 32/100
94/94 [==============================] - 7s 69ms/step - loss: 0.5942 - accuracy: 0.8326 - val_loss: 1.1778 - val_accuracy: 0.5701

Epoch 00032: val_loss did not improve from 0.90617
Epoch 33/100
94/94 [==============================] - 7s 69ms/step - loss: 0.6049 - accuracy: 0.8288 - val_loss: 1.1426 - val_accuracy: 0.5707

Epoch 00033: val_loss did not improve from 0.90617
Epoch 34/100
94/94 [==============================] - 7s 69ms/step - loss: 0.5908 - accuracy: 0.8330 - val_loss: 1.1797 - val_accuracy: 0.5731

Epoch 00034: val_loss did not improve from 0.90617
Epoch 35/100
94/94 [==============================] - 7s 69ms/step - loss: 0.5539 - accuracy: 0.8517 - val_loss: 1.2502 - val_accuracy: 0.5702

Epoch 00035: val_loss did not improve from 0.90617
Epoch 36/100
94/94 [==============================] - 7s 70ms/step - loss: 0.5382 - accuracy: 0.8601 - val_loss: 1.2382 - val_accuracy: 0.5646

Epoch 00036: val_loss did not improve from 0.90617
Epoch 37/100
94/94 [==============================] - 7s 69ms/step - loss: 0.5251 - accuracy: 0.8641 - val_loss: 1.2970 - val_accuracy: 0.5570

Epoch 00037: val_loss did not improve from 0.90617
Epoch 00037: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
15105/15105 [==============================] - 93s 6ms/step - loss: 0.9005 - accuracy: 0.6206
Testing Loss = 0.900508, Testing Accuracy = 0.620589
The data set contains images
[[0.039380911737680435, 0.834092378616333, 0.12652674317359924], [0.05941594019532204, 0.744931697845459, 0.1956523209810257], [0.5927098989486694, 0.06424590945243835, 0.34304413199424744], [0.6144132018089294, 0.1599842607975006, 0.22560247778892517], [0.12228594720363617, 0.2776613235473633, 0.6000526547431946], [0.40927770733833313, 0.2905138432979584, 0.3002084493637085], [0.3086570203304291, 0.22171872854232788, 0.46962425112724304], [0.060711078345775604, 0.7572590112686157, 0.1820298433303833], [0.7085681557655334, 0.0271123219281435, 0.2643195390701294], [0.12429444491863251, 0.4073372781276703, 0.4683682918548584]]
[[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0]]
3
$W^+$ (auc = 0.8245)
$W^-$ (auc = 0.8256)
$Z$ (auc = 0.7558)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-15 17:33:57.621615
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/100
94/94 [==============================] - 12s 70ms/step - loss: 10.8427 - accuracy: 0.4222 - val_loss: 7.0146 - val_accuracy: 0.4382

Epoch 00001: val_loss improved from inf to 7.01461, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 2/100
94/94 [==============================] - 6s 68ms/step - loss: 5.3333 - accuracy: 0.4977 - val_loss: 4.1772 - val_accuracy: 0.5012

Epoch 00002: val_loss improved from 7.01461 to 4.17720, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 3/100
94/94 [==============================] - 6s 68ms/step - loss: 3.4583 - accuracy: 0.5748 - val_loss: 3.0209 - val_accuracy: 0.5289

Epoch 00003: val_loss improved from 4.17720 to 3.02094, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 4/100
94/94 [==============================] - 6s 68ms/step - loss: 2.5681 - accuracy: 0.5997 - val_loss: 2.3184 - val_accuracy: 0.5700

Epoch 00004: val_loss improved from 3.02094 to 2.31844, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 5/100
94/94 [==============================] - 6s 68ms/step - loss: 2.0156 - accuracy: 0.6066 - val_loss: 1.8431 - val_accuracy: 0.5921

Epoch 00005: val_loss improved from 2.31844 to 1.84308, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 6/100
94/94 [==============================] - 6s 68ms/step - loss: 1.6467 - accuracy: 0.6088 - val_loss: 1.5164 - val_accuracy: 0.6064

Epoch 00006: val_loss improved from 1.84308 to 1.51642, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 7/100
94/94 [==============================] - 6s 68ms/step - loss: 1.3957 - accuracy: 0.6138 - val_loss: 1.3014 - val_accuracy: 0.6125

Epoch 00007: val_loss improved from 1.51642 to 1.30143, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 8/100
94/94 [==============================] - 6s 68ms/step - loss: 1.2246 - accuracy: 0.6150 - val_loss: 1.1614 - val_accuracy: 0.6152

Epoch 00008: val_loss improved from 1.30143 to 1.16138, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 9/100
94/94 [==============================] - 6s 68ms/step - loss: 1.1108 - accuracy: 0.6185 - val_loss: 1.0679 - val_accuracy: 0.6149

Epoch 00009: val_loss improved from 1.16138 to 1.06793, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 10/100
94/94 [==============================] - 6s 68ms/step - loss: 1.0334 - accuracy: 0.6197 - val_loss: 1.0069 - val_accuracy: 0.6155

Epoch 00010: val_loss improved from 1.06793 to 1.00688, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 11/100
94/94 [==============================] - 6s 68ms/step - loss: 0.9818 - accuracy: 0.6227 - val_loss: 0.9692 - val_accuracy: 0.6139

Epoch 00011: val_loss improved from 1.00688 to 0.96921, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 12/100
94/94 [==============================] - 6s 68ms/step - loss: 0.9471 - accuracy: 0.6248 - val_loss: 0.9425 - val_accuracy: 0.6164

Epoch 00012: val_loss improved from 0.96921 to 0.94251, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 13/100
94/94 [==============================] - 6s 68ms/step - loss: 0.9206 - accuracy: 0.6283 - val_loss: 0.9241 - val_accuracy: 0.6163

Epoch 00013: val_loss improved from 0.94251 to 0.92410, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 14/100
94/94 [==============================] - 6s 68ms/step - loss: 0.9065 - accuracy: 0.6279 - val_loss: 0.9169 - val_accuracy: 0.6177

Epoch 00014: val_loss improved from 0.92410 to 0.91692, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 15/100
94/94 [==============================] - 6s 68ms/step - loss: 0.8950 - accuracy: 0.6306 - val_loss: 0.9066 - val_accuracy: 0.6165

Epoch 00015: val_loss improved from 0.91692 to 0.90662, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 16/100
94/94 [==============================] - 6s 68ms/step - loss: 0.8832 - accuracy: 0.6351 - val_loss: 0.9043 - val_accuracy: 0.6166

Epoch 00016: val_loss improved from 0.90662 to 0.90432, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 17/100
94/94 [==============================] - 6s 68ms/step - loss: 0.8753 - accuracy: 0.6412 - val_loss: 0.9034 - val_accuracy: 0.6157

Epoch 00017: val_loss improved from 0.90432 to 0.90341, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 18/100
94/94 [==============================] - 6s 68ms/step - loss: 0.8693 - accuracy: 0.6443 - val_loss: 0.9024 - val_accuracy: 0.6154

Epoch 00018: val_loss improved from 0.90341 to 0.90237, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 19/100
94/94 [==============================] - 6s 68ms/step - loss: 0.8601 - accuracy: 0.6486 - val_loss: 0.9016 - val_accuracy: 0.6172

Epoch 00019: val_loss improved from 0.90237 to 0.90155, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 20/100
94/94 [==============================] - 6s 68ms/step - loss: 0.8510 - accuracy: 0.6552 - val_loss: 0.9076 - val_accuracy: 0.6149

Epoch 00020: val_loss did not improve from 0.90155
Epoch 21/100
94/94 [==============================] - 6s 68ms/step - loss: 0.8424 - accuracy: 0.6631 - val_loss: 0.9166 - val_accuracy: 0.6102

Epoch 00021: val_loss did not improve from 0.90155
Epoch 22/100
94/94 [==============================] - 6s 68ms/step - loss: 0.8348 - accuracy: 0.6681 - val_loss: 0.9203 - val_accuracy: 0.6108

Epoch 00022: val_loss did not improve from 0.90155
Epoch 23/100
94/94 [==============================] - 7s 69ms/step - loss: 0.8207 - accuracy: 0.6804 - val_loss: 0.9294 - val_accuracy: 0.6090

Epoch 00023: val_loss did not improve from 0.90155
Epoch 24/100
94/94 [==============================] - 6s 68ms/step - loss: 0.8080 - accuracy: 0.6903 - val_loss: 0.9362 - val_accuracy: 0.6091

Epoch 00024: val_loss did not improve from 0.90155
Epoch 25/100
94/94 [==============================] - 6s 68ms/step - loss: 0.7932 - accuracy: 0.7038 - val_loss: 0.9504 - val_accuracy: 0.6062

Epoch 00025: val_loss did not improve from 0.90155
Epoch 26/100
94/94 [==============================] - 6s 68ms/step - loss: 0.7728 - accuracy: 0.7191 - val_loss: 0.9640 - val_accuracy: 0.6052

Epoch 00026: val_loss did not improve from 0.90155
Epoch 27/100
94/94 [==============================] - 7s 69ms/step - loss: 0.7570 - accuracy: 0.7304 - val_loss: 0.9906 - val_accuracy: 0.6014

Epoch 00027: val_loss did not improve from 0.90155
Epoch 28/100
94/94 [==============================] - 6s 68ms/step - loss: 0.7443 - accuracy: 0.7402 - val_loss: 1.0187 - val_accuracy: 0.5960

Epoch 00028: val_loss did not improve from 0.90155
Epoch 29/100
94/94 [==============================] - 6s 68ms/step - loss: 0.7233 - accuracy: 0.7558 - val_loss: 1.0259 - val_accuracy: 0.5863

Epoch 00029: val_loss did not improve from 0.90155
Epoch 30/100
94/94 [==============================] - 6s 68ms/step - loss: 0.7050 - accuracy: 0.7670 - val_loss: 1.0857 - val_accuracy: 0.5642

Epoch 00030: val_loss did not improve from 0.90155
Epoch 31/100
94/94 [==============================] - 6s 68ms/step - loss: 0.6643 - accuracy: 0.7918 - val_loss: 1.0926 - val_accuracy: 0.5859

Epoch 00031: val_loss did not improve from 0.90155
Epoch 32/100
94/94 [==============================] - 6s 68ms/step - loss: 0.6312 - accuracy: 0.8125 - val_loss: 1.1245 - val_accuracy: 0.5752

Epoch 00032: val_loss did not improve from 0.90155
Epoch 33/100
94/94 [==============================] - 6s 68ms/step - loss: 0.6130 - accuracy: 0.8219 - val_loss: 1.1361 - val_accuracy: 0.5795

Epoch 00033: val_loss did not improve from 0.90155
Epoch 34/100
94/94 [==============================] - 6s 68ms/step - loss: 0.6037 - accuracy: 0.8274 - val_loss: 1.1470 - val_accuracy: 0.5626

Epoch 00034: val_loss did not improve from 0.90155
Epoch 35/100
94/94 [==============================] - 6s 68ms/step - loss: 0.5967 - accuracy: 0.8322 - val_loss: 1.1882 - val_accuracy: 0.5719

Epoch 00035: val_loss did not improve from 0.90155
Epoch 36/100
94/94 [==============================] - 6s 68ms/step - loss: 0.5670 - accuracy: 0.8444 - val_loss: 1.2093 - val_accuracy: 0.5672

Epoch 00036: val_loss did not improve from 0.90155
Epoch 37/100
94/94 [==============================] - 6s 68ms/step - loss: 0.5475 - accuracy: 0.8536 - val_loss: 1.2647 - val_accuracy: 0.5587

Epoch 00037: val_loss did not improve from 0.90155
Epoch 38/100
94/94 [==============================] - 6s 68ms/step - loss: 0.5532 - accuracy: 0.8490 - val_loss: 1.2686 - val_accuracy: 0.5743

Epoch 00038: val_loss did not improve from 0.90155
Epoch 39/100
94/94 [==============================] - 6s 68ms/step - loss: 0.5312 - accuracy: 0.8612 - val_loss: 1.3106 - val_accuracy: 0.5586

Epoch 00039: val_loss did not improve from 0.90155
Epoch 00039: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
15105/15105 [==============================] - 67s 4ms/step - loss: 0.9024 - accuracy: 0.6178
Testing Loss = 0.902434, Testing Accuracy = 0.617809
The data set contains images
[[0.03124808520078659, 0.8760128617286682, 0.09273911267518997], [0.06009203940629959, 0.7933500409126282, 0.14655794203281403], [0.5737084150314331, 0.08009976893663406, 0.3461918532848358], [0.5846518278121948, 0.15266725420951843, 0.26268094778060913], [0.0843428298830986, 0.4998749792575836, 0.4157821536064148], [0.39629942178726196, 0.2980448603630066, 0.30565565824508667], [0.3790665864944458, 0.28798991441726685, 0.33294346928596497], [0.05835023894906044, 0.7480396628379822, 0.19361011683940887], [0.6972644329071045, 0.0424954853951931, 0.2602400481700897], [0.13072755932807922, 0.3124736249446869, 0.5567988157272339]]
[[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0]]
3
$W^+$ (auc = 0.8213)
$W^-$ (auc = 0.8240)
$Z$ (auc = 0.7548)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-15 17:41:40.204139
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/100
188/188 [==============================] - 11s 37ms/step - loss: 8.2910 - accuracy: 0.4323 - val_loss: 4.3665 - val_accuracy: 0.4481

Epoch 00001: val_loss improved from inf to 4.36649, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 2/100
188/188 [==============================] - 7s 36ms/step - loss: 3.1913 - accuracy: 0.5493 - val_loss: 2.4208 - val_accuracy: 0.5733

Epoch 00002: val_loss improved from 4.36649 to 2.42085, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 3/100
188/188 [==============================] - 7s 36ms/step - loss: 1.9447 - accuracy: 0.5928 - val_loss: 1.6183 - val_accuracy: 0.5893

Epoch 00003: val_loss improved from 2.42085 to 1.61826, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 4/100
188/188 [==============================] - 7s 36ms/step - loss: 1.4000 - accuracy: 0.6027 - val_loss: 1.2434 - val_accuracy: 0.6006

Epoch 00004: val_loss improved from 1.61826 to 1.24338, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 5/100
188/188 [==============================] - 7s 36ms/step - loss: 1.1430 - accuracy: 0.6074 - val_loss: 1.0669 - val_accuracy: 0.6079

Epoch 00005: val_loss improved from 1.24338 to 1.06685, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 6/100
188/188 [==============================] - 7s 36ms/step - loss: 1.0194 - accuracy: 0.6135 - val_loss: 0.9904 - val_accuracy: 0.6044

Epoch 00006: val_loss improved from 1.06685 to 0.99044, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 7/100
188/188 [==============================] - 7s 36ms/step - loss: 0.9593 - accuracy: 0.6180 - val_loss: 0.9507 - val_accuracy: 0.6052

Epoch 00007: val_loss improved from 0.99044 to 0.95068, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 8/100
188/188 [==============================] - 7s 36ms/step - loss: 0.9290 - accuracy: 0.6182 - val_loss: 0.9288 - val_accuracy: 0.6085

Epoch 00008: val_loss improved from 0.95068 to 0.92881, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 9/100
188/188 [==============================] - 7s 36ms/step - loss: 0.9098 - accuracy: 0.6212 - val_loss: 0.9084 - val_accuracy: 0.6151

Epoch 00009: val_loss improved from 0.92881 to 0.90839, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 10/100
188/188 [==============================] - 7s 36ms/step - loss: 0.8974 - accuracy: 0.6250 - val_loss: 0.9051 - val_accuracy: 0.6133

Epoch 00010: val_loss improved from 0.90839 to 0.90515, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 11/100
188/188 [==============================] - 7s 36ms/step - loss: 0.8883 - accuracy: 0.6281 - val_loss: 0.8973 - val_accuracy: 0.6170

Epoch 00011: val_loss improved from 0.90515 to 0.89728, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 12/100
188/188 [==============================] - 7s 36ms/step - loss: 0.8806 - accuracy: 0.6306 - val_loss: 0.8990 - val_accuracy: 0.6141

Epoch 00012: val_loss did not improve from 0.89728
Epoch 13/100
188/188 [==============================] - 7s 36ms/step - loss: 0.8746 - accuracy: 0.6344 - val_loss: 0.8962 - val_accuracy: 0.6149

Epoch 00013: val_loss improved from 0.89728 to 0.89618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 14/100
188/188 [==============================] - 7s 36ms/step - loss: 0.8682 - accuracy: 0.6380 - val_loss: 0.9005 - val_accuracy: 0.6137

Epoch 00014: val_loss did not improve from 0.89618
Epoch 15/100
188/188 [==============================] - 7s 36ms/step - loss: 0.8605 - accuracy: 0.6437 - val_loss: 0.8957 - val_accuracy: 0.6174

Epoch 00015: val_loss improved from 0.89618 to 0.89570, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 16/100
188/188 [==============================] - 7s 36ms/step - loss: 0.8539 - accuracy: 0.6492 - val_loss: 0.9005 - val_accuracy: 0.6187

Epoch 00016: val_loss did not improve from 0.89570
Epoch 17/100
188/188 [==============================] - 7s 36ms/step - loss: 0.8439 - accuracy: 0.6577 - val_loss: 0.9102 - val_accuracy: 0.6112

Epoch 00017: val_loss did not improve from 0.89570
Epoch 18/100
188/188 [==============================] - 7s 36ms/step - loss: 0.8354 - accuracy: 0.6659 - val_loss: 0.9225 - val_accuracy: 0.6071

Epoch 00018: val_loss did not improve from 0.89570
Epoch 19/100
188/188 [==============================] - 7s 36ms/step - loss: 0.8230 - accuracy: 0.6765 - val_loss: 0.9225 - val_accuracy: 0.6139

Epoch 00019: val_loss did not improve from 0.89570
Epoch 20/100
188/188 [==============================] - 7s 36ms/step - loss: 0.8072 - accuracy: 0.6881 - val_loss: 0.9415 - val_accuracy: 0.6084

Epoch 00020: val_loss did not improve from 0.89570
Epoch 21/100
188/188 [==============================] - 7s 36ms/step - loss: 0.7918 - accuracy: 0.7013 - val_loss: 0.9524 - val_accuracy: 0.6075

Epoch 00021: val_loss did not improve from 0.89570
Epoch 22/100
188/188 [==============================] - 7s 36ms/step - loss: 0.7673 - accuracy: 0.7190 - val_loss: 0.9716 - val_accuracy: 0.6050

Epoch 00022: val_loss did not improve from 0.89570
Epoch 23/100
188/188 [==============================] - 7s 36ms/step - loss: 0.7422 - accuracy: 0.7370 - val_loss: 1.0118 - val_accuracy: 0.5978

Epoch 00023: val_loss did not improve from 0.89570
Epoch 24/100
188/188 [==============================] - 7s 36ms/step - loss: 0.7135 - accuracy: 0.7596 - val_loss: 1.0450 - val_accuracy: 0.5956

Epoch 00024: val_loss did not improve from 0.89570
Epoch 25/100
188/188 [==============================] - 7s 36ms/step - loss: 0.6800 - accuracy: 0.7782 - val_loss: 1.1010 - val_accuracy: 0.5875

Epoch 00025: val_loss did not improve from 0.89570
Epoch 26/100
188/188 [==============================] - 7s 36ms/step - loss: 0.6533 - accuracy: 0.7954 - val_loss: 1.1362 - val_accuracy: 0.5832

Epoch 00026: val_loss did not improve from 0.89570
Epoch 27/100
188/188 [==============================] - 7s 36ms/step - loss: 0.6531 - accuracy: 0.7947 - val_loss: 1.1557 - val_accuracy: 0.5755

Epoch 00027: val_loss did not improve from 0.89570
Epoch 28/100
188/188 [==============================] - 7s 36ms/step - loss: 0.6196 - accuracy: 0.8118 - val_loss: 1.1918 - val_accuracy: 0.5744

Epoch 00028: val_loss did not improve from 0.89570
Epoch 29/100
188/188 [==============================] - 7s 36ms/step - loss: 0.5984 - accuracy: 0.8229 - val_loss: 1.2040 - val_accuracy: 0.5729

Epoch 00029: val_loss did not improve from 0.89570
Epoch 30/100
188/188 [==============================] - 7s 36ms/step - loss: 0.5750 - accuracy: 0.8359 - val_loss: 1.2789 - val_accuracy: 0.5635

Epoch 00030: val_loss did not improve from 0.89570
Epoch 31/100
188/188 [==============================] - 7s 36ms/step - loss: 0.5497 - accuracy: 0.8487 - val_loss: 1.3743 - val_accuracy: 0.5381

Epoch 00031: val_loss did not improve from 0.89570
Epoch 32/100
188/188 [==============================] - 7s 36ms/step - loss: 0.5269 - accuracy: 0.8582 - val_loss: 1.3621 - val_accuracy: 0.5458

Epoch 00032: val_loss did not improve from 0.89570
Epoch 33/100
188/188 [==============================] - 7s 36ms/step - loss: 0.5329 - accuracy: 0.8549 - val_loss: 1.2953 - val_accuracy: 0.5562

Epoch 00033: val_loss did not improve from 0.89570
Epoch 34/100
188/188 [==============================] - 7s 37ms/step - loss: 0.5051 - accuracy: 0.8676 - val_loss: 1.3253 - val_accuracy: 0.5601

Epoch 00034: val_loss did not improve from 0.89570
Epoch 35/100
188/188 [==============================] - 7s 37ms/step - loss: 0.4776 - accuracy: 0.8820 - val_loss: 1.4292 - val_accuracy: 0.5319

Epoch 00035: val_loss did not improve from 0.89570
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
15105/15105 [==============================] - 62s 4ms/step - loss: 0.8947 - accuracy: 0.6207
Testing Loss = 0.894659, Testing Accuracy = 0.620655
The data set contains images
[[0.022524787113070488, 0.8946127891540527, 0.08286242932081223], [0.043020088225603104, 0.7795714139938354, 0.17740848660469055], [0.6313381791114807, 0.07215999811887741, 0.29650184512138367], [0.5707590579986572, 0.1624545007944107, 0.2667864263057709], [0.07004501670598984, 0.4874851703643799, 0.4424698054790497], [0.41274294257164, 0.279919296503067, 0.30733776092529297], [0.2976815104484558, 0.19461487233638763, 0.5077036023139954], [0.06558975577354431, 0.7425378561019897, 0.1918724626302719], [0.6492000818252563, 0.03515278920531273, 0.315647155046463], [0.0969163104891777, 0.23138518631458282, 0.6716985106468201]]
[[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0]]
3
$W^+$ (auc = 0.8238)
$W^-$ (auc = 0.8244)
$Z$ (auc = 0.7554)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-16 10:50:50.837831
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 82s 73ms/step - loss: 3.0785 - accuracy: 0.5719 - val_loss: 1.0114 - val_accuracy: 0.6112

Epoch 00001: val_loss improved from inf to 1.01140, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 2/100
937/937 [==============================] - 65s 70ms/step - loss: 0.9247 - accuracy: 0.6114 - val_loss: 0.8793 - val_accuracy: 0.6185

Epoch 00002: val_loss improved from 1.01140 to 0.87930, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 3/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8820 - accuracy: 0.6160 - val_loss: 0.8676 - val_accuracy: 0.6225

Epoch 00003: val_loss improved from 0.87930 to 0.86763, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 4/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8716 - accuracy: 0.6208 - val_loss: 0.8582 - val_accuracy: 0.6267

Epoch 00004: val_loss improved from 0.86763 to 0.85823, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 5/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8622 - accuracy: 0.6263 - val_loss: 0.8449 - val_accuracy: 0.6350

Epoch 00005: val_loss improved from 0.85823 to 0.84486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 6/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8525 - accuracy: 0.6326 - val_loss: 0.8355 - val_accuracy: 0.6413

Epoch 00006: val_loss improved from 0.84486 to 0.83554, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 7/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8458 - accuracy: 0.6372 - val_loss: 0.8294 - val_accuracy: 0.6444

Epoch 00007: val_loss improved from 0.83554 to 0.82942, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 8/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8401 - accuracy: 0.6401 - val_loss: 0.8269 - val_accuracy: 0.6463

Epoch 00008: val_loss improved from 0.82942 to 0.82687, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 9/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8358 - accuracy: 0.6428 - val_loss: 0.8219 - val_accuracy: 0.6489

Epoch 00009: val_loss improved from 0.82687 to 0.82189, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 10/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8324 - accuracy: 0.6442 - val_loss: 0.8204 - val_accuracy: 0.6495

Epoch 00010: val_loss improved from 0.82189 to 0.82036, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 11/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8297 - accuracy: 0.6462 - val_loss: 0.8186 - val_accuracy: 0.6503

Epoch 00011: val_loss improved from 0.82036 to 0.81861, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 12/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8274 - accuracy: 0.6468 - val_loss: 0.8167 - val_accuracy: 0.6507

Epoch 00012: val_loss improved from 0.81861 to 0.81666, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 13/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8258 - accuracy: 0.6473 - val_loss: 0.8156 - val_accuracy: 0.6516

Epoch 00013: val_loss improved from 0.81666 to 0.81556, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 14/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8244 - accuracy: 0.6485 - val_loss: 0.8171 - val_accuracy: 0.6501

Epoch 00014: val_loss did not improve from 0.81556
Epoch 15/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8215 - accuracy: 0.6505 - val_loss: 0.8126 - val_accuracy: 0.6525

Epoch 00015: val_loss improved from 0.81556 to 0.81263, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 16/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8208 - accuracy: 0.6503 - val_loss: 0.8120 - val_accuracy: 0.6535

Epoch 00016: val_loss improved from 0.81263 to 0.81204, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 17/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8189 - accuracy: 0.6519 - val_loss: 0.8131 - val_accuracy: 0.6520

Epoch 00017: val_loss did not improve from 0.81204
Epoch 18/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8180 - accuracy: 0.6524 - val_loss: 0.8104 - val_accuracy: 0.6544

Epoch 00018: val_loss improved from 0.81204 to 0.81041, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 19/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8166 - accuracy: 0.6533 - val_loss: 0.8107 - val_accuracy: 0.6535

Epoch 00019: val_loss did not improve from 0.81041
Epoch 20/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8153 - accuracy: 0.6541 - val_loss: 0.8091 - val_accuracy: 0.6542

Epoch 00020: val_loss improved from 0.81041 to 0.80910, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 21/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8133 - accuracy: 0.6551 - val_loss: 0.8096 - val_accuracy: 0.6548

Epoch 00021: val_loss did not improve from 0.80910
Epoch 22/100
937/937 [==============================] - 65s 70ms/step - loss: 0.8127 - accuracy: 0.6560 - val_loss: 0.8143 - val_accuracy: 0.6514

Epoch 00022: val_loss did not improve from 0.80910
Epoch 23/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8112 - accuracy: 0.6566 - val_loss: 0.8124 - val_accuracy: 0.6519

Epoch 00023: val_loss did not improve from 0.80910
Epoch 24/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8097 - accuracy: 0.6582 - val_loss: 0.8114 - val_accuracy: 0.6520

Epoch 00024: val_loss did not improve from 0.80910
Epoch 25/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8081 - accuracy: 0.6591 - val_loss: 0.8082 - val_accuracy: 0.6547

Epoch 00025: val_loss improved from 0.80910 to 0.80818, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 26/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8072 - accuracy: 0.6597 - val_loss: 0.8081 - val_accuracy: 0.6544

Epoch 00026: val_loss improved from 0.80818 to 0.80814, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/
Epoch 27/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8059 - accuracy: 0.6603 - val_loss: 0.8101 - val_accuracy: 0.6533

Epoch 00027: val_loss did not improve from 0.80814
Epoch 28/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8043 - accuracy: 0.6616 - val_loss: 0.8106 - val_accuracy: 0.6525

Epoch 00028: val_loss did not improve from 0.80814
Epoch 29/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8034 - accuracy: 0.6623 - val_loss: 0.8088 - val_accuracy: 0.6546

Epoch 00029: val_loss did not improve from 0.80814
Epoch 30/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8022 - accuracy: 0.6636 - val_loss: 0.8132 - val_accuracy: 0.6511

Epoch 00030: val_loss did not improve from 0.80814
Epoch 31/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8009 - accuracy: 0.6644 - val_loss: 0.8100 - val_accuracy: 0.6540

Epoch 00031: val_loss did not improve from 0.80814
Epoch 32/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7993 - accuracy: 0.6654 - val_loss: 0.8094 - val_accuracy: 0.6538

Epoch 00032: val_loss did not improve from 0.80814
Epoch 33/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7972 - accuracy: 0.6675 - val_loss: 0.8104 - val_accuracy: 0.6533

Epoch 00033: val_loss did not improve from 0.80814
Epoch 34/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7959 - accuracy: 0.6682 - val_loss: 0.8111 - val_accuracy: 0.6539

Epoch 00034: val_loss did not improve from 0.80814
Epoch 35/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7943 - accuracy: 0.6701 - val_loss: 0.8124 - val_accuracy: 0.6530

Epoch 00035: val_loss did not improve from 0.80814
Epoch 36/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7932 - accuracy: 0.6706 - val_loss: 0.8127 - val_accuracy: 0.6535

Epoch 00036: val_loss did not improve from 0.80814
Epoch 37/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7906 - accuracy: 0.6720 - val_loss: 0.8138 - val_accuracy: 0.6527

Epoch 00037: val_loss did not improve from 0.80814
Epoch 38/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7892 - accuracy: 0.6740 - val_loss: 0.8154 - val_accuracy: 0.6544

Epoch 00038: val_loss did not improve from 0.80814
Epoch 39/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7860 - accuracy: 0.6764 - val_loss: 0.8167 - val_accuracy: 0.6519

Epoch 00039: val_loss did not improve from 0.80814
Epoch 40/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7851 - accuracy: 0.6773 - val_loss: 0.8179 - val_accuracy: 0.6537

Epoch 00040: val_loss did not improve from 0.80814
Epoch 41/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7820 - accuracy: 0.6789 - val_loss: 0.8211 - val_accuracy: 0.6523

Epoch 00041: val_loss did not improve from 0.80814
Epoch 42/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7795 - accuracy: 0.6815 - val_loss: 0.8208 - val_accuracy: 0.6529

Epoch 00042: val_loss did not improve from 0.80814
Epoch 43/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7780 - accuracy: 0.6820 - val_loss: 0.8262 - val_accuracy: 0.6497

Epoch 00043: val_loss did not improve from 0.80814
Epoch 44/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7749 - accuracy: 0.6851 - val_loss: 0.8263 - val_accuracy: 0.6510

Epoch 00044: val_loss did not improve from 0.80814
Epoch 45/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7734 - accuracy: 0.6860 - val_loss: 0.8270 - val_accuracy: 0.6506

Epoch 00045: val_loss did not improve from 0.80814
Epoch 00045: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 649s 4ms/step - loss: 0.8087 - accuracy: 0.6543
Testing Loss = 0.808733, Testing Accuracy = 0.654253
The data set contains images
[[0.25995633006095886, 0.12590554356575012, 0.614138126373291], [0.39771437644958496, 0.16862241923809052, 0.43366312980651855], [0.04848635196685791, 0.18371693789958954, 0.7677967548370361], [0.7594698667526245, 0.09446419775485992, 0.14606593549251556], [0.3464833199977875, 0.32925426959991455, 0.324262410402298], [0.5136595368385315, 0.2751659154891968, 0.21117454767227173], [0.4046642482280731, 0.3222009539604187, 0.27313482761383057], [0.6402716040611267, 0.0953281819820404, 0.2644002139568329], [0.15377643704414368, 0.19378423690795898, 0.652439296245575], [0.03331567719578743, 0.16031400859355927, 0.8063702583312988]]
[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, 1.0]]
3
$W^+$ (auc = 0.8410)
$W^-$ (auc = 0.8426)
$Z$ (auc = 0.8070)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-16 17:28:14.135881
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/5
937/937 [==============================] - 70s 69ms/step - loss: 3.0546 - accuracy: 0.5733 - val_loss: 1.0090 - val_accuracy: 0.6127

Epoch 00001: val_loss improved from inf to 1.00905, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 2/5
937/937 [==============================] - 65s 69ms/step - loss: 0.9252 - accuracy: 0.6115 - val_loss: 0.8813 - val_accuracy: 0.6184

Epoch 00002: val_loss improved from 1.00905 to 0.88132, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 3/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8839 - accuracy: 0.6151 - val_loss: 0.8690 - val_accuracy: 0.6214

Epoch 00003: val_loss improved from 0.88132 to 0.86903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 4/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8739 - accuracy: 0.6193 - val_loss: 0.8607 - val_accuracy: 0.6246

Epoch 00004: val_loss improved from 0.86903 to 0.86072, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 5/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8655 - accuracy: 0.6247 - val_loss: 0.8536 - val_accuracy: 0.6295

Epoch 00005: val_loss improved from 0.86072 to 0.85361, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Epoch 1/5
937/937 [==============================] - 64s 68ms/step - loss: 3.0720 - accuracy: 0.5746 - val_loss: 1.0133 - val_accuracy: 0.6128

Epoch 00001: val_loss improved from inf to 1.01330, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 2/5
937/937 [==============================] - 64s 68ms/step - loss: 0.9260 - accuracy: 0.6114 - val_loss: 0.8811 - val_accuracy: 0.6189

Epoch 00002: val_loss improved from 1.01330 to 0.88106, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 3/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8830 - accuracy: 0.6163 - val_loss: 0.8668 - val_accuracy: 0.6232

Epoch 00003: val_loss improved from 0.88106 to 0.86677, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 4/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8724 - accuracy: 0.6205 - val_loss: 0.8619 - val_accuracy: 0.6251

Epoch 00004: val_loss improved from 0.86677 to 0.86192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 5/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8643 - accuracy: 0.6248 - val_loss: 0.8509 - val_accuracy: 0.6316

Epoch 00005: val_loss improved from 0.86192 to 0.85090, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Epoch 1/5
937/937 [==============================] - 65s 69ms/step - loss: 3.0742 - accuracy: 0.5712 - val_loss: 1.0095 - val_accuracy: 0.6142

Epoch 00001: val_loss improved from inf to 1.00947, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 2/5
937/937 [==============================] - 64s 68ms/step - loss: 0.9255 - accuracy: 0.6115 - val_loss: 0.8813 - val_accuracy: 0.6186

Epoch 00002: val_loss improved from 1.00947 to 0.88125, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 3/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8832 - accuracy: 0.6164 - val_loss: 0.8679 - val_accuracy: 0.6227

Epoch 00003: val_loss improved from 0.88125 to 0.86787, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 4/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8726 - accuracy: 0.6199 - val_loss: 0.8573 - val_accuracy: 0.6277

Epoch 00004: val_loss improved from 0.86787 to 0.85729, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 5/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8641 - accuracy: 0.6255 - val_loss: 0.8487 - val_accuracy: 0.6330

Epoch 00005: val_loss improved from 0.85729 to 0.84867, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Epoch 1/5
937/937 [==============================] - 65s 69ms/step - loss: 3.0898 - accuracy: 0.5713 - val_loss: 1.0148 - val_accuracy: 0.6111

Epoch 00001: val_loss improved from inf to 1.01479, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 2/5
937/937 [==============================] - 64s 69ms/step - loss: 0.9260 - accuracy: 0.6118 - val_loss: 0.8806 - val_accuracy: 0.6189

Epoch 00002: val_loss improved from 1.01479 to 0.88057, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 3/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8832 - accuracy: 0.6164 - val_loss: 0.8689 - val_accuracy: 0.6226

Epoch 00003: val_loss improved from 0.88057 to 0.86890, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 4/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8723 - accuracy: 0.6205 - val_loss: 0.8595 - val_accuracy: 0.6267

Epoch 00004: val_loss improved from 0.86890 to 0.85947, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 5/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8639 - accuracy: 0.6256 - val_loss: 0.8506 - val_accuracy: 0.6322

Epoch 00005: val_loss improved from 0.85947 to 0.85062, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Epoch 1/5
937/937 [==============================] - 65s 69ms/step - loss: 3.0479 - accuracy: 0.5743 - val_loss: 1.0113 - val_accuracy: 0.6095

Epoch 00001: val_loss improved from inf to 1.01129, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 2/5
937/937 [==============================] - 64s 68ms/step - loss: 0.9229 - accuracy: 0.6116 - val_loss: 0.8800 - val_accuracy: 0.6178

Epoch 00002: val_loss improved from 1.01129 to 0.88004, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 3/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8822 - accuracy: 0.6163 - val_loss: 0.8698 - val_accuracy: 0.6198

Epoch 00003: val_loss improved from 0.88004 to 0.86981, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 4/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8715 - accuracy: 0.6204 - val_loss: 0.8617 - val_accuracy: 0.6237

Epoch 00004: val_loss improved from 0.86981 to 0.86175, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 5/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8636 - accuracy: 0.6249 - val_loss: 0.8513 - val_accuracy: 0.6308

Epoch 00005: val_loss improved from 0.86175 to 0.85131, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Epoch 1/5
937/937 [==============================] - 65s 68ms/step - loss: 3.0585 - accuracy: 0.5725 - val_loss: 1.0092 - val_accuracy: 0.6127

Epoch 00001: val_loss improved from inf to 1.00922, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 2/5
937/937 [==============================] - 64s 68ms/step - loss: 0.9250 - accuracy: 0.6118 - val_loss: 0.8787 - val_accuracy: 0.6186

Epoch 00002: val_loss improved from 1.00922 to 0.87869, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 3/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8830 - accuracy: 0.6162 - val_loss: 0.8681 - val_accuracy: 0.6215

Epoch 00003: val_loss improved from 0.87869 to 0.86813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 4/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8721 - accuracy: 0.6201 - val_loss: 0.8605 - val_accuracy: 0.6250

Epoch 00004: val_loss improved from 0.86813 to 0.86047, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 5/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8644 - accuracy: 0.6248 - val_loss: 0.8527 - val_accuracy: 0.6290

Epoch 00005: val_loss improved from 0.86047 to 0.85272, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Epoch 1/5
937/937 [==============================] - 93s 98ms/step - loss: 3.0342 - accuracy: 0.5728 - val_loss: 1.0115 - val_accuracy: 0.6103

Epoch 00001: val_loss improved from inf to 1.01152, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 2/5
937/937 [==============================] - 65s 69ms/step - loss: 0.9245 - accuracy: 0.6111 - val_loss: 0.8822 - val_accuracy: 0.6171

Epoch 00002: val_loss improved from 1.01152 to 0.88218, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 3/5
937/937 [==============================] - 65s 69ms/step - loss: 0.8836 - accuracy: 0.6148 - val_loss: 0.8666 - val_accuracy: 0.6215

Epoch 00003: val_loss improved from 0.88218 to 0.86659, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 4/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8728 - accuracy: 0.6198 - val_loss: 0.8593 - val_accuracy: 0.6250

Epoch 00004: val_loss improved from 0.86659 to 0.85932, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 5/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8641 - accuracy: 0.6243 - val_loss: 0.8528 - val_accuracy: 0.6295

Epoch 00005: val_loss improved from 0.85932 to 0.85275, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Epoch 1/5
937/937 [==============================] - 211s 225ms/step - loss: 3.0402 - accuracy: 0.5700 - val_loss: 1.0133 - val_accuracy: 0.6088

Epoch 00001: val_loss improved from inf to 1.01332, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 2/5
937/937 [==============================] - 64s 69ms/step - loss: 0.9217 - accuracy: 0.6122 - val_loss: 0.8827 - val_accuracy: 0.6161

Epoch 00002: val_loss improved from 1.01332 to 0.88270, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 3/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8813 - accuracy: 0.6159 - val_loss: 0.8678 - val_accuracy: 0.6217

Epoch 00003: val_loss improved from 0.88270 to 0.86781, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 4/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8712 - accuracy: 0.6212 - val_loss: 0.8587 - val_accuracy: 0.6261

Epoch 00004: val_loss improved from 0.86781 to 0.85872, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 5/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8627 - accuracy: 0.6260 - val_loss: 0.8502 - val_accuracy: 0.6309

Epoch 00005: val_loss improved from 0.85872 to 0.85019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Epoch 1/5
937/937 [==============================] - 65s 69ms/step - loss: 3.0319 - accuracy: 0.5738 - val_loss: 1.0047 - val_accuracy: 0.6135

Epoch 00001: val_loss improved from inf to 1.00469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 2/5
937/937 [==============================] - 65s 69ms/step - loss: 0.9225 - accuracy: 0.6115 - val_loss: 0.8808 - val_accuracy: 0.6177

Epoch 00002: val_loss improved from 1.00469 to 0.88084, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 3/5
937/937 [==============================] - 65s 69ms/step - loss: 0.8813 - accuracy: 0.6166 - val_loss: 0.8681 - val_accuracy: 0.6230

Epoch 00003: val_loss improved from 0.88084 to 0.86811, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 4/5
937/937 [==============================] - 65s 69ms/step - loss: 0.8709 - accuracy: 0.6205 - val_loss: 0.8565 - val_accuracy: 0.6284

Epoch 00004: val_loss improved from 0.86811 to 0.85654, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 5/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8625 - accuracy: 0.6263 - val_loss: 0.8496 - val_accuracy: 0.6323

Epoch 00005: val_loss improved from 0.85654 to 0.84955, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Epoch 1/5
937/937 [==============================] - 65s 69ms/step - loss: 3.0855 - accuracy: 0.5748 - val_loss: 1.0144 - val_accuracy: 0.6130

Epoch 00001: val_loss improved from inf to 1.01443, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 2/5
937/937 [==============================] - 64s 69ms/step - loss: 0.9268 - accuracy: 0.6115 - val_loss: 0.8801 - val_accuracy: 0.6194

Epoch 00002: val_loss improved from 1.01443 to 0.88010, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 3/5
937/937 [==============================] - 65s 69ms/step - loss: 0.8827 - accuracy: 0.6168 - val_loss: 0.8672 - val_accuracy: 0.6228

Epoch 00003: val_loss improved from 0.88010 to 0.86717, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 4/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8720 - accuracy: 0.6206 - val_loss: 0.8567 - val_accuracy: 0.6284

Epoch 00004: val_loss improved from 0.86717 to 0.85670, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 5/5
937/937 [==============================] - 64s 69ms/step - loss: 0.8618 - accuracy: 0.6279 - val_loss: 0.8470 - val_accuracy: 0.6354

Epoch 00005: val_loss improved from 0.85670 to 0.84700, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-16 22:50:10.977860
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/5
937/937 [==============================] - 70s 68ms/step - loss: 3.0834 - accuracy: 0.5704 - val_loss: 1.0091 - val_accuracy: 0.6122

Epoch 00001: val_loss improved from inf to 1.00914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 2/5
937/937 [==============================] - 64s 68ms/step - loss: 0.9235 - accuracy: 0.6119 - val_loss: 0.8774 - val_accuracy: 0.6197

Epoch 00002: val_loss improved from 1.00914 to 0.87744, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 3/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8818 - accuracy: 0.6154 - val_loss: 0.8677 - val_accuracy: 0.6208

Epoch 00003: val_loss improved from 0.87744 to 0.86770, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 4/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8722 - accuracy: 0.6193 - val_loss: 0.8588 - val_accuracy: 0.6251

Epoch 00004: val_loss improved from 0.86770 to 0.85880, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 5/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8645 - accuracy: 0.6238 - val_loss: 0.8520 - val_accuracy: 0.6289

Epoch 00005: val_loss improved from 0.85880 to 0.85202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 612s 4ms/step - loss: 0.8514 - accuracy: 0.6296
Testing Loss = 0.851420, Testing Accuracy = 0.629607
The data set contains images
The data set contains images
The data set contains images
Epoch 1/5
937/937 [==============================] - 65s 68ms/step - loss: 3.0577 - accuracy: 0.5693 - val_loss: 1.0064 - val_accuracy: 0.6121

Epoch 00001: val_loss improved from inf to 1.00644, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 2/5
937/937 [==============================] - 64s 69ms/step - loss: 0.9234 - accuracy: 0.6111 - val_loss: 0.8799 - val_accuracy: 0.6176

Epoch 00002: val_loss improved from 1.00644 to 0.87986, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 3/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8822 - accuracy: 0.6161 - val_loss: 0.8694 - val_accuracy: 0.6202

Epoch 00003: val_loss improved from 0.87986 to 0.86936, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 4/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8716 - accuracy: 0.6198 - val_loss: 0.8606 - val_accuracy: 0.6251

Epoch 00004: val_loss improved from 0.86936 to 0.86058, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 5/5
937/937 [==============================] - 64s 68ms/step - loss: 0.8628 - accuracy: 0.6254 - val_loss: 0.8480 - val_accuracy: 0.6336

Epoch 00005: val_loss improved from 0.86058 to 0.84799, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 5, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 613s 4ms/step - loss: 0.8475 - accuracy: 0.6326
Testing Loss = 0.847451, Testing Accuracy = 0.632600
The data set contains images
N of classes 3
[[0.8314583970508915, 0.83258934554668, 0.7759742709483817], [0.8314583970508915, 0.83258934554668, 0.7759742709483817]]
[array([0.        , 0.        , 0.        , ..., 0.99539626, 0.99539626,
       1.        ]), array([0.       , 0.       , 0.       , ..., 0.9991187, 0.9991187,
       1.       ]), array([0.00000000e+00, 0.00000000e+00, 9.99890012e-06, ...,
       9.99560048e-01, 9.99560048e-01, 1.00000000e+00])]
$W^+$ (auc = 0.83 +- 0.0000 %)
$W^-$ (auc = 0.83 +- 0.0000 %)
$Z$ (auc = 0.78 +- 0.0000 %)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-10-16 23:53:15.260651
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 70s 68ms/step - loss: 3.0498 - accuracy: 0.5723 - val_loss: 1.0103 - val_accuracy: 0.6129

Epoch 00001: val_loss improved from inf to 1.01034, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.9264 - accuracy: 0.6109 - val_loss: 0.8802 - val_accuracy: 0.6186

Epoch 00002: val_loss improved from 1.01034 to 0.88019, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8838 - accuracy: 0.6160 - val_loss: 0.8690 - val_accuracy: 0.6211

Epoch 00003: val_loss improved from 0.88019 to 0.86904, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 4/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8730 - accuracy: 0.6202 - val_loss: 0.8583 - val_accuracy: 0.6269

Epoch 00004: val_loss improved from 0.86904 to 0.85833, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 5/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8640 - accuracy: 0.6257 - val_loss: 0.8507 - val_accuracy: 0.6327

Epoch 00005: val_loss improved from 0.85833 to 0.85074, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 6/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8562 - accuracy: 0.6312 - val_loss: 0.8388 - val_accuracy: 0.6406

Epoch 00006: val_loss improved from 0.85074 to 0.83881, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 7/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8483 - accuracy: 0.6354 - val_loss: 0.8331 - val_accuracy: 0.6436

Epoch 00007: val_loss improved from 0.83881 to 0.83312, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8432 - accuracy: 0.6384 - val_loss: 0.8301 - val_accuracy: 0.6457

Epoch 00008: val_loss improved from 0.83312 to 0.83005, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 9/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8387 - accuracy: 0.6411 - val_loss: 0.8242 - val_accuracy: 0.6481

Epoch 00009: val_loss improved from 0.83005 to 0.82416, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 10/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8355 - accuracy: 0.6429 - val_loss: 0.8246 - val_accuracy: 0.6480

Epoch 00010: val_loss did not improve from 0.82416
Epoch 11/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8328 - accuracy: 0.6451 - val_loss: 0.8238 - val_accuracy: 0.6483

Epoch 00011: val_loss improved from 0.82416 to 0.82382, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 12/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8305 - accuracy: 0.6457 - val_loss: 0.8184 - val_accuracy: 0.6509

Epoch 00012: val_loss improved from 0.82382 to 0.81837, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8280 - accuracy: 0.6469 - val_loss: 0.8166 - val_accuracy: 0.6521

Epoch 00013: val_loss improved from 0.81837 to 0.81658, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 14/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8270 - accuracy: 0.6477 - val_loss: 0.8165 - val_accuracy: 0.6519

Epoch 00014: val_loss improved from 0.81658 to 0.81647, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8246 - accuracy: 0.6495 - val_loss: 0.8181 - val_accuracy: 0.6500

Epoch 00015: val_loss did not improve from 0.81647
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8230 - accuracy: 0.6501 - val_loss: 0.8149 - val_accuracy: 0.6517

Epoch 00016: val_loss improved from 0.81647 to 0.81495, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8213 - accuracy: 0.6509 - val_loss: 0.8146 - val_accuracy: 0.6521

Epoch 00017: val_loss improved from 0.81495 to 0.81465, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 18/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8193 - accuracy: 0.6514 - val_loss: 0.8134 - val_accuracy: 0.6525

Epoch 00018: val_loss improved from 0.81465 to 0.81339, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 19/100
937/937 [==============================] - 65s 70ms/step - loss: 0.8185 - accuracy: 0.6521 - val_loss: 0.8122 - val_accuracy: 0.6536

Epoch 00019: val_loss improved from 0.81339 to 0.81218, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8168 - accuracy: 0.6531 - val_loss: 0.8128 - val_accuracy: 0.6524

Epoch 00020: val_loss did not improve from 0.81218
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8160 - accuracy: 0.6543 - val_loss: 0.8117 - val_accuracy: 0.6529

Epoch 00021: val_loss improved from 0.81218 to 0.81170, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 22/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8147 - accuracy: 0.6543 - val_loss: 0.8107 - val_accuracy: 0.6548

Epoch 00022: val_loss improved from 0.81170 to 0.81071, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8129 - accuracy: 0.6554 - val_loss: 0.8104 - val_accuracy: 0.6540

Epoch 00023: val_loss improved from 0.81071 to 0.81043, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 24/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8120 - accuracy: 0.6558 - val_loss: 0.8116 - val_accuracy: 0.6526

Epoch 00024: val_loss did not improve from 0.81043
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8107 - accuracy: 0.6574 - val_loss: 0.8105 - val_accuracy: 0.6536

Epoch 00025: val_loss did not improve from 0.81043
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8096 - accuracy: 0.6575 - val_loss: 0.8101 - val_accuracy: 0.6542

Epoch 00026: val_loss improved from 0.81043 to 0.81008, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8085 - accuracy: 0.6582 - val_loss: 0.8107 - val_accuracy: 0.6531

Epoch 00027: val_loss did not improve from 0.81008
Epoch 28/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8068 - accuracy: 0.6591 - val_loss: 0.8134 - val_accuracy: 0.6513

Epoch 00028: val_loss did not improve from 0.81008
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8052 - accuracy: 0.6612 - val_loss: 0.8099 - val_accuracy: 0.6541

Epoch 00029: val_loss improved from 0.81008 to 0.80994, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8036 - accuracy: 0.6623 - val_loss: 0.8112 - val_accuracy: 0.6533

Epoch 00030: val_loss did not improve from 0.80994
Epoch 31/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8030 - accuracy: 0.6626 - val_loss: 0.8147 - val_accuracy: 0.6509

Epoch 00031: val_loss did not improve from 0.80994
Epoch 32/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8020 - accuracy: 0.6633 - val_loss: 0.8097 - val_accuracy: 0.6537

Epoch 00032: val_loss improved from 0.80994 to 0.80974, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 33/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8009 - accuracy: 0.6642 - val_loss: 0.8155 - val_accuracy: 0.6502

Epoch 00033: val_loss did not improve from 0.80974
Epoch 34/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7987 - accuracy: 0.6660 - val_loss: 0.8118 - val_accuracy: 0.6529

Epoch 00034: val_loss did not improve from 0.80974
Epoch 35/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7965 - accuracy: 0.6677 - val_loss: 0.8150 - val_accuracy: 0.6504

Epoch 00035: val_loss did not improve from 0.80974
Epoch 36/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7952 - accuracy: 0.6687 - val_loss: 0.8145 - val_accuracy: 0.6504

Epoch 00036: val_loss did not improve from 0.80974
Epoch 37/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7932 - accuracy: 0.6698 - val_loss: 0.8171 - val_accuracy: 0.6498

Epoch 00037: val_loss did not improve from 0.80974
Epoch 38/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7918 - accuracy: 0.6716 - val_loss: 0.8184 - val_accuracy: 0.6493

Epoch 00038: val_loss did not improve from 0.80974
Epoch 39/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7892 - accuracy: 0.6735 - val_loss: 0.8215 - val_accuracy: 0.6466

Epoch 00039: val_loss did not improve from 0.80974
Epoch 40/100
937/937 [==============================] - 63s 67ms/step - loss: 0.7882 - accuracy: 0.6739 - val_loss: 0.8206 - val_accuracy: 0.6505

Epoch 00040: val_loss did not improve from 0.80974
Epoch 41/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7855 - accuracy: 0.6765 - val_loss: 0.8251 - val_accuracy: 0.6456

Epoch 00041: val_loss did not improve from 0.80974
Epoch 42/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7840 - accuracy: 0.6772 - val_loss: 0.8249 - val_accuracy: 0.6478

Epoch 00042: val_loss did not improve from 0.80974
Epoch 00042: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 607s 4ms/step - loss: 0.8109 - accuracy: 0.6537
Testing Loss = 0.810869, Testing Accuracy = 0.653720
The data set contains images
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 64s 68ms/step - loss: 3.0584 - accuracy: 0.5740 - val_loss: 1.0103 - val_accuracy: 0.6123

Epoch 00001: val_loss improved from inf to 1.01030, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.9242 - accuracy: 0.6115 - val_loss: 0.8804 - val_accuracy: 0.6179

Epoch 00002: val_loss improved from 1.01030 to 0.88039, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 3/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8817 - accuracy: 0.6163 - val_loss: 0.8671 - val_accuracy: 0.6221

Epoch 00003: val_loss improved from 0.88039 to 0.86710, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 4/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8705 - accuracy: 0.6213 - val_loss: 0.8581 - val_accuracy: 0.6273

Epoch 00004: val_loss improved from 0.86710 to 0.85807, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 5/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8620 - accuracy: 0.6260 - val_loss: 0.8491 - val_accuracy: 0.6332

Epoch 00005: val_loss improved from 0.85807 to 0.84914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 6/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8536 - accuracy: 0.6311 - val_loss: 0.8394 - val_accuracy: 0.6393

Epoch 00006: val_loss improved from 0.84914 to 0.83938, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8470 - accuracy: 0.6357 - val_loss: 0.8349 - val_accuracy: 0.6414

Epoch 00007: val_loss improved from 0.83938 to 0.83493, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8414 - accuracy: 0.6391 - val_loss: 0.8268 - val_accuracy: 0.6464

Epoch 00008: val_loss improved from 0.83493 to 0.82684, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 9/100
937/937 [==============================] - 66s 70ms/step - loss: 0.8376 - accuracy: 0.6412 - val_loss: 0.8225 - val_accuracy: 0.6491

Epoch 00009: val_loss improved from 0.82684 to 0.82246, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 10/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8342 - accuracy: 0.6431 - val_loss: 0.8216 - val_accuracy: 0.6485

Epoch 00010: val_loss improved from 0.82246 to 0.82156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8310 - accuracy: 0.6452 - val_loss: 0.8212 - val_accuracy: 0.6477

Epoch 00011: val_loss improved from 0.82156 to 0.82122, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8290 - accuracy: 0.6465 - val_loss: 0.8176 - val_accuracy: 0.6506

Epoch 00012: val_loss improved from 0.82122 to 0.81761, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 13/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8269 - accuracy: 0.6473 - val_loss: 0.8162 - val_accuracy: 0.6513

Epoch 00013: val_loss improved from 0.81761 to 0.81619, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8248 - accuracy: 0.6480 - val_loss: 0.8149 - val_accuracy: 0.6518

Epoch 00014: val_loss improved from 0.81619 to 0.81488, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8231 - accuracy: 0.6488 - val_loss: 0.8149 - val_accuracy: 0.6510

Epoch 00015: val_loss did not improve from 0.81488
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8220 - accuracy: 0.6501 - val_loss: 0.8150 - val_accuracy: 0.6502

Epoch 00016: val_loss did not improve from 0.81488
Epoch 17/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8202 - accuracy: 0.6508 - val_loss: 0.8138 - val_accuracy: 0.6520

Epoch 00017: val_loss improved from 0.81488 to 0.81381, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 18/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8191 - accuracy: 0.6513 - val_loss: 0.8126 - val_accuracy: 0.6512

Epoch 00018: val_loss improved from 0.81381 to 0.81258, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 19/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8174 - accuracy: 0.6522 - val_loss: 0.8152 - val_accuracy: 0.6491

Epoch 00019: val_loss did not improve from 0.81258
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8161 - accuracy: 0.6535 - val_loss: 0.8131 - val_accuracy: 0.6512

Epoch 00020: val_loss did not improve from 0.81258
Epoch 21/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8144 - accuracy: 0.6542 - val_loss: 0.8135 - val_accuracy: 0.6501

Epoch 00021: val_loss did not improve from 0.81258
Epoch 22/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8128 - accuracy: 0.6560 - val_loss: 0.8127 - val_accuracy: 0.6514

Epoch 00022: val_loss did not improve from 0.81258
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8127 - accuracy: 0.6556 - val_loss: 0.8138 - val_accuracy: 0.6504

Epoch 00023: val_loss did not improve from 0.81258
Epoch 24/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8108 - accuracy: 0.6568 - val_loss: 0.8125 - val_accuracy: 0.6515

Epoch 00024: val_loss improved from 0.81258 to 0.81251, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8100 - accuracy: 0.6577 - val_loss: 0.8117 - val_accuracy: 0.6518

Epoch 00025: val_loss improved from 0.81251 to 0.81172, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8090 - accuracy: 0.6584 - val_loss: 0.8122 - val_accuracy: 0.6511

Epoch 00026: val_loss did not improve from 0.81172
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8069 - accuracy: 0.6588 - val_loss: 0.8116 - val_accuracy: 0.6520

Epoch 00027: val_loss improved from 0.81172 to 0.81161, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8061 - accuracy: 0.6603 - val_loss: 0.8114 - val_accuracy: 0.6526

Epoch 00028: val_loss improved from 0.81161 to 0.81138, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8045 - accuracy: 0.6613 - val_loss: 0.8115 - val_accuracy: 0.6525

Epoch 00029: val_loss did not improve from 0.81138
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8032 - accuracy: 0.6620 - val_loss: 0.8132 - val_accuracy: 0.6516

Epoch 00030: val_loss did not improve from 0.81138
Epoch 31/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8016 - accuracy: 0.6630 - val_loss: 0.8144 - val_accuracy: 0.6509

Epoch 00031: val_loss did not improve from 0.81138
Epoch 32/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8003 - accuracy: 0.6645 - val_loss: 0.8145 - val_accuracy: 0.6503

Epoch 00032: val_loss did not improve from 0.81138
Epoch 33/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7988 - accuracy: 0.6650 - val_loss: 0.8129 - val_accuracy: 0.6515

Epoch 00033: val_loss did not improve from 0.81138
Epoch 34/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7971 - accuracy: 0.6661 - val_loss: 0.8145 - val_accuracy: 0.6507

Epoch 00034: val_loss did not improve from 0.81138
Epoch 35/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7954 - accuracy: 0.6684 - val_loss: 0.8126 - val_accuracy: 0.6544

Epoch 00035: val_loss did not improve from 0.81138
Epoch 36/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7939 - accuracy: 0.6699 - val_loss: 0.8149 - val_accuracy: 0.6533

Epoch 00036: val_loss did not improve from 0.81138
Epoch 37/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7926 - accuracy: 0.6707 - val_loss: 0.8173 - val_accuracy: 0.6520

Epoch 00037: val_loss did not improve from 0.81138
Epoch 38/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7908 - accuracy: 0.6719 - val_loss: 0.8185 - val_accuracy: 0.6510

Epoch 00038: val_loss did not improve from 0.81138
Epoch 00038: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 651s 4ms/step - loss: 0.8119 - accuracy: 0.6517
Testing Loss = 0.811873, Testing Accuracy = 0.651673
The data set contains images
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 65s 68ms/step - loss: 3.0677 - accuracy: 0.5667 - val_loss: 1.0082 - val_accuracy: 0.6139

Epoch 00001: val_loss improved from inf to 1.00815, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.9240 - accuracy: 0.6120 - val_loss: 0.8800 - val_accuracy: 0.6187

Epoch 00002: val_loss improved from 1.00815 to 0.88003, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 3/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8816 - accuracy: 0.6159 - val_loss: 0.8657 - val_accuracy: 0.6230

Epoch 00003: val_loss improved from 0.88003 to 0.86569, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 4/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8712 - accuracy: 0.6194 - val_loss: 0.8575 - val_accuracy: 0.6265

Epoch 00004: val_loss improved from 0.86569 to 0.85752, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 5/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8631 - accuracy: 0.6245 - val_loss: 0.8489 - val_accuracy: 0.6327

Epoch 00005: val_loss improved from 0.85752 to 0.84894, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8540 - accuracy: 0.6306 - val_loss: 0.8383 - val_accuracy: 0.6396

Epoch 00006: val_loss improved from 0.84894 to 0.83825, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8467 - accuracy: 0.6356 - val_loss: 0.8296 - val_accuracy: 0.6444

Epoch 00007: val_loss improved from 0.83825 to 0.82963, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8417 - accuracy: 0.6388 - val_loss: 0.8256 - val_accuracy: 0.6462

Epoch 00008: val_loss improved from 0.82963 to 0.82558, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 9/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8377 - accuracy: 0.6404 - val_loss: 0.8237 - val_accuracy: 0.6473

Epoch 00009: val_loss improved from 0.82558 to 0.82370, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8346 - accuracy: 0.6423 - val_loss: 0.8216 - val_accuracy: 0.6481

Epoch 00010: val_loss improved from 0.82370 to 0.82159, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8318 - accuracy: 0.6439 - val_loss: 0.8206 - val_accuracy: 0.6481

Epoch 00011: val_loss improved from 0.82159 to 0.82061, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8297 - accuracy: 0.6450 - val_loss: 0.8200 - val_accuracy: 0.6485

Epoch 00012: val_loss improved from 0.82061 to 0.82002, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8277 - accuracy: 0.6456 - val_loss: 0.8169 - val_accuracy: 0.6502

Epoch 00013: val_loss improved from 0.82002 to 0.81693, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8258 - accuracy: 0.6475 - val_loss: 0.8148 - val_accuracy: 0.6511

Epoch 00014: val_loss improved from 0.81693 to 0.81480, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8240 - accuracy: 0.6480 - val_loss: 0.8136 - val_accuracy: 0.6515

Epoch 00015: val_loss improved from 0.81480 to 0.81360, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8217 - accuracy: 0.6496 - val_loss: 0.8135 - val_accuracy: 0.6514

Epoch 00016: val_loss improved from 0.81360 to 0.81355, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8206 - accuracy: 0.6501 - val_loss: 0.8120 - val_accuracy: 0.6520

Epoch 00017: val_loss improved from 0.81355 to 0.81202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 18/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8191 - accuracy: 0.6514 - val_loss: 0.8139 - val_accuracy: 0.6510

Epoch 00018: val_loss did not improve from 0.81202
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8180 - accuracy: 0.6520 - val_loss: 0.8121 - val_accuracy: 0.6524

Epoch 00019: val_loss did not improve from 0.81202
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8170 - accuracy: 0.6528 - val_loss: 0.8108 - val_accuracy: 0.6514

Epoch 00020: val_loss improved from 0.81202 to 0.81079, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 21/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8150 - accuracy: 0.6538 - val_loss: 0.8098 - val_accuracy: 0.6525

Epoch 00021: val_loss improved from 0.81079 to 0.80980, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8140 - accuracy: 0.6545 - val_loss: 0.8116 - val_accuracy: 0.6514

Epoch 00022: val_loss did not improve from 0.80980
Epoch 23/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8131 - accuracy: 0.6549 - val_loss: 0.8097 - val_accuracy: 0.6531

Epoch 00023: val_loss improved from 0.80980 to 0.80968, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 24/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8118 - accuracy: 0.6558 - val_loss: 0.8100 - val_accuracy: 0.6528

Epoch 00024: val_loss did not improve from 0.80968
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8108 - accuracy: 0.6562 - val_loss: 0.8109 - val_accuracy: 0.6520

Epoch 00025: val_loss did not improve from 0.80968
Epoch 26/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8091 - accuracy: 0.6573 - val_loss: 0.8106 - val_accuracy: 0.6522

Epoch 00026: val_loss did not improve from 0.80968
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8088 - accuracy: 0.6578 - val_loss: 0.8157 - val_accuracy: 0.6492

Epoch 00027: val_loss did not improve from 0.80968
Epoch 28/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8069 - accuracy: 0.6590 - val_loss: 0.8083 - val_accuracy: 0.6537

Epoch 00028: val_loss improved from 0.80968 to 0.80831, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8060 - accuracy: 0.6596 - val_loss: 0.8121 - val_accuracy: 0.6514

Epoch 00029: val_loss did not improve from 0.80831
Epoch 30/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8044 - accuracy: 0.6609 - val_loss: 0.8113 - val_accuracy: 0.6517

Epoch 00030: val_loss did not improve from 0.80831
Epoch 31/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8040 - accuracy: 0.6618 - val_loss: 0.8151 - val_accuracy: 0.6489

Epoch 00031: val_loss did not improve from 0.80831
Epoch 32/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8030 - accuracy: 0.6622 - val_loss: 0.8141 - val_accuracy: 0.6502

Epoch 00032: val_loss did not improve from 0.80831
Epoch 33/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8008 - accuracy: 0.6633 - val_loss: 0.8127 - val_accuracy: 0.6512

Epoch 00033: val_loss did not improve from 0.80831
Epoch 34/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7998 - accuracy: 0.6648 - val_loss: 0.8172 - val_accuracy: 0.6485

Epoch 00034: val_loss did not improve from 0.80831
Epoch 35/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7991 - accuracy: 0.6649 - val_loss: 0.8239 - val_accuracy: 0.6433

Epoch 00035: val_loss did not improve from 0.80831
Epoch 36/100
937/937 [==============================] - 65s 69ms/step - loss: 0.7966 - accuracy: 0.6669 - val_loss: 0.8148 - val_accuracy: 0.6502

Epoch 00036: val_loss did not improve from 0.80831
Epoch 37/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7953 - accuracy: 0.6678 - val_loss: 0.8130 - val_accuracy: 0.6511

Epoch 00037: val_loss did not improve from 0.80831
Epoch 38/100
937/937 [==============================] - 64s 69ms/step - loss: 0.7939 - accuracy: 0.6692 - val_loss: 0.8211 - val_accuracy: 0.6458

Epoch 00038: val_loss did not improve from 0.80831
Epoch 00038: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 674s 4ms/step - loss: 0.8091 - accuracy: 0.6533
Testing Loss = 0.809122, Testing Accuracy = 0.653287
The data set contains images
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 65s 69ms/step - loss: 3.0918 - accuracy: 0.5693 - val_loss: 1.0091 - val_accuracy: 0.6140

Epoch 00001: val_loss improved from inf to 1.00908, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.9236 - accuracy: 0.6116 - val_loss: 0.8773 - val_accuracy: 0.6200

Epoch 00002: val_loss improved from 1.00908 to 0.87729, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8811 - accuracy: 0.6170 - val_loss: 0.8670 - val_accuracy: 0.6228

Epoch 00003: val_loss improved from 0.87729 to 0.86700, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 4/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8702 - accuracy: 0.6214 - val_loss: 0.8562 - val_accuracy: 0.6283

Epoch 00004: val_loss improved from 0.86700 to 0.85619, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 5/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8612 - accuracy: 0.6270 - val_loss: 0.8477 - val_accuracy: 0.6336

Epoch 00005: val_loss improved from 0.85619 to 0.84766, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8532 - accuracy: 0.6317 - val_loss: 0.8368 - val_accuracy: 0.6420

Epoch 00006: val_loss improved from 0.84766 to 0.83681, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8456 - accuracy: 0.6368 - val_loss: 0.8318 - val_accuracy: 0.6442

Epoch 00007: val_loss improved from 0.83681 to 0.83180, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 8/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8406 - accuracy: 0.6400 - val_loss: 0.8262 - val_accuracy: 0.6465

Epoch 00008: val_loss improved from 0.83180 to 0.82619, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 9/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8365 - accuracy: 0.6422 - val_loss: 0.8237 - val_accuracy: 0.6475

Epoch 00009: val_loss improved from 0.82619 to 0.82372, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8338 - accuracy: 0.6434 - val_loss: 0.8195 - val_accuracy: 0.6492

Epoch 00010: val_loss improved from 0.82372 to 0.81950, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8308 - accuracy: 0.6454 - val_loss: 0.8207 - val_accuracy: 0.6492

Epoch 00011: val_loss did not improve from 0.81950
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8288 - accuracy: 0.6460 - val_loss: 0.8181 - val_accuracy: 0.6493

Epoch 00012: val_loss improved from 0.81950 to 0.81813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8267 - accuracy: 0.6472 - val_loss: 0.8174 - val_accuracy: 0.6502

Epoch 00013: val_loss improved from 0.81813 to 0.81737, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 14/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8251 - accuracy: 0.6477 - val_loss: 0.8153 - val_accuracy: 0.6509

Epoch 00014: val_loss improved from 0.81737 to 0.81535, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8235 - accuracy: 0.6487 - val_loss: 0.8143 - val_accuracy: 0.6516

Epoch 00015: val_loss improved from 0.81535 to 0.81427, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 16/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8217 - accuracy: 0.6502 - val_loss: 0.8127 - val_accuracy: 0.6532

Epoch 00016: val_loss improved from 0.81427 to 0.81274, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 17/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8202 - accuracy: 0.6508 - val_loss: 0.8123 - val_accuracy: 0.6525

Epoch 00017: val_loss improved from 0.81274 to 0.81234, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 18/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8190 - accuracy: 0.6518 - val_loss: 0.8117 - val_accuracy: 0.6528

Epoch 00018: val_loss improved from 0.81234 to 0.81175, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 19/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8177 - accuracy: 0.6522 - val_loss: 0.8199 - val_accuracy: 0.6472

Epoch 00019: val_loss did not improve from 0.81175
Epoch 20/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8159 - accuracy: 0.6538 - val_loss: 0.8103 - val_accuracy: 0.6536

Epoch 00020: val_loss improved from 0.81175 to 0.81028, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8148 - accuracy: 0.6544 - val_loss: 0.8148 - val_accuracy: 0.6506

Epoch 00021: val_loss did not improve from 0.81028
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8141 - accuracy: 0.6543 - val_loss: 0.8202 - val_accuracy: 0.6462

Epoch 00022: val_loss did not improve from 0.81028
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8129 - accuracy: 0.6552 - val_loss: 0.8144 - val_accuracy: 0.6504

Epoch 00023: val_loss did not improve from 0.81028
Epoch 24/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8113 - accuracy: 0.6561 - val_loss: 0.8174 - val_accuracy: 0.6479

Epoch 00024: val_loss did not improve from 0.81028
Epoch 25/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8100 - accuracy: 0.6570 - val_loss: 0.8128 - val_accuracy: 0.6515

Epoch 00025: val_loss did not improve from 0.81028
Epoch 26/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8086 - accuracy: 0.6583 - val_loss: 0.8157 - val_accuracy: 0.6491

Epoch 00026: val_loss did not improve from 0.81028
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8076 - accuracy: 0.6584 - val_loss: 0.8143 - val_accuracy: 0.6494

Epoch 00027: val_loss did not improve from 0.81028
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8065 - accuracy: 0.6597 - val_loss: 0.8204 - val_accuracy: 0.6452

Epoch 00028: val_loss did not improve from 0.81028
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8053 - accuracy: 0.6606 - val_loss: 0.8173 - val_accuracy: 0.6481

Epoch 00029: val_loss did not improve from 0.81028
Epoch 30/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8033 - accuracy: 0.6618 - val_loss: 0.8146 - val_accuracy: 0.6504

Epoch 00030: val_loss did not improve from 0.81028
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 679s 5ms/step - loss: 0.8107 - accuracy: 0.6530
Testing Loss = 0.810668, Testing Accuracy = 0.652980
The data set contains images
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 64s 68ms/step - loss: 3.0548 - accuracy: 0.5707 - val_loss: 1.0076 - val_accuracy: 0.6125

Epoch 00001: val_loss improved from inf to 1.00762, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.9238 - accuracy: 0.6113 - val_loss: 0.8785 - val_accuracy: 0.6192

Epoch 00002: val_loss improved from 1.00762 to 0.87851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8827 - accuracy: 0.6156 - val_loss: 0.8694 - val_accuracy: 0.6204

Epoch 00003: val_loss improved from 0.87851 to 0.86937, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 4/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8731 - accuracy: 0.6187 - val_loss: 0.8623 - val_accuracy: 0.6237

Epoch 00004: val_loss improved from 0.86937 to 0.86233, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 5/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8655 - accuracy: 0.6227 - val_loss: 0.8517 - val_accuracy: 0.6298

Epoch 00005: val_loss improved from 0.86233 to 0.85175, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8583 - accuracy: 0.6271 - val_loss: 0.8442 - val_accuracy: 0.6344

Epoch 00006: val_loss improved from 0.85175 to 0.84424, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8502 - accuracy: 0.6331 - val_loss: 0.8355 - val_accuracy: 0.6407

Epoch 00007: val_loss improved from 0.84424 to 0.83548, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 8/100
937/937 [==============================] - 65s 70ms/step - loss: 0.8439 - accuracy: 0.6365 - val_loss: 0.8288 - val_accuracy: 0.6448

Epoch 00008: val_loss improved from 0.83548 to 0.82877, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 9/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8386 - accuracy: 0.6404 - val_loss: 0.8248 - val_accuracy: 0.6467

Epoch 00009: val_loss improved from 0.82877 to 0.82482, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8356 - accuracy: 0.6415 - val_loss: 0.8202 - val_accuracy: 0.6485

Epoch 00010: val_loss improved from 0.82482 to 0.82021, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8326 - accuracy: 0.6435 - val_loss: 0.8190 - val_accuracy: 0.6490

Epoch 00011: val_loss improved from 0.82021 to 0.81900, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8302 - accuracy: 0.6447 - val_loss: 0.8179 - val_accuracy: 0.6495

Epoch 00012: val_loss improved from 0.81900 to 0.81790, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 13/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8277 - accuracy: 0.6462 - val_loss: 0.8184 - val_accuracy: 0.6486

Epoch 00013: val_loss did not improve from 0.81790
Epoch 14/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8254 - accuracy: 0.6472 - val_loss: 0.8146 - val_accuracy: 0.6517

Epoch 00014: val_loss improved from 0.81790 to 0.81462, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8243 - accuracy: 0.6480 - val_loss: 0.8170 - val_accuracy: 0.6498

Epoch 00015: val_loss did not improve from 0.81462
Epoch 16/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8225 - accuracy: 0.6493 - val_loss: 0.8130 - val_accuracy: 0.6519

Epoch 00016: val_loss improved from 0.81462 to 0.81296, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 17/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8211 - accuracy: 0.6499 - val_loss: 0.8129 - val_accuracy: 0.6526

Epoch 00017: val_loss improved from 0.81296 to 0.81295, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 18/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8196 - accuracy: 0.6507 - val_loss: 0.8138 - val_accuracy: 0.6507

Epoch 00018: val_loss did not improve from 0.81295
Epoch 19/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8186 - accuracy: 0.6515 - val_loss: 0.8110 - val_accuracy: 0.6530

Epoch 00019: val_loss improved from 0.81295 to 0.81100, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8169 - accuracy: 0.6525 - val_loss: 0.8115 - val_accuracy: 0.6526

Epoch 00020: val_loss did not improve from 0.81100
Epoch 21/100
937/937 [==============================] - 65s 69ms/step - loss: 0.8159 - accuracy: 0.6532 - val_loss: 0.8106 - val_accuracy: 0.6536

Epoch 00021: val_loss improved from 0.81100 to 0.81061, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8153 - accuracy: 0.6531 - val_loss: 0.8145 - val_accuracy: 0.6505

Epoch 00022: val_loss did not improve from 0.81061
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8133 - accuracy: 0.6542 - val_loss: 0.8107 - val_accuracy: 0.6527

Epoch 00023: val_loss did not improve from 0.81061
Epoch 24/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8134 - accuracy: 0.6545 - val_loss: 0.8117 - val_accuracy: 0.6515

Epoch 00024: val_loss did not improve from 0.81061
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8112 - accuracy: 0.6561 - val_loss: 0.8134 - val_accuracy: 0.6508

Epoch 00025: val_loss did not improve from 0.81061
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8102 - accuracy: 0.6565 - val_loss: 0.8115 - val_accuracy: 0.6530

Epoch 00026: val_loss did not improve from 0.81061
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8094 - accuracy: 0.6573 - val_loss: 0.8121 - val_accuracy: 0.6520

Epoch 00027: val_loss did not improve from 0.81061
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8085 - accuracy: 0.6582 - val_loss: 0.8124 - val_accuracy: 0.6510

Epoch 00028: val_loss did not improve from 0.81061
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8075 - accuracy: 0.6586 - val_loss: 0.8132 - val_accuracy: 0.6507

Epoch 00029: val_loss did not improve from 0.81061
Epoch 30/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8059 - accuracy: 0.6600 - val_loss: 0.8108 - val_accuracy: 0.6530

Epoch 00030: val_loss did not improve from 0.81061
Epoch 31/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8049 - accuracy: 0.6611 - val_loss: 0.8134 - val_accuracy: 0.6512

Epoch 00031: val_loss did not improve from 0.81061
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 676s 5ms/step - loss: 0.8104 - accuracy: 0.6533
Testing Loss = 0.810400, Testing Accuracy = 0.653333
The data set contains images
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 65s 68ms/step - loss: 3.0289 - accuracy: 0.5741 - val_loss: 1.0098 - val_accuracy: 0.6095

Epoch 00001: val_loss improved from inf to 1.00982, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.9233 - accuracy: 0.6116 - val_loss: 0.8788 - val_accuracy: 0.6185

Epoch 00002: val_loss improved from 1.00982 to 0.87881, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8820 - accuracy: 0.6167 - val_loss: 0.8664 - val_accuracy: 0.6221

Epoch 00003: val_loss improved from 0.87881 to 0.86636, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 4/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8702 - accuracy: 0.6220 - val_loss: 0.8569 - val_accuracy: 0.6288

Epoch 00004: val_loss improved from 0.86636 to 0.85687, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 5/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8599 - accuracy: 0.6287 - val_loss: 0.8460 - val_accuracy: 0.6369

Epoch 00005: val_loss improved from 0.85687 to 0.84595, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8509 - accuracy: 0.6343 - val_loss: 0.8399 - val_accuracy: 0.6403

Epoch 00006: val_loss improved from 0.84595 to 0.83993, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8443 - accuracy: 0.6382 - val_loss: 0.8291 - val_accuracy: 0.6451

Epoch 00007: val_loss improved from 0.83993 to 0.82914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8399 - accuracy: 0.6405 - val_loss: 0.8255 - val_accuracy: 0.6468

Epoch 00008: val_loss improved from 0.82914 to 0.82548, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 9/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8358 - accuracy: 0.6420 - val_loss: 0.8224 - val_accuracy: 0.6485

Epoch 00009: val_loss improved from 0.82548 to 0.82241, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8325 - accuracy: 0.6446 - val_loss: 0.8210 - val_accuracy: 0.6483

Epoch 00010: val_loss improved from 0.82241 to 0.82102, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8304 - accuracy: 0.6450 - val_loss: 0.8204 - val_accuracy: 0.6487

Epoch 00011: val_loss improved from 0.82102 to 0.82040, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 12/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8281 - accuracy: 0.6467 - val_loss: 0.8187 - val_accuracy: 0.6489

Epoch 00012: val_loss improved from 0.82040 to 0.81867, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8259 - accuracy: 0.6479 - val_loss: 0.8152 - val_accuracy: 0.6511

Epoch 00013: val_loss improved from 0.81867 to 0.81521, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8249 - accuracy: 0.6481 - val_loss: 0.8144 - val_accuracy: 0.6512

Epoch 00014: val_loss improved from 0.81521 to 0.81442, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8228 - accuracy: 0.6495 - val_loss: 0.8138 - val_accuracy: 0.6519

Epoch 00015: val_loss improved from 0.81442 to 0.81376, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 16/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8208 - accuracy: 0.6501 - val_loss: 0.8130 - val_accuracy: 0.6524

Epoch 00016: val_loss improved from 0.81376 to 0.81303, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8192 - accuracy: 0.6519 - val_loss: 0.8136 - val_accuracy: 0.6512

Epoch 00017: val_loss did not improve from 0.81303
Epoch 18/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8173 - accuracy: 0.6531 - val_loss: 0.8112 - val_accuracy: 0.6533

Epoch 00018: val_loss improved from 0.81303 to 0.81115, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8162 - accuracy: 0.6535 - val_loss: 0.8112 - val_accuracy: 0.6550

Epoch 00019: val_loss did not improve from 0.81115
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8146 - accuracy: 0.6548 - val_loss: 0.8103 - val_accuracy: 0.6536

Epoch 00020: val_loss improved from 0.81115 to 0.81035, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8133 - accuracy: 0.6556 - val_loss: 0.8086 - val_accuracy: 0.6543

Epoch 00021: val_loss improved from 0.81035 to 0.80862, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8116 - accuracy: 0.6569 - val_loss: 0.8090 - val_accuracy: 0.6567

Epoch 00022: val_loss did not improve from 0.80862
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8099 - accuracy: 0.6576 - val_loss: 0.8079 - val_accuracy: 0.6567

Epoch 00023: val_loss improved from 0.80862 to 0.80792, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 24/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8089 - accuracy: 0.6585 - val_loss: 0.8091 - val_accuracy: 0.6562

Epoch 00024: val_loss did not improve from 0.80792
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8073 - accuracy: 0.6597 - val_loss: 0.8074 - val_accuracy: 0.6574

Epoch 00025: val_loss improved from 0.80792 to 0.80742, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8063 - accuracy: 0.6605 - val_loss: 0.8091 - val_accuracy: 0.6559

Epoch 00026: val_loss did not improve from 0.80742
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8047 - accuracy: 0.6617 - val_loss: 0.8081 - val_accuracy: 0.6567

Epoch 00027: val_loss did not improve from 0.80742
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8035 - accuracy: 0.6622 - val_loss: 0.8090 - val_accuracy: 0.6568

Epoch 00028: val_loss did not improve from 0.80742
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8019 - accuracy: 0.6633 - val_loss: 0.8099 - val_accuracy: 0.6555

Epoch 00029: val_loss did not improve from 0.80742
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8004 - accuracy: 0.6652 - val_loss: 0.8094 - val_accuracy: 0.6558

Epoch 00030: val_loss did not improve from 0.80742
Epoch 31/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7993 - accuracy: 0.6655 - val_loss: 0.8102 - val_accuracy: 0.6558

Epoch 00031: val_loss did not improve from 0.80742
Epoch 32/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7971 - accuracy: 0.6669 - val_loss: 0.8131 - val_accuracy: 0.6531

Epoch 00032: val_loss did not improve from 0.80742
Epoch 33/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7957 - accuracy: 0.6684 - val_loss: 0.8150 - val_accuracy: 0.6527

Epoch 00033: val_loss did not improve from 0.80742
Epoch 34/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7941 - accuracy: 0.6695 - val_loss: 0.8150 - val_accuracy: 0.6530

Epoch 00034: val_loss did not improve from 0.80742
Epoch 35/100
937/937 [==============================] - 63s 68ms/step - loss: 0.7932 - accuracy: 0.6704 - val_loss: 0.8157 - val_accuracy: 0.6524

Epoch 00035: val_loss did not improve from 0.80742
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 674s 4ms/step - loss: 0.8080 - accuracy: 0.6567
Testing Loss = 0.808048, Testing Accuracy = 0.656687
The data set contains images
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 65s 68ms/step - loss: 3.1055 - accuracy: 0.5699 - val_loss: 1.0138 - val_accuracy: 0.6123

Epoch 00001: val_loss improved from inf to 1.01382, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.9258 - accuracy: 0.6109 - val_loss: 0.8797 - val_accuracy: 0.6178

Epoch 00002: val_loss improved from 1.01382 to 0.87967, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8824 - accuracy: 0.6157 - val_loss: 0.8691 - val_accuracy: 0.6202

Epoch 00003: val_loss improved from 0.87967 to 0.86912, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 4/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8714 - accuracy: 0.6205 - val_loss: 0.8570 - val_accuracy: 0.6269

Epoch 00004: val_loss improved from 0.86912 to 0.85697, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 5/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8627 - accuracy: 0.6255 - val_loss: 0.8496 - val_accuracy: 0.6325

Epoch 00005: val_loss improved from 0.85697 to 0.84961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 6/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8541 - accuracy: 0.6309 - val_loss: 0.8376 - val_accuracy: 0.6403

Epoch 00006: val_loss improved from 0.84961 to 0.83764, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8467 - accuracy: 0.6364 - val_loss: 0.8309 - val_accuracy: 0.6443

Epoch 00007: val_loss improved from 0.83764 to 0.83087, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8423 - accuracy: 0.6381 - val_loss: 0.8266 - val_accuracy: 0.6461

Epoch 00008: val_loss improved from 0.83087 to 0.82660, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 9/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8382 - accuracy: 0.6404 - val_loss: 0.8231 - val_accuracy: 0.6474

Epoch 00009: val_loss improved from 0.82660 to 0.82309, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8351 - accuracy: 0.6422 - val_loss: 0.8208 - val_accuracy: 0.6486

Epoch 00010: val_loss improved from 0.82309 to 0.82080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 11/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8323 - accuracy: 0.6442 - val_loss: 0.8214 - val_accuracy: 0.6480

Epoch 00011: val_loss did not improve from 0.82080
Epoch 12/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8299 - accuracy: 0.6454 - val_loss: 0.8209 - val_accuracy: 0.6482

Epoch 00012: val_loss did not improve from 0.82080
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8280 - accuracy: 0.6463 - val_loss: 0.8191 - val_accuracy: 0.6491

Epoch 00013: val_loss improved from 0.82080 to 0.81905, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 14/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8256 - accuracy: 0.6485 - val_loss: 0.8151 - val_accuracy: 0.6522

Epoch 00014: val_loss improved from 0.81905 to 0.81510, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 15/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8244 - accuracy: 0.6486 - val_loss: 0.8169 - val_accuracy: 0.6501

Epoch 00015: val_loss did not improve from 0.81510
Epoch 16/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8227 - accuracy: 0.6498 - val_loss: 0.8147 - val_accuracy: 0.6509

Epoch 00016: val_loss improved from 0.81510 to 0.81466, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 17/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8212 - accuracy: 0.6504 - val_loss: 0.8143 - val_accuracy: 0.6509

Epoch 00017: val_loss improved from 0.81466 to 0.81431, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 18/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8190 - accuracy: 0.6521 - val_loss: 0.8125 - val_accuracy: 0.6525

Epoch 00018: val_loss improved from 0.81431 to 0.81247, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 19/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8176 - accuracy: 0.6529 - val_loss: 0.8147 - val_accuracy: 0.6516

Epoch 00019: val_loss did not improve from 0.81247
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8164 - accuracy: 0.6530 - val_loss: 0.8156 - val_accuracy: 0.6501

Epoch 00020: val_loss did not improve from 0.81247
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8150 - accuracy: 0.6546 - val_loss: 0.8104 - val_accuracy: 0.6538

Epoch 00021: val_loss improved from 0.81247 to 0.81045, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 22/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8135 - accuracy: 0.6546 - val_loss: 0.8112 - val_accuracy: 0.6529

Epoch 00022: val_loss did not improve from 0.81045
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8124 - accuracy: 0.6556 - val_loss: 0.8103 - val_accuracy: 0.6540

Epoch 00023: val_loss improved from 0.81045 to 0.81030, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 24/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8117 - accuracy: 0.6563 - val_loss: 0.8109 - val_accuracy: 0.6541

Epoch 00024: val_loss did not improve from 0.81030
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8098 - accuracy: 0.6579 - val_loss: 0.8122 - val_accuracy: 0.6526

Epoch 00025: val_loss did not improve from 0.81030
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8094 - accuracy: 0.6579 - val_loss: 0.8107 - val_accuracy: 0.6534

Epoch 00026: val_loss did not improve from 0.81030
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8078 - accuracy: 0.6598 - val_loss: 0.8114 - val_accuracy: 0.6525

Epoch 00027: val_loss did not improve from 0.81030
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8076 - accuracy: 0.6590 - val_loss: 0.8149 - val_accuracy: 0.6508

Epoch 00028: val_loss did not improve from 0.81030
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8058 - accuracy: 0.6607 - val_loss: 0.8123 - val_accuracy: 0.6522

Epoch 00029: val_loss did not improve from 0.81030
Epoch 30/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8036 - accuracy: 0.6618 - val_loss: 0.8121 - val_accuracy: 0.6524

Epoch 00030: val_loss did not improve from 0.81030
Epoch 31/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8024 - accuracy: 0.6631 - val_loss: 0.8113 - val_accuracy: 0.6535

Epoch 00031: val_loss did not improve from 0.81030
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 677s 5ms/step - loss: 0.8105 - accuracy: 0.6525
Testing Loss = 0.810458, Testing Accuracy = 0.652500
The data set contains images
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 64s 68ms/step - loss: 3.0636 - accuracy: 0.5714 - val_loss: 1.0090 - val_accuracy: 0.6107

Epoch 00001: val_loss improved from inf to 1.00896, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.9229 - accuracy: 0.6105 - val_loss: 0.8791 - val_accuracy: 0.6183

Epoch 00002: val_loss improved from 1.00896 to 0.87911, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8827 - accuracy: 0.6162 - val_loss: 0.8692 - val_accuracy: 0.6211

Epoch 00003: val_loss improved from 0.87911 to 0.86917, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 4/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8731 - accuracy: 0.6195 - val_loss: 0.8585 - val_accuracy: 0.6263

Epoch 00004: val_loss improved from 0.86917 to 0.85849, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 5/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8647 - accuracy: 0.6239 - val_loss: 0.8516 - val_accuracy: 0.6304

Epoch 00005: val_loss improved from 0.85849 to 0.85156, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8566 - accuracy: 0.6290 - val_loss: 0.8478 - val_accuracy: 0.6342

Epoch 00006: val_loss improved from 0.85156 to 0.84785, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 7/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8491 - accuracy: 0.6347 - val_loss: 0.8328 - val_accuracy: 0.6423

Epoch 00007: val_loss improved from 0.84785 to 0.83280, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8428 - accuracy: 0.6383 - val_loss: 0.8274 - val_accuracy: 0.6457

Epoch 00008: val_loss improved from 0.83280 to 0.82736, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 9/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8382 - accuracy: 0.6405 - val_loss: 0.8245 - val_accuracy: 0.6475

Epoch 00009: val_loss improved from 0.82736 to 0.82454, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8344 - accuracy: 0.6429 - val_loss: 0.8224 - val_accuracy: 0.6480

Epoch 00010: val_loss improved from 0.82454 to 0.82240, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 11/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8323 - accuracy: 0.6438 - val_loss: 0.8222 - val_accuracy: 0.6475

Epoch 00011: val_loss improved from 0.82240 to 0.82223, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 12/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8301 - accuracy: 0.6448 - val_loss: 0.8208 - val_accuracy: 0.6481

Epoch 00012: val_loss improved from 0.82223 to 0.82079, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 13/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8282 - accuracy: 0.6459 - val_loss: 0.8206 - val_accuracy: 0.6475

Epoch 00013: val_loss improved from 0.82079 to 0.82056, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8259 - accuracy: 0.6480 - val_loss: 0.8174 - val_accuracy: 0.6488

Epoch 00014: val_loss improved from 0.82056 to 0.81745, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 15/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8246 - accuracy: 0.6481 - val_loss: 0.8139 - val_accuracy: 0.6517

Epoch 00015: val_loss improved from 0.81745 to 0.81391, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 16/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8224 - accuracy: 0.6493 - val_loss: 0.8151 - val_accuracy: 0.6505

Epoch 00016: val_loss did not improve from 0.81391
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8212 - accuracy: 0.6508 - val_loss: 0.8130 - val_accuracy: 0.6520

Epoch 00017: val_loss improved from 0.81391 to 0.81297, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 18/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8200 - accuracy: 0.6510 - val_loss: 0.8148 - val_accuracy: 0.6501

Epoch 00018: val_loss did not improve from 0.81297
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8181 - accuracy: 0.6520 - val_loss: 0.8128 - val_accuracy: 0.6517

Epoch 00019: val_loss improved from 0.81297 to 0.81281, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8167 - accuracy: 0.6529 - val_loss: 0.8120 - val_accuracy: 0.6526

Epoch 00020: val_loss improved from 0.81281 to 0.81200, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 21/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8159 - accuracy: 0.6536 - val_loss: 0.8156 - val_accuracy: 0.6494

Epoch 00021: val_loss did not improve from 0.81200
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8140 - accuracy: 0.6550 - val_loss: 0.8131 - val_accuracy: 0.6510

Epoch 00022: val_loss did not improve from 0.81200
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8122 - accuracy: 0.6561 - val_loss: 0.8113 - val_accuracy: 0.6524

Epoch 00023: val_loss improved from 0.81200 to 0.81131, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 24/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8112 - accuracy: 0.6571 - val_loss: 0.8155 - val_accuracy: 0.6495

Epoch 00024: val_loss did not improve from 0.81131
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8106 - accuracy: 0.6569 - val_loss: 0.8189 - val_accuracy: 0.6473

Epoch 00025: val_loss did not improve from 0.81131
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8086 - accuracy: 0.6587 - val_loss: 0.8169 - val_accuracy: 0.6481

Epoch 00026: val_loss did not improve from 0.81131
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8077 - accuracy: 0.6592 - val_loss: 0.8207 - val_accuracy: 0.6461

Epoch 00027: val_loss did not improve from 0.81131
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8064 - accuracy: 0.6599 - val_loss: 0.8132 - val_accuracy: 0.6511

Epoch 00028: val_loss did not improve from 0.81131
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8048 - accuracy: 0.6615 - val_loss: 0.8181 - val_accuracy: 0.6483

Epoch 00029: val_loss did not improve from 0.81131
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8030 - accuracy: 0.6624 - val_loss: 0.8175 - val_accuracy: 0.6481

Epoch 00030: val_loss did not improve from 0.81131
Epoch 31/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8022 - accuracy: 0.6630 - val_loss: 0.8167 - val_accuracy: 0.6493

Epoch 00031: val_loss did not improve from 0.81131
Epoch 32/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8005 - accuracy: 0.6648 - val_loss: 0.8288 - val_accuracy: 0.6410

Epoch 00032: val_loss did not improve from 0.81131
Epoch 33/100
937/937 [==============================] - 64s 68ms/step - loss: 0.7989 - accuracy: 0.6653 - val_loss: 0.8152 - val_accuracy: 0.6500

Epoch 00033: val_loss did not improve from 0.81131
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 670s 4ms/step - loss: 0.8119 - accuracy: 0.6524
Testing Loss = 0.811886, Testing Accuracy = 0.652427
The data set contains images
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 64s 68ms/step - loss: 3.0375 - accuracy: 0.5768 - val_loss: 1.0107 - val_accuracy: 0.6127

Epoch 00001: val_loss improved from inf to 1.01070, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.9257 - accuracy: 0.6115 - val_loss: 0.8826 - val_accuracy: 0.6176

Epoch 00002: val_loss improved from 1.01070 to 0.88262, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 3/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8829 - accuracy: 0.6166 - val_loss: 0.8675 - val_accuracy: 0.6224

Epoch 00003: val_loss improved from 0.88262 to 0.86751, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 4/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8720 - accuracy: 0.6217 - val_loss: 0.8579 - val_accuracy: 0.6276

Epoch 00004: val_loss improved from 0.86751 to 0.85790, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 5/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8636 - accuracy: 0.6254 - val_loss: 0.8513 - val_accuracy: 0.6312

Epoch 00005: val_loss improved from 0.85790 to 0.85132, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8553 - accuracy: 0.6309 - val_loss: 0.8394 - val_accuracy: 0.6389

Epoch 00006: val_loss improved from 0.85132 to 0.83940, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8483 - accuracy: 0.6349 - val_loss: 0.8350 - val_accuracy: 0.6420

Epoch 00007: val_loss improved from 0.83940 to 0.83499, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8432 - accuracy: 0.6381 - val_loss: 0.8280 - val_accuracy: 0.6455

Epoch 00008: val_loss improved from 0.83499 to 0.82800, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 9/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8391 - accuracy: 0.6407 - val_loss: 0.8283 - val_accuracy: 0.6445

Epoch 00009: val_loss did not improve from 0.82800
Epoch 10/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8353 - accuracy: 0.6422 - val_loss: 0.8254 - val_accuracy: 0.6456

Epoch 00010: val_loss improved from 0.82800 to 0.82544, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 11/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8324 - accuracy: 0.6439 - val_loss: 0.8239 - val_accuracy: 0.6460

Epoch 00011: val_loss improved from 0.82544 to 0.82388, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 12/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8305 - accuracy: 0.6452 - val_loss: 0.8204 - val_accuracy: 0.6485

Epoch 00012: val_loss improved from 0.82388 to 0.82044, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8280 - accuracy: 0.6460 - val_loss: 0.8193 - val_accuracy: 0.6488

Epoch 00013: val_loss improved from 0.82044 to 0.81930, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8267 - accuracy: 0.6466 - val_loss: 0.8175 - val_accuracy: 0.6494

Epoch 00014: val_loss improved from 0.81930 to 0.81754, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8248 - accuracy: 0.6479 - val_loss: 0.8154 - val_accuracy: 0.6507

Epoch 00015: val_loss improved from 0.81754 to 0.81538, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8224 - accuracy: 0.6494 - val_loss: 0.8154 - val_accuracy: 0.6505

Epoch 00016: val_loss improved from 0.81538 to 0.81537, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8215 - accuracy: 0.6500 - val_loss: 0.8143 - val_accuracy: 0.6512

Epoch 00017: val_loss improved from 0.81537 to 0.81425, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 18/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8193 - accuracy: 0.6511 - val_loss: 0.8128 - val_accuracy: 0.6518

Epoch 00018: val_loss improved from 0.81425 to 0.81275, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8182 - accuracy: 0.6520 - val_loss: 0.8124 - val_accuracy: 0.6519

Epoch 00019: val_loss improved from 0.81275 to 0.81241, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8167 - accuracy: 0.6530 - val_loss: 0.8144 - val_accuracy: 0.6505

Epoch 00020: val_loss did not improve from 0.81241
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8151 - accuracy: 0.6540 - val_loss: 0.8119 - val_accuracy: 0.6526

Epoch 00021: val_loss improved from 0.81241 to 0.81187, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 22/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8138 - accuracy: 0.6550 - val_loss: 0.8117 - val_accuracy: 0.6530

Epoch 00022: val_loss improved from 0.81187 to 0.81174, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 23/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8120 - accuracy: 0.6568 - val_loss: 0.8120 - val_accuracy: 0.6517

Epoch 00023: val_loss did not improve from 0.81174
Epoch 24/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8099 - accuracy: 0.6579 - val_loss: 0.8146 - val_accuracy: 0.6512

Epoch 00024: val_loss did not improve from 0.81174
Epoch 25/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8096 - accuracy: 0.6577 - val_loss: 0.8137 - val_accuracy: 0.6513

Epoch 00025: val_loss did not improve from 0.81174
Epoch 26/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8081 - accuracy: 0.6586 - val_loss: 0.8128 - val_accuracy: 0.6519

Epoch 00026: val_loss did not improve from 0.81174
Epoch 27/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8068 - accuracy: 0.6601 - val_loss: 0.8121 - val_accuracy: 0.6526

Epoch 00027: val_loss did not improve from 0.81174
Epoch 28/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8049 - accuracy: 0.6613 - val_loss: 0.8154 - val_accuracy: 0.6505

Epoch 00028: val_loss did not improve from 0.81174
Epoch 29/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8040 - accuracy: 0.6623 - val_loss: 0.8160 - val_accuracy: 0.6510

Epoch 00029: val_loss did not improve from 0.81174
Epoch 30/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8026 - accuracy: 0.6629 - val_loss: 0.8161 - val_accuracy: 0.6501

Epoch 00030: val_loss did not improve from 0.81174
Epoch 31/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8011 - accuracy: 0.6646 - val_loss: 0.8177 - val_accuracy: 0.6495

Epoch 00031: val_loss did not improve from 0.81174
Epoch 00031: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 674s 4ms/step - loss: 0.8119 - accuracy: 0.6524
Testing Loss = 0.811916, Testing Accuracy = 0.652433
The data set contains images
The data set contains images
The data set contains images
Epoch 1/100
937/937 [==============================] - 65s 68ms/step - loss: 3.0592 - accuracy: 0.5699 - val_loss: 1.0089 - val_accuracy: 0.6123

Epoch 00001: val_loss improved from inf to 1.00892, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 2/100
937/937 [==============================] - 64s 68ms/step - loss: 0.9239 - accuracy: 0.6121 - val_loss: 0.8785 - val_accuracy: 0.6199

Epoch 00002: val_loss improved from 1.00892 to 0.87852, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 3/100
937/937 [==============================] - 64s 69ms/step - loss: 0.8819 - accuracy: 0.6170 - val_loss: 0.8684 - val_accuracy: 0.6225

Epoch 00003: val_loss improved from 0.87852 to 0.86840, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 4/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8710 - accuracy: 0.6217 - val_loss: 0.8583 - val_accuracy: 0.6278

Epoch 00004: val_loss improved from 0.86840 to 0.85826, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 5/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8620 - accuracy: 0.6266 - val_loss: 0.8503 - val_accuracy: 0.6321

Epoch 00005: val_loss improved from 0.85826 to 0.85033, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 6/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8537 - accuracy: 0.6325 - val_loss: 0.8414 - val_accuracy: 0.6379

Epoch 00006: val_loss improved from 0.85033 to 0.84144, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 7/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8473 - accuracy: 0.6361 - val_loss: 0.8342 - val_accuracy: 0.6419

Epoch 00007: val_loss improved from 0.84144 to 0.83421, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 8/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8416 - accuracy: 0.6390 - val_loss: 0.8284 - val_accuracy: 0.6457

Epoch 00008: val_loss improved from 0.83421 to 0.82844, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 9/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8373 - accuracy: 0.6417 - val_loss: 0.8258 - val_accuracy: 0.6474

Epoch 00009: val_loss improved from 0.82844 to 0.82583, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 10/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8339 - accuracy: 0.6440 - val_loss: 0.8250 - val_accuracy: 0.6462

Epoch 00010: val_loss improved from 0.82583 to 0.82495, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 11/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8322 - accuracy: 0.6440 - val_loss: 0.8209 - val_accuracy: 0.6481

Epoch 00011: val_loss improved from 0.82495 to 0.82091, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 12/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8298 - accuracy: 0.6457 - val_loss: 0.8181 - val_accuracy: 0.6499

Epoch 00012: val_loss improved from 0.82091 to 0.81807, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 13/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8275 - accuracy: 0.6465 - val_loss: 0.8214 - val_accuracy: 0.6467

Epoch 00013: val_loss did not improve from 0.81807
Epoch 14/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8254 - accuracy: 0.6484 - val_loss: 0.8156 - val_accuracy: 0.6512

Epoch 00014: val_loss improved from 0.81807 to 0.81565, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 15/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8235 - accuracy: 0.6494 - val_loss: 0.8198 - val_accuracy: 0.6485

Epoch 00015: val_loss did not improve from 0.81565
Epoch 16/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8219 - accuracy: 0.6501 - val_loss: 0.8128 - val_accuracy: 0.6531

Epoch 00016: val_loss improved from 0.81565 to 0.81285, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 17/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8209 - accuracy: 0.6513 - val_loss: 0.8145 - val_accuracy: 0.6514

Epoch 00017: val_loss did not improve from 0.81285
Epoch 18/100
937/937 [==============================] - 63s 68ms/step - loss: 0.8190 - accuracy: 0.6517 - val_loss: 0.8143 - val_accuracy: 0.6508

Epoch 00018: val_loss did not improve from 0.81285
Epoch 19/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8173 - accuracy: 0.6525 - val_loss: 0.8126 - val_accuracy: 0.6523

Epoch 00019: val_loss improved from 0.81285 to 0.81265, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 20/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8159 - accuracy: 0.6538 - val_loss: 0.8114 - val_accuracy: 0.6528

Epoch 00020: val_loss improved from 0.81265 to 0.81144, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 21/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8148 - accuracy: 0.6546 - val_loss: 0.8127 - val_accuracy: 0.6517

Epoch 00021: val_loss did not improve from 0.81144
Epoch 22/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8135 - accuracy: 0.6554 - val_loss: 0.8143 - val_accuracy: 0.6497

Epoch 00022: val_loss did not improve from 0.81144
Epoch 23/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8121 - accuracy: 0.6561 - val_loss: 0.8138 - val_accuracy: 0.6503

Epoch 00023: val_loss did not improve from 0.81144
Epoch 24/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8110 - accuracy: 0.6566 - val_loss: 0.8137 - val_accuracy: 0.6507

Epoch 00024: val_loss did not improve from 0.81144
Epoch 25/100
937/937 [==============================] - 63s 67ms/step - loss: 0.8095 - accuracy: 0.6576 - val_loss: 0.8121 - val_accuracy: 0.6522

Epoch 00025: val_loss did not improve from 0.81144
Epoch 26/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8078 - accuracy: 0.6589 - val_loss: 0.8113 - val_accuracy: 0.6524

Epoch 00026: val_loss improved from 0.81144 to 0.81127, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 27/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8075 - accuracy: 0.6589 - val_loss: 0.8144 - val_accuracy: 0.6511

Epoch 00027: val_loss did not improve from 0.81127
Epoch 28/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8063 - accuracy: 0.6596 - val_loss: 0.8125 - val_accuracy: 0.6520

Epoch 00028: val_loss did not improve from 0.81127
Epoch 29/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8043 - accuracy: 0.6616 - val_loss: 0.8132 - val_accuracy: 0.6514

Epoch 00029: val_loss did not improve from 0.81127
Epoch 30/100
937/937 [==============================] - 64s 68ms/step - loss: 0.8034 - accuracy: 0.6624 - val_loss: 0.8130 - val_accuracy: 0.6518

Epoch 00030: val_loss did not improve from 0.81127
Epoch 00030: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4NAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
150000/150000 [==============================] - 676s 5ms/step - loss: 0.8116 - accuracy: 0.6526
Testing Loss = 0.811615, Testing Accuracy = 0.652587
The data set contains images
N of classes 3
[array([[0.23771112, 0.13154058, 0.63074827],
       [0.54557669, 0.16582151, 0.28860179],
       [0.06520317, 0.14296927, 0.79182756],
       ...,
       [0.64252174, 0.24455434, 0.11292399],
       [0.09776167, 0.07463566, 0.82760268],
       [0.77302653, 0.10344225, 0.12353126]]), array([[0.30274743, 0.19634652, 0.50090605],
       [0.52161705, 0.22554235, 0.25284064],
       [0.05031516, 0.15222943, 0.79745543],
       ...,
       [0.58207303, 0.29667655, 0.12125046],
       [0.13546503, 0.10435554, 0.76017946],
       [0.71952283, 0.12434841, 0.15612878]]), array([[0.25846985, 0.14369836, 0.59783179],
       [0.49926853, 0.19901291, 0.30171862],
       [0.07403861, 0.14819872, 0.77776271],
       ...,
       [0.5295853 , 0.34416902, 0.12624568],
       [0.16499877, 0.11544251, 0.71955872],
       [0.61721647, 0.16813441, 0.21464911]]), array([[0.22471632, 0.15169302, 0.62359065],
       [0.47525799, 0.1976998 , 0.32704213],
       [0.05967761, 0.15495725, 0.78536516],
       ...,
       [0.55399656, 0.29911062, 0.14689285],
       [0.15263486, 0.0888731 , 0.75849205],
       [0.63808507, 0.18204281, 0.17987214]]), array([[0.22367354, 0.1270685 , 0.64925796],
       [0.41438711, 0.15984124, 0.42577162],
       [0.06230701, 0.14876151, 0.78893155],
       ...,
       [0.6225031 , 0.24263684, 0.13486004],
       [0.17053753, 0.08873442, 0.74072802],
       [0.63240707, 0.16739868, 0.20019417]]), array([[0.21893872, 0.11245541, 0.66860586],
       [0.50889111, 0.22112708, 0.26998177],
       [0.04604241, 0.15110993, 0.80284762],
       ...,
       [0.63799417, 0.23755163, 0.12445415],
       [0.11721633, 0.06619383, 0.81658977],
       [0.66271079, 0.16376963, 0.17351952]]), array([[0.26575556, 0.14199659, 0.59224778],
       [0.45226932, 0.16743959, 0.38029107],
       [0.06513844, 0.17418981, 0.76067173],
       ...,
       [0.61189145, 0.26063475, 0.12747385],
       [0.1521495 , 0.0879107 , 0.75993979],
       [0.72652882, 0.10810041, 0.16537078]]), array([[0.21940412, 0.14942177, 0.63117409],
       [0.47555497, 0.1850345 , 0.33941054],
       [0.05423995, 0.14640139, 0.79935867],
       ...,
       [0.55509007, 0.306977  , 0.137933  ],
       [0.12674092, 0.08143452, 0.79182458],
       [0.61728942, 0.15912597, 0.22358468]]), array([[0.20538802, 0.14231023, 0.65230173],
       [0.49617702, 0.16746598, 0.33635694],
       [0.06296451, 0.1578626 , 0.7791729 ],
       ...,
       [0.65368909, 0.23039541, 0.11591551],
       [0.15889043, 0.1073195 , 0.7337901 ],
       [0.59424549, 0.17853707, 0.22721744]]), array([[0.18209016, 0.1430545 , 0.67485535],
       [0.54671353, 0.13520265, 0.31808385],
       [0.06280747, 0.15736669, 0.77982581],
       ...,
       [0.58368516, 0.29947132, 0.11684354],
       [0.13362882, 0.07444481, 0.79192632],
       [0.6399104 , 0.17292953, 0.18716007]])]
[[0.8403279938129002, 0.8416433969209589, 0.805519716462388], [0.8403279938129002, 0.8416433969209589, 0.805519716462388], [0.8403279938129002, 0.8416433969209589, 0.805519716462388], [0.8403279938129002, 0.8416433969209589, 0.805519716462388], [0.8403279938129002, 0.8416433969209589, 0.805519716462388], [0.8403279938129002, 0.8416433969209589, 0.805519716462388], [0.8403279938129002, 0.8416433969209589, 0.805519716462388], [0.8403279938129002, 0.8416433969209589, 0.805519716462388], [0.8403279938129002, 0.8416433969209589, 0.805519716462388], [0.8403279938129002, 0.8416433969209589, 0.805519716462388]]
[array([0.        , 0.        , 0.        , ..., 0.99202085, 0.99202085,
       1.        ]), array([0.        , 0.        , 0.        , ..., 0.99856789, 0.99856789,
       1.        ]), array([0.        , 0.        , 0.        , ..., 0.99901011, 0.99901011,
       1.        ])]
$W^+$ (auc = 84.03 +- 0.0000 %)
$W^-$ (auc = 84.16 +- 0.0000 %)
$Z$ (auc = 80.55 +- 0.0000 %)


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-01 22:28:22.543150
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 54s 67ms/step - loss: 1.3824 - accuracy: 0.4787 - val_loss: 0.9883 - val_accuracy: 0.4956

Epoch 00001: val_loss improved from inf to 0.98835, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 2/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9894 - accuracy: 0.4933 - val_loss: 0.9747 - val_accuracy: 0.5048

Epoch 00002: val_loss improved from 0.98835 to 0.97466, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 3/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9816 - accuracy: 0.4996 - val_loss: 0.9972 - val_accuracy: 0.4854

Epoch 00003: val_loss did not improve from 0.97466
Epoch 4/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9768 - accuracy: 0.5032 - val_loss: 0.9725 - val_accuracy: 0.5018

Epoch 00004: val_loss improved from 0.97466 to 0.97247, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 5/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9729 - accuracy: 0.5059 - val_loss: 0.9581 - val_accuracy: 0.5146

Epoch 00005: val_loss improved from 0.97247 to 0.95805, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 6/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9706 - accuracy: 0.5074 - val_loss: 0.9609 - val_accuracy: 0.5165

Epoch 00006: val_loss did not improve from 0.95805
Epoch 7/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9679 - accuracy: 0.5091 - val_loss: 0.9600 - val_accuracy: 0.5182

Epoch 00007: val_loss did not improve from 0.95805
Epoch 8/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9668 - accuracy: 0.5106 - val_loss: 0.9562 - val_accuracy: 0.5153

Epoch 00008: val_loss improved from 0.95805 to 0.95618, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 9/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9647 - accuracy: 0.5119 - val_loss: 0.9568 - val_accuracy: 0.5133

Epoch 00009: val_loss did not improve from 0.95618
Epoch 10/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9625 - accuracy: 0.5131 - val_loss: 0.9527 - val_accuracy: 0.5172

Epoch 00010: val_loss improved from 0.95618 to 0.95271, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 11/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9608 - accuracy: 0.5148 - val_loss: 0.9555 - val_accuracy: 0.5154

Epoch 00011: val_loss did not improve from 0.95271
Epoch 12/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9595 - accuracy: 0.5160 - val_loss: 0.9554 - val_accuracy: 0.5141

Epoch 00012: val_loss did not improve from 0.95271
Epoch 13/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9581 - accuracy: 0.5167 - val_loss: 0.9591 - val_accuracy: 0.5132

Epoch 00013: val_loss did not improve from 0.95271
Epoch 14/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9568 - accuracy: 0.5171 - val_loss: 0.9498 - val_accuracy: 0.5183

Epoch 00014: val_loss improved from 0.95271 to 0.94980, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 15/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9559 - accuracy: 0.5187 - val_loss: 0.9505 - val_accuracy: 0.5190

Epoch 00015: val_loss did not improve from 0.94980
Epoch 16/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9543 - accuracy: 0.5194 - val_loss: 0.9552 - val_accuracy: 0.5156

Epoch 00016: val_loss did not improve from 0.94980
Epoch 17/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9532 - accuracy: 0.5208 - val_loss: 0.9510 - val_accuracy: 0.5188

Epoch 00017: val_loss did not improve from 0.94980
Epoch 18/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9515 - accuracy: 0.5222 - val_loss: 0.9509 - val_accuracy: 0.5199

Epoch 00018: val_loss did not improve from 0.94980
Epoch 19/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9506 - accuracy: 0.5225 - val_loss: 0.9572 - val_accuracy: 0.5156

Epoch 00019: val_loss did not improve from 0.94980
Epoch 20/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9485 - accuracy: 0.5242 - val_loss: 0.9538 - val_accuracy: 0.5184

Epoch 00020: val_loss did not improve from 0.94980
Epoch 21/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9460 - accuracy: 0.5264 - val_loss: 0.9549 - val_accuracy: 0.5176

Epoch 00021: val_loss did not improve from 0.94980
Epoch 22/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9447 - accuracy: 0.5269 - val_loss: 0.9540 - val_accuracy: 0.5183

Epoch 00022: val_loss did not improve from 0.94980
Epoch 23/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9430 - accuracy: 0.5294 - val_loss: 0.9552 - val_accuracy: 0.5194

Epoch 00023: val_loss did not improve from 0.94980
Epoch 24/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9430 - accuracy: 0.5302 - val_loss: 0.9586 - val_accuracy: 0.5189

Epoch 00024: val_loss did not improve from 0.94980
Epoch 00024: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 528s 4ms/step - loss: 0.9496 - accuracy: 0.5182
Testing Loss = 0.949619, Testing Accuracy = 0.518239
The data set contains images
N of classes 3
$W^+$ (auc = 65.86 +- 0.0000 %)
$W^-$ (auc = 67.66 +- 0.0000 %)
$Z$ (auc = 82.49 +- 0.0000 %)
The summarized testing accuracy = 51.82 +- 0.0000 %, with the loss = 0.9496 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-02 00:04:06.082897
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 54s 67ms/step - loss: 1.4385 - accuracy: 0.4799 - val_loss: 0.9890 - val_accuracy: 0.4982

Epoch 00001: val_loss improved from inf to 0.98897, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 2/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9858 - accuracy: 0.4966 - val_loss: 1.0104 - val_accuracy: 0.4728

Epoch 00002: val_loss did not improve from 0.98897
Epoch 3/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9801 - accuracy: 0.5006 - val_loss: 0.9820 - val_accuracy: 0.4981

Epoch 00003: val_loss improved from 0.98897 to 0.98201, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 4/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9750 - accuracy: 0.5042 - val_loss: 0.9935 - val_accuracy: 0.4865

Epoch 00004: val_loss did not improve from 0.98201
Epoch 5/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9726 - accuracy: 0.5057 - val_loss: 0.9675 - val_accuracy: 0.5062

Epoch 00005: val_loss improved from 0.98201 to 0.96755, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 6/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9707 - accuracy: 0.5073 - val_loss: 0.9669 - val_accuracy: 0.5113

Epoch 00006: val_loss improved from 0.96755 to 0.96689, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 7/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9687 - accuracy: 0.5088 - val_loss: 0.9630 - val_accuracy: 0.5092

Epoch 00007: val_loss improved from 0.96689 to 0.96305, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 8/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9665 - accuracy: 0.5095 - val_loss: 0.9565 - val_accuracy: 0.5178

Epoch 00008: val_loss improved from 0.96305 to 0.95652, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 9/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9643 - accuracy: 0.5120 - val_loss: 0.9586 - val_accuracy: 0.5129

Epoch 00009: val_loss did not improve from 0.95652
Epoch 10/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9627 - accuracy: 0.5135 - val_loss: 0.9546 - val_accuracy: 0.5156

Epoch 00010: val_loss improved from 0.95652 to 0.95459, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 11/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9607 - accuracy: 0.5142 - val_loss: 0.9532 - val_accuracy: 0.5169

Epoch 00011: val_loss improved from 0.95459 to 0.95323, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 12/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9598 - accuracy: 0.5156 - val_loss: 0.9502 - val_accuracy: 0.5213

Epoch 00012: val_loss improved from 0.95323 to 0.95016, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 13/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9587 - accuracy: 0.5169 - val_loss: 0.9520 - val_accuracy: 0.5213

Epoch 00013: val_loss did not improve from 0.95016
Epoch 14/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9576 - accuracy: 0.5186 - val_loss: 0.9507 - val_accuracy: 0.5210

Epoch 00014: val_loss did not improve from 0.95016
Epoch 15/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9563 - accuracy: 0.5192 - val_loss: 0.9543 - val_accuracy: 0.5192

Epoch 00015: val_loss did not improve from 0.95016
Epoch 16/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9542 - accuracy: 0.5203 - val_loss: 0.9562 - val_accuracy: 0.5140

Epoch 00016: val_loss did not improve from 0.95016
Epoch 17/100
748/748 [==============================] - 50s 67ms/step - loss: 0.9531 - accuracy: 0.5242 - val_loss: 0.9566 - val_accuracy: 0.5375

Epoch 00017: val_loss did not improve from 0.95016
Epoch 18/100
748/748 [==============================] - 50s 67ms/step - loss: 0.8735 - accuracy: 0.6337 - val_loss: 0.8059 - val_accuracy: 0.6726

Epoch 00018: val_loss improved from 0.95016 to 0.80589, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 19/100
748/748 [==============================] - 51s 67ms/step - loss: 0.8273 - accuracy: 0.6631 - val_loss: 0.7961 - val_accuracy: 0.6746

Epoch 00019: val_loss improved from 0.80589 to 0.79609, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 20/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8155 - accuracy: 0.6691 - val_loss: 0.7937 - val_accuracy: 0.6758

Epoch 00020: val_loss improved from 0.79609 to 0.79373, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 21/100
748/748 [==============================] - 50s 67ms/step - loss: 0.8113 - accuracy: 0.6716 - val_loss: 0.7872 - val_accuracy: 0.6804

Epoch 00021: val_loss improved from 0.79373 to 0.78721, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 22/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8065 - accuracy: 0.6737 - val_loss: 0.7938 - val_accuracy: 0.6740

Epoch 00022: val_loss did not improve from 0.78721
Epoch 23/100
748/748 [==============================] - 50s 67ms/step - loss: 0.8031 - accuracy: 0.6756 - val_loss: 0.7891 - val_accuracy: 0.6772

Epoch 00023: val_loss did not improve from 0.78721
Epoch 24/100
748/748 [==============================] - 50s 67ms/step - loss: 0.8012 - accuracy: 0.6777 - val_loss: 0.7864 - val_accuracy: 0.6808

Epoch 00024: val_loss improved from 0.78721 to 0.78643, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 25/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7979 - accuracy: 0.6792 - val_loss: 0.7881 - val_accuracy: 0.6775

Epoch 00025: val_loss did not improve from 0.78643
Epoch 26/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7973 - accuracy: 0.6800 - val_loss: 0.7845 - val_accuracy: 0.6787

Epoch 00026: val_loss improved from 0.78643 to 0.78449, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 27/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7954 - accuracy: 0.6808 - val_loss: 0.7878 - val_accuracy: 0.6741

Epoch 00027: val_loss did not improve from 0.78449
Epoch 28/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7925 - accuracy: 0.6830 - val_loss: 0.7872 - val_accuracy: 0.6760

Epoch 00028: val_loss did not improve from 0.78449
Epoch 29/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7901 - accuracy: 0.6855 - val_loss: 0.7902 - val_accuracy: 0.6744

Epoch 00029: val_loss did not improve from 0.78449
Epoch 30/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7893 - accuracy: 0.6858 - val_loss: 0.7904 - val_accuracy: 0.6764

Epoch 00030: val_loss did not improve from 0.78449
Epoch 31/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7865 - accuracy: 0.6875 - val_loss: 0.7933 - val_accuracy: 0.6763

Epoch 00031: val_loss did not improve from 0.78449
Epoch 32/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7870 - accuracy: 0.6879 - val_loss: 0.7900 - val_accuracy: 0.6773

Epoch 00032: val_loss did not improve from 0.78449
Epoch 33/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7854 - accuracy: 0.6891 - val_loss: 0.7943 - val_accuracy: 0.6714

Epoch 00033: val_loss did not improve from 0.78449
Epoch 34/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7828 - accuracy: 0.6913 - val_loss: 0.7950 - val_accuracy: 0.6703

Epoch 00034: val_loss did not improve from 0.78449
Epoch 35/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7818 - accuracy: 0.6916 - val_loss: 0.7967 - val_accuracy: 0.6753

Epoch 00035: val_loss did not improve from 0.78449
Epoch 36/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7780 - accuracy: 0.6951 - val_loss: 0.8006 - val_accuracy: 0.6708

Epoch 00036: val_loss did not improve from 0.78449
Epoch 00036: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwApAU6pAKkB2gF4cgEAAAByAQAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4PAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 516s 4ms/step - loss: 0.7870 - accuracy: 0.6779
Testing Loss = 0.787049, Testing Accuracy = 0.677918
The data set contains images
N of classes 3
$W^+$ (auc = 84.92 +- 0.0000 %)
$W^-$ (auc = 84.88 +- 0.0000 %)
$Z$ (auc = 83.20 +- 0.0000 %)
The summarized testing accuracy = 67.79 +- 0.0000 %, with the loss = 0.7870 +- 0.000000


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2022-11-06 09:42:36.192712
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 142s 165ms/step - loss: 3.5359 - accuracy: 0.5984 - val_loss: 1.1272 - val_accuracy: 0.6518

Epoch 00001: val_loss improved from inf to 1.12723, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 2/100
748/748 [==============================] - 53s 70ms/step - loss: 0.9421 - accuracy: 0.6489 - val_loss: 0.8466 - val_accuracy: 0.6564

Epoch 00002: val_loss improved from 1.12723 to 0.84665, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 3/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8467 - accuracy: 0.6536 - val_loss: 0.8197 - val_accuracy: 0.6618

Epoch 00003: val_loss improved from 0.84665 to 0.81966, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 4/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8306 - accuracy: 0.6573 - val_loss: 0.8084 - val_accuracy: 0.6663

Epoch 00004: val_loss improved from 0.81966 to 0.80840, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 5/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8216 - accuracy: 0.6610 - val_loss: 0.8018 - val_accuracy: 0.6689

Epoch 00005: val_loss improved from 0.80840 to 0.80177, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 6/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8145 - accuracy: 0.6642 - val_loss: 0.7935 - val_accuracy: 0.6739

Epoch 00006: val_loss improved from 0.80177 to 0.79352, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 7/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8078 - accuracy: 0.6675 - val_loss: 0.7895 - val_accuracy: 0.6763

Epoch 00007: val_loss improved from 0.79352 to 0.78953, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 8/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8022 - accuracy: 0.6705 - val_loss: 0.7831 - val_accuracy: 0.6796

Epoch 00008: val_loss improved from 0.78953 to 0.78313, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 9/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7973 - accuracy: 0.6737 - val_loss: 0.7816 - val_accuracy: 0.6805

Epoch 00009: val_loss improved from 0.78313 to 0.78164, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 10/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7935 - accuracy: 0.6753 - val_loss: 0.7816 - val_accuracy: 0.6798

Epoch 00010: val_loss improved from 0.78164 to 0.78158, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 11/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7906 - accuracy: 0.6769 - val_loss: 0.7792 - val_accuracy: 0.6805

Epoch 00011: val_loss improved from 0.78158 to 0.77919, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 12/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7878 - accuracy: 0.6780 - val_loss: 0.7777 - val_accuracy: 0.6814

Epoch 00012: val_loss improved from 0.77919 to 0.77770, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 13/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7850 - accuracy: 0.6795 - val_loss: 0.7726 - val_accuracy: 0.6841

Epoch 00013: val_loss improved from 0.77770 to 0.77258, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 14/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7827 - accuracy: 0.6809 - val_loss: 0.7726 - val_accuracy: 0.6842

Epoch 00014: val_loss improved from 0.77258 to 0.77255, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 15/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7815 - accuracy: 0.6820 - val_loss: 0.7723 - val_accuracy: 0.6842

Epoch 00015: val_loss improved from 0.77255 to 0.77226, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 16/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7788 - accuracy: 0.6834 - val_loss: 0.7691 - val_accuracy: 0.6857

Epoch 00016: val_loss improved from 0.77226 to 0.76914, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 17/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7774 - accuracy: 0.6845 - val_loss: 0.7682 - val_accuracy: 0.6864

Epoch 00017: val_loss improved from 0.76914 to 0.76818, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 18/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7753 - accuracy: 0.6851 - val_loss: 0.7688 - val_accuracy: 0.6857

Epoch 00018: val_loss did not improve from 0.76818
Epoch 19/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7736 - accuracy: 0.6860 - val_loss: 0.7688 - val_accuracy: 0.6852

Epoch 00019: val_loss did not improve from 0.76818
Epoch 20/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7719 - accuracy: 0.6871 - val_loss: 0.7668 - val_accuracy: 0.6864

Epoch 00020: val_loss improved from 0.76818 to 0.76680, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 21/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7703 - accuracy: 0.6884 - val_loss: 0.7667 - val_accuracy: 0.6869

Epoch 00021: val_loss improved from 0.76680 to 0.76669, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 22/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7687 - accuracy: 0.6892 - val_loss: 0.7675 - val_accuracy: 0.6866

Epoch 00022: val_loss did not improve from 0.76669
Epoch 23/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7669 - accuracy: 0.6903 - val_loss: 0.7673 - val_accuracy: 0.6864

Epoch 00023: val_loss did not improve from 0.76669
Epoch 24/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7653 - accuracy: 0.6916 - val_loss: 0.7676 - val_accuracy: 0.6868

Epoch 00024: val_loss did not improve from 0.76669
Epoch 25/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7640 - accuracy: 0.6921 - val_loss: 0.7671 - val_accuracy: 0.6868

Epoch 00025: val_loss did not improve from 0.76669
Epoch 26/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7620 - accuracy: 0.6934 - val_loss: 0.7672 - val_accuracy: 0.6870

Epoch 00026: val_loss did not improve from 0.76669
Epoch 27/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7610 - accuracy: 0.6946 - val_loss: 0.7658 - val_accuracy: 0.6882

Epoch 00027: val_loss improved from 0.76669 to 0.76575, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 28/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7594 - accuracy: 0.6956 - val_loss: 0.7670 - val_accuracy: 0.6878

Epoch 00028: val_loss did not improve from 0.76575
Epoch 29/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7571 - accuracy: 0.6972 - val_loss: 0.7697 - val_accuracy: 0.6855

Epoch 00029: val_loss did not improve from 0.76575
Epoch 30/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7555 - accuracy: 0.6985 - val_loss: 0.7702 - val_accuracy: 0.6864

Epoch 00030: val_loss did not improve from 0.76575
Epoch 31/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7532 - accuracy: 0.7003 - val_loss: 0.7691 - val_accuracy: 0.6873

Epoch 00031: val_loss did not improve from 0.76575
Epoch 32/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7504 - accuracy: 0.7029 - val_loss: 0.7735 - val_accuracy: 0.6846

Epoch 00032: val_loss did not improve from 0.76575
Epoch 33/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7488 - accuracy: 0.7038 - val_loss: 0.7732 - val_accuracy: 0.6854

Epoch 00033: val_loss did not improve from 0.76575
Epoch 34/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7477 - accuracy: 0.7048 - val_loss: 0.7748 - val_accuracy: 0.6845

Epoch 00034: val_loss did not improve from 0.76575
Epoch 35/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7450 - accuracy: 0.7064 - val_loss: 0.7766 - val_accuracy: 0.6840

Epoch 00035: val_loss did not improve from 0.76575
Epoch 36/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7431 - accuracy: 0.7080 - val_loss: 0.7775 - val_accuracy: 0.6847

Epoch 00036: val_loss did not improve from 0.76575
Epoch 37/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7399 - accuracy: 0.7100 - val_loss: 0.7810 - val_accuracy: 0.6828

Epoch 00037: val_loss did not improve from 0.76575
Epoch 00037: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_1 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_2 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_2', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 536s 4ms/step - loss: 0.7688 - accuracy: 0.6866
Testing Loss = 0.768847, Testing Accuracy = 0.686612
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 52s 69ms/step - loss: 3.5369 - accuracy: 0.6073 - val_loss: 1.1370 - val_accuracy: 0.6514

Epoch 00001: val_loss improved from inf to 1.13701, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 2/100
748/748 [==============================] - 52s 69ms/step - loss: 0.9482 - accuracy: 0.6489 - val_loss: 0.8478 - val_accuracy: 0.6584

Epoch 00002: val_loss improved from 1.13701 to 0.84780, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 3/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8489 - accuracy: 0.6534 - val_loss: 0.8212 - val_accuracy: 0.6620

Epoch 00003: val_loss improved from 0.84780 to 0.82122, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 4/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8323 - accuracy: 0.6570 - val_loss: 0.8108 - val_accuracy: 0.6665

Epoch 00004: val_loss improved from 0.82122 to 0.81077, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 5/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8236 - accuracy: 0.6604 - val_loss: 0.8023 - val_accuracy: 0.6711

Epoch 00005: val_loss improved from 0.81077 to 0.80227, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 6/100
748/748 [==============================] - 51s 69ms/step - loss: 0.8162 - accuracy: 0.6644 - val_loss: 0.7959 - val_accuracy: 0.6747

Epoch 00006: val_loss improved from 0.80227 to 0.79590, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 7/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8087 - accuracy: 0.6677 - val_loss: 0.7908 - val_accuracy: 0.6768

Epoch 00007: val_loss improved from 0.79590 to 0.79077, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 8/100
748/748 [==============================] - 52s 70ms/step - loss: 0.8036 - accuracy: 0.6704 - val_loss: 0.7894 - val_accuracy: 0.6768

Epoch 00008: val_loss improved from 0.79077 to 0.78943, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 9/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7986 - accuracy: 0.6732 - val_loss: 0.7837 - val_accuracy: 0.6802

Epoch 00009: val_loss improved from 0.78943 to 0.78369, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 10/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7951 - accuracy: 0.6748 - val_loss: 0.7813 - val_accuracy: 0.6809

Epoch 00010: val_loss improved from 0.78369 to 0.78125, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 11/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7914 - accuracy: 0.6776 - val_loss: 0.7786 - val_accuracy: 0.6821

Epoch 00011: val_loss improved from 0.78125 to 0.77858, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 12/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7888 - accuracy: 0.6782 - val_loss: 0.7781 - val_accuracy: 0.6822

Epoch 00012: val_loss improved from 0.77858 to 0.77813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 13/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7866 - accuracy: 0.6795 - val_loss: 0.7760 - val_accuracy: 0.6829

Epoch 00013: val_loss improved from 0.77813 to 0.77596, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 14/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7838 - accuracy: 0.6804 - val_loss: 0.7734 - val_accuracy: 0.6849

Epoch 00014: val_loss improved from 0.77596 to 0.77343, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 15/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7823 - accuracy: 0.6812 - val_loss: 0.7748 - val_accuracy: 0.6838

Epoch 00015: val_loss did not improve from 0.77343
Epoch 16/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7801 - accuracy: 0.6825 - val_loss: 0.7722 - val_accuracy: 0.6857

Epoch 00016: val_loss improved from 0.77343 to 0.77222, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 17/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7783 - accuracy: 0.6840 - val_loss: 0.7746 - val_accuracy: 0.6837

Epoch 00017: val_loss did not improve from 0.77222
Epoch 18/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7766 - accuracy: 0.6847 - val_loss: 0.7696 - val_accuracy: 0.6865

Epoch 00018: val_loss improved from 0.77222 to 0.76961, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 19/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7750 - accuracy: 0.6854 - val_loss: 0.7699 - val_accuracy: 0.6866

Epoch 00019: val_loss did not improve from 0.76961
Epoch 20/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7725 - accuracy: 0.6871 - val_loss: 0.7695 - val_accuracy: 0.6867

Epoch 00020: val_loss improved from 0.76961 to 0.76952, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 21/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7716 - accuracy: 0.6876 - val_loss: 0.7687 - val_accuracy: 0.6864

Epoch 00021: val_loss improved from 0.76952 to 0.76872, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 22/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7699 - accuracy: 0.6892 - val_loss: 0.7669 - val_accuracy: 0.6880

Epoch 00022: val_loss improved from 0.76872 to 0.76686, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/1
Epoch 23/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7677 - accuracy: 0.6908 - val_loss: 0.7704 - val_accuracy: 0.6850

Epoch 00023: val_loss did not improve from 0.76686
Epoch 24/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7661 - accuracy: 0.6915 - val_loss: 0.7686 - val_accuracy: 0.6864

Epoch 00024: val_loss did not improve from 0.76686
Epoch 25/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7645 - accuracy: 0.6928 - val_loss: 0.7689 - val_accuracy: 0.6864

Epoch 00025: val_loss did not improve from 0.76686
Epoch 26/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7627 - accuracy: 0.6942 - val_loss: 0.7692 - val_accuracy: 0.6859

Epoch 00026: val_loss did not improve from 0.76686
Epoch 27/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7616 - accuracy: 0.6945 - val_loss: 0.7701 - val_accuracy: 0.6854

Epoch 00027: val_loss did not improve from 0.76686
Epoch 28/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7597 - accuracy: 0.6967 - val_loss: 0.7720 - val_accuracy: 0.6850

Epoch 00028: val_loss did not improve from 0.76686
Epoch 29/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7574 - accuracy: 0.6978 - val_loss: 0.7724 - val_accuracy: 0.6846

Epoch 00029: val_loss did not improve from 0.76686
Epoch 30/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7563 - accuracy: 0.6987 - val_loss: 0.7706 - val_accuracy: 0.6860

Epoch 00030: val_loss did not improve from 0.76686
Epoch 31/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7536 - accuracy: 0.7005 - val_loss: 0.7765 - val_accuracy: 0.6821

Epoch 00031: val_loss did not improve from 0.76686
Epoch 32/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7518 - accuracy: 0.7019 - val_loss: 0.7735 - val_accuracy: 0.6849

Epoch 00032: val_loss did not improve from 0.76686
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_1 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_5 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_1"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_1 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_4 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_4 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_5 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_5 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_3 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_1 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_3 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_4 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_4 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_5 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_1_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_1', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_3', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_4', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_4', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_5', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_5', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 539s 5ms/step - loss: 0.7700 - accuracy: 0.6853
Testing Loss = 0.769957, Testing Accuracy = 0.685259
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 52s 69ms/step - loss: 3.5669 - accuracy: 0.5986 - val_loss: 1.1354 - val_accuracy: 0.6524

Epoch 00001: val_loss improved from inf to 1.13543, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 2/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9445 - accuracy: 0.6476 - val_loss: 0.8443 - val_accuracy: 0.6591

Epoch 00002: val_loss improved from 1.13543 to 0.84432, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 3/100
748/748 [==============================] - 51s 69ms/step - loss: 0.8467 - accuracy: 0.6530 - val_loss: 0.8195 - val_accuracy: 0.6619

Epoch 00003: val_loss improved from 0.84432 to 0.81953, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 4/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8310 - accuracy: 0.6577 - val_loss: 0.8091 - val_accuracy: 0.6663

Epoch 00004: val_loss improved from 0.81953 to 0.80912, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 5/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8220 - accuracy: 0.6607 - val_loss: 0.8020 - val_accuracy: 0.6699

Epoch 00005: val_loss improved from 0.80912 to 0.80197, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 6/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8155 - accuracy: 0.6643 - val_loss: 0.7954 - val_accuracy: 0.6744

Epoch 00006: val_loss improved from 0.80197 to 0.79537, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 7/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8085 - accuracy: 0.6672 - val_loss: 0.7890 - val_accuracy: 0.6768

Epoch 00007: val_loss improved from 0.79537 to 0.78898, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 8/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8022 - accuracy: 0.6707 - val_loss: 0.7860 - val_accuracy: 0.6786

Epoch 00008: val_loss improved from 0.78898 to 0.78598, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 9/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7977 - accuracy: 0.6731 - val_loss: 0.7829 - val_accuracy: 0.6804

Epoch 00009: val_loss improved from 0.78598 to 0.78285, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 10/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7939 - accuracy: 0.6747 - val_loss: 0.7785 - val_accuracy: 0.6827

Epoch 00010: val_loss improved from 0.78285 to 0.77846, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 11/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7905 - accuracy: 0.6774 - val_loss: 0.7770 - val_accuracy: 0.6834

Epoch 00011: val_loss improved from 0.77846 to 0.77697, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 12/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7877 - accuracy: 0.6789 - val_loss: 0.7763 - val_accuracy: 0.6841

Epoch 00012: val_loss improved from 0.77697 to 0.77629, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 13/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7851 - accuracy: 0.6797 - val_loss: 0.7748 - val_accuracy: 0.6848

Epoch 00013: val_loss improved from 0.77629 to 0.77480, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 14/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7833 - accuracy: 0.6814 - val_loss: 0.7709 - val_accuracy: 0.6871

Epoch 00014: val_loss improved from 0.77480 to 0.77093, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 15/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7808 - accuracy: 0.6822 - val_loss: 0.7699 - val_accuracy: 0.6867

Epoch 00015: val_loss improved from 0.77093 to 0.76992, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 16/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7787 - accuracy: 0.6835 - val_loss: 0.7690 - val_accuracy: 0.6876

Epoch 00016: val_loss improved from 0.76992 to 0.76896, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 17/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7767 - accuracy: 0.6842 - val_loss: 0.7685 - val_accuracy: 0.6872

Epoch 00017: val_loss improved from 0.76896 to 0.76854, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 18/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7752 - accuracy: 0.6850 - val_loss: 0.7689 - val_accuracy: 0.6870

Epoch 00018: val_loss did not improve from 0.76854
Epoch 19/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7733 - accuracy: 0.6867 - val_loss: 0.7680 - val_accuracy: 0.6876

Epoch 00019: val_loss improved from 0.76854 to 0.76795, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 20/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7720 - accuracy: 0.6877 - val_loss: 0.7658 - val_accuracy: 0.6888

Epoch 00020: val_loss improved from 0.76795 to 0.76582, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 21/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7704 - accuracy: 0.6887 - val_loss: 0.7661 - val_accuracy: 0.6885

Epoch 00021: val_loss did not improve from 0.76582
Epoch 22/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7684 - accuracy: 0.6900 - val_loss: 0.7668 - val_accuracy: 0.6883

Epoch 00022: val_loss did not improve from 0.76582
Epoch 23/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7672 - accuracy: 0.6909 - val_loss: 0.7671 - val_accuracy: 0.6890

Epoch 00023: val_loss did not improve from 0.76582
Epoch 24/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7655 - accuracy: 0.6919 - val_loss: 0.7655 - val_accuracy: 0.6887

Epoch 00024: val_loss improved from 0.76582 to 0.76550, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/2
Epoch 25/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7634 - accuracy: 0.6936 - val_loss: 0.7657 - val_accuracy: 0.6894

Epoch 00025: val_loss did not improve from 0.76550
Epoch 26/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7618 - accuracy: 0.6940 - val_loss: 0.7656 - val_accuracy: 0.6893

Epoch 00026: val_loss did not improve from 0.76550
Epoch 27/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7600 - accuracy: 0.6953 - val_loss: 0.7662 - val_accuracy: 0.6897

Epoch 00027: val_loss did not improve from 0.76550
Epoch 28/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7584 - accuracy: 0.6969 - val_loss: 0.7668 - val_accuracy: 0.6895

Epoch 00028: val_loss did not improve from 0.76550
Epoch 29/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7568 - accuracy: 0.6982 - val_loss: 0.7686 - val_accuracy: 0.6882

Epoch 00029: val_loss did not improve from 0.76550
Epoch 30/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7546 - accuracy: 0.6998 - val_loss: 0.7690 - val_accuracy: 0.6884

Epoch 00030: val_loss did not improve from 0.76550
Epoch 31/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7526 - accuracy: 0.7003 - val_loss: 0.7683 - val_accuracy: 0.6893

Epoch 00031: val_loss did not improve from 0.76550
Epoch 32/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7506 - accuracy: 0.7025 - val_loss: 0.7714 - val_accuracy: 0.6872

Epoch 00032: val_loss did not improve from 0.76550
Epoch 33/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7492 - accuracy: 0.7038 - val_loss: 0.7757 - val_accuracy: 0.6849

Epoch 00033: val_loss did not improve from 0.76550
Epoch 34/100
748/748 [==============================] - 99s 133ms/step - loss: 0.7473 - accuracy: 0.7056 - val_loss: 0.7824 - val_accuracy: 0.6810

Epoch 00034: val_loss did not improve from 0.76550
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_2 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_8 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_2"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_2 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_6 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_6 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_7 (Conv2D)            (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_7 (MaxPooling2 (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_8 (Conv2D)            (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_8 (MaxPooling2 (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_6 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_2 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_6 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_7 (Dropout)          (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_7 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_8 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_2', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_2_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_2', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_8', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_8', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_2', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 603s 5ms/step - loss: 0.7686 - accuracy: 0.6868
Testing Loss = 0.768581, Testing Accuracy = 0.686762
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 231s 303ms/step - loss: 3.5551 - accuracy: 0.6023 - val_loss: 1.1369 - val_accuracy: 0.6527

Epoch 00001: val_loss improved from inf to 1.13692, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 2/100
748/748 [==============================] - 230s 307ms/step - loss: 0.9492 - accuracy: 0.6480 - val_loss: 0.8472 - val_accuracy: 0.6582

Epoch 00002: val_loss improved from 1.13692 to 0.84725, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 3/100
748/748 [==============================] - 262s 350ms/step - loss: 0.8492 - accuracy: 0.6525 - val_loss: 0.8219 - val_accuracy: 0.6608

Epoch 00003: val_loss improved from 0.84725 to 0.82192, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 4/100
748/748 [==============================] - 215s 288ms/step - loss: 0.8324 - accuracy: 0.6568 - val_loss: 0.8096 - val_accuracy: 0.6651

Epoch 00004: val_loss improved from 0.82192 to 0.80957, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 5/100
748/748 [==============================] - 198s 264ms/step - loss: 0.8232 - accuracy: 0.6600 - val_loss: 0.8025 - val_accuracy: 0.6692

Epoch 00005: val_loss improved from 0.80957 to 0.80251, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 6/100
748/748 [==============================] - 124s 165ms/step - loss: 0.8156 - accuracy: 0.6635 - val_loss: 0.7946 - val_accuracy: 0.6731

Epoch 00006: val_loss improved from 0.80251 to 0.79457, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 7/100
748/748 [==============================] - 53s 71ms/step - loss: 0.8092 - accuracy: 0.6668 - val_loss: 0.7882 - val_accuracy: 0.6772

Epoch 00007: val_loss improved from 0.79457 to 0.78815, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 8/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8032 - accuracy: 0.6702 - val_loss: 0.7847 - val_accuracy: 0.6796

Epoch 00008: val_loss improved from 0.78815 to 0.78469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 9/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7975 - accuracy: 0.6730 - val_loss: 0.7816 - val_accuracy: 0.6812

Epoch 00009: val_loss improved from 0.78469 to 0.78163, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 10/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7943 - accuracy: 0.6747 - val_loss: 0.7799 - val_accuracy: 0.6814

Epoch 00010: val_loss improved from 0.78163 to 0.77988, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 11/100
748/748 [==============================] - 52s 70ms/step - loss: 0.7912 - accuracy: 0.6763 - val_loss: 0.7791 - val_accuracy: 0.6819

Epoch 00011: val_loss improved from 0.77988 to 0.77911, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 12/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7879 - accuracy: 0.6781 - val_loss: 0.7756 - val_accuracy: 0.6838

Epoch 00012: val_loss improved from 0.77911 to 0.77560, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 13/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7855 - accuracy: 0.6798 - val_loss: 0.7724 - val_accuracy: 0.6852

Epoch 00013: val_loss improved from 0.77560 to 0.77241, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 14/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7833 - accuracy: 0.6807 - val_loss: 0.7743 - val_accuracy: 0.6838

Epoch 00014: val_loss did not improve from 0.77241
Epoch 15/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7815 - accuracy: 0.6814 - val_loss: 0.7706 - val_accuracy: 0.6855

Epoch 00015: val_loss improved from 0.77241 to 0.77060, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 16/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7792 - accuracy: 0.6836 - val_loss: 0.7721 - val_accuracy: 0.6849

Epoch 00016: val_loss did not improve from 0.77060
Epoch 17/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7771 - accuracy: 0.6841 - val_loss: 0.7695 - val_accuracy: 0.6863

Epoch 00017: val_loss improved from 0.77060 to 0.76947, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 18/100
748/748 [==============================] - 85s 113ms/step - loss: 0.7757 - accuracy: 0.6852 - val_loss: 0.7695 - val_accuracy: 0.6865

Epoch 00018: val_loss did not improve from 0.76947
Epoch 19/100
748/748 [==============================] - 50s 67ms/step - loss: 0.7736 - accuracy: 0.6862 - val_loss: 0.7665 - val_accuracy: 0.6880

Epoch 00019: val_loss improved from 0.76947 to 0.76649, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 20/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7722 - accuracy: 0.6866 - val_loss: 0.7665 - val_accuracy: 0.6884

Epoch 00020: val_loss improved from 0.76649 to 0.76647, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 21/100
748/748 [==============================] - 102s 137ms/step - loss: 0.7703 - accuracy: 0.6884 - val_loss: 0.7670 - val_accuracy: 0.6875

Epoch 00021: val_loss did not improve from 0.76647
Epoch 22/100
748/748 [==============================] - 91s 122ms/step - loss: 0.7690 - accuracy: 0.6887 - val_loss: 0.7655 - val_accuracy: 0.6888

Epoch 00022: val_loss improved from 0.76647 to 0.76552, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/3
Epoch 23/100
748/748 [==============================] - 62s 83ms/step - loss: 0.7674 - accuracy: 0.6906 - val_loss: 0.7668 - val_accuracy: 0.6875

Epoch 00023: val_loss did not improve from 0.76552
Epoch 24/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7654 - accuracy: 0.6915 - val_loss: 0.7661 - val_accuracy: 0.6880

Epoch 00024: val_loss did not improve from 0.76552
Epoch 25/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7641 - accuracy: 0.6919 - val_loss: 0.7667 - val_accuracy: 0.6883

Epoch 00025: val_loss did not improve from 0.76552
Epoch 26/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7627 - accuracy: 0.6930 - val_loss: 0.7673 - val_accuracy: 0.6878

Epoch 00026: val_loss did not improve from 0.76552
Epoch 27/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7608 - accuracy: 0.6950 - val_loss: 0.7668 - val_accuracy: 0.6887

Epoch 00027: val_loss did not improve from 0.76552
Epoch 28/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7602 - accuracy: 0.6957 - val_loss: 0.7685 - val_accuracy: 0.6869

Epoch 00028: val_loss did not improve from 0.76552
Epoch 29/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7574 - accuracy: 0.6974 - val_loss: 0.7679 - val_accuracy: 0.6882

Epoch 00029: val_loss did not improve from 0.76552
Epoch 30/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7559 - accuracy: 0.6983 - val_loss: 0.7687 - val_accuracy: 0.6867

Epoch 00030: val_loss did not improve from 0.76552
Epoch 31/100
748/748 [==============================] - 79s 106ms/step - loss: 0.7544 - accuracy: 0.7001 - val_loss: 0.7677 - val_accuracy: 0.6885

Epoch 00031: val_loss did not improve from 0.76552
Epoch 32/100
748/748 [==============================] - 160s 213ms/step - loss: 0.7519 - accuracy: 0.7012 - val_loss: 0.7732 - val_accuracy: 0.6835

Epoch 00032: val_loss did not improve from 0.76552
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_3 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_11 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_3"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_3 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_9 (Conv2D)            (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_9 (MaxPooling2 (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_10 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_10 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_11 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_11 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_9 (Dropout)          (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_3 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_9 (Dense)              (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_10 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_10 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_11 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_3_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_3', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_9', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_9', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_10', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_10', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_11', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_11', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 454s 4ms/step - loss: 0.7692 - accuracy: 0.6863
Testing Loss = 0.769219, Testing Accuracy = 0.686344
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 224s 295ms/step - loss: 3.5482 - accuracy: 0.6044 - val_loss: 1.1314 - val_accuracy: 0.6531

Epoch 00001: val_loss improved from inf to 1.13136, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 2/100
748/748 [==============================] - 221s 295ms/step - loss: 0.9451 - accuracy: 0.6478 - val_loss: 0.8466 - val_accuracy: 0.6583

Epoch 00002: val_loss improved from 1.13136 to 0.84661, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 3/100
748/748 [==============================] - 263s 352ms/step - loss: 0.8487 - accuracy: 0.6529 - val_loss: 0.8205 - val_accuracy: 0.6621

Epoch 00003: val_loss improved from 0.84661 to 0.82054, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 4/100
748/748 [==============================] - 226s 302ms/step - loss: 0.8321 - accuracy: 0.6567 - val_loss: 0.8094 - val_accuracy: 0.6667

Epoch 00004: val_loss improved from 0.82054 to 0.80937, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 5/100
748/748 [==============================] - 260s 348ms/step - loss: 0.8233 - accuracy: 0.6605 - val_loss: 0.8020 - val_accuracy: 0.6702

Epoch 00005: val_loss improved from 0.80937 to 0.80196, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 6/100
748/748 [==============================] - 203s 271ms/step - loss: 0.8152 - accuracy: 0.6642 - val_loss: 0.7952 - val_accuracy: 0.6749

Epoch 00006: val_loss improved from 0.80196 to 0.79524, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 7/100
748/748 [==============================] - 196s 261ms/step - loss: 0.8087 - accuracy: 0.6676 - val_loss: 0.7881 - val_accuracy: 0.6777

Epoch 00007: val_loss improved from 0.79524 to 0.78812, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 8/100
748/748 [==============================] - 192s 256ms/step - loss: 0.8028 - accuracy: 0.6707 - val_loss: 0.7842 - val_accuracy: 0.6802

Epoch 00008: val_loss improved from 0.78812 to 0.78419, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 9/100
748/748 [==============================] - 157s 209ms/step - loss: 0.7981 - accuracy: 0.6729 - val_loss: 0.7801 - val_accuracy: 0.6818

Epoch 00009: val_loss improved from 0.78419 to 0.78012, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 10/100
748/748 [==============================] - 94s 126ms/step - loss: 0.7940 - accuracy: 0.6750 - val_loss: 0.7801 - val_accuracy: 0.6820

Epoch 00010: val_loss improved from 0.78012 to 0.78010, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 11/100
748/748 [==============================] - 98s 131ms/step - loss: 0.7904 - accuracy: 0.6765 - val_loss: 0.7764 - val_accuracy: 0.6838

Epoch 00011: val_loss improved from 0.78010 to 0.77637, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 12/100
748/748 [==============================] - 103s 138ms/step - loss: 0.7875 - accuracy: 0.6786 - val_loss: 0.7749 - val_accuracy: 0.6846

Epoch 00012: val_loss improved from 0.77637 to 0.77491, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 13/100
748/748 [==============================] - 103s 138ms/step - loss: 0.7853 - accuracy: 0.6800 - val_loss: 0.7721 - val_accuracy: 0.6854

Epoch 00013: val_loss improved from 0.77491 to 0.77213, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 14/100
748/748 [==============================] - 103s 138ms/step - loss: 0.7825 - accuracy: 0.6810 - val_loss: 0.7731 - val_accuracy: 0.6851

Epoch 00014: val_loss did not improve from 0.77213
Epoch 15/100
748/748 [==============================] - 99s 133ms/step - loss: 0.7803 - accuracy: 0.6828 - val_loss: 0.7693 - val_accuracy: 0.6870

Epoch 00015: val_loss improved from 0.77213 to 0.76930, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 16/100
748/748 [==============================] - 96s 129ms/step - loss: 0.7788 - accuracy: 0.6830 - val_loss: 0.7677 - val_accuracy: 0.6875

Epoch 00016: val_loss improved from 0.76930 to 0.76770, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 17/100
748/748 [==============================] - 104s 139ms/step - loss: 0.7771 - accuracy: 0.6838 - val_loss: 0.7682 - val_accuracy: 0.6874

Epoch 00017: val_loss did not improve from 0.76770
Epoch 18/100
748/748 [==============================] - 96s 128ms/step - loss: 0.7746 - accuracy: 0.6855 - val_loss: 0.7667 - val_accuracy: 0.6881

Epoch 00018: val_loss improved from 0.76770 to 0.76667, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 19/100
748/748 [==============================] - 103s 138ms/step - loss: 0.7730 - accuracy: 0.6868 - val_loss: 0.7658 - val_accuracy: 0.6885

Epoch 00019: val_loss improved from 0.76667 to 0.76582, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 20/100
748/748 [==============================] - 97s 130ms/step - loss: 0.7714 - accuracy: 0.6866 - val_loss: 0.7655 - val_accuracy: 0.6886

Epoch 00020: val_loss improved from 0.76582 to 0.76546, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 21/100
748/748 [==============================] - 103s 137ms/step - loss: 0.7702 - accuracy: 0.6876 - val_loss: 0.7650 - val_accuracy: 0.6884

Epoch 00021: val_loss improved from 0.76546 to 0.76500, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 22/100
748/748 [==============================] - 103s 138ms/step - loss: 0.7682 - accuracy: 0.6896 - val_loss: 0.7649 - val_accuracy: 0.6882

Epoch 00022: val_loss improved from 0.76500 to 0.76486, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 23/100
748/748 [==============================] - 98s 131ms/step - loss: 0.7665 - accuracy: 0.6906 - val_loss: 0.7645 - val_accuracy: 0.6887

Epoch 00023: val_loss improved from 0.76486 to 0.76452, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/4
Epoch 24/100
748/748 [==============================] - 103s 137ms/step - loss: 0.7655 - accuracy: 0.6912 - val_loss: 0.7657 - val_accuracy: 0.6881

Epoch 00024: val_loss did not improve from 0.76452
Epoch 25/100
748/748 [==============================] - 99s 132ms/step - loss: 0.7641 - accuracy: 0.6922 - val_loss: 0.7648 - val_accuracy: 0.6894

Epoch 00025: val_loss did not improve from 0.76452
Epoch 26/100
748/748 [==============================] - 98s 131ms/step - loss: 0.7622 - accuracy: 0.6933 - val_loss: 0.7682 - val_accuracy: 0.6871

Epoch 00026: val_loss did not improve from 0.76452
Epoch 27/100
748/748 [==============================] - 103s 138ms/step - loss: 0.7603 - accuracy: 0.6953 - val_loss: 0.7658 - val_accuracy: 0.6889

Epoch 00027: val_loss did not improve from 0.76452
Epoch 28/100
748/748 [==============================] - 104s 139ms/step - loss: 0.7589 - accuracy: 0.6960 - val_loss: 0.7658 - val_accuracy: 0.6886

Epoch 00028: val_loss did not improve from 0.76452
Epoch 29/100
748/748 [==============================] - 106s 141ms/step - loss: 0.7570 - accuracy: 0.6980 - val_loss: 0.7667 - val_accuracy: 0.6891

Epoch 00029: val_loss did not improve from 0.76452
Epoch 30/100
748/748 [==============================] - 102s 137ms/step - loss: 0.7544 - accuracy: 0.6993 - val_loss: 0.7670 - val_accuracy: 0.6886

Epoch 00030: val_loss did not improve from 0.76452
Epoch 31/100
748/748 [==============================] - 98s 131ms/step - loss: 0.7532 - accuracy: 0.7005 - val_loss: 0.7711 - val_accuracy: 0.6860

Epoch 00031: val_loss did not improve from 0.76452
Epoch 32/100
748/748 [==============================] - 103s 138ms/step - loss: 0.7507 - accuracy: 0.7021 - val_loss: 0.7702 - val_accuracy: 0.6864

Epoch 00032: val_loss did not improve from 0.76452
Epoch 33/100
748/748 [==============================] - 102s 136ms/step - loss: 0.7495 - accuracy: 0.7035 - val_loss: 0.7741 - val_accuracy: 0.6843

Epoch 00033: val_loss did not improve from 0.76452
Epoch 00033: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_4 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_14 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_4"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_4 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_4 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_12 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_12 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_13 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_13 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_14 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_14 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_12 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_4 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_12 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_13 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_13 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_14 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_4_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_4', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_4', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_12', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_12', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_13', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_13', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_14', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_14', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 623s 5ms/step - loss: 0.7678 - accuracy: 0.6877
Testing Loss = 0.767837, Testing Accuracy = 0.687656
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 104s 138ms/step - loss: 3.5509 - accuracy: 0.6042 - val_loss: 1.1342 - val_accuracy: 0.6534

Epoch 00001: val_loss improved from inf to 1.13424, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 2/100
748/748 [==============================] - 76s 101ms/step - loss: 0.9463 - accuracy: 0.6487 - val_loss: 0.8469 - val_accuracy: 0.6581

Epoch 00002: val_loss improved from 1.13424 to 0.84694, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 3/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8470 - accuracy: 0.6542 - val_loss: 0.8188 - val_accuracy: 0.6634

Epoch 00003: val_loss improved from 0.84694 to 0.81877, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 4/100
748/748 [==============================] - 51s 69ms/step - loss: 0.8307 - accuracy: 0.6584 - val_loss: 0.8091 - val_accuracy: 0.6672

Epoch 00004: val_loss improved from 0.81877 to 0.80915, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 5/100
748/748 [==============================] - 51s 69ms/step - loss: 0.8220 - accuracy: 0.6621 - val_loss: 0.8004 - val_accuracy: 0.6714

Epoch 00005: val_loss improved from 0.80915 to 0.80038, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 6/100
748/748 [==============================] - 51s 69ms/step - loss: 0.8146 - accuracy: 0.6649 - val_loss: 0.7935 - val_accuracy: 0.6751

Epoch 00006: val_loss improved from 0.80038 to 0.79346, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 7/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8075 - accuracy: 0.6693 - val_loss: 0.7881 - val_accuracy: 0.6784

Epoch 00007: val_loss improved from 0.79346 to 0.78813, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 8/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8002 - accuracy: 0.6728 - val_loss: 0.7858 - val_accuracy: 0.6801

Epoch 00008: val_loss improved from 0.78813 to 0.78581, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 9/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7959 - accuracy: 0.6758 - val_loss: 0.7830 - val_accuracy: 0.6810

Epoch 00009: val_loss improved from 0.78581 to 0.78298, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 10/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7926 - accuracy: 0.6770 - val_loss: 0.7804 - val_accuracy: 0.6823

Epoch 00010: val_loss improved from 0.78298 to 0.78038, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 11/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7889 - accuracy: 0.6789 - val_loss: 0.7783 - val_accuracy: 0.6829

Epoch 00011: val_loss improved from 0.78038 to 0.77835, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 12/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7861 - accuracy: 0.6798 - val_loss: 0.7727 - val_accuracy: 0.6854

Epoch 00012: val_loss improved from 0.77835 to 0.77273, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 13/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7836 - accuracy: 0.6814 - val_loss: 0.7724 - val_accuracy: 0.6860

Epoch 00013: val_loss improved from 0.77273 to 0.77235, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 14/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7815 - accuracy: 0.6821 - val_loss: 0.7721 - val_accuracy: 0.6859

Epoch 00014: val_loss improved from 0.77235 to 0.77210, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 15/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7794 - accuracy: 0.6837 - val_loss: 0.7696 - val_accuracy: 0.6872

Epoch 00015: val_loss improved from 0.77210 to 0.76957, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 16/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7773 - accuracy: 0.6848 - val_loss: 0.7682 - val_accuracy: 0.6879

Epoch 00016: val_loss improved from 0.76957 to 0.76817, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 17/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7757 - accuracy: 0.6853 - val_loss: 0.7680 - val_accuracy: 0.6877

Epoch 00017: val_loss improved from 0.76817 to 0.76804, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 18/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7735 - accuracy: 0.6871 - val_loss: 0.7664 - val_accuracy: 0.6884

Epoch 00018: val_loss improved from 0.76804 to 0.76640, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 19/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7723 - accuracy: 0.6880 - val_loss: 0.7658 - val_accuracy: 0.6885

Epoch 00019: val_loss improved from 0.76640 to 0.76575, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 20/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7706 - accuracy: 0.6886 - val_loss: 0.7652 - val_accuracy: 0.6887

Epoch 00020: val_loss improved from 0.76575 to 0.76516, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 21/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7689 - accuracy: 0.6904 - val_loss: 0.7673 - val_accuracy: 0.6880

Epoch 00021: val_loss did not improve from 0.76516
Epoch 22/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7674 - accuracy: 0.6908 - val_loss: 0.7644 - val_accuracy: 0.6889

Epoch 00022: val_loss improved from 0.76516 to 0.76436, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/5
Epoch 23/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7658 - accuracy: 0.6915 - val_loss: 0.7649 - val_accuracy: 0.6894

Epoch 00023: val_loss did not improve from 0.76436
Epoch 24/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7638 - accuracy: 0.6928 - val_loss: 0.7646 - val_accuracy: 0.6895

Epoch 00024: val_loss did not improve from 0.76436
Epoch 25/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7622 - accuracy: 0.6940 - val_loss: 0.7655 - val_accuracy: 0.6891

Epoch 00025: val_loss did not improve from 0.76436
Epoch 26/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7610 - accuracy: 0.6953 - val_loss: 0.7655 - val_accuracy: 0.6893

Epoch 00026: val_loss did not improve from 0.76436
Epoch 27/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7589 - accuracy: 0.6963 - val_loss: 0.7665 - val_accuracy: 0.6882

Epoch 00027: val_loss did not improve from 0.76436
Epoch 28/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7574 - accuracy: 0.6978 - val_loss: 0.7664 - val_accuracy: 0.6888

Epoch 00028: val_loss did not improve from 0.76436
Epoch 29/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7553 - accuracy: 0.6985 - val_loss: 0.7681 - val_accuracy: 0.6884

Epoch 00029: val_loss did not improve from 0.76436
Epoch 30/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7538 - accuracy: 0.6999 - val_loss: 0.7687 - val_accuracy: 0.6876

Epoch 00030: val_loss did not improve from 0.76436
Epoch 31/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7513 - accuracy: 0.7014 - val_loss: 0.7694 - val_accuracy: 0.6881

Epoch 00031: val_loss did not improve from 0.76436
Epoch 32/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7497 - accuracy: 0.7032 - val_loss: 0.7701 - val_accuracy: 0.6872

Epoch 00032: val_loss did not improve from 0.76436
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_5 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_17 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_5"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_5 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_5 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_15 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_15 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_16 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_16 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_17 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_17 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_15 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_5 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_15 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_16 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_16 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_17 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_5', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_5_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_5', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_5', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_15', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_15', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_16', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_16', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_17', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_17', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 530s 4ms/step - loss: 0.7677 - accuracy: 0.6879
Testing Loss = 0.767724, Testing Accuracy = 0.687914
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 52s 69ms/step - loss: 3.5355 - accuracy: 0.6084 - val_loss: 1.1368 - val_accuracy: 0.6533

Epoch 00001: val_loss improved from inf to 1.13681, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 2/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9474 - accuracy: 0.6485 - val_loss: 0.8470 - val_accuracy: 0.6589

Epoch 00002: val_loss improved from 1.13681 to 0.84698, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 3/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8486 - accuracy: 0.6535 - val_loss: 0.8210 - val_accuracy: 0.6634

Epoch 00003: val_loss improved from 0.84698 to 0.82096, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 4/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8327 - accuracy: 0.6577 - val_loss: 0.8113 - val_accuracy: 0.6666

Epoch 00004: val_loss improved from 0.82096 to 0.81128, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 5/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8231 - accuracy: 0.6610 - val_loss: 0.8025 - val_accuracy: 0.6711

Epoch 00005: val_loss improved from 0.81128 to 0.80250, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 6/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8155 - accuracy: 0.6652 - val_loss: 0.7949 - val_accuracy: 0.6747

Epoch 00006: val_loss improved from 0.80250 to 0.79490, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 7/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8082 - accuracy: 0.6689 - val_loss: 0.7898 - val_accuracy: 0.6785

Epoch 00007: val_loss improved from 0.79490 to 0.78984, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 8/100
748/748 [==============================] - 51s 69ms/step - loss: 0.8028 - accuracy: 0.6712 - val_loss: 0.7858 - val_accuracy: 0.6793

Epoch 00008: val_loss improved from 0.78984 to 0.78577, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 9/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7979 - accuracy: 0.6737 - val_loss: 0.7821 - val_accuracy: 0.6807

Epoch 00009: val_loss improved from 0.78577 to 0.78212, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 10/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7936 - accuracy: 0.6760 - val_loss: 0.7770 - val_accuracy: 0.6834

Epoch 00010: val_loss improved from 0.78212 to 0.77695, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 11/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7905 - accuracy: 0.6777 - val_loss: 0.7766 - val_accuracy: 0.6831

Epoch 00011: val_loss improved from 0.77695 to 0.77660, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 12/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7878 - accuracy: 0.6786 - val_loss: 0.7769 - val_accuracy: 0.6826

Epoch 00012: val_loss did not improve from 0.77660
Epoch 13/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7850 - accuracy: 0.6803 - val_loss: 0.7731 - val_accuracy: 0.6849

Epoch 00013: val_loss improved from 0.77660 to 0.77308, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 14/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7829 - accuracy: 0.6814 - val_loss: 0.7726 - val_accuracy: 0.6852

Epoch 00014: val_loss improved from 0.77308 to 0.77255, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 15/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7808 - accuracy: 0.6830 - val_loss: 0.7704 - val_accuracy: 0.6860

Epoch 00015: val_loss improved from 0.77255 to 0.77039, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 16/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7787 - accuracy: 0.6838 - val_loss: 0.7720 - val_accuracy: 0.6851

Epoch 00016: val_loss did not improve from 0.77039
Epoch 17/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7771 - accuracy: 0.6848 - val_loss: 0.7689 - val_accuracy: 0.6866

Epoch 00017: val_loss improved from 0.77039 to 0.76888, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 18/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7748 - accuracy: 0.6856 - val_loss: 0.7695 - val_accuracy: 0.6867

Epoch 00018: val_loss did not improve from 0.76888
Epoch 19/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7738 - accuracy: 0.6862 - val_loss: 0.7702 - val_accuracy: 0.6856

Epoch 00019: val_loss did not improve from 0.76888
Epoch 20/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7718 - accuracy: 0.6880 - val_loss: 0.7665 - val_accuracy: 0.6879

Epoch 00020: val_loss improved from 0.76888 to 0.76648, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 21/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7703 - accuracy: 0.6885 - val_loss: 0.7675 - val_accuracy: 0.6871

Epoch 00021: val_loss did not improve from 0.76648
Epoch 22/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7685 - accuracy: 0.6902 - val_loss: 0.7665 - val_accuracy: 0.6871

Epoch 00022: val_loss did not improve from 0.76648
Epoch 23/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7666 - accuracy: 0.6912 - val_loss: 0.7678 - val_accuracy: 0.6865

Epoch 00023: val_loss did not improve from 0.76648
Epoch 24/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7650 - accuracy: 0.6920 - val_loss: 0.7661 - val_accuracy: 0.6877

Epoch 00024: val_loss improved from 0.76648 to 0.76607, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/6
Epoch 25/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7635 - accuracy: 0.6934 - val_loss: 0.7672 - val_accuracy: 0.6870

Epoch 00025: val_loss did not improve from 0.76607
Epoch 26/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7617 - accuracy: 0.6942 - val_loss: 0.7666 - val_accuracy: 0.6875

Epoch 00026: val_loss did not improve from 0.76607
Epoch 27/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7607 - accuracy: 0.6947 - val_loss: 0.7665 - val_accuracy: 0.6875

Epoch 00027: val_loss did not improve from 0.76607
Epoch 28/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7585 - accuracy: 0.6962 - val_loss: 0.7684 - val_accuracy: 0.6870

Epoch 00028: val_loss did not improve from 0.76607
Epoch 29/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7569 - accuracy: 0.6979 - val_loss: 0.7675 - val_accuracy: 0.6881

Epoch 00029: val_loss did not improve from 0.76607
Epoch 30/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7549 - accuracy: 0.6992 - val_loss: 0.7677 - val_accuracy: 0.6878

Epoch 00030: val_loss did not improve from 0.76607
Epoch 31/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7530 - accuracy: 0.7006 - val_loss: 0.7701 - val_accuracy: 0.6866

Epoch 00031: val_loss did not improve from 0.76607
Epoch 32/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7511 - accuracy: 0.7025 - val_loss: 0.7716 - val_accuracy: 0.6862

Epoch 00032: val_loss did not improve from 0.76607
Epoch 33/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7489 - accuracy: 0.7038 - val_loss: 0.7728 - val_accuracy: 0.6851

Epoch 00033: val_loss did not improve from 0.76607
Epoch 34/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7467 - accuracy: 0.7050 - val_loss: 0.7739 - val_accuracy: 0.6854

Epoch 00034: val_loss did not improve from 0.76607
Epoch 00034: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_6 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_20 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_6"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_6 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_6 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_18 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_18 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_19 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_19 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_20 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_20 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_18 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_6 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_18 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_19 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_19 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_20 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_6', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_6_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_6', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_6', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_18', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_18', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_19', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_19', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_20', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_20', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_6', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_19', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_20', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_20', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 527s 4ms/step - loss: 0.7692 - accuracy: 0.6864
Testing Loss = 0.769225, Testing Accuracy = 0.686445
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 51s 68ms/step - loss: 3.5205 - accuracy: 0.6065 - val_loss: 1.1315 - val_accuracy: 0.6536

Epoch 00001: val_loss improved from inf to 1.13149, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 2/100
748/748 [==============================] - 51s 68ms/step - loss: 0.9462 - accuracy: 0.6483 - val_loss: 0.8475 - val_accuracy: 0.6584

Epoch 00002: val_loss improved from 1.13149 to 0.84748, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 3/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8482 - accuracy: 0.6535 - val_loss: 0.8220 - val_accuracy: 0.6612

Epoch 00003: val_loss improved from 0.84748 to 0.82202, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 4/100
748/748 [==============================] - 51s 69ms/step - loss: 0.8315 - accuracy: 0.6571 - val_loss: 0.8099 - val_accuracy: 0.6658

Epoch 00004: val_loss improved from 0.82202 to 0.80992, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 5/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8227 - accuracy: 0.6611 - val_loss: 0.8016 - val_accuracy: 0.6708

Epoch 00005: val_loss improved from 0.80992 to 0.80161, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 6/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8146 - accuracy: 0.6650 - val_loss: 0.7954 - val_accuracy: 0.6745

Epoch 00006: val_loss improved from 0.80161 to 0.79540, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 7/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8080 - accuracy: 0.6685 - val_loss: 0.7904 - val_accuracy: 0.6763

Epoch 00007: val_loss improved from 0.79540 to 0.79045, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 8/100
748/748 [==============================] - 52s 69ms/step - loss: 0.8024 - accuracy: 0.6709 - val_loss: 0.7868 - val_accuracy: 0.6783

Epoch 00008: val_loss improved from 0.79045 to 0.78681, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 9/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7973 - accuracy: 0.6734 - val_loss: 0.7843 - val_accuracy: 0.6796

Epoch 00009: val_loss improved from 0.78681 to 0.78430, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 10/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7940 - accuracy: 0.6759 - val_loss: 0.7791 - val_accuracy: 0.6817

Epoch 00010: val_loss improved from 0.78430 to 0.77912, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 11/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7902 - accuracy: 0.6780 - val_loss: 0.7779 - val_accuracy: 0.6821

Epoch 00011: val_loss improved from 0.77912 to 0.77787, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 12/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7872 - accuracy: 0.6790 - val_loss: 0.7753 - val_accuracy: 0.6840

Epoch 00012: val_loss improved from 0.77787 to 0.77534, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 13/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7844 - accuracy: 0.6807 - val_loss: 0.7741 - val_accuracy: 0.6842

Epoch 00013: val_loss improved from 0.77534 to 0.77411, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 14/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7828 - accuracy: 0.6809 - val_loss: 0.7715 - val_accuracy: 0.6854

Epoch 00014: val_loss improved from 0.77411 to 0.77154, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 15/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7803 - accuracy: 0.6820 - val_loss: 0.7690 - val_accuracy: 0.6867

Epoch 00015: val_loss improved from 0.77154 to 0.76903, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 16/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7783 - accuracy: 0.6831 - val_loss: 0.7716 - val_accuracy: 0.6857

Epoch 00016: val_loss did not improve from 0.76903
Epoch 17/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7769 - accuracy: 0.6840 - val_loss: 0.7698 - val_accuracy: 0.6864

Epoch 00017: val_loss did not improve from 0.76903
Epoch 18/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7752 - accuracy: 0.6857 - val_loss: 0.7690 - val_accuracy: 0.6869

Epoch 00018: val_loss improved from 0.76903 to 0.76901, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 19/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7728 - accuracy: 0.6867 - val_loss: 0.7682 - val_accuracy: 0.6868

Epoch 00019: val_loss improved from 0.76901 to 0.76819, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 20/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7717 - accuracy: 0.6870 - val_loss: 0.7698 - val_accuracy: 0.6860

Epoch 00020: val_loss did not improve from 0.76819
Epoch 21/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7698 - accuracy: 0.6887 - val_loss: 0.7667 - val_accuracy: 0.6878

Epoch 00021: val_loss improved from 0.76819 to 0.76669, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 22/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7688 - accuracy: 0.6898 - val_loss: 0.7674 - val_accuracy: 0.6870

Epoch 00022: val_loss did not improve from 0.76669
Epoch 23/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7670 - accuracy: 0.6900 - val_loss: 0.7658 - val_accuracy: 0.6876

Epoch 00023: val_loss improved from 0.76669 to 0.76577, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 24/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7659 - accuracy: 0.6910 - val_loss: 0.7673 - val_accuracy: 0.6869

Epoch 00024: val_loss did not improve from 0.76577
Epoch 25/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7637 - accuracy: 0.6923 - val_loss: 0.7646 - val_accuracy: 0.6884

Epoch 00025: val_loss improved from 0.76577 to 0.76457, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/7
Epoch 26/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7615 - accuracy: 0.6941 - val_loss: 0.7665 - val_accuracy: 0.6879

Epoch 00026: val_loss did not improve from 0.76457
Epoch 27/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7602 - accuracy: 0.6950 - val_loss: 0.7666 - val_accuracy: 0.6877

Epoch 00027: val_loss did not improve from 0.76457
Epoch 28/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7592 - accuracy: 0.6957 - val_loss: 0.7675 - val_accuracy: 0.6867

Epoch 00028: val_loss did not improve from 0.76457
Epoch 29/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7575 - accuracy: 0.6972 - val_loss: 0.7673 - val_accuracy: 0.6881

Epoch 00029: val_loss did not improve from 0.76457
Epoch 30/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7547 - accuracy: 0.6994 - val_loss: 0.7704 - val_accuracy: 0.6860

Epoch 00030: val_loss did not improve from 0.76457
Epoch 31/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7535 - accuracy: 0.7002 - val_loss: 0.7687 - val_accuracy: 0.6878

Epoch 00031: val_loss did not improve from 0.76457
Epoch 32/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7507 - accuracy: 0.7024 - val_loss: 0.7703 - val_accuracy: 0.6870

Epoch 00032: val_loss did not improve from 0.76457
Epoch 33/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7495 - accuracy: 0.7035 - val_loss: 0.7707 - val_accuracy: 0.6867

Epoch 00033: val_loss did not improve from 0.76457
Epoch 34/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7464 - accuracy: 0.7059 - val_loss: 0.7725 - val_accuracy: 0.6866

Epoch 00034: val_loss did not improve from 0.76457
Epoch 35/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7443 - accuracy: 0.7071 - val_loss: 0.7737 - val_accuracy: 0.6859

Epoch 00035: val_loss did not improve from 0.76457
Epoch 00035: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_7 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_23 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_7"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_7 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_7 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_21 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_21 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_22 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_22 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_23 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_23 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_21 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_7 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_21 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_22 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_22 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_23 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_7', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_7_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_7', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_7', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_21', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_21', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_22', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_22', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_23', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_23', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_21', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_7', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_21', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_22', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_22', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_23', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_23', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 530s 4ms/step - loss: 0.7678 - accuracy: 0.6863
Testing Loss = 0.767823, Testing Accuracy = 0.686261
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 52s 68ms/step - loss: 3.5105 - accuracy: 0.6052 - val_loss: 1.1323 - val_accuracy: 0.6521

Epoch 00001: val_loss improved from inf to 1.13235, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 2/100
748/748 [==============================] - 51s 69ms/step - loss: 0.9464 - accuracy: 0.6477 - val_loss: 0.8485 - val_accuracy: 0.6571

Epoch 00002: val_loss improved from 1.13235 to 0.84850, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 3/100
748/748 [==============================] - 51s 69ms/step - loss: 0.8493 - accuracy: 0.6530 - val_loss: 0.8231 - val_accuracy: 0.6608

Epoch 00003: val_loss improved from 0.84850 to 0.82311, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 4/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8332 - accuracy: 0.6570 - val_loss: 0.8115 - val_accuracy: 0.6646

Epoch 00004: val_loss improved from 0.82311 to 0.81153, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 5/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8238 - accuracy: 0.6600 - val_loss: 0.8033 - val_accuracy: 0.6697

Epoch 00005: val_loss improved from 0.81153 to 0.80326, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 6/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8167 - accuracy: 0.6636 - val_loss: 0.7960 - val_accuracy: 0.6740

Epoch 00006: val_loss improved from 0.80326 to 0.79600, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 7/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8100 - accuracy: 0.6664 - val_loss: 0.7894 - val_accuracy: 0.6774

Epoch 00007: val_loss improved from 0.79600 to 0.78943, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 8/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8036 - accuracy: 0.6706 - val_loss: 0.7854 - val_accuracy: 0.6794

Epoch 00008: val_loss improved from 0.78943 to 0.78541, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 9/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7988 - accuracy: 0.6725 - val_loss: 0.7847 - val_accuracy: 0.6800

Epoch 00009: val_loss improved from 0.78541 to 0.78469, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 10/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7947 - accuracy: 0.6748 - val_loss: 0.7807 - val_accuracy: 0.6816

Epoch 00010: val_loss improved from 0.78469 to 0.78071, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 11/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7915 - accuracy: 0.6765 - val_loss: 0.7787 - val_accuracy: 0.6819

Epoch 00011: val_loss improved from 0.78071 to 0.77867, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 12/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7889 - accuracy: 0.6773 - val_loss: 0.7792 - val_accuracy: 0.6816

Epoch 00012: val_loss did not improve from 0.77867
Epoch 13/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7866 - accuracy: 0.6793 - val_loss: 0.7761 - val_accuracy: 0.6835

Epoch 00013: val_loss improved from 0.77867 to 0.77606, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 14/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7836 - accuracy: 0.6801 - val_loss: 0.7731 - val_accuracy: 0.6840

Epoch 00014: val_loss improved from 0.77606 to 0.77306, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 15/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7814 - accuracy: 0.6817 - val_loss: 0.7734 - val_accuracy: 0.6843

Epoch 00015: val_loss did not improve from 0.77306
Epoch 16/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7796 - accuracy: 0.6823 - val_loss: 0.7718 - val_accuracy: 0.6852

Epoch 00016: val_loss improved from 0.77306 to 0.77176, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 17/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7773 - accuracy: 0.6845 - val_loss: 0.7704 - val_accuracy: 0.6855

Epoch 00017: val_loss improved from 0.77176 to 0.77044, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 18/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7759 - accuracy: 0.6851 - val_loss: 0.7707 - val_accuracy: 0.6853

Epoch 00018: val_loss did not improve from 0.77044
Epoch 19/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7737 - accuracy: 0.6867 - val_loss: 0.7695 - val_accuracy: 0.6859

Epoch 00019: val_loss improved from 0.77044 to 0.76946, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 20/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7725 - accuracy: 0.6872 - val_loss: 0.7699 - val_accuracy: 0.6852

Epoch 00020: val_loss did not improve from 0.76946
Epoch 21/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7713 - accuracy: 0.6882 - val_loss: 0.7685 - val_accuracy: 0.6868

Epoch 00021: val_loss improved from 0.76946 to 0.76851, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 22/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7693 - accuracy: 0.6890 - val_loss: 0.7665 - val_accuracy: 0.6886

Epoch 00022: val_loss improved from 0.76851 to 0.76651, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/8
Epoch 23/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7679 - accuracy: 0.6903 - val_loss: 0.7676 - val_accuracy: 0.6879

Epoch 00023: val_loss did not improve from 0.76651
Epoch 24/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7656 - accuracy: 0.6916 - val_loss: 0.7672 - val_accuracy: 0.6876

Epoch 00024: val_loss did not improve from 0.76651
Epoch 25/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7639 - accuracy: 0.6928 - val_loss: 0.7677 - val_accuracy: 0.6874

Epoch 00025: val_loss did not improve from 0.76651
Epoch 26/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7623 - accuracy: 0.6940 - val_loss: 0.7671 - val_accuracy: 0.6877

Epoch 00026: val_loss did not improve from 0.76651
Epoch 27/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7610 - accuracy: 0.6945 - val_loss: 0.7681 - val_accuracy: 0.6872

Epoch 00027: val_loss did not improve from 0.76651
Epoch 28/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7592 - accuracy: 0.6957 - val_loss: 0.7680 - val_accuracy: 0.6877

Epoch 00028: val_loss did not improve from 0.76651
Epoch 29/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7570 - accuracy: 0.6972 - val_loss: 0.7695 - val_accuracy: 0.6862

Epoch 00029: val_loss did not improve from 0.76651
Epoch 30/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7551 - accuracy: 0.6990 - val_loss: 0.7696 - val_accuracy: 0.6867

Epoch 00030: val_loss did not improve from 0.76651
Epoch 31/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7536 - accuracy: 0.7001 - val_loss: 0.7713 - val_accuracy: 0.6865

Epoch 00031: val_loss did not improve from 0.76651
Epoch 32/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7511 - accuracy: 0.7017 - val_loss: 0.7719 - val_accuracy: 0.6866

Epoch 00032: val_loss did not improve from 0.76651
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_8 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_26 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_8"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_8 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_8 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_24 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_24 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_25 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_25 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_26 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_26 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_24 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_8 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_24 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_25 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_25 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_26 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_8', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_8_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_8', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_8', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_24', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_24', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_25', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_25', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_26', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_26', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_24', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_8', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_24', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_25', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_25', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_26', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_26', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 524s 4ms/step - loss: 0.7702 - accuracy: 0.6858
Testing Loss = 0.770153, Testing Accuracy = 0.685843
The data set contains images
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 52s 68ms/step - loss: 3.5322 - accuracy: 0.5992 - val_loss: 1.1240 - val_accuracy: 0.6519

Epoch 00001: val_loss improved from inf to 1.12401, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 2/100
748/748 [==============================] - 52s 69ms/step - loss: 0.9414 - accuracy: 0.6488 - val_loss: 0.8422 - val_accuracy: 0.6592

Epoch 00002: val_loss improved from 1.12401 to 0.84216, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 3/100
748/748 [==============================] - 52s 70ms/step - loss: 0.8460 - accuracy: 0.6539 - val_loss: 0.8175 - val_accuracy: 0.6631

Epoch 00003: val_loss improved from 0.84216 to 0.81746, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 4/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8293 - accuracy: 0.6575 - val_loss: 0.8070 - val_accuracy: 0.6672

Epoch 00004: val_loss improved from 0.81746 to 0.80695, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 5/100
748/748 [==============================] - 51s 69ms/step - loss: 0.8204 - accuracy: 0.6615 - val_loss: 0.7986 - val_accuracy: 0.6714

Epoch 00005: val_loss improved from 0.80695 to 0.79860, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 6/100
748/748 [==============================] - 51s 69ms/step - loss: 0.8138 - accuracy: 0.6641 - val_loss: 0.7930 - val_accuracy: 0.6741

Epoch 00006: val_loss improved from 0.79860 to 0.79302, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 7/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8071 - accuracy: 0.6677 - val_loss: 0.7874 - val_accuracy: 0.6784

Epoch 00007: val_loss improved from 0.79302 to 0.78736, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 8/100
748/748 [==============================] - 51s 68ms/step - loss: 0.8021 - accuracy: 0.6705 - val_loss: 0.7872 - val_accuracy: 0.6776

Epoch 00008: val_loss improved from 0.78736 to 0.78719, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 9/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7976 - accuracy: 0.6730 - val_loss: 0.7799 - val_accuracy: 0.6819

Epoch 00009: val_loss improved from 0.78719 to 0.77987, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 10/100
748/748 [==============================] - 52s 69ms/step - loss: 0.7930 - accuracy: 0.6753 - val_loss: 0.7776 - val_accuracy: 0.6829

Epoch 00010: val_loss improved from 0.77987 to 0.77762, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 11/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7899 - accuracy: 0.6769 - val_loss: 0.7733 - val_accuracy: 0.6842

Epoch 00011: val_loss improved from 0.77762 to 0.77334, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 12/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7872 - accuracy: 0.6792 - val_loss: 0.7728 - val_accuracy: 0.6850

Epoch 00012: val_loss improved from 0.77334 to 0.77283, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 13/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7846 - accuracy: 0.6801 - val_loss: 0.7708 - val_accuracy: 0.6855

Epoch 00013: val_loss improved from 0.77283 to 0.77083, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 14/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7825 - accuracy: 0.6814 - val_loss: 0.7708 - val_accuracy: 0.6859

Epoch 00014: val_loss improved from 0.77083 to 0.77077, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 15/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7801 - accuracy: 0.6825 - val_loss: 0.7720 - val_accuracy: 0.6860

Epoch 00015: val_loss did not improve from 0.77077
Epoch 16/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7777 - accuracy: 0.6833 - val_loss: 0.7699 - val_accuracy: 0.6865

Epoch 00016: val_loss improved from 0.77077 to 0.76994, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 17/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7756 - accuracy: 0.6857 - val_loss: 0.7673 - val_accuracy: 0.6873

Epoch 00017: val_loss improved from 0.76994 to 0.76728, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 18/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7748 - accuracy: 0.6854 - val_loss: 0.7662 - val_accuracy: 0.6880

Epoch 00018: val_loss improved from 0.76728 to 0.76623, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 19/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7728 - accuracy: 0.6867 - val_loss: 0.7653 - val_accuracy: 0.6885

Epoch 00019: val_loss improved from 0.76623 to 0.76531, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 20/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7714 - accuracy: 0.6882 - val_loss: 0.7666 - val_accuracy: 0.6878

Epoch 00020: val_loss did not improve from 0.76531
Epoch 21/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7689 - accuracy: 0.6894 - val_loss: 0.7675 - val_accuracy: 0.6875

Epoch 00021: val_loss did not improve from 0.76531
Epoch 22/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7676 - accuracy: 0.6903 - val_loss: 0.7646 - val_accuracy: 0.6886

Epoch 00022: val_loss improved from 0.76531 to 0.76459, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/9
Epoch 23/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7657 - accuracy: 0.6913 - val_loss: 0.7656 - val_accuracy: 0.6889

Epoch 00023: val_loss did not improve from 0.76459
Epoch 24/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7638 - accuracy: 0.6930 - val_loss: 0.7649 - val_accuracy: 0.6891

Epoch 00024: val_loss did not improve from 0.76459
Epoch 25/100
748/748 [==============================] - 51s 69ms/step - loss: 0.7625 - accuracy: 0.6940 - val_loss: 0.7673 - val_accuracy: 0.6882

Epoch 00025: val_loss did not improve from 0.76459
Epoch 26/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7610 - accuracy: 0.6954 - val_loss: 0.7658 - val_accuracy: 0.6886

Epoch 00026: val_loss did not improve from 0.76459
Epoch 27/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7584 - accuracy: 0.6973 - val_loss: 0.7693 - val_accuracy: 0.6871

Epoch 00027: val_loss did not improve from 0.76459
Epoch 28/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7568 - accuracy: 0.6981 - val_loss: 0.7688 - val_accuracy: 0.6878

Epoch 00028: val_loss did not improve from 0.76459
Epoch 29/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7552 - accuracy: 0.6999 - val_loss: 0.7691 - val_accuracy: 0.6883

Epoch 00029: val_loss did not improve from 0.76459
Epoch 30/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7529 - accuracy: 0.7017 - val_loss: 0.7731 - val_accuracy: 0.6861

Epoch 00030: val_loss did not improve from 0.76459
Epoch 31/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7501 - accuracy: 0.7028 - val_loss: 0.7724 - val_accuracy: 0.6869

Epoch 00031: val_loss did not improve from 0.76459
Epoch 32/100
748/748 [==============================] - 51s 68ms/step - loss: 0.7475 - accuracy: 0.7053 - val_loss: 0.7729 - val_accuracy: 0.6866

Epoch 00032: val_loss did not improve from 0.76459
Epoch 00032: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential_9 (Sequential)    (None, 512)               12127912  [0m
[92m_________________________________________________________________[0m
[92mdense_29 (Dense)             multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 12,129,451[0m
[92mTrainable params: 12,129,447[0m
[92mNon-trainable params: 4[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential_9"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda_9 (Lambda)            (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_9 (Batch (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d_27 (Conv2D)           (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_27 (MaxPooling (None, 37, 37, 32)        0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_28 (Conv2D)           (None, 37, 37, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_28 (MaxPooling (None, 18, 18, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mconv2d_29 (Conv2D)           (None, 18, 18, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d_29 (MaxPooling (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mdropout_27 (Dropout)         (None, 9, 9, 256)         0         [0m
[94m_________________________________________________________________[0m
[94mflatten_9 (Flatten)          (None, 20736)             0         [0m
[94m_________________________________________________________________[0m
[94mdense_27 (Dense)             (None, 512)               10617344  [0m
[94m_________________________________________________________________[0m
[94mdropout_28 (Dropout)         (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_28 (Dense)             (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_29 (Dropout)         (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 12,127,912[0m
[94mTrainable params: 12,127,908[0m
[94mNon-trainable params: 4[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential_9', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_9_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda_9', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT4QAAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_9', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_27', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_27', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_28', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_28', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_29', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_29', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_27', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'noise_shape': None, 'seed': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_9', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_27', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_28', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_28', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_29', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_29', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 534s 4ms/step - loss: 0.7685 - accuracy: 0.6865
Testing Loss = 0.768462, Testing Accuracy = 0.686520
The data set contains images
N of classes 3
$W^+$ (auc = 85.56 +- 0.0228 %)
$W^-$ (auc = 85.53 +- 0.0255 %)
$Z$ (auc = 84.00 +- 0.0371 %)
The summarized testing accuracy = 68.66 +- 0.0737 %, with the loss = 0.7688 +- 0.000820


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
New Run
Current date and time = 2023-01-03 17:01:15.254466
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
The data set contains images
Number of training datasets: 383186.
Epoch 1/100
748/748 [==============================] - 660s 823ms/step - loss: 4.3917 - accuracy: 0.3475 - val_loss: 2.0221 - val_accuracy: 0.3637

Epoch 00001: val_loss improved from inf to 2.02210, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 2/100
748/748 [==============================] - 620s 828ms/step - loss: 1.6276 - accuracy: 0.3819 - val_loss: 1.3468 - val_accuracy: 0.4854

Epoch 00002: val_loss improved from 2.02210 to 1.34675, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 3/100
748/748 [==============================] - 608s 812ms/step - loss: 1.2214 - accuracy: 0.4749 - val_loss: 1.1330 - val_accuracy: 0.4685

Epoch 00003: val_loss improved from 1.34675 to 1.13296, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 4/100
748/748 [==============================] - 604s 807ms/step - loss: 1.0649 - accuracy: 0.4975 - val_loss: 1.0225 - val_accuracy: 0.5153

Epoch 00004: val_loss improved from 1.13296 to 1.02253, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 5/100
748/748 [==============================] - 603s 806ms/step - loss: 1.0033 - accuracy: 0.5049 - val_loss: 0.9972 - val_accuracy: 0.4949

Epoch 00005: val_loss improved from 1.02253 to 0.99718, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 6/100
748/748 [==============================] - 604s 808ms/step - loss: 0.9810 - accuracy: 0.5078 - val_loss: 1.0227 - val_accuracy: 0.4398

Epoch 00006: val_loss did not improve from 0.99718
Epoch 7/100
748/748 [==============================] - 601s 804ms/step - loss: 0.9715 - accuracy: 0.5094 - val_loss: 0.9927 - val_accuracy: 0.4777

Epoch 00007: val_loss improved from 0.99718 to 0.99266, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 8/100
748/748 [==============================] - 601s 803ms/step - loss: 0.9676 - accuracy: 0.5092 - val_loss: 0.9727 - val_accuracy: 0.4965

Epoch 00008: val_loss improved from 0.99266 to 0.97268, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 9/100
748/748 [==============================] - 600s 802ms/step - loss: 0.9646 - accuracy: 0.5108 - val_loss: 0.9608 - val_accuracy: 0.5065

Epoch 00009: val_loss improved from 0.97268 to 0.96080, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 10/100
748/748 [==============================] - 600s 802ms/step - loss: 0.9637 - accuracy: 0.5124 - val_loss: 1.0050 - val_accuracy: 0.4558

Epoch 00010: val_loss did not improve from 0.96080
Epoch 11/100
748/748 [==============================] - 599s 801ms/step - loss: 0.9620 - accuracy: 0.5130 - val_loss: 0.9960 - val_accuracy: 0.4674

Epoch 00011: val_loss did not improve from 0.96080
Epoch 12/100
748/748 [==============================] - 599s 800ms/step - loss: 0.9602 - accuracy: 0.5132 - val_loss: 0.9876 - val_accuracy: 0.4752

Epoch 00012: val_loss did not improve from 0.96080
Epoch 13/100
748/748 [==============================] - 598s 800ms/step - loss: 0.9602 - accuracy: 0.5134 - val_loss: 0.9826 - val_accuracy: 0.4806

Epoch 00013: val_loss did not improve from 0.96080
Epoch 14/100
748/748 [==============================] - 598s 799ms/step - loss: 0.9590 - accuracy: 0.5143 - val_loss: 0.9521 - val_accuracy: 0.5255

Epoch 00014: val_loss improved from 0.96080 to 0.95209, saving model to /home/samhuang/ML/best_model/best_model_ternary_CNN_kappa0.15/Try/0
Epoch 15/100
748/748 [==============================] - 597s 798ms/step - loss: 0.9572 - accuracy: 0.5150 - val_loss: 1.1186 - val_accuracy: 0.3703

Epoch 00015: val_loss did not improve from 0.95209
Epoch 16/100
748/748 [==============================] - 597s 798ms/step - loss: 0.9573 - accuracy: 0.5148 - val_loss: 0.9780 - val_accuracy: 0.4806

Epoch 00016: val_loss did not improve from 0.95209
Epoch 17/100
748/748 [==============================] - 597s 798ms/step - loss: 0.9556 - accuracy: 0.5159 - val_loss: 0.9590 - val_accuracy: 0.5051

Epoch 00017: val_loss did not improve from 0.95209
Epoch 18/100
748/748 [==============================] - 597s 798ms/step - loss: 0.9550 - accuracy: 0.5167 - val_loss: 0.9797 - val_accuracy: 0.4816

Epoch 00018: val_loss did not improve from 0.95209
Epoch 19/100
748/748 [==============================] - 596s 797ms/step - loss: 0.9540 - accuracy: 0.5173 - val_loss: 0.9943 - val_accuracy: 0.4627

Epoch 00019: val_loss did not improve from 0.95209
Epoch 20/100
748/748 [==============================] - 596s 797ms/step - loss: 0.9537 - accuracy: 0.5169 - val_loss: 0.9613 - val_accuracy: 0.5051

Epoch 00020: val_loss did not improve from 0.95209
Epoch 21/100
748/748 [==============================] - 596s 797ms/step - loss: 0.9524 - accuracy: 0.5177 - val_loss: 0.9952 - val_accuracy: 0.4580

Epoch 00021: val_loss did not improve from 0.95209
Epoch 22/100
748/748 [==============================] - 596s 797ms/step - loss: 0.9527 - accuracy: 0.5179 - val_loss: 1.0037 - val_accuracy: 0.4497

Epoch 00022: val_loss did not improve from 0.95209
Epoch 23/100
748/748 [==============================] - 596s 796ms/step - loss: 0.9523 - accuracy: 0.5187 - val_loss: 1.1165 - val_accuracy: 0.3698

Epoch 00023: val_loss did not improve from 0.95209
Epoch 24/100
748/748 [==============================] - 596s 796ms/step - loss: 0.9515 - accuracy: 0.5186 - val_loss: 0.9734 - val_accuracy: 0.4875

Epoch 00024: val_loss did not improve from 0.95209
Epoch 00024: early stopping
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
[92mModel: "CNN3"[0m
[92m_________________________________________________________________[0m
[92mLayer (type)                 Output Shape              Param #   [0m
[92m=================================================================[0m
[92msequential (Sequential)      (None, 512)               365106984 [0m
[92m_________________________________________________________________[0m
[92mdense_2 (Dense)              multiple                  1539      [0m
[92m=================================================================[0m
[92mTotal params: 365,108,523[0m
[92mTrainable params: 365,107,687[0m
[92mNon-trainable params: 836[0m
[92m_________________________________________________________________[0m
None

@LAYER1       @@@@@@@@@@@@@@@@@@@@@@
[94mModel: "sequential"[0m
[94m_________________________________________________________________[0m
[94mLayer (type)                 Output Shape              Param #   [0m
[94m=================================================================[0m
[94mlambda (Lambda)              (None, 75, 75, 2)         0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization (BatchNo (None, 75, 75, 2)         8         [0m
[94m_________________________________________________________________[0m
[94mconv2d (Conv2D)              (None, 75, 75, 32)        2336      [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_1 (Batch (None, 75, 75, 32)        128       [0m
[94m_________________________________________________________________[0m
[94mconv2d_1 (Conv2D)            (None, 75, 75, 128)       65664     [0m
[94m_________________________________________________________________[0m
[94mmax_pooling2d (MaxPooling2D) (None, 37, 37, 128)       0         [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_2 (Batch (None, 37, 37, 128)       512       [0m
[94m_________________________________________________________________[0m
[94mconv2d_2 (Conv2D)            (None, 37, 37, 256)       1179904   [0m
[94m_________________________________________________________________[0m
[94mbatch_normalization_3 (Batch (None, 37, 37, 256)       1024      [0m
[94m_________________________________________________________________[0m
[94mconv2d_3 (Conv2D)            (None, 37, 37, 512)       4719104   [0m
[94m_________________________________________________________________[0m
[94mflatten (Flatten)            (None, 700928)            0         [0m
[94m_________________________________________________________________[0m
[94mdense (Dense)                (None, 512)               358875648 [0m
[94m_________________________________________________________________[0m
[94mdropout (Dropout)            (None, 512)               0         [0m
[94m_________________________________________________________________[0m
[94mdense_1 (Dense)              (None, 512)               262656    [0m
[94m_________________________________________________________________[0m
[94mdropout_1 (Dropout)          (None, 512)               0         [0m
[94m=================================================================[0m
[94mTotal params: 365,106,984[0m
[94mTrainable params: 365,106,148[0m
[94mNon-trainable params: 836[0m
[94m_________________________________________________________________[0m
None
[92m%Optimizer:
[0m {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}
[92m%Layer detail:
[0m {'name': 'sequential', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 75, 75, 2), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'lambda_input'}}, {'class_name': 'Lambda', 'config': {'name': 'lambda', 'trainable': True, 'dtype': 'float32', 'function': ('4wEAAAAAAAAAAAAAAAEAAAAGAAAAUwAAAHMgAAAAfABkAGQAhQJkAGQAhQJkAGQAhQJkAGQAhQJm\nBBkAUwCpAU6pAKkB2gF4cgIAAAByAgAAAPofL2hvbWUvc2FtaHVhbmcvTUwvQ05OL21vZGVscy5w\nedoIPGxhbWJkYT52AAAA8wAAAAA=\n', None, None), 'function_type': 'lambda', 'module': 'models', 'output_shape': None, 'output_shape_type': 'raw', 'output_shape_module': None, 'arguments': {}}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (4, 4), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_2', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_3', 'trainable': True, 'dtype': 'float32', 'axis': ListWrapper([3]), 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_3', 'trainable': True, 'dtype': 'float32', 'filters': 512, 'kernel_size': (6, 6), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Flatten', 'config': {'name': 'flatten', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 0.009999999776482582}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.5, 'noise_shape': None, 'seed': None}}]}

@LAYER2       @@@@@@@@@@@@@@@@@@@@@@
[92m%Layer detail:
[0m {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}

****************************************************
history keys:
 dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
history params:
 {'verbose': 1, 'epochs': 100, 'steps': None}
****************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
The data set contains images
119746/119746 [==============================] - 1279s 11ms/step - loss: 0.9519 - accuracy: 0.5252
Testing Loss = 0.951859, Testing Accuracy = 0.525237
The data set contains images
N of classes 3
$W^+$ (auc = 64.59 +- 0.0000 %)
$W^-$ (auc = 68.58 +- 0.0000 %)
$Z$ (auc = 82.19 +- 0.0000 %)
N of classes 3
$W^+$ (acc = 0.00 +- 0.0000 %
$W^-$ (acc = 46.01 +- 0.0000 %
$Z$ (acc = 60.10 +- 0.0000 %
The summarized testing accuracy = 52.52 +- 0.0000 %, with the loss = 0.9519 +- 0.000000
